<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Java知识体系构建]]></title><description><![CDATA[Obsidian digital garden]]></description><link>http://github.com/dylang/node-rss</link><image><url>lib\media\favicon.png</url><title>Java知识体系构建</title><link></link></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Mon, 08 Apr 2024 14:02:22 GMT</lastBuildDate><atom:link href="lib\rss.xml" rel="self" type="application/rss+xml"/><pubDate>Mon, 08 Apr 2024 13:59:55 GMT</pubDate><copyright><![CDATA[kegh]]></copyright><ttl>60</ttl><dc:creator>kegh</dc:creator><item><title><![CDATA[01、计算机硬件]]></title><description><![CDATA[ 
 ]]></description><link>01、通用基础\01、计算机基础\01、计算机硬件.html</link><guid isPermaLink="false">01、通用基础/01、计算机基础/01、计算机硬件.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:45 GMT</pubDate></item><item><title><![CDATA[02、操作系统]]></title><description><![CDATA[ 
 <br><br>--Microsoft 公司推出的操作系统。（在 windows 之前的操作系统）<br>
--DOS 是英文"Disk Operating System"的缩写, 其中文含意是"磁盘操作系统".<br>
--DOS 是单用户、单任务的操作系统.（只能执行一个任务）<br>【2】DOS 命令<br>
--在 windows 中，我们通过鼠标菜单等来操作系统，而在 dos 操作系统中，要通过 dos 命令来操作系统。<br>
--是 DOS 操作系统的命令，是一种面向磁盘的操作命令，<br>
--不区分大小写。<br>
【3】命令学习：<br>
Windows 给我们保留了类似 dos 系统的操作界面，可以直接操作磁盘！<br>
Dos 也是一种操作系统，是在 windows 出现以前用的，后来 windows 出来后基本没人用了，但是当 windows 崩溃的时候，还是要的 dos 方式解决，它是一种纯命令方式，cmd 其实就是在 windows 状态下进入 dos 方式。<br>控制命令台：win+r---&gt;cmd<br>【4】具体 dos 命令：<br>
（1）切换盘符： c:  d:  e:   大小写没有区分<br>
（2）显示详细信息：dir<br>（3）改变当前目录：cd<br>（4）<br>
. 当前目录<br>
..  代表上一层目录<br>（5）清屏：cls<br>
（6）切换历史命令：上下箭头<br>
（7）补全命令： tab 按键<br>
（8）创建目录：md<br>
删除目录：rd<br>（9）复制文件命令：copy:<br>（10）删除文件：del<br>
Del 后面如果接的是文件夹/目录：那么删除的就是这个文件夹下的文件，而不是文件夹]]></description><link>01、通用基础\01、计算机基础\02、操作系统.html</link><guid isPermaLink="false">01、通用基础/01、计算机基础/02、操作系统.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:45 GMT</pubDate></item><item><title><![CDATA[03、通用概念]]></title><description><![CDATA[ 
 <br><br>比特、位 (bit)：计算机存储数据的最小单元 (0、1)<br>字节 (Byte)：处理数据的基本单位 (8 bit/Byte)<br><br><br><br>基数：R 进制的基数=R<br><br>
<br>原码： 最高位为符号位，0表示正数，1表示负数。
<br>反码： 负数的反码是对该数的原码除符号位外的各位取反。
<br>补码： 负数的补码是在其反码的基础上加1。
<br><br>原码就是符号位加上真值的绝对值, 即用第一位表示符号, 其余位表示值. 比如如果是 8 位二进制:<br>
[+1]原&nbsp;= 0000 0001
[-1]原&nbsp;= 1000 0001
<br>第一位是符号位. 因为第一位是符号位, 所以 8 位二进制数的取值范围就是:<br>
[1111 1111 , 0111 1111]
<br>即<br>
[-127 , 127]
<br>原码是人脑最容易理解和计算的表示方式。<br><br>正数的反码是其本身<br>负数的反码是在其原码的基础上，符号位不变，其余各个位取反。<br>
[+1] = [00000001]原&nbsp;= [00000001]反
[-1] = [10000001]原&nbsp;= [11111110]反
<br>可见如果一个反码表示的是负数，人脑无法直观的看出来它的数值.，通常要将其转换成原码再计算。<br><br>补码的表示方法是:<br>正数的补码就是其本身<br>负数的补码是在其原码的基础上, 符号位不变, 其余各位取反, 最后+1. (即在反码的基础上+1)<br>
[+1] = [00000001]原&nbsp;= [00000001]反&nbsp;= [00000001]补
[-1] = [10000001]原&nbsp;= [11111110]反&nbsp;= [11111111]补
<br>对于负数, 补码表示方式也是人脑无法直观看出其数值的. 通常也需要转换成原码在计算其数值.<br>进制的介绍：<br>
十进制整数，如：99, -500, 0<br>
八进制整数，要求以 0 开头，如：015<br>
十六进制数，要求 0 x 或 0 X 开头，如：0 x 15<br>
二进制：要求 0 b 或者 0 B 开头，如：0 b 11<br>几进制：就是逢几进 1 的问题：<br>平时实际生活中用的最多的是：十进制<br>
计算机用二进制最多 <br>【2】二进制转换为十进制：<br>
二进制： 1101<br>1*2^3  +   1*2^2   +  0*2^1  +     1*2^0
复制<br>=    8         +      4       +     0       +      1<br>
=  13 <br>【3】十进制转换为二进制：<br>
十进制  13   <br>【4】八进制转换十进制：<br>
八进制： 16<br>18^1 +   68^0<br>
=   8     +  6<br>
=14<br>【5】十进制转换为八进制：<br>
十进制 14：<br>【6】八进制转换为十六进制：<br>把十进制当做一个中转站：<br>八进制---》十进制---》十六进制<br>实际上根本不用自己转换这么麻烦：我们可以直接用系统中提供给我们的计算器：<br><br>UTF-8 和 Unicode 有何区别？<br>Unicode 与 ASCII 类似，都是一种字符集。<br>字符集为每个字符分配一个唯一的 ID，我们使用到的所有字符在 Unicode 字符集中都有一个唯一的 ID，例如 a 在 Unicode 与 ASCII 中的编码都是 97。汉字“你”在 Unicode 中的编码为 20320，在不同国家的字符集中，字符所对应的 ID 也会不同。而无论任何情况下，Unicode 中的字符的 ID 都是不会变化的。<br>UTF-8 是编码规则，将 Unicode 中字符的 ID 以某种方式进行编码，UTF-8 的是一种变长编码规则，从 1 到 4 个字节不等。编码规则如下：<br>
<br>0 xxxxxx 表示文字符号 0～127，兼容 ASCII 字符集。
<br>从 128 到 0 x 10 ffff 表示其他字符。
<br>根据这个规则，拉丁文语系的字符编码一般情况下每个字符占用一个字节，而中文每个字符占用 3 个字节。<br>广义的 Unicode 指的是一个标准，它定义了字符集及编码规则，即 Unicode 字符集和 UTF-8、UTF-16 编码等。]]></description><link>01、通用基础\01、计算机基础\03、通用概念.html</link><guid isPermaLink="false">01、通用基础/01、计算机基础/03、通用概念.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:45 GMT</pubDate></item><item><title><![CDATA[Linux常见命令]]></title><description><![CDATA[ 
 ]]></description><link>01、通用基础\01、计算机基础\linux常见命令.html</link><guid isPermaLink="false">01、通用基础/01、计算机基础/Linux常见命令.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Fri, 15 Mar 2024 12:17:41 GMT</pubDate></item><item><title><![CDATA[Linux日志查询详解]]></title><description><![CDATA[ 
 ]]></description><link>01、通用基础\01、计算机基础\linux日志查询详解.html</link><guid isPermaLink="false">01、通用基础/01、计算机基础/Linux日志查询详解.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Fri, 15 Mar 2024 12:17:49 GMT</pubDate></item><item><title><![CDATA[01、计算机网络基础部分梳理]]></title><description><![CDATA[ 
 ]]></description><link>01、通用基础\02、计算机网络\01、计算机网络基础部分梳理.html</link><guid isPermaLink="false">01、通用基础/02、计算机网络/01、计算机网络基础部分梳理.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:45 GMT</pubDate></item><item><title><![CDATA[02、工具-网络抓包神器 tcpdump 使用详解]]></title><description><![CDATA[ 
 ]]></description><link>01、通用基础\02、计算机网络\02、工具-网络抓包神器-tcpdump-使用详解.html</link><guid isPermaLink="false">01、通用基础/02、计算机网络/02、工具-网络抓包神器 tcpdump 使用详解.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:43 GMT</pubDate></item><item><title><![CDATA[03、七层网络协议]]></title><description><![CDATA[ 
 <br><br>首先要全局上理解 7层协议，4层，5层 的对应关系。<br>书本上：<br>
<img src="\01、通用基础\02、计算机网络\assets\03、七层网络协议\img-20240304_194139.png"><br>方便理解：<br>
<img src="\01、通用基础\02、计算机网络\assets\03、七层网络协议\img-20240304_212633.png"><br><br>国际标准化组织 ISO 于1984年提出了 OSI（Open System Interconnection Reference Model，开放系统互联参考模型）<br>OSI 依层次结构来划分：<br>
<br>应用层（Application）
<br>表示层（Presentation）
<br>会话层（Session）
<br>传输层（Transport）
<br>网络层（Network）
<br>数据链路层（Data Link）
<br>物理层（Physical）
<br>OSI七层参考模型的各个层次的划分遵循下列原则：<br>
<br>同一层中的各网络节点都有相同的层次结构，具有同样的功能。
<br>同一节点内相邻层之间通过接口(可以是逻辑接口)进行通信。
<br>七层结构中的每一层使用下一层提供的服务，并且向其上层提供服务。
<br>不同节点的同等层按照协议实现对等层之间的通信。
<br><br>主要功能：<br>
利用传输介质为数据链路层提供物理连接（物理连接可以是光缆、电缆、双绞线、无线电波），实现比特流的透明传输。传的是信号，即 010101... 这些二进制位。数据的单位称为比特 (bit)。<br><br>在计算机网络中由于各种干扰的存在，导致物理链路是不可靠的。<br>主要功能：负责建立和管理节点间的链路。<br>
在物理层提供的比特流的基础上，通过差错控制、流量控制方法，使有差错的物理线路变为无差错的数据链路，即提供可靠的通过物理介质传输数据的方法。“帧”。<br><br>在数据链路层提供的两个相邻端点之间的数据帧的传送功能上，进一步管理网络中的数据通信，控制数据链路层与传输层之间的信息转发，建立、维持和终止网络的连接，将数据设法从源端经过若干个中间节点传送到目的端（点到点），从而向传输层提供最基本的端到端的数据传输服务。具体地说，数据链路层的数据在这一层被转换为数据包，然后通过路径选择、分段组合、顺序、进/出路由等控制，将信息从一个网络设备传送到另一个网络设备。数据链路层和网络层的区别为：数据链路层的目的是解决同一网络内节点之间的通信，而网络层主要解决不同子网间的通信。<br>网络层定义了一个 IP 协议。<br><br>OSI 下 3 层的任务是数据通信，上 3 层的任务是数据处理。<br>主要功能是：向用户提供可靠的端到端的差错和流量控制，保证报文的正确传输，同时向高层屏蔽下层数据通信的细节，即向用户透明地传送报文。<br>数据单元也称作数据包 (packets)。但是，当谈论 TCP 等具体的协议时又有特殊的叫法，TCP 的数据单元称为段 (segments)而 UDP 协议的数据单元称为“数据报 (datagrams)”。<br>传输层协议的代表包括：TCP、UDP 等。<br><br>如服务器验证用户登录便是由会话层完成的。<br>会话层是OSI模型的第5层，是用户应用程序和网络之间的接口，该层的主要功能是：组织和协调两个会话进程之间的通信  ，并对数据交换进行管理。当建立会话时，用户必须提供他们想要连接的远程地址。而这些地址与MAC地址或网络层的逻辑地址不同，它们是为用户专门设计的，更便于用户记忆。域名就是一种网络上使用的远程地址。会话层的具体功能如下：<br>
<br>会话管理：允许用户在两个实体设备之间建立、维持和终止会话，并支持它们之间的数据交换。
<br>会话流量控制：提供会话流量控制和交叉会话功能。
<br>寻址：使用远程地址建立会话连接。
<br>出错控制：从逻辑上讲会话层主要负责数据交换的建立、保持和终止，但实际的工作却是接收来自传输层的数据，并负责纠正错误。
<br><br>表示层是OSI模型的第六层，它对来自应用层的命令和数据进行解释，对各种语法赋予相应的含义，并按照一定的格式传送给会话层。该层的主要功能是：处理用户信息的表示问题，如编码、数据格式转换和加密解密等。表示层的具体功能如下：<br>
<br>数据格式处理：协商和建立数据交换的格式，解决各应用程序之间在数据格式表示上的差异。
<br>数据的编码：处理字符集和数字的转换。
<br>压缩和解压缩：为了减少数据的传输量，这一层还负责数据的压缩与恢复。
<br>数据的加密和解密：可以提高网络的安全性。
<br><br>应用层是 OSI 参考模型的最高层，它是计算机用户，以及各种应用程序和网络之间的接口，该层的主要功能是：直接向用户提供服务，完成用户希望在网络上完成的各种工作。它在其他 6 层工作的基础上，负责完成网络中应用程序与网络操作系统之间的联系，建立与结束使用者之间的联系，并完成网络用户提出的各种网络服务及应用所需的监督、管理和服务等各种协议。此外该层还负责协调各个应用程序间的工作。应用层的具体功能如下：<br>用户接口：应用层是用户与网络，以及应用程序与网络间的直接接口，使得用户能够与网络进行交互式联系。<br>
实现各种服务：该层具有的各种应用程序可以完成和实现用户请求的各种服务。<br>应用层协议的代表包括：Telnet、FTP、HTTP 等。<br><br>四层是指 TCP/IP 四层模型，<br>
主要包括：<br>
<br>应用层
<br>运输层
<br>网络层
<br>网络接口层
<br><br>五层体系结构包括：<br>
<br>应用层
<br>运输层
<br>网络层
<br>数据链路层
<br>物理层
<br>五层协议只是 OSI 和 TCP/IP 的综合，实际应用还是 TCP/IP 的四层结构。<br>
为了方便可以把下两层称为网络接口层。<br><br>1、应用层：<br>
产生网络流量的程序<br>
2、表示层：<br>
传输之前是否进行加密或者压缩处理<br>
3、会话层：<br>
可靠传输、流量控制、不可靠传输<br>
4、传输层：<br>
5、网络层：<br>
6、数据链路层：<br>
7、物理层：<br><br><img src="\01、通用基础\02、计算机网络\assets\03、七层网络协议\img-20240304_201000.png"><br><img src="\01、通用基础\02、计算机网络\assets\03、七层网络协议\img-20240304_210221.png"><br><br>数据在各层之间的传递过程<br>结合层次所在的协议理解<br>图引用自《图解HTTP》。下图就是这四层协议在数据传输过程中的工作方式，在发送端是应用层--&gt;链路层这个方向的封包过程，每经过一层都会增加该层的头部。而接收端则是从链路层--&gt;应用层解包的过程，每经过一层则会去掉相应的首部。<br><img src="\01、通用基础\02、计算机网络\assets\03、七层网络协议\img-20240304_212820.png"><br><br>OSI 七层模型通过七个层次化的结构模型使不同的系统不同的网络之间实现可靠的通讯，因此其最主要的功能就是帮助不同类型的主机实现数据传输 。完成中继功能的节点通常称为中继系统。一个设备工作在哪一层，关键看它工作时利用哪一层的数据头部信息。网桥工作时，是以MAC头部来决定转发端口的，因此显然它是数据链路层的设备。具体说:<br>
<br>物理层：网卡，网线，集线器，中继器，调制解调器
<br>数据链路层：网桥，交换机
<br>网络层：路由器
<br>网关工作在第四层传输层及其以上 　　 集线器是物理层设备,采用广播的形式来传输信息。
<br>交换机就是用来进行报文交换的机器。多为链路层设备(二层交换机)，能够进行地址学习，采用存储转发的形式来交换报文。<br>路由器的一个作用是连通不同的网络，另一个作用是选择信息传送的线路。选择通畅快捷的近路，能大大提高通信速度，减轻网络系统通信负荷，节约网络系统资源，提高网络系统畅通率。<br><br>交换机拥有一条很高带宽的内部总线和内部交换矩阵。交换机的所有的端口都挂接在这条总线上，控制电路收到数据包以后，处理端口会查找内存中的地址对照表以确定目的MAC（网卡的硬件地址）的NIC（网卡）挂接在哪个端口上，通过内部交换矩阵迅速将数据包传送到目的端口，目的MAC若不存在则广播到所有的端口，接收端口回应后交换机会“学习”新的地址，并把它添加入内部MAC地址表中。 使用交换机也可以把网络“分段”，通过对照MAC地址表，交换机只允许必要的网络流量通过交换机。通过交换机的过滤和转发，可以有效的隔离广播风暴，减少误包和错包的出现，避免共享冲突。 交换机在同一时刻可进行多个端口对之间的数据传输。每一端口都可视为独立的网段，连接在其上的网络设备独自享有全部的带宽，无须同其他设备竞争使用。当节点A向节点D发送数据时，节点B可同时向节点C发送数据，而且这两个传输都享有网络的全部带宽，都有着自己的虚拟连接。总之，交换机是一种基于MAC地址识别，能完成封装转发数据包功能的网络设备。交换机可以"学习"MAC地址，并把其存放在内部地址表中，通过在数据帧的始发者和目标接收者之间建立临时的交换路径，使数据帧直接由源地址到达目的地址。<br><br>集线器的英文称为“Hub”。集线器的主要功能是对接收到的信号进行再生整形放大，以扩大网络的传输距离，同时把所有节点集中在以它为中心的节点上。它 工作于OSI(开放系统互联参考模型)参考模型第一层，即“物理层”。集线器与网卡、网线等传输介质一样，属于局域网中的基础设备，采用 CSMA/CD（即带冲突检测的载波监听多路访问技术)介质访问控制机制。集线器每个接口简单的收发比特，收到1就转发1，收到0就转发0，不进行碰撞检 测。集线器属于纯硬件网络底层设备，基本上不具有类似于交换机的"智能记忆"能力和"学习"能力。它也不具备交换机所具有的MAC地址表，所以它发送数据 时都是没有针对性的，而是采用广播方式发送。也就是说当它要向某节点发送数据时，不是直接把数据发送到目的节点，而是把数据包发送到与集线器相连的所有节点。HUB是一个多端口的转发器，当以HUB为中心设备时，网络中某条线路产生了故障，并不影响其它线路的工作。所以HUB在局域网中得到了广泛的应用。 大多数的时候它用在星型与树型网络拓扑结构中。<br><br>路由器从功能上可以划分为：路由选择和分组转发。<br><br>分组转发结构由三个部分组成：交换结构、一组输入端口和一组输出端口。<br>“/images/develop/network/dev-network-protocol-13.jpeg” could not be found.<br>路由器分组转发流程<br>
<br>从数据报的首部提取目的主机的 IP 地址 D，得到目的网络地址 N。
<br>若 N 就是与此路由器直接相连的某个网络地址，则进行直接交付；
<br>若路由表中有目的地址为 D 的特定主机路由，则把数据报传送给表中所指明的下一跳路由器；
<br>若路由表中有到达网络 N 的路由，则把数据报传送给路由表中所指明的下一跳路由器；
<br>若路由表中有一个默认路由，则把数据报传送给路由表中所指明的默认路由器；
<br>报告转发分组出错。
<br>“/images/develop/network/dev-network-protocol-14.jpeg” could not be found.<br><br>路由选择协议都是自适应的，能随着网络通信量和拓扑结构的变化而自适应地进行调整。<br>互联网可以划分为许多较小的自治系统 AS，一个 AS 可以使用一种和别的 AS 不同的路由选择协议。<br>可以把路由选择协议划分为两大类：<br>
<br>自治系统内部的路由选择：RIP 和 OSPF
<br>自治系统间的路由选择：BGP
<br><br>RIP 是一种基于距离向量的路由选择协议。距离是指跳数，直接相连的路由器跳数为 1。跳数最多为 15，超过 15 表示不可达。<br>RIP 按固定的时间间隔仅和相邻路由器交换自己的路由表，经过若干次交换之后，所有路由器最终会知道到达本自治系统中任何一个网络的最短距离和下一跳路由器地址。<br>距离向量算法：<br>
<br>对地址为 X 的相邻路由器发来的 RIP 报文，先修改报文中的所有项目，把下一跳字段中的地址改为 X，并把所有的距离字段加 1；
<br>对修改后的 RIP 报文中的每一个项目，进行以下步骤：
<br>若原来的路由表中没有目的网络 N，则把该项目添加到路由表中；
<br>否则：若下一跳路由器地址是 X，则把收到的项目替换原来路由表中的项目；否则：若收到的项目中的距离 d 小于路由表中的距离，则进行更新（例如原始路由表项为 Net2, 5, P，新表项为 Net2, 4, X，则更新）；否则什么也不做。
<br>若 3 分钟还没有收到相邻路由器的更新路由表，则把该相邻路由器标为不可达，即把距离置为 16。
<br>RIP 协议实现简单，开销小。但是 RIP 能使用的最大距离为 15，限制了网络的规模。并且当网络出现故障时，要经过比较长的时间才能将此消息传送到所有路由器。<br><br>开放最短路径优先 OSPF，是为了克服 RIP 的缺点而开发出来的。<br>开放表示 OSPF 不受某一家厂商控制，而是公开发表的；最短路径优先表示使用了 Dijkstra 提出的最短路径算法 SPF。<br>OSPF 具有以下特点：<br>
<br>向本自治系统中的所有路由器发送信息，这种方法是洪泛法。
<br>发送的信息就是与相邻路由器的链路状态，链路状态包括与哪些路由器相连以及链路的度量，度量用费用、距离、时延、带宽等来表示。
<br>只有当链路状态发生变化时，路由器才会发送信息。
<br>所有路由器都具有全网的拓扑结构图，并且是一致的。相比于 RIP，OSPF 的更新过程收敛的很快。
<br><br>BGP（Border Gateway Protocol，边界网关协议）<br>AS 之间的路由选择很困难，主要是由于：<br>
<br>互联网规模很大；
<br>各个 AS 内部使用不同的路由选择协议，无法准确定义路径的度量；
<br>AS 之间的路由选择必须考虑有关的策略，比如有些 AS 不愿意让其它 AS 经过。
<br>BGP 只能寻找一条比较好的路由，而不是最佳路由。
<br>每个 AS 都必须配置 BGP 发言人，通过在两个相邻 BGP 发言人之间建立 TCP 连接来交换路由信息。<br>“/images/develop/network/dev-network-protocol-15.png” could not be found.<br><br>首先说HUB,也就是集线器。它的作用可以简单的理解为将一些机器连接起来组成一个局域网。而交换机（又名交换式集线器）作用与集线器大体相同。但是两者在性能上有区别：集线器采用的式共享带宽的工作方式，而交换机是独享带宽。这样在机器很多或数据量很大时，两者将会有比较明显的。<br>
<br>工作位置不同 ：集线器工作在物理层，而交换机工作在数据链路层。
<br>工作方式不同 ： 集线器是一种广播方式，当集线器的某个端口工作时其他端口都能收听到信息。交换机工作时端口互不影响。
<br>带宽不同 ：集线器是所有端口共享一条带宽，在同一时刻只能有两个端口传输数据；而交换机每个端口独占一条带宽。
<br>性能不同 ：交换机以MAC地址进行寻址，有一定额外的寻址开销；集线器以广播方式传输数据，流量小时性能下降不明显，适用于共享总线的局域网。
<br><br>总的来说，路由器与交换机的主要区别体现在以下几个方面：<br>
<br>工作层次不同。最初的的交换机是工作在数据链路层，而路由器一开始就设计工作在网络层。由于交换机工作在数据链路层，所以它的工作原理比较简单，而路由器工作在网络层，可以得到更多的协议信息，路由器可以做出更加智能的转发决策。<br>

<br>数据转发所依据的对象不同。交换机是利用物理地址或者说MAC地址来确定转发数据的目的地址。而路由器则是利用IP地址来确定数据转发的地址。IP地址是在软件中实现的，描述的是设备所在的网络。MAC地址通常是硬件自带的，由网卡生产商来分配的，而且已经固化到了网卡中去，一般来说是不可更改的。而IP地址则通常由网络管理员或系统自动分配。<br>

<br>传统的交换机只能分割冲突域，不能分割广播域；而路由器可以分割广播域。由交换机连接的网段仍属于同一个广播域，广播数据包会在交换机连接的所有网段上传播，在某些情况下会导致通信拥挤和安全漏洞。连接到路由器上的网段会被分配成不同的广播域，广播数据不会穿过路由器。虽然第三层以上交换机具有VLAN功能，也可以分割广播域，但是各子广播域之间是不能通信交流的，它们之间的交流仍然需要路由器。<br>

<br>交换机负责同一个网段的通信，而路由器负责不同网段的通信。路由器提供了防火墙的服务。路由器仅仅转发特定地址的数据包，不传送不支持路由协议的数据包传送和未知目标网络数据包的传送，从而可以防止广播风暴。<br>

<br><br>路由表是指路由器或者其他互联网网络设备上存储的一张路由信息表，该表中存有到达特定网络终端的路径，在某些情况下，还有一些与这些路径相关的度量。路由器的主要工作就是为经过路由器的每个数据包寻找一条最佳的传输路径，并将该数据有效地传送到目的站点。由此可见，选择最佳路径的策略即路由算法是路由器的关键所在。为了完成这项工作，在路由器中保存着各种传输路径的相关数据——路由表（Routing Table），供路由选择时使用，表中包含的信息决定了数据转发的策略。路由表可以是由系统管理员固定设置好的，也可以由系统动态修改，可以由路由器自动调整，也可以由主机控制。<br>
<br>静态路由表：由系统管理员事先设置好固定的路由表称之为静态（static）路由表，一般是在系统安装时就根据网络的配置情况预先设定的，它不会随未来网络结构的改变而改变。<br>

<br>动态路由表：动态（Dynamic）路由表是路由器根据网络系统的运行情况而自动调整的路由表。路由器根据路由选择协议（Routing Protocol）提供的功能，自动学习和记忆网络运行情况，在需要时自动计算数据传输的最佳路径。<br>

<br>路由器通常依靠所建立及维护的路由表来决定如何转发。路由表能力是指路由表内所容纳路由表项数量的极限。路由表中的表项内容包括：<br>
<br>destination mask pre costdestination：目的地址，用来标识IP包的目的地址或者目的网络。
<br>mask：网络掩码，与目的地址一起标识目的主机或者路由器所在的网段的地址。
<br>pre：标识路由加入IP路由表的优先级。可能到达一个目的地有多条路由，但是优先级的存在让他们先选择优先级高的路由进行利用。
<br>cost：路由开销，当到达一个目的地的多个路由优先级相同时，路由开销最小的将成为最优路由。
<br>interface：输出接口，说明IP包将从该路由器哪个接口转发。 nexthop：下一跳IP地址，说明IP包所经过的下一个路由器。[1]
<br><br>网络 7 层的理论和理解：<br>
<a rel="noopener" class="external-link" href="https://blog.csdn.net/qq_36756682/article/details/104112765?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-104112765-blog-81352985.235%5Ev43%5Epc_blog_bottom_relevance_base4&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-104112765-blog-81352985.235%5Ev43%5Epc_blog_bottom_relevance_base4&amp;utm_relevant_index=2" target="_blank">https://blog.csdn.net/qq_36756682/article/details/104112765?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-104112765-blog-81352985.235%5Ev43%5Epc_blog_bottom_relevance_base4&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-104112765-blog-81352985.235%5Ev43%5Epc_blog_bottom_relevance_base4&amp;utm_relevant_index=2</a>]]></description><link>01、通用基础\02、计算机网络\03、七层网络协议.html</link><guid isPermaLink="false">01、通用基础/02、计算机网络/03、七层网络协议.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Fri, 05 Apr 2024 09:28:28 GMT</pubDate><enclosure url="01、通用基础\02、计算机网络\assets\03、七层网络协议\img-20240304_194139.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;01、通用基础\02、计算机网络\assets\03、七层网络协议\img-20240304_194139.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[04、网络协议 - IP 相关协议详解]]></title><description><![CDATA[ 
 ]]></description><link>01、通用基础\02、计算机网络\04、网络协议-ip-相关协议详解.html</link><guid isPermaLink="false">01、通用基础/02、计算机网络/04、网络协议 - IP 相关协议详解.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:44 GMT</pubDate></item><item><title><![CDATA[05、网络协议 - TCP 协议详解]]></title><description><![CDATA[ 
 ]]></description><link>01、通用基础\02、计算机网络\05、网络协议-tcp-协议详解.html</link><guid isPermaLink="false">01、通用基础/02、计算机网络/05、网络协议 - TCP 协议详解.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:45 GMT</pubDate></item><item><title><![CDATA[06、网络协议 - UDP 协议详解]]></title><description><![CDATA[ 
 ]]></description><link>01、通用基础\02、计算机网络\06、网络协议-udp-协议详解.html</link><guid isPermaLink="false">01、通用基础/02、计算机网络/06、网络协议 - UDP 协议详解.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:45 GMT</pubDate></item><item><title><![CDATA[07、网络协议 - HTTP 协议详解]]></title><description><![CDATA[ 
 <br><br><br>URI 包含 URL 和 URN，目前 WEB 只有 URL 比较流行，所以见到的基本都是 URL。<br>
<br>URI(Uniform Resource Identifier，统一资源标识符)
<br>URL(Uniform Resource Locator，统一资源定位符)
<br>URN(Uniform Resource Name，统一资源名称)
<br><img src="\01、通用基础\02、计算机网络\assets\07、网络协议-http-协议详解\img-20240304_215954.png"><br><br><br>“/images/pics/HTTP_RequestMessageExample.png” could not be found.<br><br>“/images/pics/HTTP_ResponseMessageExample.png” could not be found.<br><br>客户端发送的 请求报文 第一行为请求行，包含了方法字段。<br><br>
获取资源
<br>当前网络请求中，绝大部分使用的是 GET 方法。<br><br>
获取报文首部
<br>和 GET 方法一样，但是不返回报文实体主体部分。<br>主要用于确认 URL 的有效性以及资源更新的日期时间等。<br><br>
传输实体主体
<br>POST 主要用来传输数据，而 GET 主要用来获取资源。<br>更多 POST 与 GET 的比较请见第八章。<br><br>
上传文件
<br>由于自身不带验证机制，任何人都可以上传文件，因此存在安全性问题，一般不使用该方法。<br>PUT /new.html HTTP/1.1
Host: example.com
Content-type: text/html
Content-length: 16

&lt;p&gt;New File&lt;/p&gt;
复制<br><br>
对资源进行部分修改
<br>PUT 也可以用于修改资源，但是只能完全替代原始资源，PATCH 允许部分修改。<br>PATCH /file.txt HTTP/1.1
Host: www.example.com
Content-Type: application/example
If-Match: "e0023aa4e"
Content-Length: 100

[description of changes]
复制<br><br>
删除文件
<br>与 PUT 功能相反，并且同样不带验证机制。<br>DELETE /file.html HTTP/1.1
复制<br><br>
查询支持的方法
<br>查询指定的 URL 能够支持的方法。<br>会返回 Allow: GET, POST, HEAD, OPTIONS 这样的内容。<br><br>
要求在与代理服务器通信时建立隧道
<br>使用 SSL(Secure Sockets Layer，安全套接层)和 TLS(Transport Layer Security，传输层安全)协议把通信内容加密后经网络隧道传输。<br>CONNECT www.example.com:443 HTTP/1.1
复制<br>“/images/pics/dc00f70e-c5c8-4d20-baf1-2d70014a97e3.jpg” could not be found.<br><br>
追踪路径
<br>服务器会将通信路径返回给客户端。<br>发送请求时，在 Max-Forwards 首部字段中填入数值，每经过一个服务器就会减 1，当数值为 0 时就停止传输。<br>通常不会使用 TRACE，并且它容易受到 XST 攻击(Cross-Site Tracing，跨站追踪)。<br><br>服务器返回的 响应报文 中第一行为状态行，包含了状态码以及原因短语，用来告知客户端请求的结果。<br><br><br>
<br>100 Continue : 表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应。
<br><br>
<br>200 OK<br>

<br>204 No Content : 请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，而不需要返回数据时使用。<br>

<br>206 Partial Content : 表示客户端进行了范围请求，响应报文包含由 Content-Range 指定范围的实体内容。<br>

<br><br>
<br>301 Moved Permanently : 永久性重定向<br>

<br>302 Found : 临时性重定向<br>

<br>303 See Other : 和 302 有着相同的功能，但是 303 明确要求客户端应该采用 GET 方法获取资源。<br>

<br>注: 虽然 HTTP 协议规定 301、302 状态下重定向时不允许把 POST 方法改成 GET 方法，但是大多数浏览器都会在 301、302 和 303 状态下的重定向把 POST 方法改成 GET 方法。<br>

<br>304 Not Modified : 如果请求报文首部包含一些条件，例如: If-Match，If-Modified-Since，If-None-Match，If-Range，If-Unmodified-Since，如果不满足条件，则服务器会返回 304 状态码。<br>

<br>307 Temporary Redirect : 临时重定向，与 302 的含义类似，但是 307 要求浏览器不会把重定向请求的 POST 方法改成 GET 方法。<br>

<br><br>
<br>400 Bad Request : 请求报文中存在语法错误。<br>

<br>401 Unauthorized : 该状态码表示发送的请求需要有认证信息(BASIC 认证、DIGEST 认证)。如果之前已进行过一次请求，则表示用户认证失败。<br>

<br>403 Forbidden : 请求被拒绝。<br>

<br>404 Not Found<br>

<br><br>
<br>500 Internal Server Error : 服务器正在执行请求时发生错误。<br>

<br>503 Service Unavailable : 服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。<br>

<br><br>有 4 种类型的首部字段: 通用首部字段、请求首部字段、响应首部字段和实体首部字段。<br>各种首部字段及其含义如下(不需要全记，仅供查阅):<br><br><br><br><br><br><br><br><br><br><br>HTTP 协议是无状态的，主要是为了让 HTTP 协议尽可能简单，使得它能够处理大量事务。HTTP/1.1 引入 Cookie 来保存状态信息。<br>Cookie 是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器之后向同一服务器再次发起请求时被携带上，用于告知服务端两个请求是否来自同一浏览器。由于之后每次请求都会需要携带 Cookie 数据，因此会带来额外的性能开销(尤其是在移动环境下)。<br>Cookie 曾一度用于客户端数据的存储，因为当时并没有其它合适的存储办法而作为唯一的存储手段，但现在随着现代浏览器开始支持各种各样的存储方式，Cookie 渐渐被淘汰。新的浏览器 API 已经允许开发者直接将数据存储到本地，如使用 Web storage API (本地存储和会话存储)或 IndexedDB。<br><br>
<br>会话状态管理(如用户登录状态、购物车、游戏分数或其它需要记录的信息)
<br>个性化设置(如用户自定义设置、主题等)
<br>浏览器行为跟踪(如跟踪分析用户行为等)
<br><br>服务器发送的响应报文包含 Set-Cookie 首部字段，客户端得到响应报文后把 Cookie 内容保存到浏览器中。<br>HTTP/1.0 200 OK
Content-type: text/html
Set-Cookie: yummy_cookie=choco
Set-Cookie: tasty_cookie=strawberry

[page content]
复制<br>客户端之后对同一个服务器发送请求时，会从浏览器中取出 Cookie 信息并通过 Cookie 请求首部字段发送给服务器。<br>GET /sample_page.html HTTP/1.1
Host: www.example.org
Cookie: yummy_cookie=choco; tasty_cookie=strawberry
复制<br><br>
<br>会话期 Cookie: 浏览器关闭之后它会被自动删除，也就是说它仅在会话期内有效。
<br>持久性 Cookie: 指定一个特定的过期时间(Expires)或有效期(max-age)之后就成为了持久性的 Cookie。
<br>Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT;
复制<br><br>通过 Document.cookie 属性可创建新的 Cookie，也可通过该属性访问非 HttpOnly 标记的 Cookie。<br>document.cookie = "yummy_cookie=choco";
document.cookie = "tasty_cookie=strawberry";
console.log(document.cookie);
复制<br><br>标记为 Secure 的 Cookie 只能通过被 HTTPS 协议加密过的请求发送给服务端。但即便设置了 Secure 标记，敏感信息也不应该通过 Cookie 传输，因为 Cookie 有其固有的不安全性，Secure 标记也无法提供确实的安全保障。<br>标记为 HttpOnly 的 Cookie 不能被 JavaScript 脚本调用。跨站脚本攻击 (XSS) 常常使用 JavaScript 的 Document.cookie API 窃取用户的 Cookie 信息，因此使用 HttpOnly 标记可以在一定程度上避免 XSS 攻击。<br>Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; Secure; HttpOnly
复制<br><br>Domain 标识指定了哪些主机可以接受 Cookie。如果不指定，默认为当前文档的主机(不包含子域名)。如果指定了 Domain，则一般包含子域名。例如，如果设置 Domain=mozilla.org，则 Cookie 也包含在子域名中(如 developer.mozilla.org)。<br>Path 标识指定了主机下的哪些路径可以接受 Cookie(该 URL 路径必须存在于请求 URL 中)。以字符 %x2F ("/") 作为路径分隔符，子路径也会被匹配。例如，设置 Path=/docs，则以下地址都会匹配:<br>
<br>/docs
<br>/docs/Web/
<br>/docs/Web/HTTP
<br><br>除了可以将用户信息通过 Cookie 存储在用户浏览器中，也可以利用 Session 存储在服务器端，存储在服务器端的信息更加安全。<br>Session 可以存储在服务器上的文件、数据库或者内存中。也可以将 Session 存储在 Redis 这种内存型数据库中，效率会更高。<br>使用 Session 维护用户登录状态的过程如下:<br>
<br>用户进行登录时，用户提交包含用户名和密码的表单，放入 HTTP 请求报文中；
<br>服务器验证该用户名和密码；
<br>如果正确则把用户信息存储到 Redis 中，它在 Redis 中的 Key 称为 Session ID；
<br>服务器返回的响应报文的 Set-Cookie 首部字段包含了这个 Session ID，客户端收到响应报文之后将该 Cookie 值存入浏览器中；
<br>客户端之后对同一个服务器进行请求时会包含该 Cookie 值，服务器收到之后提取出 Session ID，从 Redis 中取出用户信息，继续之前的业务操作。
<br>应该注意 Session ID 的安全性问题，不能让它被恶意攻击者轻易获取，那么就不能产生一个容易被猜到的 Session ID 值。此外，还需要经常重新生成 Session ID。在对安全性要求极高的场景下，例如转账等操作，除了使用 Session 管理用户状态之外，还需要对用户进行重新验证，比如重新输入密码，或者使用短信验证码等方式。<br><br>此时无法使用 Cookie 来保存用户信息，只能使用 Session。除此之外，不能再将 Session ID 存放到 Cookie 中，而是使用 URL 重写技术，将 Session ID 作为 URL 的参数进行传递。<br><br>
<br>Cookie 只能存储 ASCII 码字符串，而 Session 则可以存取任何类型的数据，因此在考虑数据复杂性时首选 Session；
<br>Cookie 存储在浏览器中，容易被恶意查看。如果非要将一些隐私数据存在 Cookie 中，可以将 Cookie 值进行加密，然后在服务器进行解密；
<br>对于大型网站，如果用户所有的信息都存储在 Session 中，那么开销是非常大的，因此不建议将所有的用户信息都存储到 Session 中。
<br><br><br>
<br>缓解服务器压力；
<br>降低客户端获取资源的延迟: 缓存通常位于内存中，读取缓存的速度更快。并且缓存在地理位置上也有可能比源服务器来得近，例如浏览器缓存。
<br><br>
<br>让代理服务器进行缓存；
<br>让客户端浏览器进行缓存。
<br><br>HTTP/1.1 通过 Cache-Control 首部字段来控制缓存。<br>(一)禁止进行缓存<br>no-store 指令规定不能对请求或响应的任何一部分进行缓存。<br>Cache-Control: no-store
复制<br>(二)强制确认缓存<br>no-cache 指令规定缓存服务器需要先向源服务器验证缓存资源的有效性，只有当缓存资源有效才将能使用该缓存对客户端的请求进行响应。<br>Cache-Control: no-cache
复制<br>(三)私有缓存和公共缓存<br>private 指令规定了将资源作为私有缓存，只能被单独用户所使用，一般存储在用户浏览器中。<br>Cache-Control: private
复制<br>public 指令规定了将资源作为公共缓存，可以被多个用户所使用，一般存储在代理服务器中。<br>Cache-Control: public
复制<br>(四)缓存过期机制<br>max-age 指令出现在请求报文中，并且缓存资源的缓存时间小于该指令指定的时间，那么就能接受该缓存。<br>max-age 指令出现在响应报文中，表示缓存资源在缓存服务器中保存的时间。<br>Cache-Control: max-age=31536000
复制<br>Expires 首部字段也可以用于告知缓存服务器该资源什么时候会过期。<br>
<br>在 HTTP/1.1 中，会优先处理 max-age 指令；
<br>在 HTTP/1.0 中，max-age 指令会被忽略掉。
<br>Expires: Wed, 04 Jul 2012 08:26:05 GMT
复制<br><br>需要先了解 ETag 首部字段的含义，它是资源的唯一标识。URL 不能唯一表示资源，例如 http://www.google.com/ 有中文和英文两个资源，只有 ETag 才能对这两个资源进行唯一标识。<br>ETag: "82e22293907ce725faf67773957acd12"
复制<br>可以将缓存资源的 ETag 值放入 If-None-Match 首部，服务器收到该请求后，判断缓存资源的 ETag 值和资源的最新 ETag 值是否一致，如果一致则表示缓存资源有效，返回 304 Not Modified。<br>If-None-Match: "82e22293907ce725faf67773957acd12"
复制<br>Last-Modified 首部字段也可以用于缓存验证，它包含在源服务器发送的响应报文中，指示源服务器对资源的最后修改时间。但是它是一种弱校验器，因为只能精确到一秒，所以它通常作为 ETag 的备用方案。如果响应首部字段里含有这个信息，客户端可以在后续的请求中带上 If-Modified-Since 来验证缓存。服务器只在所请求的资源在给定的日期时间之后对内容进行过修改的情况下才会将资源返回，状态码为 200 OK。如果请求的资源从那时起未经修改，那么返回一个不带有消息主体的 304 Not Modified 响应。<br>Last-Modified: Wed, 21 Oct 2015 07:28:00 GMT
复制<br>If-Modified-Since: Wed, 21 Oct 2015 07:28:00 GMT
复制<br><br>“/images/pics/HTTP1_x_Connections.png” could not be found.<br><br>当浏览器访问一个包含多张图片的 HTML 页面时，除了请求访问 HTML 页面资源，还会请求图片资源。如果每进行一次 HTTP 通信就要新建一个 TCP 连接，那么开销会很大。<br>长连接只需要建立一次 TCP 连接就能进行多次 HTTP 通信。<br>
<br>从 HTTP/1.1 开始默认是长连接的，如果要断开连接，需要由客户端或者服务器端提出断开，使用 Connection : close；
<br>在 HTTP/1.1 之前默认是短连接的，如果需要使用长连接，则使用 Connection : Keep-Alive。
<br><br>默认情况下，HTTP 请求是按顺序发出的，下一个请求只有在当前请求收到响应之后才会被发出。由于会受到网络延迟和带宽的限制，在下一个请求被发送到服务器之前，可能需要等待很长时间。<br>流水线是在同一条长连接上发出连续的请求，而不用等待响应返回，这样可以避免连接延迟。<br><br>通过内容协商返回最合适的内容，例如根据浏览器的默认语言选择返回中文界面还是英文界面。<br><br>(一)服务端驱动型<br>客户端设置特定的 HTTP 首部字段，例如 Accept、Accept-Charset、Accept-Encoding、Accept-Language、Content-Languag，服务器根据这些字段返回特定的资源。<br>它存在以下问题:<br>
<br>服务器很难知道客户端浏览器的全部信息；
<br>客户端提供的信息相当冗长(HTTP/2 协议的首部压缩机制缓解了这个问题)，并且存在隐私风险(HTTP 指纹识别技术)；
<br>给定的资源需要返回不同的展现形式，共享缓存的效率会降低，而服务器端的实现会越来越复杂。
<br>(二)代理驱动型<br>服务器返回 300 Multiple Choices 或者 406 Not Acceptable，客户端从中选出最合适的那个资源。<br><br>Vary: Accept-Language
复制<br>在使用内容协商的情况下，只有当缓存服务器中的缓存满足内容协商条件时，才能使用该缓存，否则应该向源服务器请求该资源。<br>例如，一个客户端发送了一个包含 Accept-Language 首部字段的请求之后，源服务器返回的响应包含 Vary: Accept-Language 内容，缓存服务器对这个响应进行缓存之后，在客户端下一次访问同一个 URL 资源，并且 Accept-Language 与缓存中的对应的值相同时才会返回该缓存。<br><br>内容编码将实体主体进行压缩，从而减少传输的数据量。<br>常用的内容编码有: gzip、compress、deflate、identity。<br>浏览器发送 Accept-Encoding 首部，其中包含有它所支持的压缩算法，以及各自的优先级。服务器则从中选择一种，使用该算法对响应的消息主体进行压缩，并且发送 Content-Encoding 首部来告知浏览器它选择了哪一种算法。由于该内容协商过程是基于编码类型来选择资源的展现形式的，在响应的 Vary 首部至少要包含 Content-Encoding。<br><br>如果网络出现中断，服务器只发送了一部分数据，范围请求可以使得客户端只请求服务器未发送的那部分数据，从而避免服务器重新发送所有数据。<br><br>在请求报文中添加 Range 首部字段指定请求的范围。<br>GET /z4d4kWk.jpg HTTP/1.1
Host: i.imgur.com
Range: bytes=0-1023
复制<br>请求成功的话服务器返回的响应包含 206 Partial Content 状态码。<br>HTTP/1.1 206 Partial Content
Content-Range: bytes 0-1023/146515
Content-Length: 1024
...
(binary content)
复制<br><br>响应首部字段 Accept-Ranges 用于告知客户端是否能处理范围请求，可以处理使用 bytes，否则使用 none。<br>Accept-Ranges: bytes
复制<br><br>
<br>在请求成功的情况下，服务器会返回 206 Partial Content 状态码。
<br>在请求的范围越界的情况下，服务器会返回 416 Requested Range Not Satisfiable 状态码。
<br>在不支持范围请求的情况下，服务器会返回 200 OK 状态码。
<br><br>Chunked Transfer Coding，可以把数据分割成多块，让浏览器逐步显示页面。<br><br>一份报文主体内可含有多种类型的实体同时发送，每个部分之间用 boundary 字段定义的分隔符进行分隔，每个部分都可以有首部字段。<br>例如，上传多个表单时可以使用如下方式:<br>Content-Type: multipart/form-data; boundary=AaB03x

--AaB03x
Content-Disposition: form-data; name="submit-name"

Larry
--AaB03x
Content-Disposition: form-data; name="files"; filename="file1.txt"
Content-Type: text/plain

... contents of file1.txt ...
--AaB03x--
复制<br><br>HTTP/1.1 使用虚拟主机技术，使得一台服务器拥有多个域名，并且在逻辑上可以看成多个服务器。<br><br><br>代理服务器接受客户端的请求，并且转发给其它服务器。<br>使用代理的主要目的是:<br>
<br>缓存
<br>负载均衡
<br>网络访问控制
<br>访问日志记录
<br>代理服务器分为正向代理和反向代理两种:<br>
<br>用户察觉得到正向代理的存在。
<br>“/images/pics/a314bb79-5b18-4e63-a976-3448bffa6f1b.png” could not be found.<br>
<br>而反向代理一般位于内部网络中，用户察觉不到。
<br>“/images/pics/2d09a847-b854-439c-9198-b29c65810944.png” could not be found.<br><br>与代理服务器不同的是，网关服务器会将 HTTP 转化为其它协议进行通信，从而请求其它非 HTTP 服务器的服务。<br><br>使用 SSL 等加密手段，在客户端和服务器之间建立一条安全的通信线路。<br><br>HTTP 有以下安全性问题:<br>
<br>使用明文进行通信，内容可能会被窃听；
<br>不验证通信方的身份，通信方的身份有可能遭遇伪装；
<br>无法证明报文的完整性，报文有可能遭篡改。
<br>HTTPs 并不是新协议，而是让 HTTP 先和 SSL(Secure Sockets Layer)通信，再由 SSL 和 TCP 通信，也就是说 HTTPs 使用了隧道进行通信。<br>通过使用 SSL，HTTPs 具有了加密(防窃听)、认证(防伪装)和完整性保护(防篡改)。<br>“/images/pics/ssl-offloading.jpg” could not be found.<br><br><br>对称密钥加密(Symmetric-Key Encryption)，加密和解密使用同一密钥。<br>
<br>优点: 运算速度快；
<br>缺点: 无法安全地将密钥传输给通信方。
<br>“/images/pics/7fffa4b8-b36d-471f-ad0c-a88ee763bb76.png” could not be found.<br><br>非对称密钥加密，又称公开密钥加密(Public-Key Encryption)，加密和解密使用不同的密钥。<br>公开密钥所有人都可以获得，通信发送方获得接收方的公开密钥之后，就可以使用公开密钥进行加密，接收方收到通信内容后使用私有密钥解密。<br>非对称密钥除了用来加密，还可以用来进行签名。因为私有密钥无法被其他人获取，因此通信发送方使用其私有密钥进行签名，通信接收方使用发送方的公开密钥对签名进行解密，就能判断这个签名是否正确。<br>
<br>优点: 可以更安全地将公开密钥传输给通信发送方；
<br>缺点: 运算速度慢。
<br>“/images/pics/39ccb299-ee99-4dd1-b8b4-2f9ec9495cb4.png” could not be found.<br><br>HTTPs 采用混合的加密机制，使用非对称密钥加密用于传输对称密钥来保证传输过程的安全性，之后使用对称密钥加密进行通信来保证通信过程的效率。(下图中的 Session Key 就是对称密钥)<br>“/images/pics/How-HTTPS-Works.png” could not be found.<br><br>通过使用 证书 来对通信方进行认证。<br>数字证书认证机构(CA，Certificate Authority)是客户端与服务器双方都可信赖的第三方机构。<br>服务器的运营人员向 CA 提出公开密钥的申请，CA 在判明提出申请者的身份之后，会对已申请的公开密钥做数字签名，然后分配这个已签名的公开密钥，并将该公开密钥放入公开密钥证书后绑定在一起。<br>进行 HTTPs 通信时，服务器会把证书发送给客户端。客户端取得其中的公开密钥之后，先使用数字签名进行验证，如果验证通过，就可以开始通信了。<br>通信开始时，客户端需要使用服务器的公开密钥将自己的私有密钥传输给服务器，之后再进行对称密钥加密。<br>“/images/pics/2017-06-11-ca.png” could not be found.<br><br>SSL 提供报文摘要功能来进行完整性保护。<br>HTTP 也提供了 MD5 报文摘要功能，但不是安全的。例如报文内容被篡改之后，同时重新计算 MD5 的值，通信接收方是无法意识到发生了篡改。<br>HTTPs 的报文摘要功能之所以安全，是因为它结合了加密和认证这两个操作。试想一下，加密之后的报文，遭到篡改之后，也很难重新计算报文摘要，因为无法轻易获取明文。<br><br>
<br>因为需要进行加密解密等过程，因此速度会更慢；
<br>需要支付证书授权的高额费用。
<br><br><a data-tooltip-position="top" aria-label="https://aotu.io/notes/2016/08/16/nginx-https/index.html" rel="noopener" class="external-link" href="https://aotu.io/notes/2016/08/16/nginx-https/index.html" target="_blank">Nginx 配置 HTTPS 服务器在新窗口打开</a><br><br><br>HTTP/1.x 实现简单是以牺牲性能为代价的:<br>
<br>客户端需要使用多个连接才能实现并发和缩短延迟；
<br>不会压缩请求和响应首部，从而导致不必要的网络流量；
<br>不支持有效的资源优先级，致使底层 TCP 连接的利用率低下。
<br><br>HTTP/2.0 将报文分成 HEADERS 帧和 DATA 帧，它们都是二进制格式的。<br>“/images/pics/86e6a91d-a285-447a-9345-c5484b8d0c47.png” could not be found.<br>在通信过程中，只会有一个 TCP 连接存在，它承载了任意数量的双向数据流(Stream)。<br>
<br>一个数据流都有一个唯一标识符和可选的优先级信息，用于承载双向信息。
<br>消息(Message)是与逻辑请求或响应消息对应的完整的一系列帧。
<br>帧(Fram)是最小的通信单位，来自不同数据流的帧可以交错发送，然后再根据每个帧头的数据流标识符重新组装。
<br>“/images/pics/af198da1-2480-4043-b07f-a3b91a88b815.png” could not be found.<br><br>HTTP/2.0 在客户端请求一个资源时，会把相关的资源一起发送给客户端，客户端就不需要再次发起请求了。例如客户端请求 page.html 页面，服务端就把 script.js 和 style.css 等与之相关的资源一起发给客户端。<br>“/images/pics/e3f1657c-80fc-4dfa-9643-bf51abd201c6.png” could not be found.<br><br>HTTP/1.1 的首部带有大量信息，而且每次都要重复发送。<br>HTTP/2.0 要求客户端和服务器同时维护和更新一个包含之前见过的首部字段表，从而避免了重复传输。<br>不仅如此，HTTP/2.0 也使用 Huffman 编码对首部字段进行压缩。<br>“/images/pics/_u4E0B_u8F7D.png” could not be found.<br><br><br>GET 用于获取资源，而 POST 用于传输实体主体。<br><br>GET 和 POST 的请求都能使用额外的参数，但是 GET 的参数是以查询字符串出现在 URL 中，而 POST 的参数存储在实体主体中。不能因为 POST 参数存储在实体主体中就认为它的安全性更高，因为照样可以通过一些抓包工具(Fiddler)查看。<br>因为 URL 只支持 ASCII 码，因此 GET 的参数中如果存在中文等字符就需要先进行编码。例如 中文 会转换为 %E4%B8%AD%E6%96%87，而空格会转换为 %20。POST 参考支持标准字符集。<br>GET /test/demo_form.asp?name1=value1&amp;name2=value2 HTTP/1.1
复制<br>POST /test/demo_form.asp HTTP/1.1
Host: w3schools.com
name1=value1&amp;name2=value2
复制<br><br>安全的 HTTP 方法不会改变服务器状态，也就是说它只是可读的。<br>GET 方法是安全的，而 POST 却不是，因为 POST 的目的是传送实体主体内容，这个内容可能是用户上传的表单数据，上传成功之后，服务器可能把这个数据存储到数据库中，因此状态也就发生了改变。<br>安全的方法除了 GET 之外还有: HEAD、OPTIONS。<br>不安全的方法除了 POST 之外还有 PUT、DELETE。<br><br>幂等的 HTTP 方法，同样的请求被执行一次与连续执行多次的效果是一样的，服务器的状态也是一样的。换句话说就是，幂等方法不应该具有副作用(统计用途除外)。<br>所有的安全方法也都是幂等的。<br>在正确实现的条件下，GET，HEAD，PUT 和 DELETE 等方法都是幂等的，而 POST 方法不是。<br>GET /pageX HTTP/1.1 是幂等的，连续调用多次，客户端接收到的结果都是一样的:<br>GET /pageX HTTP/1.1
GET /pageX HTTP/1.1
GET /pageX HTTP/1.1
GET /pageX HTTP/1.1
复制<br>POST /add_row HTTP/1.1 不是幂等的，如果调用多次，就会增加多行记录:<br>POST /add_row HTTP/1.1   -&gt; Adds a 1nd row
POST /add_row HTTP/1.1   -&gt; Adds a 2nd row
POST /add_row HTTP/1.1   -&gt; Adds a 3rd row
复制<br>DELETE /idX/delete HTTP/1.1 是幂等的，即便不同的请求接收到的状态码不一样:<br>DELETE /idX/delete HTTP/1.1   -&gt; Returns 200 if idX exists
DELETE /idX/delete HTTP/1.1   -&gt; Returns 404 as it just got deleted
DELETE /idX/delete HTTP/1.1   -&gt; Returns 404
复制<br><br>如果要对响应进行缓存，需要满足以下条件:<br>
<br>请求报文的 HTTP 方法本身是可缓存的，包括 GET 和 HEAD，但是 PUT 和 DELETE 不可缓存，POST 在多数情况下不可缓存的。
<br>响应报文的状态码是可缓存的，包括: 200, 203, 204, 206, 300, 301, 404, 405, 410, 414, and 501。
<br>响应报文的 Cache-Control 首部字段没有指定不进行缓存。
<br><br>为了阐述 POST 和 GET 的另一个区别，需要先了解 XMLHttpRequest:<br>
XMLHttpRequest 是一个 API，它为客户端提供了在客户端和服务器之间传输数据的功能。它提供了一个通过 URL 来获取数据的简单方式，并且不会使整个页面刷新。这使得网页只更新一部分页面而不会打扰到用户。XMLHttpRequest 在 AJAX 中被大量使用。
<br>
<br>在使用 XMLHttpRequest 的 POST 方法时，浏览器会先发送 Header 再发送 Data。但并不是所有浏览器会这么做，例如火狐就不会。
<br>而 GET 方法 Header 和 Data 会一起发送。
<br><br>
详细内容请见上文
<br>
<br>HTTP/1.1 默认是长连接<br>

<br>HTTP/1.1 支持管线化处理<br>

<br>HTTP/1.1 支持同时打开多个 TCP 连接<br>

<br>HTTP/1.1 支持虚拟主机<br>

<br>HTTP/1.1 新增状态码 100<br>

<br>HTTP/1.1 支持分块传输编码<br>

<br>HTTP/1.1 新增缓存处理指令 max-age<br>

<br><br>
<br>上野宣. 图解 HTTP[M]. 人民邮电出版社, 2014.
<br><a data-tooltip-position="top" aria-label="https://developer.mozilla.org/en-US/docs/Web/HTTP" rel="noopener" class="external-link" href="https://developer.mozilla.org/en-US/docs/Web/HTTP" target="_blank">MDN : HTTP在新窗口打开</a>
<br><a data-tooltip-position="top" aria-label="https://developers.google.com/web/fundamentals/performance/http2/?hl=zh-cn" rel="noopener" class="external-link" href="https://developers.google.com/web/fundamentals/performance/http2/?hl=zh-cn" target="_blank">HTTP/2 简介在新窗口打开</a>
<br><a data-tooltip-position="top" aria-label="http://php.net/manual/zh/function.htmlspecialchars.php" rel="noopener" class="external-link" href="http://php.net/manual/zh/function.htmlspecialchars.php" target="_blank">htmlspecialchars在新窗口打开</a>
<br><a data-tooltip-position="top" aria-label="http://java2db.com/java-io/how-to-get-and-the-difference-between-file-uri-and-url-in-java" rel="noopener" class="external-link" href="http://java2db.com/java-io/how-to-get-and-the-difference-between-file-uri-and-url-in-java" target="_blank">Difference between file URI and URL in java在新窗口打开</a>
<br><a data-tooltip-position="top" aria-label="https://software-security.sans.org/developer-how-to/fix-sql-injection-in-java-using-prepared-callable-statement" rel="noopener" class="external-link" href="https://software-security.sans.org/developer-how-to/fix-sql-injection-in-java-using-prepared-callable-statement" target="_blank">How to Fix SQL Injection Using Java PreparedStatement &amp; CallableStatement在新窗口打开</a>
<br><a data-tooltip-position="top" aria-label="https://www.cnblogs.com/hyddd/archive/2009/03/31/1426026.html" rel="noopener" class="external-link" href="https://www.cnblogs.com/hyddd/archive/2009/03/31/1426026.html" target="_blank">浅谈 HTTP 中 Get 与 Post 的区别在新窗口打开</a>
<br><a data-tooltip-position="top" aria-label="https://www.webdancers.com/are-http-and-www-necesary/" rel="noopener" class="external-link" href="https://www.webdancers.com/are-http-and-www-necesary/" target="_blank">Are http:// and www really necessary?在新窗口打开</a>
<br><a data-tooltip-position="top" aria-label="https://www.ntu.edu.sg/home/ehchua/programming/webprogramming/HTTP_Basics.html" rel="noopener" class="external-link" href="https://www.ntu.edu.sg/home/ehchua/programming/webprogramming/HTTP_Basics.html" target="_blank">HTTP (HyperText Transfer Protocol)在新窗口打开</a>
<br><a data-tooltip-position="top" aria-label="https://www.igvita.com/2011/12/01/web-vpn-secure-proxies-with-spdy-chrome/" rel="noopener" class="external-link" href="https://www.igvita.com/2011/12/01/web-vpn-secure-proxies-with-spdy-chrome/" target="_blank">Web-VPN: Secure Proxies with SPDY &amp; Chrome在新窗口打开</a>
<br><a data-tooltip-position="top" aria-label="http://en.wikipedia.org/wiki/File:HTTP_persistent_connection.svg" rel="noopener" class="external-link" href="http://en.wikipedia.org/wiki/File:HTTP_persistent_connection.svg" target="_blank">File:HTTP persistent connection.svg在新窗口打开</a>
<br><a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/Proxy_server" rel="noopener" class="external-link" href="https://en.wikipedia.org/wiki/Proxy_server" target="_blank">Proxy server在新窗口打开</a>
<br><a data-tooltip-position="top" aria-label="https://www.x-cart.com/blog/what-is-https-and-ssl.html" rel="noopener" class="external-link" href="https://www.x-cart.com/blog/what-is-https-and-ssl.html" target="_blank">What Is This HTTPS/SSL Thing And Why Should You Care?在新窗口打开</a>
<br><a data-tooltip-position="top" aria-label="https://securebox.comodo.com/ssl-sniffing/ssl-offloading/" rel="noopener" class="external-link" href="https://securebox.comodo.com/ssl-sniffing/ssl-offloading/" target="_blank">What is SSL Offloading?在新窗口打开</a>
<br><a data-tooltip-position="top" aria-label="https://docs.oracle.com/cd/E19424-01/820-4811/6ng8i26bn/index.html" rel="noopener" class="external-link" href="https://docs.oracle.com/cd/E19424-01/820-4811/6ng8i26bn/index.html" target="_blank">Sun Directory Server Enterprise Edition 7.0 Reference - Key Encryption在新窗口打开</a>
<br><a data-tooltip-position="top" aria-label="https://www.codeproject.com/Articles/326574/An-Introduction-to-Mutual-SSL-Authentication" rel="noopener" class="external-link" href="https://www.codeproject.com/Articles/326574/An-Introduction-to-Mutual-SSL-Authentication" target="_blank">An Introduction to Mutual SSL Authentication在新窗口打开</a>
<br><a data-tooltip-position="top" aria-label="https://danielmiessler.com/study/url-uri/" rel="noopener" class="external-link" href="https://danielmiessler.com/study/url-uri/" target="_blank">The Difference Between URLs and URIs在新窗口打开</a>
<br><a data-tooltip-position="top" aria-label="https://juejin.im/entry/5766c29d6be3ff006a31b84e#comment" rel="noopener" class="external-link" href="https://juejin.im/entry/5766c29d6be3ff006a31b84e#comment" target="_blank">Cookie 与 Session 的区别在新窗口打开</a>
<br><a data-tooltip-position="top" aria-label="https://www.zhihu.com/question/19786827" rel="noopener" class="external-link" href="https://www.zhihu.com/question/19786827" target="_blank">COOKIE 和 SESSION 有什么区别在新窗口打开</a>
<br><a data-tooltip-position="top" aria-label="https://harttle.land/2015/08/10/cookie-session.html" rel="noopener" class="external-link" href="https://harttle.land/2015/08/10/cookie-session.html" target="_blank">Cookie/Session 的机制与安全在新窗口打开</a>
<br><a data-tooltip-position="top" aria-label="https://shijianan.com/2017/06/11/https/" rel="noopener" class="external-link" href="https://shijianan.com/2017/06/11/https/" target="_blank">HTTPS 证书原理在新窗口打开</a>
<br><a data-tooltip-position="top" aria-label="https://stackoverflow.com/questions/176264/what-is-the-difference-between-a-uri-a-url-and-a-urn" rel="noopener" class="external-link" href="https://stackoverflow.com/questions/176264/what-is-the-difference-between-a-uri-a-url-and-a-urn" target="_blank">What is the difference between a URI, a URL and a URN?在新窗口打开</a>
<br><a data-tooltip-position="top" aria-label="https://developer.mozilla.org/zh-CN/docs/Web/API/XMLHttpRequest" rel="noopener" class="external-link" href="https://developer.mozilla.org/zh-CN/docs/Web/API/XMLHttpRequest" target="_blank">XMLHttpRequest在新窗口打开</a>
<br><a data-tooltip-position="top" aria-label="https://blog.josephscott.org/2009/08/27/xmlhttprequest-xhr-uses-multiple-packets-for-http-post/" rel="noopener" class="external-link" href="https://blog.josephscott.org/2009/08/27/xmlhttprequest-xhr-uses-multiple-packets-for-http-post/" target="_blank">XMLHttpRequest (XHR) Uses Multiple Packets for HTTP POST?在新窗口打开</a>
<br><a data-tooltip-position="top" aria-label="https://www.ssl2buy.com/wiki/symmetric-vs-asymmetric-encryption-what-are-differences" rel="noopener" class="external-link" href="https://www.ssl2buy.com/wiki/symmetric-vs-asymmetric-encryption-what-are-differences" target="_blank">Symmetric vs. Asymmetric Encryption – What are differences?在新窗口打开</a>
<br><a data-tooltip-position="top" aria-label="https://www.kancloud.cn/digest/web-performance-http2" rel="noopener" class="external-link" href="https://www.kancloud.cn/digest/web-performance-http2" target="_blank">Web 性能优化与 HTTP/2在新窗口打开</a>
<br><a data-tooltip-position="top" aria-label="https://developers.google.com/web/fundamentals/performance/http2/?hl=zh-cn" rel="noopener" class="external-link" href="https://developers.google.com/web/fundamentals/performance/http2/?hl=zh-cn" target="_blank">HTTP/2 简介在新窗口打开</a>
<br><a data-tooltip-position="top" aria-label="https://www.cnblogs.com/upyun/p/8508126.html" rel="noopener" class="external-link" href="https://www.cnblogs.com/upyun/p/8508126.html" target="_blank">科普 TLS 1.3—新特性与开启方式</a>
<br><br>著作权归@pdai所有 原文链接：<a rel="noopener" class="external-link" href="https://pdai.tech/md/develop/protocol/dev-protocol-http.html" target="_blank">https://pdai.tech/md/develop/protocol/dev-protocol-http.html</a>]]></description><link>01、通用基础\02、计算机网络\07、网络协议-http-协议详解.html</link><guid isPermaLink="false">01、通用基础/02、计算机网络/07、网络协议 - HTTP 协议详解.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Fri, 05 Apr 2024 09:28:29 GMT</pubDate><enclosure url="01、通用基础\02、计算机网络\assets\07、网络协议-http-协议详解\img-20240304_215954.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;01、通用基础\02、计算机网络\assets\07、网络协议-http-协议详解\img-20240304_215954.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[08、网络协议 - DNS 相关详解]]></title><description><![CDATA[ 
 ]]></description><link>01、通用基础\02、计算机网络\08、网络协议-dns-相关详解.html</link><guid isPermaLink="false">01、通用基础/02、计算机网络/08、网络协议 - DNS 相关详解.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:45 GMT</pubDate></item><item><title><![CDATA[09、输入URL 到页面加载过程详解]]></title><description><![CDATA[ 
 <br><br>
URL : Uniform / Universal Resource Locator ， 即统一资源定位符。<br>
实际上就是网站网址。浏览器就是靠URL来查找资源位置。
<br>可以把URL分割成几个部分：协议、网络地址、资源路径。<br>
<br>传送协议： URL包含协议部分，是浏览器和www万维网之间的沟通方式，它会告诉浏览器正确在网路上找到资源位置。最常见的网络传输协议的是HTTP协议（超文本传输协议）（ https则是进行加密的网络传输）；其他也还有ftp 、file、 https、mailto 、git 等。还有自定义的协议（私有协议），例如tencent。不同协议有不同的通讯内容格式。
<br>网络地址： 指示该连接网络上哪一台计算机，可以是域名或者IP地址，可以包括端口号；
<br>资源路径： 指示从服务器上获取哪一项资源。
<br>例如： <a rel="noopener" class="external-link" href="http://www.quaro.com/question/123456/" target="_blank">http://www.quaro.com/question/123456/</a><br>
<br>协议部分：http
<br>网络地址：<a data-tooltip-position="top" aria-label="http://www.quaro.com" rel="noopener" class="external-link" href="http://www.quaro.com" target="_blank">www.quaro.com</a>
<br>资源路径：/question/123456/
<br><br><br>IP 地址：IP 协议为互联网上的每一个网络和每一台主机分配的一个逻辑地址。IP 地址如同门牌号码，通过 IP 地址才能确定一台主机位置。服务器本质也是一台主机，想要访问某个服务器，必须先知道它的 IP 地址。<br>域名 DN（domain name ）：域名是为了识别主机名称和组织机构名称的一种具有分层的名称。 IP 地址由四个数字组成，中间用点号连接，在使用过程中难记忆且易输错，所以用我们熟悉的字母和数字组合来代替纯数字的 IP 地址，比如我们只会记住 <a data-tooltip-position="top" aria-label="http://www.baidu.com" rel="noopener" class="external-link" href="http://www.baidu.com" target="_blank">www.baidu.com</a> （百度域名） 而不是 220.181.112.244（百度的其中一个 IP 地址）。<br>计算机域名系统 DNS （ Domain Name System or Domain Name Service）： 它是由域名解析器和域名服务器组成的。 域名服务器是指保存有该网络中所有主机的域名和对应IP地址，并具有将域名转换为IP地址功能的服务器。 每个域名都对应一个或多个提供相同服务的服务器的 IP 地址，只有知道服务器 IP 地址才能建立连接，所以需要通过 DNS 把域名解析成一个 IP 地址。<br><br>
通过域名查找IP过程：浏览器缓存 -&gt; 系统缓存 -&gt; 本地DNS服务器缓存
<br>
<br>浏览器搜索自己的DNS缓存（维护一张域名与IP地址对应表）
<br>搜索操作系统中的DNS缓存（维护一张域名与IP地址对应表）
<br>搜索操作系统的hosts文件（windows环境下，维护一张域名与IP地址对应表）
<br>操作系统将域名发送到本地区域服务器（LNDS），进行查找，成功则返回结果（递归查询），失败则发起一个迭代DNS请求（迭代查询）
<br>本地域名服务器LDNS将得到的IP地址返回给操作系统，同时也将IP地址缓存起来
<br>操作系统将IP地址返回给浏览器，同时将IP地址缓存起来
<br><br><img src="\01、通用基础\02、计算机网络\assets\09、输入url-到页面加载过程详解\img-20240304_213216.png"><br>
<br>
递归查询：客户端与服务器之间属于递归查询，即当客户机向DNS 服务器发出请求后，若 DNS 服务器本身不能解析，会向另一个 DNS 服务器发出查询请求，最后将结果转交给客户端的过程。服务器必须回答目标 IP 与域名的映射关系。

<br>
迭代查询：DNS 服务器之间属于迭代查询。服务器接收到一次迭代查询回复一次结果，这个结果不一定是目标 IP 与域名的映射关系，也可以是其他 DNS 服务器的地址。

<br><br><br>包括：<br>
<br>TCP连接建立
<br>发送http 请求
<br>服务端处理
<br>返回http 结果
<br>TCP连接关闭。
<br><br>
上一步找到IP之后，便可以开始建立TCP连接了，这里就是我们所说的TCP3次握手。
详情可以参考：<a class="internal-link" data-href="05、网络协议 - TCP 协议详解.md" href="\01、通用基础\02、计算机网络\05、网络协议-tcp-协议详解.html" target="_self" rel="noopener">05、网络协议 - TCP 协议详解</a>
<br><img src="\01、通用基础\02、计算机网络\assets\09、输入url-到页面加载过程详解\img-20240304_213416.png"><br><br>
与服务器建立了连接后，就可以向服务器发起请求了。
详情可以参考： <a class="internal-link" data-href="07、网络协议 - HTTP 协议详解.md" href="\01、通用基础\02、计算机网络\07、网络协议-http-协议详解.html" target="_self" rel="noopener">07、网络协议 - HTTP 协议详解</a>
<br>请求报文结构如下：<br><img src="\01、通用基础\02、计算机网络\assets\09、输入url-到页面加载过程详解\img-20240304_213913.png"><br><img src="\01、通用基础\02、计算机网络\assets\09、输入url-到页面加载过程详解\img-20240304_213919.png"><br><br>服务器端收到请求后的由web服务器（准确说应该是http服务器）处理请求，诸如Apache、Ngnix、IIS等。web服务器解析用户请求，知道了需要调度哪些资源文件，再通过相应的这些资源文件处理用户请求和参数，并调用数据库信息，最后将结果通过web服务器返回给浏览器客户端。<br><img src="\01、通用基础\02、计算机网络\assets\09、输入url-到页面加载过程详解\img-20240304_214021.png"><br><br>服务器处理完请求后，就会发送响应结果。响应报文的结构如下：<br><img src="\01、通用基础\02、计算机网络\assets\09、输入url-到页面加载过程详解\img-20240304_214200.png"><br>响应结果中会有对应的HTTP状态码，可分为5类：<br><img src="\01、通用基础\02、计算机网络\assets\09、输入url-到页面加载过程详解\img-20240304_214212.png"><br><br>为了避免服务器与客户端双方的资源占用和损耗，当双方没有请求或响应传递时，任意一方都可以发起关闭请求。与创建 TCP 连接的3次握手类似，关闭 TCP 连接，需要4次握手。<br><img src="\01、通用基础\02、计算机网络\assets\09、输入url-到页面加载过程详解\img-20240304_214245.png"><br><br>浏览器构成<br><img src="\01、通用基础\02、计算机网络\assets\09、输入url-到页面加载过程详解\img-20240304_214312.png"><br>浏览器内核也称渲染引擎，主要有3种：<br>
<br>Trident内核： IE
<br>Webkit内核：Chrome,Safari
<br>Gecko内核：FireFox
<br><br><br>加载过程如下：<br>
<br>当浏览器获得一个html文件时，会”自上而下“加载，并在加载过程中进行解析渲染。
<br>加载过程中遇到外部css文件，浏览器另外发出一个请求，来获取css文件。
<br>遇到图片资源，浏览器也会另外发出一个请求，来获取图片资源。这是异步请求，并不会影响html文档进行加载。
<br>但是当文档加载过程中遇到js文件，html文档会挂起渲染（加载解析渲染同步）的线程，不仅要等待文档中js文件加载完毕，还要等待解析执行完毕，才可以恢复html文档的渲染线程。
<br>加载外联js和css的阻塞情况：一个不太严谨但方便记忆的口诀：JS 全阻塞，CSS 半阻塞<br>
<br>JS 会阻塞后续 DOM 解析以及其它资源(如 CSS，JS 或图片资源)的加载。
<br>CSS不阻塞DOM的加载和解析（它只阻塞DOM的渲染呈现。这里谈加载），不会阻塞其它资源(如图片)的加载，但是会阻塞 后续JS 文件的执行（原因之一是，js执行代码可能会依赖到css样式。css只阻塞执行而不阻塞js的加载）。
<br>鉴于上面的特性，当css后面存在js的时候，css会间接地阻塞js后面资源的加载（css阻塞js，js阻塞其他资源 ）。
<br>现代浏览器会进行 prefetch 优化，浏览器在获得 html 文档之后会对页面上引用的资源进行提前下载
<br>外联js文件使用defer属性和asyn可以达到异步非阻塞加载的效果，由于现代浏览器都存在 prefetch，所以 defer, async 可能并没有太多的用途，可以作为了解扩展知识，仅仅将脚本文件放到 body 底部(但还是在&lt;/body&gt;之前)就可以起到很不错的优化效果（遵循先解析再渲染再执行script这个顺序）。当把js放在最后的时候，其实浏览器将自动忽略&lt;/body&gt;标签，从而自动在最后的最后补上&lt;/body&gt;。<br><br><img src="\01、通用基础\02、计算机网络\assets\09、输入url-到页面加载过程详解\img-20240304_214326.png"><br>步骤如下：<br>
<br>解析html，生成dom树
<br>解析css，生成cssom树
<br>将dom树和cssom树合并，生成渲染树
<br>遍历渲染树，开始布局和计算
<br>绘制渲染树，显示到屏幕
<br><br>当浏览器接收到服务器响应来的HTML文档后，会自上而下扫描文档，开始解析，遍历文档节点，生成DOM树。<br>整个构建过程其实包括： 字节 -&gt; 字符 -&gt; 令牌 -&gt; 节点对象 -&gt; 对象模型，下面是示例代码和配图：<br>&lt;html&gt;
  &lt;head&gt;
    &lt;meta name="viewport" content="width=device-width,initial-scale=1"&gt;
    &lt;link href="style.css" rel="stylesheet"&gt;
    &lt;title&gt;Critical Path&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;p&gt;Hello &lt;span&gt;web performance&lt;/span&gt; students!&lt;/p&gt;
    &lt;div&gt;&lt;img src="awesome-photo.jpg"&gt;&lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;
复制<br>“/images/develop/network/dev-network-url-11.png” could not be found.<br><br>
<br>每个css文件都被分析成一个stylesheet对象，每个对象都包含CSS规则。
<br>css规则对象包含对应于css语法的选择器和声明对象以及其他对象。
<br>构建过程没有什么特别的差别，下面是示例代码和配图：<br>body { font-size: 16px }
p { font-weight: bold }
span { color: red }
p span { display: none }
img { float: right }
复制<br>“/images/develop/network/dev-network-url-12.png” could not be found.<br><br>
<br>浏览器会先从dom树的根节点开始遍历每个可见节点，找到其适配的CSS样式规则并应用。
<br>将dom树与cssom树结合在一起，这就是渲染树。 “/images/develop/network/dev-network-url-13.png” could not be found.
<br>每一个渲染对象都对应着dom节点，但是非视觉（隐藏，不占位）dom元素不会插入渲染树，如&lt;head&gt;元素或声明display: none;的元素。
<br>渲染对象与dom节点不是简单的一对一的关系，一个dom可以对应一个渲染对象，但一个dom元素也可能对应多个渲染对象，因为有很多元素不止包含一个css盒子。（如当文本被折行时，会产生多个行盒，这些行会生成多个渲染对象；又如行内元素同时包含块元素和行内元素，则会创建一个匿名块级盒包含内部行内元素，此时一个dom对应多个渲染对象）
<br><br>布局阶段会从渲染树的根节点开始遍历，然后确定每个节点对象在页面上的确切大小与位置。 布局阶段的输出是一个盒子模型，它会精确地捕获每个元素在屏幕内的确切位置与大小，所有相对的测量值也都会被转换为屏幕内的绝对像素值。<br><br>在绘制阶段，浏览器会立即发出Paint Setup与Paint事件，开始将渲染树绘制成像素，绘制所需的时间跟CSS样式的复杂度成正比，绘制完成后，用户就可以看到页面的最终呈现效果了。<br><br>当用户在浏览网页时进行交互或通过 js 脚本改变页面结构时，以上的部分操作有可能重复运行，此过程称为 Repaint 或 Reflow。<br><br>当元素改变的时候，将不会影响元素在页面当中的位置（比如 background-color, border-color, visibility），浏览器仅仅会应用新的样式重绘此元素，此过程称为 Repaint。<br><br>当元素改变的时候，将会影响文档内容或结构，或元素位置，此过程称为 Reflow。（ HTML 使用的是 flow based layout ，也就是流式布局，所以，如果某元件的几何尺寸发生了变化，需要重新布局，也就叫 Reflow。）<br>
Reflow 的成本比 Repaint 的成本高得多的多。我们应当尽量避免Reflow。
<br><br><br>
<br>html文档结构层次尽量少，最好不深于6层
<br>首屏html可以少量，主体结构动态插入
<br>尽量减少将 DOM 节点属性值放在循环当中，会导致大量读写此属性值。
<br>创建有效的 HTML 和 CSS ，不要忘记指定文档编码，比如&lt;meta charset="utf-8"&gt;。
<br><br>
<br>使用媒体查询，减少初次cssom树的构建量
<br>尽量用id和class，不要过渡层叠
<br>样式结构层次尽量简单
<br>尽可能的为产生动画的 HTML 元素使用 fixed 或 absolute 的 position ，那么修改他们的 CSS 是不会 Reflow 的。
<br><br>
<br>使用defer和async，避免对文档的阻塞
<br>可以的话，动态插入js，避免阻塞
<br>不要通过 JS 逐条修改 DOM 的样式，提前定义好 CSS 的 Class 进行操作。
<br><br>
<br>css放到head，让cssom树先行构建；js放到&lt;/body&gt;前，保证dom树先行构建，不被阻塞 避免js文件的插入跟在css文件之后，避免css解析对js执行的延迟，造成阻塞
<br><br>
<br>对页面资源进行压缩，对传输进行gzip压缩
<br>利用link标签的rel属性进行预解析，运用http缓存
<br><br>
<br><a rel="noopener" class="external-link" href="https://www.zhihu.com/question/263866883/answer/276139578" target="_blank">https://www.zhihu.com/question/263866883/answer/276139578</a>
<br><a rel="noopener" class="external-link" href="https://segmentfault.com/a/1190000008835506" target="_blank">https://segmentfault.com/a/1190000008835506</a>
<br><a rel="noopener" class="external-link" href="https://segmentfault.com/a/1190000013522717" target="_blank">https://segmentfault.com/a/1190000013522717</a>
<br><a rel="noopener" class="external-link" href="https://blog.csdn.net/qq_29311407/article/details/79988700" target="_blank">https://blog.csdn.net/qq_29311407/article/details/79988700</a>
<br><a rel="noopener" class="external-link" href="https://www.cnblogs.com/yongwunaci/p/10671999.html" target="_blank">https://www.cnblogs.com/yongwunaci/p/10671999.html</a>
<br><a rel="noopener" class="external-link" href="https://www.jianshu.com/p/8758e8a237ee" target="_blank">https://www.jianshu.com/p/8758e8a237ee</a>
]]></description><link>01、通用基础\02、计算机网络\09、输入url-到页面加载过程详解.html</link><guid isPermaLink="false">01、通用基础/02、计算机网络/09、输入URL 到页面加载过程详解.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Fri, 05 Apr 2024 09:28:29 GMT</pubDate><enclosure url="01、通用基础\02、计算机网络\assets\09、输入url-到页面加载过程详解\img-20240304_213216.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;01、通用基础\02、计算机网络\assets\09、输入url-到页面加载过程详解\img-20240304_213216.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[10、工具-netstat查看服务及监听端口详解]]></title><description><![CDATA[ 
 <br><br>netstat命令各个参数说明如下：<br>-a   或–all                             显示所有连线中的Socket。
-A                                       &lt;网络类型&gt;或–&lt;网络类型&gt; 列出该网络类型连线中的相关地址。
-c   或–continuous               持续列出网络状态。
-C 或–cache                       显示路由器配置的快取信息。
-e  或–extend                     显示网络其他相关信息。
-F  或 –fib                          显示FIB。
-g  或–groups                     显示多重广播功能群组组员名单。
-h  或–help                        在线帮助。
-i   或–interfaces                 显示网络界面信息表单。
-l  或–listening                    显示监控中的服务器的Socket。
-M   或–masquerade           显示伪装的网络连线。
-n  或–numeric                   直接使用IP地址，而不通过域名服务器。
-N   或–netlink或–symbolic  显示网络硬件外围设备的符号连接名称。
-o  或–timers                      显示计时器。
-p   或–programs                显示正在使用Socket的程序识别码和程序名称。
-r  或–route                        显示 Routing Table。
-s  或–statistice 显示网络工作信息统计表。
-t  或–tcp 显示TCP 传输协议的连线状况。
-u或–udp 显示UDP传输协议的连线状况。
-v或–verbose 显示指令执行过程。
-V 或–version 显示版本信息。
-w或–raw 显示RAW传输协议的连线状况。
-x或–unix 此参数的效果和指定”-A unix”参数相同。
–ip或–inet 此参数的效果和指定”-A inet”参数相同。
复制<br><br>以查看当前所有tcp/udp端口为例：<br>[root@pdai-centos ~]# netstat -tulnp
Active Internet connections (servers and established)
Proto Recv-Q Send-Q Local Address               Foreign Address             State       PID/Program name   
tcp        0      0 0.0.0.0:22                  0.0.0.0:*                   LISTEN      1904/sshd           
tcp        0      0 127.0.0.1:631               0.0.0.0:*                   LISTEN      1750/cupsd          
tcp        0      0 0.0.0.0:44567               0.0.0.0:*                   LISTEN      1713/rpc.statd      
tcp        0      0 0.0.0.0:10050               0.0.0.0:*                   LISTEN      1965/zabbix_agentd  
tcp        0      0 172.172.230.xxx:3306        0.0.0.0:*                   LISTEN      31849/mysqld        
tcp        0      0 0.0.0.0:111                 0.0.0.0:*                   LISTEN      1576/rpcbind        
tcp        0      0 172.172.230.xxx:46327       172.172.100.3:80            TIME_WAIT   -                   
tcp        0      0 172.172.230.xxx:46329       172.172.100.3:80            TIME_WAIT   -                   
tcp        0     52 172.172.230.xxx:22          172.172.173.222:50043       ESTABLISHED 6095/sshd           
tcp        0      0 172.172.230.xxx:46326       172.172.100.3:80            TIME_WAIT   -                   
tcp        0      0 172.172.230.xxx:5401        172.172.100.3:443           TIME_WAIT   -                   
tcp        0      0 :::22                       :::*                        LISTEN      1904/sshd           
tcp        0      0 ::1:631                     :::*                        LISTEN      1750/cupsd          
tcp        0      0 :::11776                    :::*                        LISTEN      1713/rpc.statd      
tcp        0      0 :::10050                    :::*                        LISTEN      1965/zabbix_agentd  
tcp        0      0 :::111                      :::*                        LISTEN      1576/rpcbind       
复制<br>对上述返回内容进一步解释如下：<br><br>Proto:协议名（tcp协议还是udp协议)<br>recv-Q: 网络接收队列<br>表示收到的数据已经在本地接收缓冲，但是还有多少没有被进程取走，recv() 如果接收队列Recv-Q一直处于阻塞状态，可能是遭受了拒绝服务 denial-of-service 攻击。<br>send-Q: 网路发送队列 对方没有收到的数据或者说没有Ack的,还是本地缓冲区. 如果发送队列Send-Q不能很快的清零，可能是有应用向外发送数据包过快，或者是对方接收数据包不够快。<br>这两个值通常应该为0，如果不为0可能是有问题的。packets在两个队列里都不应该有堆积状态。可接受短暂的非0情况。<br>从步骤一的结果中可以看到22端口对应的链路的 send-Q中堆积了大量的数据包 ,可以判定是发送数据给目的地址的时候出现了阻塞的问题，导致了包堆积在本地缓存中，不能成功发出去。<br><br>
<br>Local Address 部分的0.0.0.0:22 表示监听服务器上所有ip地址的所有(0.0.0.0表示本地所有ip)，比如你的服务器是有172.172.230.210和 172.172.230.11两个ip地址，那么0.0.0.0:22此时表示监听172.172.230.210,172.172.230.xxx,127.0.0.1三个地址的22端口<br>

<br>:::22 这个也表示监听本地所有ip的22端口，跟上面的区别是这里表示的是IPv6地址，上面的0.0.0.0表示的是本地所有IPv4地址 NOTE “:::” 这三个: 的前两个"::"，是"0:0:0:0:0:0:0:0"的缩写，相当于IPv6的"0.0.0.0"，就是本机的所有IPv6地址，第三个:是IP和端口的分隔符<br>

<br>127.0.0.1:631 这个表示监听本机的loopback地址的631端口(如果某个服务只监听了回环地址，那么只能在本机进行访问，无法通过tcp/ip 协议进行远程访问)<br>

<br>::1:631 这个表示监听IPv6的回环地址的631端口,::1这个表示IPv6的loopback地址<br>

<br>172.172.230.xxx:3306 这里我们看到我们的mysqld进程监听的是172.172.230.xxx的3306端口,这是因为我们在启动的时候指定了bind_address=172.172.230.xxx参数，如果不指定bind_address的话，mysqld默认监听:::3306(本机所有ip地址的3306端口 -IPv6)<br>

<br><br>与本机端口通信的外部socket。显示规则与Local Address相同<br><br>共有11种链路状态 + Unknown，共计12种state值，前面11种是按照TCP连接建立的三次握手和TCP连接断开的四次挥手过程来描述的。<br><br>备注<br>
<br>SYN: (同步序列编号,Synchronize Sequence Numbers)该标志仅在三次握手建立TCP连接时有效。表示一个新的TCP连接请求。
<br>ACK: (确认编号,Acknowledgement Number)是对TCP请求的确认标志,同时提示对端系统已经成功接收所有数据。
<br>FIN: (结束标志,FINish)用来结束一个TCP回话.但对应端口仍处于开放状态,准备接收后续数据。
<br><br>PID即进程id，Program即使用该socket的应用程序<br><br>netstat -t/-u/-l/-r/-n<br>
【显示网络相关信息，-t: TCP 协议，-u: UDP 协议，-l:监听，-r:路由，-n:显示 IP 地址和端口号】<br>注：以下返回内容中，我用xxx注释掉了一部分敏感ip地址。<br><br><br>netstat -ano
复制<br>注：删减了部分结果<br><br>netstat -tlun
复制<br><br>netstat -rn
复制<br><br>netstat -a 
复制<br><br>netstat -at
复制<br><br>netstat -au 
复制<br><br>netstat -lt  
复制<br><br>netstat -lu 
复制<br><br>以ssh为例<br>netstat -ap | grep ssh 
复制<br><br><br>netstat -anlp|grep 80|grep tcp|awk '{print $5}'|awk -F: '{print $1}'|sort|uniq -c|sort -nr|head -n20
 
netstat -ant |awk '/:80/{split($5,ip,”:”);++A[ip[1]]}END{for(i in A) print A[i],i}' |sort -rn|head -n20
复制<br><br>netstat -n|grep TIME_WAIT|awk '{print $5}'|sort|uniq -c|sort -rn|head -n20
复制<br><br>netstat -an | grep SYN | awk '{print $5}' | awk -F: '{print $1}' | sort | uniq -c | sort -nr | more
复制<br><br>netstat -ntlp | grep 80 | awk '{print $7}' | cut -d/ -f1
复制]]></description><link>01、通用基础\02、计算机网络\10、工具-netstat查看服务及监听端口详解.html</link><guid isPermaLink="false">01、通用基础/02、计算机网络/10、工具-netstat查看服务及监听端口详解.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:43 GMT</pubDate></item><item><title><![CDATA[01、线性表 - 数组和矩阵]]></title><description><![CDATA[ 
 ]]></description><link>01、通用基础\04、数据结构算法\01、数据结构\01、线性表-数组和矩阵.html</link><guid isPermaLink="false">01、通用基础/04、数据结构算法/01、数据结构/01、线性表 - 数组和矩阵.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:43 GMT</pubDate></item><item><title><![CDATA[02、线性表 - 链表]]></title><description><![CDATA[ 
 ]]></description><link>01、通用基础\04、数据结构算法\01、数据结构\02、线性表-链表.html</link><guid isPermaLink="false">01、通用基础/04、数据结构算法/01、数据结构/02、线性表 - 链表.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:44 GMT</pubDate></item><item><title><![CDATA[03、线性表(散列) - 哈希表]]></title><description><![CDATA[ 
 ]]></description><link>01、通用基础\04、数据结构算法\01、数据结构\03、线性表(散列)-哈希表.html</link><guid isPermaLink="false">01、通用基础/04、数据结构算法/01、数据结构/03、线性表(散列) - 哈希表.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:43 GMT</pubDate></item><item><title><![CDATA[一. 初识算法]]></title><description><![CDATA[ 
 <br><br><br>定义<br>在数学和计算机科学领域，算法是一系列有限的严谨指令，通常用于解决一类特定问题或执行计算<br>
In mathematics and computer science, an algorithm (/ˈælɡərɪðəm/) is a finite sequence of rigorous instructions, typically used to solve a class of specific problems or to perform a computation.<a href="\#fn-1-33dbe2937a530ff5" class="footnote-link" target="_self" rel="noopener">[1]</a>
<br>Introduction to Algorithm<a href="\#fn-2-33dbe2937a530ff5" class="footnote-link" target="_self" rel="noopener">[2]</a><br>不正式的说，算法就是任何定义优良的计算过程：接收一些值作为输入，在有限的时间内，产生一些值作为输出。<br>
Informally, an algorithm is any well-defined computational procedure that takes some value, or set of values, as input and produces some value, or set of values, as output in a finite amount of time.
<br><br>定义<br>在计算机科学领域，数据结构是一种数据组织、管理和存储格式，通常被选择用来高效访问数据<br>
In computer science, a data structure is a data organization, management, and storage format that is usually chosen for efficient access to data
<br>Introduction to Algorithm<a href="\#fn-2-33dbe2937a530ff5" class="footnote-link" target="_self" rel="noopener">[2-1]</a><br>数据结构是一种存储和组织数据的方式，旨在便于访问和修改<br>
A data structure is a way to store and organize data in order to facilitate access and modifications
<br>接下来我们通过对一个非常著名的二分查找算法的讲解来认识一下算法<br><br>二分查找算法也称折半查找，是一种非常高效的工作于有序数组的查找算法。后续的课程中还会学习更多的查找算法，但在此之前，不妨用它作为入门。<br><br>需求：在有序数组  内，查找值 <br>
<br>如果找到返回索引
<br>如果找不到返回 
<br><br>java 实现<br>public static int binarySearch(int[] a, int target) {
    int i = 0, j = a.length - 1;
    while (i &lt;= j) {
        int m = (i + j) &gt;&gt;&gt; 1;
        if (target &lt; a[m]) {			// 在左边
            j = m - 1;
        } else if (a[m] &lt; target) {		// 在右边
            i = m + 1;
        } else {
            return m;
        }
    }
    return -1;
}
复制<br>
<br> 对应着搜索区间 （注意是闭合的区间）， 意味着搜索区间内还有未比较的元素， 指向的元素也可能是比较的目标

<br>思考：如果不加  行不行？
<br>回答：不行，因为这意味着  指向的元素会漏过比较


<br> 对应着中间位置，中间位置左边和右边的元素可能不相等（差一个），不会影响结果
<br>如果某次未找到，那么缩小后的区间内不包含 
<br><br>另一种写法<br>public static int binarySearch(int[] a, int target) {
    int i = 0, j = a.length;
    while (i &lt; j) {
        int m = (i + j) &gt;&gt;&gt; 1;
        if (target &lt; a[m]) {			// 在左边
            j = m;
        } else if (a[m] &lt; target) {		// 在右边
            i = m + 1;
        } else {
            return m;
        }
    }
    return -1;
}
复制<br>
<br> 对应着搜索区间 （注意是左闭右开的区间）， 意味着搜索区间内还有未比较的元素， 指向的一定不是查找目标

<br>思考：为啥这次不加  的条件了？
<br>回答：这回  指向的不是查找目标，如果还加  条件，就意味着  指向的还会再次比较，找不到时，会死循环


<br>如果某次要缩小右边界，那么 ，因为此时的  已经不是查找目标了
<br><br>时间复杂度<br>下面的查找算法也能得出与之前二分查找一样的结果，那你能说出它差在哪里吗？<br>public static int search(int[] a, int k) {
    for (
        int i = 0;
        i &lt; a.length;
        i++
    ) {
        if (a[i] == k) {
            return i;
        }
    }
    return -1;
}
复制<br>考虑最坏情况下（没找到）例如 [1,2,3,4] 查找 5<br>
<br>int i = 0 只执行一次
<br>i &lt; a.length 受数组元素个数  的影响，比较  次
<br>i++ 受数组元素个数  的影响，自增  次
<br>a[i] == k 受元素个数  的影响，比较  次
<br>return -1，执行一次
<br>粗略认为每行代码执行时间是 ，假设  那么<br>
<br>总执行时间是 
<br>可以推导出更一般地公式为， 
<br>如果套用二分查找算法，还是 [1,2,3,4] 查找 5<br>public static int binarySearch(int[] a, int target) {
    int i = 0, j = a.length - 1;
    while (i &lt;= j) {
        int m = (i + j) &gt;&gt;&gt; 1;
        if (target &lt; a[m]) {			// 在左边
            j = m - 1;
        } else if (a[m] &lt; target) {		// 在右边
            i = m + 1;
        } else {
            return m;
        }
    }
    return -1;
}
复制<br>
<br>
int i = 0, j = a.length - 1 各执行 1 次

<br>
i &lt;= j 比较  再加 1 次

<br>
(i + j) &gt;&gt;&gt; 1 计算  次

<br>
接下来 if() else if() else 会执行  次，分别为

<br>if 比较
<br>else if 比较
<br>else if 比较成立后的赋值语句


<br>
return -1，执行一次

<br>结果：<br>
<br>总执行时间为 
<br>更一般地公式为 
<br>
注意：
左侧未找到和右侧未找到结果不一样，这里不做分析
<br>两个算法比较，可以看到  在较小的时候，二者花费的次数差不多<br><img style="zoom:50%;" alt="image-20221108095747933" src="\imgs\image-20221108095747933.png" referrerpolicy="no-referrer"><br>但随着  越来越大，比如说  时，用二分查找算法（红色）也就是 ，而蓝色算法则需要 <br><img style="zoom:50%;" alt="image-20221108100014451" src="\imgs\image-20221108100014451.png" referrerpolicy="no-referrer"><br>
画图采用的是 <a data-tooltip-position="top" aria-label="https://www.desmos.com/calculator?lang=zh-CN" rel="noopener" class="external-link" href="https://www.desmos.com/calculator?lang=zh-CN" target="_blank">Desmos | 图形计算器</a>
<br>计算机科学中，时间复杂度是用来衡量：一个算法的执行，随数据规模增大，而增长的时间成本<br>
<br>不依赖于环境因素
<br>如何表示时间复杂度呢？<br>
<br>
假设算法要处理的数据规模是 ，代码总的执行行数用函数  来表示，例如：

<br>线性查找算法的函数 
<br>二分查找算法的函数 


<br>
为了对  进行化简，应当抓住主要矛盾，找到一个变化趋势与之相近的表示法

<br>大  表示法<a href="\#fn-4-33dbe2937a530ff5" class="footnote-link" target="_self" rel="noopener">[4]</a><br>“.\imgs\image-20221108103846566.png” could not be found.<br>其中<br>
<br> 都为一个常数
<br> 是实际执行代码行数与 n 的函数
<br> 是经过化简，变化趋势与  一致的 n 的函数
<br>渐进上界<br>渐进上界（asymptotic upper bound）：从某个常数 开始， 总是位于  上方，那么记作 <br>
<br>代表算法执行的最差情况
<br>例1<br>
<br> 
<br>
<br>取 ，在 之后， 可以作为  的渐进上界，因此表示法写作 
<br>例2<br>
<br>
<br>
<br>
<br>已知  来说，求 <br>
<br>表达式中相乘的常量，可以省略，如

<br> 中的 


<br>多项式中数量规模更小（低次项）的表达式，如

<br> 中的 
<br> 中的 


<br>不同底数的对数，渐进上界可以用一个对数函数  表示

<br>例如： 可以替换为 ，因为 ，相乘的常量  可以省略


<br>类似的，对数的常数次幂可省略

<br>如： 


<br>常见大  表示法<br>“.\imgs\image-20221108114915524.png” could not be found.<br> 按时间复杂度从低到高<br>
<br>黑色横线 ，常量时间，意味着算法时间并不随数据规模而变化
<br>绿色 ，对数时间
<br>蓝色 ，线性时间，算法时间与数据规模成正比
<br>橙色 ，拟线性时间
<br>红色  平方时间
<br>黑色朝上  指数时间
<br>没画出来的 
<br>渐进下界<br>渐进下界（asymptotic lower bound）：从某个常数 开始， 总是位于  下方，那么记作 <br>渐进紧界<br>渐进紧界（asymptotic tight bounds）：从某个常数 开始， 总是在  和  之间，那么记作 <br>空间复杂度<br>与时间复杂度类似，一般也使用大  表示法来衡量：一个算法执行随数据规模增大，而增长的额外空间成本<br>public static int binarySearchBasic(int[] a, int target) {
    int i = 0, j = a.length - 1;    // 设置指针和初值
    while (i &lt;= j) {                // i~j 范围内有东西
        int m = (i + j) &gt;&gt;&gt; 1;
        if(target &lt; a[m]) {         // 目标在左边
            j = m - 1;
        } else if (a[m] &lt; target) { // 目标在右边
            i = m + 1;
        } else {                    // 找到了
            return m;
        }
    }
    return -1;
}
复制<br>二分查找性能<br>下面分析二分查找算法的性能<br>时间复杂度<br>
<br>最坏情况：
<br>最好情况：如果待查找元素恰好在数组中央，只需要循环一次 
<br>空间复杂度<br>
<br>需要常数个指针 ，因此额外占用的空间是  
<br><br>public static int binarySearchBalance(int[] a, int target) {
    int i = 0, j = a.length;
    while (1 &lt; j - i) {
        int m = (i + j) &gt;&gt;&gt; 1;
        if (target &lt; a[m]) {
            j = m;
        } else {
            i = m;
        }
    }
    return (a[i] == target) ? i : -1;
}
复制<br>思想：<br>
<br>左闭右开的区间， 指向的可能是目标，而  指向的不是目标
<br>不奢望循环内通过  找出目标, 缩小区间直至剩 1 个, 剩下的这个可能就是要找的（通过 ）

<br> 的含义是，在范围内待比较的元素个数 &gt; 1


<br>改变  边界时，它指向的可能是目标，因此不能 
<br>循环内的平均比较次数减少了
<br>时间复杂度 
<br><br>private static int binarySearch0(long[] a, int fromIndex, int toIndex,
                                     long key) {
    int low = fromIndex;
    int high = toIndex - 1;

    while (low &lt;= high) {
        int mid = (low + high) &gt;&gt;&gt; 1;
        long midVal = a[mid];

        if (midVal &lt; key)
            low = mid + 1;
        else if (midVal &gt; key)
            high = mid - 1;
        else
            return mid; // key found
    }
    return -(low + 1);  // key not found.
}
复制<br>
<br>例如  要插入  那么就是找到一个位置，这个位置左侧元素都比它小

<br>等循环结束，若没找到，low 左侧元素肯定都比 target 小，因此 low 即插入点


<br>插入点取负是为了与找到情况区分
<br>-1 是为了把索引 0 位置的插入点与找到的情况进行区分
<br><br>有时我们希望返回的是最左侧的重复元素，如果用 Basic 二分查找<br>
<br>
对于数组 ，查找元素4，结果是索引3

<br>
对于数组 ，查找元素4，结果也是索引3，并不是最左侧的元素

<br>public static int binarySearchLeftmost1(int[] a, int target) {
    int i = 0, j = a.length - 1;
    int candidate = -1;
    while (i &lt;= j) {
        int m = (i + j) &gt;&gt;&gt; 1;
        if (target &lt; a[m]) {
            j = m - 1;
        } else if (a[m] &lt; target) {
            i = m + 1;
        } else {
            candidate = m; // 记录候选位置
            j = m - 1;     // 继续向左
        }
    }
    return candidate;
}
复制<br>如果希望返回的是最右侧元素<br>public static int binarySearchRightmost1(int[] a, int target) {
    int i = 0, j = a.length - 1;
    int candidate = -1;
    while (i &lt;= j) {
        int m = (i + j) &gt;&gt;&gt; 1;
        if (target &lt; a[m]) {
            j = m - 1;
        } else if (a[m] &lt; target) {
            i = m + 1;
        } else {
            candidate = m; // 记录候选位置
            i = m + 1;	   // 继续向右
        }
    }
    return candidate;
}
复制<br>应用<br>对于 Leftmost 与 Rightmost，可以返回一个比 -1 更有用的值<br>Leftmost 改为<br>public static int binarySearchLeftmost(int[] a, int target) {
    int i = 0, j = a.length - 1;
    while (i &lt;= j) {
        int m = (i + j) &gt;&gt;&gt; 1;
        if (target &lt;= a[m]) {
            j = m - 1;
        } else {
            i = m + 1;
        }
    }
    return i; 
}
复制<br>
<br>leftmost 返回值的另一层含义： 的元素个数
<br>小于等于中间值，都要向左找
<br>Rightmost 改为<br>public static int binarySearchRightmost(int[] a, int target) {
    int i = 0, j = a.length - 1;
    while (i &lt;= j) {
        int m = (i + j) &gt;&gt;&gt; 1;
        if (target &lt; a[m]) {
            j = m - 1;
        } else {
            i = m + 1;
        }
    }
    return i - 1;
}
复制<br>
<br>大于等于中间值，都要向右找
<br>几个名词<br>“imgs/image-20221125174155058.png” could not be found.<br>范围查询：<br>
<br>查询 ，
<br>查询 ，
<br>查询 ，$rightmost(4) + 1 .. \infty $
<br>查询 ， 
<br>查询 ，
<br>查询 ，
<br>求排名：<br>
<br> 可以不存在，如：
<br> 也可以存在，如：
<br>求前任（predecessor）：<br>
<br>，前任 
<br>，前任 
<br>求后任（successor）：<br>
<br>，后任 
<br>，后任 
<br>求最近邻居：<br>
<br>前任和后任距离更近者
<br><br><br><br>定义<br>在计算机科学中，数组是由一组元素（值或变量）组成的数据结构，每个元素有至少一个索引或键来标识<br>
In computer science, an array is a data structure consisting of a collection of elements (values or variables), each identified by at least one array index or key
<br>因为数组内的元素是连续存储的，所以数组中元素的地址，可以通过其索引计算出来，例如：<br>int[] array = {1,2,3,4,5}
复制<br>知道了数组的数据起始地址 ，就可以由公式  计算出索引  元素的地址<br>
<br> 即索引，在 Java、C 等语言都是从 0 开始
<br> 是每个元素占用字节，例如  占 ， 占 
<br>小测试<br>byte[] array = {1,2,3,4,5}
复制<br>已知 array 的数据的起始地址是 0x7138f94c8，那么元素 3 的地址是什么？<br>
答：0x7138f94c8 + 2 * 1 = 0x7138f94ca
<br>空间占用<br>Java 中数组结构为<br>
<br>8 字节 markword
<br>4 字节 class 指针（压缩 class 指针的情况）
<br>4 字节 数组大小（决定了数组最大容量是 ）
<br>数组元素 + 对齐字节（java 中所有对象大小都是 8 字节的整数倍<a href="\#fn-5-33dbe2937a530ff5" class="footnote-link" target="_self" rel="noopener">[5]</a>，不足的要用对齐字节补足）
<br>例如<br>int[] array = {1, 2, 3, 4, 5};
复制<br>的大小为 40 个字节，组成如下<br>8 + 4 + 4 + 5*4 + 4(alignment)
复制<br>随机访问性能<br>即根据索引查找元素，时间复杂度是 <br><br>java 版本<br>public class DynamicArray implements Iterable&lt;Integer&gt; {
    private int size = 0; // 逻辑大小
    private int capacity = 8; // 容量
    private int[] array = {};


    /**
     * 向最后位置 [size] 添加元素
     *
     * @param element 待添加元素
     */
    public void addLast(int element) {
        add(size, element);
    }

    /**
     * 向 [0 .. size] 位置添加元素
     *
     * @param index   索引位置
     * @param element 待添加元素
     */
    public void add(int index, int element) {
        checkAndGrow();

        // 添加逻辑
        if (index &gt;= 0 &amp;&amp; index &lt; size) {
            // 向后挪动, 空出待插入位置
            System.arraycopy(array, index,
                    array, index + 1, size - index);
        }
        array[index] = element;
        size++;
    }

    private void checkAndGrow() {
        // 容量检查
        if (size == 0) {
            array = new int[capacity];
        } else if (size == capacity) {
            // 进行扩容, 1.5 1.618 2
            capacity += capacity &gt;&gt; 1;
            int[] newArray = new int[capacity];
            System.arraycopy(array, 0,
                    newArray, 0, size);
            array = newArray;
        }
    }

    /**
     * 从 [0 .. size) 范围删除元素
     *
     * @param index 索引位置
     * @return 被删除元素
     */
    public int remove(int index) { // [0..size)
        int removed = array[index];
        if (index &lt; size - 1) {
            // 向前挪动
            System.arraycopy(array, index + 1,
                    array, index, size - index - 1);
        }
        size--;
        return removed;
    }


    /**
     * 查询元素
     *
     * @param index 索引位置, 在 [0..size) 区间内
     * @return 该索引位置的元素
     */
    public int get(int index) {
        return array[index];
    }

    /**
     * 遍历方法1
     *
     * @param consumer 遍历要执行的操作, 入参: 每个元素
     */
    public void foreach(Consumer&lt;Integer&gt; consumer) {
        for (int i = 0; i &lt; size; i++) {
            // 提供 array[i]
            // 返回 void
            consumer.accept(array[i]);
        }
    }

    /**
     * 遍历方法2 - 迭代器遍历
     */
    @Override
    public Iterator&lt;Integer&gt; iterator() {
        return new Iterator&lt;Integer&gt;() {
            int i = 0;

            @Override
            public boolean hasNext() { // 有没有下一个元素
                return i &lt; size;
            }

            @Override
            public Integer next() { // 返回当前元素,并移动到下一个元素
                return array[i++];
            }
        };
    }

    /**
     * 遍历方法3 - stream 遍历
     *
     * @return stream 流
     */
    public IntStream stream() {
        return IntStream.of(Arrays.copyOfRange(array, 0, size));
    }
}
复制<br>
<br>这些方法实现，都简化了 index 的有效性判断，假设输入的 index 都是合法的
<br>插入或删除性能<br>头部位置，时间复杂度是 <br>中间位置，时间复杂度是 <br>尾部位置，时间复杂度是 （均摊来说）<br><br>int[][] array = {
    {11, 12, 13, 14, 15},
    {21, 22, 23, 24, 25},
    {31, 32, 33, 34, 35},
};
复制<br>内存图如下<br><img style="zoom:67%;" alt="image-20221104114132056" src="\imgs\image-20221104114132056.png" referrerpolicy="no-referrer"><br>
<br>
二维数组占 32 个字节，其中 array[0]，array[1]，array[2] 三个元素分别保存了指向三个一维数组的引用

<br>
三个一维数组各占 40 个字节

<br>
它们在内层布局上是连续的

<br>更一般的，对一个二维数组 <br>
<br> 是外层数组的长度，可以看作 row 行
<br> 是内层数组的长度，可以看作 column 列
<br>当访问 ，时，就相当于

<br>先找到第  个内层数组（行）
<br>再找到此内层数组中第  个元素（列）


<br>小测试<br>Java 环境下（不考虑类指针和引用压缩，此为默认情况），有下面的二维数组<br>byte[][] array = {
    {11, 12, 13, 14, 15},
    {21, 22, 23, 24, 25},
    {31, 32, 33, 34, 35},
};
复制<br>已知 array 对象起始地址是 0x1000，那么 23 这个元素的地址是什么？<br>
答：

<br>起始地址 0x1000
<br>外层数组大小：16字节对象头 + 3元素 * 每个引用4字节 + 4 对齐字节 = 32 = 0x20
<br>第一个内层数组大小：16字节对象头 + 5元素 * 每个byte1字节 + 3 对齐字节 = 24 = 0x18
<br>第二个内层数组，16字节对象头 = 0x10，待查找元素索引为 2
<br>最后结果 = 0x1000 + 0x20 + 0x18 + 0x10 + 2*1 = 0x104a

<br><br>这里只讨论空间局部性<br>
<br>cpu 读取内存（速度慢）数据后，会将其放入高速缓存（速度快）当中，如果后来的计算再用到此数据，在缓存中能读到的话，就不必读内存了
<br>缓存的最小存储单位是缓存行（cache line），一般是 64 bytes，一次读的数据少了不划算啊，因此最少读 64 bytes 填满一个缓存行，因此读入某个数据时也会读取其临近的数据，这就是所谓空间局部性
<br>对效率的影响<br>比较下面 ij 和 ji 两个方法的执行效率<br>int rows = 1000000;
int columns = 14;
int[][] a = new int[rows][columns];

StopWatch sw = new StopWatch();
sw.start("ij");
ij(a, rows, columns);
sw.stop();
sw.start("ji");
ji(a, rows, columns);
sw.stop();
System.out.println(sw.prettyPrint());
复制<br>ij 方法<br>public static void ij(int[][] a, int rows, int columns) {
    long sum = 0L;
    for (int i = 0; i &lt; rows; i++) {
        for (int j = 0; j &lt; columns; j++) {
            sum += a[i][j];
        }
    }
    System.out.println(sum);
}
复制<br>ji 方法<br>public static void ji(int[][] a, int rows, int columns) {
    long sum = 0L;
    for (int j = 0; j &lt; columns; j++) {
        for (int i = 0; i &lt; rows; i++) {
            sum += a[i][j];
        }
    }
    System.out.println(sum);
}
复制<br>执行结果<br>0
0
StopWatch '': running time = 96283300 ns
---------------------------------------------
ns         %     Task name
---------------------------------------------
016196200  017%  ij
080087100  083%  ji
复制<br>可以看到 ij 的效率比 ji 快很多，为什么呢？<br>
<br>缓存是有限的，当新数据来了后，一些旧的缓存行数据就会被覆盖
<br>如果不能充分利用缓存的数据，就会造成效率低下
<br>以 ji 执行为例，第一次内循环要读入  这条数据，由于局部性原理，读入  的同时也读入了 ，如图所示<br>“.\imgs\image-20221104164329026.png” could not be found.<br>但很遗憾，第二次内循环要的是  这条数据，缓存中没有，于是再读入了下图的数据<br>“.\imgs\image-20221104164716282.png” could not be found.<br>这显然是一种浪费，因为  包括  这些数据虽然读入了缓存，却没有及时用上，而缓存的大小是有限的，等执行到第九次内循环时<br>“.\imgs\image-20221104164947154.png” could not be found.<br>缓存的第一行数据已经被新的数据  覆盖掉了，以后如果再想读，比如 ，又得到内存去读了<br>同理可以分析 ij 函数则能充分利用局部性原理加载到的缓存数据<br>举一反三<br>
<br>
I/O 读写时同样可以体现局部性原理

<br>
数组可以充分利用局部性原理，那么链表呢？

答：链表不行，因为链表的元素并非相邻存储


<br><br>java 中对数组元素的读写都有越界检查，类似于下面的代码<br>bool is_within_bounds(int index) const        
{ 
    return 0 &lt;= index &amp;&amp; index &lt; length(); 
}
复制<br>
<br>代码位置：openjdk\src\hotspot\share\oops\arrayOop.hpp
<br>只不过此检查代码，不需要由程序员自己来调用，JVM 会帮我们调用<br><br><br>定义<br>在计算机科学中，链表是数据元素的线性集合，其每个元素都指向下一个元素，元素存储上并不连续<br>
In computer science, a linked list is a linear collection of data elements whose order is not given by their physical placement in memory. Instead, each element points to the next. 
<br>可以分类为<a href="\#fn-6-33dbe2937a530ff5" class="footnote-link" target="_self" rel="noopener">[6]</a><br>
<br>单向链表，每个元素只知道其下一个元素是谁
<br>“.\imgs\image-20221110083407176.png” could not be found.<br>
<br>双向链表，每个元素知道其上一个元素和下一个元素
<br>“.\imgs\image-20221110083427372.png” could not be found.<br>
<br>循环链表，通常的链表尾节点 tail 指向的都是 null，而循环链表的 tail 指向的是头节点 head
<br>“.\imgs\image-20221110083538273.png” could not be found.<br>链表内还有一种特殊的节点称为哨兵（Sentinel）节点，也叫做哑元（ Dummy）节点，它不存储数据，通常用作头尾，用来简化边界判断，如下图所示<br>“.\imgs\image-20221110084611550.png” could not be found.<br>随机访问性能<br>根据 index 查找，时间复杂度 <br>插入或删除性能<br>
<br>起始位置：
<br>结束位置：如果已知 tail 尾节点是 ，不知道 tail 尾节点是 
<br>中间位置：根据 index 查找时间 + 
<br><br>根据单向链表的定义，首先定义一个存储 value 和 next 指针的类 Node，和一个描述头部节点的引用<br>public class SinglyLinkedList {
    
    private Node head; // 头部节点
    
    private static class Node { // 节点类
        int value;
        Node next;

        public Node(int value, Node next) {
            this.value = value;
            this.next = next;
        }
    }
}
复制<br>
<br>Node 定义为内部类，是为了对外隐藏实现细节，没必要让类的使用者关心 Node 结构
<br>定义为 static 内部类，是因为 Node 不需要与 SinglyLinkedList 实例相关，多个 SinglyLinkedList实例能共用 Node 类定义
<br>头部添加<br>public class SinglyLinkedList {
    // ...
    public void addFirst(int value) {
		this.head = new Node(value, this.head);
    }
}
复制<br>
<br>如果 this.head == null，新增节点指向 null，并作为新的 this.head
<br>如果 this.head != null，新增节点指向原来的 this.head，并作为新的 this.head

<br>注意赋值操作执行顺序是从右到左


<br>while 遍历<br>public class SinglyLinkedList {
    // ...
    public void loop() {
        Node curr = this.head;
        while (curr != null) {
            // 做一些事
            curr = curr.next;
        }
    }
}
复制<br>for 遍历<br>public class SinglyLinkedList {
    // ...
    public void loop() {
        for (Node curr = this.head; curr != null; curr = curr.next) {
            // 做一些事
        }
    }
}
复制<br>
<br>以上两种遍历都可以把要做的事以 Consumer 函数的方式传递进来

<br>Consumer 的规则是一个参数，无返回值，因此像 System.out::println 方法等都是 Consumer
<br>调用 Consumer 时，将当前节点 curr.value 作为参数传递给它


<br>迭代器遍历<br>public class SinglyLinkedList implements Iterable&lt;Integer&gt; {
    // ...
    private class NodeIterator implements Iterator&lt;Integer&gt; {
        Node curr = head;
        
        public boolean hasNext() {
            return curr != null;
        }

        public Integer next() {
            int value = curr.value;
            curr = curr.next;
            return value;
        }
    }
    
    public Iterator&lt;Integer&gt; iterator() {
        return new NodeIterator();
    }
}
复制<br>
<br>hasNext 用来判断是否还有必要调用 next
<br>next 做两件事

<br>返回当前节点的 value
<br>指向下一个节点


<br>NodeIterator 要定义为非 static 内部类，是因为它与 SinglyLinkedList 实例相关，是对某个 SinglyLinkedList 实例的迭代
<br>递归遍历<br>public class SinglyLinkedList implements Iterable&lt;Integer&gt; {
    // ...
    public void loop() {
        recursion(this.head);
    }

    private void recursion(Node curr) {
        if (curr == null) {
            return;
        }
        // 前面做些事
        recursion(curr.next);
        // 后面做些事
    }
}
复制<br>尾部添加<br>public class SinglyLinkedList {
    // ...
    private Node findLast() {
        if (this.head == null) {
            return null;
        }
        Node curr;
        for (curr = this.head; curr.next != null; ) {
            curr = curr.next;
        }
        return curr;
    }
    
    public void addLast(int value) {
        Node last = findLast();
        if (last == null) {
            addFirst(value);
            return;
        }
        last.next = new Node(value, null);
    }
}
复制<br>
<br>注意，找最后一个节点，终止条件是 curr.next == null 
<br>分成两个方法是为了代码清晰，而且 findLast() 之后还能复用
<br>尾部添加多个<br>public class SinglyLinkedList {
    // ...
	public void addLast(int first, int... rest) {
        
        Node sublist = new Node(first, null);
        Node curr = sublist;
        for (int value : rest) {
            curr.next = new Node(value, null);
            curr = curr.next;
        }
        
        Node last = findLast();
        if (last == null) {
            this.head = sublist;
            return;
        }
        last.next = sublist;
    }
}
复制<br>
<br>先串成一串 sublist
<br>再作为一个整体添加
<br>根据索引获取<br>public class SinglyLinkedList {
    // ...
	private Node findNode(int index) {
        int i = 0;
        for (Node curr = this.head; curr != null; curr = curr.next, i++) {
            if (index == i) {
                return curr;
            }
        }
        return null;
    }
    
    private IllegalArgumentException illegalIndex(int index) {
        return new IllegalArgumentException(String.format("index [%d] 不合法%n", index));
    }
    
    public int get(int index) {
        Node node = findNode(index);
        if (node != null) {
            return node.value;
        }
        throw illegalIndex(index);
    }
}
复制<br>
<br>同样，分方法可以实现复用
<br>插入<br>public class SinglyLinkedList {
    // ...
	public void insert(int index, int value) {
        if (index == 0) {
            addFirst(value);
            return;
        }
        Node prev = findNode(index - 1); // 找到上一个节点
        if (prev == null) { // 找不到
            throw illegalIndex(index);
        }
        prev.next = new Node(value, prev.next);
    }
}
复制<br>
<br>插入包括下面的删除，都必须找到上一个节点
<br>删除<br>public class SinglyLinkedList {
    // ...
	public void remove(int index) {
        if (index == 0) {
            if (this.head != null) {
                this.head = this.head.next;
                return;
            } else {
                throw illegalIndex(index);
            }
        }
        Node prev = findNode(index - 1);
        Node curr;
        if (prev != null &amp;&amp; (curr = prev.next) != null) {
            prev.next = curr.next;
        } else {
            throw illegalIndex(index);
        }
    }
}
复制<br>
<br>第一个 if 块对应着 removeFirst 情况
<br>最后一个 if 块对应着至少得两个节点的情况

<br>不仅仅判断上一个节点非空，还要保证当前节点非空


<br><br>观察之前单向链表的实现，发现每个方法内几乎都有判断是不是 head 这样的代码，能不能简化呢？<br>用一个不参与数据存储的特殊 Node 作为哨兵，它一般被称为哨兵或哑元，拥有哨兵节点的链表称为带头链表<br>public class SinglyLinkedListSentinel {
    // ...
    private Node head = new Node(Integer.MIN_VALUE, null);
}
复制<br>
<br>具体存什么值无所谓，因为不会用到它的值
<br>加入哨兵节点后，代码会变得比较简单，先看几个工具方法<br>public class SinglyLinkedListSentinel {
    // ...
    
    // 根据索引获取节点
    private Node findNode(int index) {
        int i = -1;
        for (Node curr = this.head; curr != null; curr = curr.next, i++) {
            if (i == index) {
                return curr;
            }
        }
        return null;
    }
    
    // 获取最后一个节点
    private Node findLast() {
        Node curr;
        for (curr = this.head; curr.next != null; ) {
            curr = curr.next;
        }
        return curr;
    }
}
复制<br>
<br>findNode 与之前类似，只是 i 初始值设置为 -1 对应哨兵，实际传入的 index 也是 
<br>findLast 绝不会返回 null 了，就算没有其它节点，也会返回哨兵作为最后一个节点
<br>这样，代码简化为<br>public class SinglyLinkedListSentinel {
    // ...
    
    public void addLast(int value) {
        Node last = findLast();
        /*
        改动前
        if (last == null) {
            this.head = new Node(value, null);
            return;
        }
        */
        last.next = new Node(value, null);
    }
    
    public void insert(int index, int value) {
        /*
        改动前
        if (index == 0) {
            this.head = new Node(value, this.head);
            return;
        }
        */
        // index 传入 0 时，返回的是哨兵
        Node prev = findNode(index - 1);
        if (prev != null) {
            prev.next = new Node(value, prev.next);
        } else {
            throw illegalIndex(index);
        }
    }
    
    public void remove(int index) {
        /*
        改动前
        if (index == 0) {
            if (this.head != null) {
                this.head = this.head.next;
                return;
            } else {
                throw illegalIndex(index);
            }
        }
        */
        // index 传入 0 时，返回的是哨兵
        Node prev = findNode(index - 1);
        Node curr;
        if (prev != null &amp;&amp; (curr = prev.next) != null) {
            prev.next = curr.next;
        } else {
            throw illegalIndex(index);
        }
    }
    
    public void addFirst(int value) {
        /*
        改动前
        this.head = new Node(value, this.head);
        */
		this.head.next = new Node(value, this.head.next);
        // 也可以视为 insert 的特例, 即 insert(0, value);
    }
}
复制<br>
<br>对于删除，前面说了【最后一个 if 块对应着至少得两个节点的情况】，现在有了哨兵，就凑足了两个节点
<br><br>public class DoublyLinkedListSentinel implements Iterable&lt;Integer&gt; {

    private final Node head;
    private final Node tail;

    public DoublyLinkedListSentinel() {
        head = new Node(null, 666, null);
        tail = new Node(null, 888, null);
        head.next = tail;
        tail.prev = head;
    }

    private Node findNode(int index) {
        int i = -1;
        for (Node p = head; p != tail; p = p.next, i++) {
            if (i == index) {
                return p;
            }
        }
        return null;
    }

    public void addFirst(int value) {
        insert(0, value);
    }

    public void removeFirst() {
        remove(0);
    }

    public void addLast(int value) {
        Node prev = tail.prev;
        Node added = new Node(prev, value, tail);
        prev.next = added;
        tail.prev = added;
    }

    public void removeLast() {
        Node removed = tail.prev;
        if (removed == head) {
            throw illegalIndex(0);
        }
        Node prev = removed.prev;
        prev.next = tail;
        tail.prev = prev;
    }

    public void insert(int index, int value) {
        Node prev = findNode(index - 1);
        if (prev == null) {
            throw illegalIndex(index);
        }
        Node next = prev.next;
        Node inserted = new Node(prev, value, next);
        prev.next = inserted;
        next.prev = inserted;
    }

    public void remove(int index) {
        Node prev = findNode(index - 1);
        if (prev == null) {
            throw illegalIndex(index);
        }
        Node removed = prev.next;
        if (removed == tail) {
            throw illegalIndex(index);
        }
        Node next = removed.next;
        prev.next = next;
        next.prev = prev;
    }

    private IllegalArgumentException illegalIndex(int index) {
        return new IllegalArgumentException(
                String.format("index [%d] 不合法%n", index));
    }

    @Override
    public Iterator&lt;Integer&gt; iterator() {
        return new Iterator&lt;Integer&gt;() {
            Node p = head.next;

            @Override
            public boolean hasNext() {
                return p != tail;
            }

            @Override
            public Integer next() {
                int value = p.value;
                p = p.next;
                return value;
            }
        };
    }

    static class Node {
        Node prev;
        int value;
        Node next;

        public Node(Node prev, int value, Node next) {
            this.prev = prev;
            this.value = value;
            this.next = next;
        }
    }
}
复制<br><br>双向环形链表带哨兵，这时哨兵既作为头，也作为尾<br>“imgs/image-20221229144232651.png” could not be found.<br>“imgs/image-20221229143756065.png” could not be found.<br>“imgs/image-20221229153338425.png” could not be found.<br>“imgs/image-20221229154248800.png” could not be found.<br>参考实现<br>public class DoublyLinkedListSentinel implements Iterable&lt;Integer&gt; {

    @Override
    public Iterator&lt;Integer&gt; iterator() {
        return new Iterator&lt;&gt;() {
            Node p = sentinel.next;

            @Override
            public boolean hasNext() {
                return p != sentinel;
            }

            @Override
            public Integer next() {
                int value = p.value;
                p = p.next;
                return value;
            }
        };
    }

    static class Node {
        Node prev;
        int value;
        Node next;

        public Node(Node prev, int value, Node next) {
            this.prev = prev;
            this.value = value;
            this.next = next;
        }
    }

    private final Node sentinel = new Node(null, -1, null); // 哨兵

    public DoublyLinkedListSentinel() {
        sentinel.next = sentinel;
        sentinel.prev = sentinel;
    }

    /**
     * 添加到第一个
     * @param value 待添加值
     */
    public void addFirst(int value) {
        Node next = sentinel.next;
        Node prev = sentinel;
        Node added = new Node(prev, value, next);
        prev.next = added;
        next.prev = added;
    }

    /**
     * 添加到最后一个
     * @param value 待添加值
     */
    public void addLast(int value) {
        Node prev = sentinel.prev;
        Node next = sentinel;
        Node added = new Node(prev, value, next);
        prev.next = added;
        next.prev = added;
    }
    
    /**
     * 删除第一个
     */
    public void removeFirst() {
        Node removed = sentinel.next;
        if (removed == sentinel) {
            throw new IllegalArgumentException("非法");
        }
        Node a = sentinel;
        Node b = removed.next;
        a.next = b;
        b.prev = a;
    }

    /**
     * 删除最后一个
     */
    public void removeLast() {
        Node removed = sentinel.prev;
        if (removed == sentinel) {
            throw new IllegalArgumentException("非法");
        }
        Node a = removed.prev;
        Node b = sentinel;
        a.next = b;
        b.prev = a;
    }

    /**
     * 根据值删除节点
     * &lt;p&gt;假定 value 在链表中作为 key, 有唯一性&lt;/p&gt;
     * @param value 待删除值
     */
    public void removeByValue(int value) {
        Node removed = findNodeByValue(value);
        if (removed != null) {
            Node prev = removed.prev;
            Node next = removed.next;
            prev.next = next;
            next.prev = prev;
        }
    }

    private Node findNodeByValue(int value) {
        Node p = sentinel.next;
        while (p != sentinel) {
            if (p.value == value) {
                return p;
            }
            p = p.next;
        }
        return null;
    }

}
复制<br><br><br>定义<br>计算机科学中，递归是一种解决计算问题的方法，其中解决方案取决于同一类问题的更小子集<br>
In computer science, recursion is a method of solving a computational problem where the solution depends on solutions to smaller instances of the same problem.
<br>比如单链表递归遍历的例子：<br>void f(Node node) {
    if(node == null) {
        return;
    }
    println("before:" + node.value)
    f(node.next);
    println("after:" + node.value)
}
复制<br>说明：<br>
<br>自己调用自己，如果说每个函数对应着一种解决方案，自己调用自己意味着解决方案是一样的（有规律的）
<br>每次调用，函数处理的数据会较上次缩减（子集），而且最后会缩减至无需继续递归
<br>内层函数调用（子集处理）完成，外层函数才能算调用完成
<br>原理<br>假设链表中有 3 个节点，value 分别为 1，2，3，以上代码的执行流程就类似于下面的伪码<br>// 1 -&gt; 2 -&gt; 3 -&gt; null  f(1)

void f(Node node = 1) {
    println("before:" + node.value) // 1
    void f(Node node = 2) {
        println("before:" + node.value) // 2
        void f(Node node = 3) {
            println("before:" + node.value) // 3
            void f(Node node = null) {
                if(node == null) {
                    return;
                }
            }
            println("after:" + node.value) // 3
        }
        println("after:" + node.value) // 2
    }
    println("after:" + node.value) // 1
}
复制<br>思路<br>
<br>确定能否使用递归求解
<br>推导出递推关系，即父问题与子问题的关系，以及递归的结束条件
<br>例如之前遍历链表的递推关系为<br><br>
<br>深入到最里层叫做递
<br>从最里层出来叫做归
<br>在递的过程中，外层函数内的局部变量（以及方法参数）并未消失，归的时候还可以用到
<br><br>E01. 阶乘<br>用递归方法求阶乘 <br>
<br>
阶乘的定义 ，其中  为自然数，当然 

<br>
递推关系

<br><br>代码<br>private static int f(int n) {
    if (n == 1) {
        return 1;
    }
    return n * f(n - 1);
}
复制<br>拆解伪码如下，假设 n 初始值为 3<br>f(int n = 3) { // 解决不了,递
    return 3 * f(int n = 2) { // 解决不了,继续递
        return 2 * f(int n = 1) {
            if (n == 1) { // 可以解决, 开始归
                return 1;
            }
        }
    }
}
复制<br>E02. 反向打印字符串<br>用递归反向打印字符串，n 为字符在整个字符串 str 中的索引位置<br>
<br>递：n 从 0 开始，每次 n + 1，一直递到 n == str.length() - 1
<br>归：从 n == str.length() 开始归，从归打印，自然是逆序的
<br>递推关系<br><br>代码为<br>public static void reversePrint(String str, int index) {
    if (index == str.length()) {
        return;
    }
    reversePrint(str, index + 1);
    System.out.println(str.charAt(index));
}
复制<br>拆解伪码如下，假设字符串为 "abc"<br>void reversePrint(String str, int index = 0) {
    void reversePrint(String str, int index = 1) {
        void reversePrint(String str, int index = 2) {
            void reversePrint(String str, int index = 3) { 
                if (index == str.length()) {
                    return; // 开始归
                }
            }
            System.out.println(str.charAt(index)); // 打印 c
        }
        System.out.println(str.charAt(index)); // 打印 b
    }
    System.out.println(str.charAt(index)); // 打印 a
}
复制<br><br>E01. 斐波那契数列<br>
<br>之前的例子是每个递归函数只包含一个自身的调用，这称之为 single recursion
<br>如果每个递归函数例包含多个自身调用，称之为 multi recursion
<br>递推关系<br><br>下面的表格列出了数列的前几项<br><br>实现<br>public static int f(int n) {
    if (n == 0) {
        return 0;
    }
    if (n == 1) {
        return 1;
    }
    return f(n - 1) + f(n - 2);
}
复制<br>执行流程<br>“imgs/2.gif” could not be found.<br>
<br>绿色代表正在执行（对应递），灰色代表执行结束（对应归）
<br>递不到头，不能归，对应着深度优先搜索
<br>时间复杂度<br>
<br>递归的次数也符合斐波那契规律，
<br>时间复杂度推导过程

<br>斐波那契通项公式 
<br>简化为：
<br>带入递归次数公式 
<br>时间复杂度为 


<br>

<br>更多 Fibonacci 参考<a href="\#fn-7-33dbe2937a530ff5" class="footnote-link" target="_self" rel="noopener">[7]</a><a href="\#fn-8-33dbe2937a530ff5" class="footnote-link" target="_self" rel="noopener">[8]</a><a href="\#fn-9-33dbe2937a530ff5" class="footnote-link" target="_self" rel="noopener">[9]</a>
<br>以上时间复杂度分析，未考虑大数相加的因素

<br>变体1 - 兔子问题<a href="\#fn-7-33dbe2937a530ff5" class="footnote-link" target="_self" rel="noopener">[7-1]</a><br>“imgs/image-20221110155655827.png” could not be found.<br>
<br>第一个月，有一对未成熟的兔子（黑色，注意图中个头较小）
<br>第二个月，它们成熟
<br>第三个月，它们能产下一对新的小兔子（蓝色）
<br>所有兔子遵循相同规律，求第  个月的兔子数
<br>分析<br>兔子问题如何与斐波那契联系起来呢？设第 n 个月兔子数为 <br>
<br> = 上个月兔子数 + 新生的小兔子数
<br>而【新生的小兔子数】实际就是【上个月成熟的兔子数】
<br>因为需要一个月兔子就成熟，所以【上个月成熟的兔子数】也就是【上上个月的兔子数】
<br>上个月兔子数，即 
<br>上上个月的兔子数，即 
<br>因此本质还是斐波那契数列，只是从其第一项开始<br>变体2 - 青蛙爬楼梯<br>
<br>楼梯有  阶
<br>青蛙要爬到楼顶，可以一次跳一阶，也可以一次跳两阶
<br>只能向上跳，问有多少种跳法
<br>分析<br><br>
<br>
因此本质上还是斐波那契数列，只是从其第二项开始

<br>
对应 leetcode 题目 <a data-tooltip-position="top" aria-label="https://leetcode.cn/problems/climbing-stairs/" rel="noopener" class="external-link" href="https://leetcode.cn/problems/climbing-stairs/" target="_blank">70. 爬楼梯 - 力扣（LeetCode）</a>

<br><br>上述代码存在很多重复的计算，例如求  递归分解过程<br>“imgs/image-20221207092417933.png” could not be found.<br>可以看到（颜色相同的是重复的）：<br>
<br> 重复了 2 次
<br> 重复了 3 次
<br> 重复了 5 次
<br> 重复了 3 次
<br>随着   的增大，重复次数非常可观，如何优化呢？<br>Memoization 记忆法（也称备忘录）是一种优化技术，通过存储函数调用结果（通常比较昂贵），当再次出现相同的输入（子问题）时，就能实现加速效果，改进后的代码<br>public static void main(String[] args) {
    int n = 13;
    int[] cache = new int[n + 1];
    Arrays.fill(cache, -1);
    cache[0] = 0;
    cache[1] = 1;
    System.out.println(f(cache, n));
}

public static int f(int[] cache, int n) {
    if (cache[n] != -1) {
        return cache[n];
    }

    cache[n] = f(cache, n - 1) + f(cache, n - 2);
    return cache[n];
}
复制<br>优化后的图示，只要结果被缓存，就不会执行其子问题<br>“imgs/image-20221213173225807.png” could not be found.<br>
<br>改进后的时间复杂度为 
<br>请自行验证改进后的效果
<br>请自行分析改进后的空间复杂度
<br>
注意

<br>记忆法是动态规划的一种情况，强调的是自顶向下的解决
<br>记忆法的本质是空间换时间

<br><br>爆栈<br>用递归做 <br>public static long sum(long n) {
    if (n == 1) {
        return 1;
    }
    return n + sum(n - 1);
}
复制<br>在我的机器上   时，爆栈了<br>Exception in thread "main" java.lang.StackOverflowError
	at Test.sum(Test.java:10)
	at Test.sum(Test.java:10)
	at Test.sum(Test.java:10)
	at Test.sum(Test.java:10)
	at Test.sum(Test.java:10)
	...
复制<br>为什么呢？<br>
<br>每次方法调用是需要消耗一定的栈内存的，这些内存用来存储方法参数、方法内局部变量、返回地址等等
<br>方法调用占用的内存需要等到方法结束时才会释放
<br>而递归调用我们之前讲过，不到最深不会回头，最内层方法没完成之前，外层方法都结束不了

<br>例如， 这个方法内有个需要执行 ， 没返回前，加号前面的  不能释放 
<br>看下面伪码


<br>long sum(long n = 3) {
    return 3 + long sum(long n = 2) {
        return 2 + long sum(long n = 1) {
            return 1;
        }
    }
}
复制<br>尾调用<br>如果函数的最后一步是调用一个函数，那么称为尾调用，例如<br>function a() {
    return b()
}
复制<br>下面三段代码不能叫做尾调用<br>function a() {
    const c = b()
    return c
}
复制<br>
<br>因为最后一步并非调用函数
<br>function a() {
    return b() + 1
}
复制<br>
<br>最后一步执行的是加法
<br>function a(x) {
    return b() + x
}
复制<br>
<br>最后一步执行的是加法
<br>一些语言<a href="\#fn-10-33dbe2937a530ff5" class="footnote-link" target="_self" rel="noopener">[10]</a>的编译器能够对尾调用做优化，例如<br>function a() {
    // 做前面的事
    return b() 
}

function b() {
    // 做前面的事
    return c()
}

function c() {
    return 1000
}

a()
复制<br>没优化之前的伪码<br>function a() {
    return function b() {
        return function c() {
            return 1000
        }
    }
}
复制<br>优化后伪码如下<br>a()
b()
c()
复制<br>为何尾递归才能优化？<br>调用 a 时<br>
<br>a 返回时发现：没什么可留给 b 的，将来返回的结果 b 提供就可以了，用不着我 a 了，我的内存就可以释放
<br>调用 b 时<br>
<br>b 返回时发现：没什么可留给 c 的，将来返回的结果 c 提供就可以了，用不着我 b 了，我的内存就可以释放
<br>如果调用 a 时<br>
<br>不是尾调用，例如 return b() + 1，那么 a 就不能提前结束，因为它还得利用 b 的结果做加法
<br>尾递归<br>尾递归是尾调用的一种特例，也就是最后一步执行的是同一个函数<br>尾递归避免爆栈<br>安装 Scala<br>“imgs/image-20221111122709227.png” could not be found.<br>Scala 入门<br>object Main {
  def main(args: Array[String]): Unit = {
    println("Hello Scala")
  }
}
复制<br>
<br>Scala 是 java 的近亲，java 中的类都可以拿来重用
<br>类型是放在变量后面的
<br>Unit 表示无返回值，类似于 void
<br>不需要以分号作为结尾，当然加上也对
<br>还是先写一个会爆栈的函数<br>def sum(n: Long): Long = {
    if (n == 1) {
        return 1
    }
    return n + sum(n - 1)
}
复制<br>
<br>Scala 最后一行代码若作为返回值，可以省略 return
<br>不出所料，在  时，还是出了异常<br>println(sum(11000))

Exception in thread "main" java.lang.StackOverflowError
	at Main$.sum(Main.scala:25)
	at Main$.sum(Main.scala:25)
	at Main$.sum(Main.scala:25)
	at Main$.sum(Main.scala:25)
	...
复制<br>这是因为以上代码，还不是尾调用，要想成为尾调用，那么：<br>
<br>最后一行代码，必须是一次函数调用
<br>内层函数必须摆脱与外层函数的关系，内层函数执行后不依赖于外层的变量或常量
<br>def sum(n: Long): Long = {
    if (n == 1) {
        return 1
    }
    return n + sum(n - 1)  // 依赖于外层函数的 n 变量
}
复制<br>如何让它执行后就摆脱对 n 的依赖呢？<br>
<br>不能等递归回来再做加法，那样就必须保留外层的 n
<br>把 n 当做内层函数的一个参数传进去，这时 n 就属于内层函数了
<br>传参时就完成累加, 不必等回来时累加
<br>sum(n - 1, n + 累加器)
复制<br>改写后代码如下<br>@tailrec
def sum(n: Long, accumulator: Long): Long = {
    if (n == 1) {
        return 1 + accumulator
    } 
    return sum(n - 1, n + accumulator)
}
复制<br>
<br>accumulator 作为累加器
<br>@tailrec 注解是 scala 提供的，用来检查方法是否符合尾递归
<br>这回 sum(10000000, 0) 也没有问题，打印 50000005000000
<br>执行流程如下，以伪码表示 <br>// 首次调用
def sum(n = 4, accumulator = 0): Long = {
    return sum(4 - 1, 4 + accumulator)
}

// 接下来调用内层 sum, 传参时就完成了累加, 不必等回来时累加，当内层 sum 调用后，外层 sum 空间没必要保留
def sum(n = 3, accumulator = 4): Long = {
    return sum(3 - 1, 3 + accumulator)
}

// 继续调用内层 sum
def sum(n = 2, accumulator = 7): Long = {
    return sum(2 - 1, 2 + accumulator)
}

// 继续调用内层 sum, 这是最后的 sum 调用完就返回最后结果 10, 前面所有其它 sum 的空间早已释放
def sum(n = 1, accumulator = 9): Long = {
    if (1 == 1) {
        return 1 + accumulator
    }
}
复制<br>本质上，尾递归优化是将函数的递归调用，变成了函数的循环调用<br>改循环避免爆栈<br>public static void main(String[] args) {
    long n = 100000000;
    long sum = 0;
    for (long i = n; i &gt;= 1; i--) {
        sum += i;
    }
    System.out.println(sum);
}
复制<br><br>若有递归式<br><br>其中 <br>
<br> 是问题的运行时间， 是数据规模
<br> 是子问题个数
<br> 是子问题运行时间，每个子问题被拆成原问题数据规模的 
<br> 是除递归外执行的计算
<br>令 ，即 <br>那么<br><br>例1<br> <br>
<br>此时 ，由后者决定整个时间复杂度 
<br>如果觉得对数不好算，可以换为求【 的几次方能等于 】
<br>例2<br><br>
<br>
<br>此时 ，由后者决定整个时间复杂度 
<br>例3<br><br>
<br>
<br>此时 ，时间复杂度 
<br>例4<br><br>
<br>
<br>此时 ，由后者决定整个时间复杂度 
<br>例5<br><br>
<br>
<br>此时 ，由前者决定整个时间复杂度 
<br>例6<br><br>
<br>
<br>此时 ，时间复杂度 
<br>例7. 二分查找递归<br>int f(int[] a, int target, int i, int j) {
    if (i &gt; j) {
        return -1;
    }
    int m = (i + j) &gt;&gt;&gt; 1;
    if (target &lt; a[m]) {
        return f(a, target, i, m - 1);
    } else if (a[m] &lt; target) {
        return f(a, target, m + 1, j);
    } else {
        return m;
    }
}
复制<br>
<br>子问题个数 
<br>子问题数据规模缩小倍数 
<br>除递归外执行的计算是常数级 
<br><br>
<br>此时 ，时间复杂度 
<br>例8. 归并排序递归<br>void split(B[], i, j, A[])
{
    if (j - i &lt;= 1)                    
        return;                                
    m = (i + j) / 2;             
    
    // 递归
    split(A, i, m, B);  
    split(A, m, j, B); 
    
    // 合并
    merge(B, i, m, j, A);
}
复制<br>
<br>子问题个数 
<br>子问题数据规模缩小倍数 
<br>除递归外，主要时间花在合并上，它可以用  表示
<br><br>
<br>此时 ，时间复杂度 
<br>例9. 快速排序递归<br>algorithm quicksort(A, lo, hi) is 
  if lo &gt;= hi || lo &lt; 0 then 
    return
  
  // 分区
  p := partition(A, lo, hi) 
  
  // 递归
  quicksort(A, lo, p - 1) 
  quicksort(A, p + 1, hi) 
复制<br>
<br>子问题个数 
<br>子问题数据规模缩小倍数

<br>如果分区分的好，
<br>如果分区没分好，例如分区1 的数据是 0，分区 2 的数据是 


<br>除递归外，主要时间花在分区上，它可以用  表示
<br>情况1 - 分区分的好<br><br>
<br>此时 ，时间复杂度 
<br>情况2 - 分区没分好<br><br>
<br>此时不能用主定理求解
<br><br>像下面的递归式，都不能用主定理求解<br>例1 - 递归求和<br>long sum(long n) {
    if (n == 1) {
        return 1;
    }
    return n + sum(n - 1);
}
复制<br>，<br>下面为展开过程<br><br><br>...<br> <br>
<br>其中  即 
<br>带入求得 
<br>时间复杂度为 <br>例2 - 递归冒泡排序<br>void bubble(int[] a, int high) {
    if(0 == high) {
        return;
    }
    for (int i = 0; i &lt; high; i++) {
        if (a[i] &gt; a[i + 1]) {
            swap(a, i, i + 1);
        }
    }
    bubble(a, high - 1);
}
复制<br>，<br>下面为展开过程<br><br><br>...<br><br>时间复杂度 <br>
注：

<br>等差数列求和为  

<br>例3 - 递归快排<br>快速排序分区没分好的极端情况<br>，<br><br>下面为展开过程<br><br><br>...<br><br>时间复杂度 <br>不会推导的同学可以进入 <a rel="noopener" class="external-link" href="https://www.wolframalpha.com/" target="_blank">https://www.wolframalpha.com/</a><br>
<br>例1 输入 f(n) = f(n - 1) + c, f(1) = c
<br>例2 输入 f(n) = f(n - 1) + n, f(1) = c
<br>例3 输入 f(n) = f(n - 1) + n + c, f(1) = c
<br><br><br>计算机科学中，queue 是以顺序的方式维护的一组数据集合，在一端添加数据，从另一端移除数据。习惯来说，添加的一端称为尾，移除的一端称为头，就如同生活中的排队买商品<br>
In computer science, a queue is a collection of entities that are maintained in a sequence and can be modified by  the addition of entities at one end of the sequence and the removal of  entities from the other end of the sequence
<br>先定义一个简化的队列接口<br>public interface Queue&lt;E&gt; {

    /**
     * 向队列尾插入值
     * @param value 待插入值
     * @return 插入成功返回 true, 插入失败返回 false
     */
    boolean offer(E value);

    /**
     * 从对列头获取值, 并移除
     * @return 如果队列非空返回对头值, 否则返回 null
     */
    E poll();

    /**
     * 从对列头获取值, 不移除
     * @return 如果队列非空返回对头值, 否则返回 null
     */
    E peek();

    /**
     * 检查队列是否为空
     * @return 空返回 true, 否则返回 false
     */
    boolean isEmpty();

    /**
     * 检查队列是否已满
     * @return 满返回 true, 否则返回 false
     */
    boolean isFull();
}
复制<br><br>下面以单向环形带哨兵链表方式来实现队列<br>“imgs/image-20221230150105089.png” could not be found.<br>“imgs/image-20221230150141318.png” could not be found.<br>“imgs/image-20221230150153271.png” could not be found.<br>代码<br>public class LinkedListQueue&lt;E&gt;
        implements Queue&lt;E&gt;, Iterable&lt;E&gt; {

    private static class Node&lt;E&gt; {
        E value;
        Node&lt;E&gt; next;

        public Node(E value, Node&lt;E&gt; next) {
            this.value = value;
            this.next = next;
        }
    }

    private Node&lt;E&gt; head = new Node&lt;&gt;(null, null);
    private Node&lt;E&gt; tail = head;
    private int size = 0;
    private int capacity = Integer.MAX_VALUE;

    {
        tail.next = head;
    }

    public LinkedListQueue() {
    }

    public LinkedListQueue(int capacity) {
        this.capacity = capacity;
    }

    @Override
    public boolean offer(E value) {
        if (isFull()) {
            return false;
        }
        Node&lt;E&gt; added = new Node&lt;&gt;(value, head);
        tail.next = added;
        tail = added;
        size++;
        return true;
    }

    @Override
    public E poll() {
        if (isEmpty()) {
            return null;
        }
        Node&lt;E&gt; first = head.next;
        head.next = first.next;
        if (first == tail) {
            tail = head;
        }
        size--;
        return first.value;
    }

    @Override
    public E peek() {
        if (isEmpty()) {
            return null;
        }
        return head.next.value;
    }

    @Override
    public boolean isEmpty() {
        return head == tail;
    }

    @Override
    public boolean isFull() {
        return size == capacity;
    }

    @Override
    public Iterator&lt;E&gt; iterator() {
        return new Iterator&lt;E&gt;() {
            Node&lt;E&gt; p = head.next;
            @Override
            public boolean hasNext() {
                return p != head;
            }
            @Override
            public E next() {
                E value = p.value;
                p = p.next;
                return value;
            }
        };
    }
}
复制<br><br>好处<br>
<br>对比普通数组，起点和终点更为自由，不用考虑数据移动
<br>“环”意味着不会存在【越界】问题
<br>数组性能更佳
<br>环形数组比较适合实现有界队列、RingBuffer 等
<br>“imgs/image-20221228175413998.png” could not be found.<br>下标计算<br>例如，数组长度是 5，当前位置是 3 ，向前走 2 步，此时下标为 <br>“imgs/image-20221228180357257.png” could not be found.<br><br>
<br>cur 当前指针位置
<br>step 前进步数
<br>length 数组长度
<br>
注意：

<br>如果 step = 1，也就是一次走一步，可以在 &gt;= length 时重置为 0 即可

<br>判断空<br>“imgs/image-20221231081009018.png” could not be found.<br>判断满<br>“imgs/image-20221231080909475.png” could not be found.<br>满之后的策略可以根据业务需求决定<br>
<br>例如我们要实现的环形队列，满之后就拒绝入队
<br>代码<br>public class ArrayQueue&lt;E&gt; implements Queue&lt;E&gt;, Iterable&lt;E&gt;{

    private int head = 0;
    private int tail = 0;
    private final E[] array;
    private final int length;

    @SuppressWarnings("all")
    public ArrayQueue(int capacity) {
        length = capacity + 1;
        array = (E[]) new Object[length];
    }

    @Override
    public boolean offer(E value) {
        if (isFull()) {
            return false;
        }
        array[tail] = value;
        tail = (tail + 1) % length;
        return true;
    }

    @Override
    public E poll() {
        if (isEmpty()) {
            return null;
        }
        E value = array[head];
        head = (head + 1) % length;
        return value;
    }

    @Override
    public E peek() {
        if (isEmpty()) {
            return null;
        }
        return array[head];
    }

    @Override
    public boolean isEmpty() {
        return tail == head;
    }

    @Override
    public boolean isFull() {
        return (tail + 1) % length == head;
    }

    @Override
    public Iterator&lt;E&gt; iterator() {
        return new Iterator&lt;E&gt;() {
            int p = head;
            @Override
            public boolean hasNext() {
                return p != tail;
            }

            @Override
            public E next() {
                E value = array[p];
                p = (p + 1) % array.length;
                return value;
            }
        };
    }
}
复制<br>判断空、满方法2<br>引入 size <br>public class ArrayQueue2&lt;E&gt; implements Queue&lt;E&gt;, Iterable&lt;E&gt; {

    private int head = 0;
    private int tail = 0;
    private final E[] array;
    private final int capacity;
    private int size = 0;

    @SuppressWarnings("all")
    public ArrayQueue2(int capacity) {
        this.capacity = capacity;
        array = (E[]) new Object[capacity];
    }

    @Override
    public boolean offer(E value) {
        if (isFull()) {
            return false;
        }
        array[tail] = value;
        tail = (tail + 1) % capacity;
        size++;
        return true;
    }

    @Override
    public E poll() {
        if (isEmpty()) {
            return null;
        }
        E value = array[head];
        head = (head + 1) % capacity;
        size--;
        return value;
    }

    @Override
    public E peek() {
        if (isEmpty()) {
            return null;
        }
        return array[head];
    }

    @Override
    public boolean isEmpty() {
        return size == 0;
    }

    @Override
    public boolean isFull() {
        return size == capacity;
    }

    @Override
    public Iterator&lt;E&gt; iterator() {
        return new Iterator&lt;E&gt;() {
            int p = head;

            @Override
            public boolean hasNext() {
                return p != tail;
            }

            @Override
            public E next() {
                E value = array[p];
                p = (p + 1) % capacity;
                return value;
            }
        };
    }
}
复制<br>判断空、满方法3<br>
<br>
head 和 tail 不断递增，用到索引时，再用它们进行计算，两个问题

<br>
如何保证 head 和 tail 自增超过正整数最大值的正确性

<br>
如何让取模运算性能更高



<br>
答案：让 capacity 为 2 的幂

<br>public class ArrayQueue3&lt;E&gt; implements Queue&lt;E&gt;, Iterable&lt;E&gt; {

    private int head = 0;
    private int tail = 0;
    private final E[] array;
    private final int capacity;

    @SuppressWarnings("all")
    public ArrayQueue3(int capacity) {
        if ((capacity &amp; capacity - 1) != 0) {
            throw new IllegalArgumentException("capacity 必须为 2 的幂");
        }
        this.capacity = capacity;
        array = (E[]) new Object[this.capacity];
    }

    @Override
    public boolean offer(E value) {
        if (isFull()) {
            return false;
        }
        array[tail &amp; capacity - 1] = value;
        tail++;
        return true;
    }

    @Override
    public E poll() {
        if (isEmpty()) {
            return null;
        }
        E value = array[head &amp; capacity - 1];
        head++;
        return value;
    }

    @Override
    public E peek() {
        if (isEmpty()) {
            return null;
        }
        return array[head &amp; capacity - 1];
    }

    @Override
    public boolean isEmpty() {
        return tail - head == 0;
    }

    @Override
    public boolean isFull() {
        return tail - head == capacity;
    }

    @Override
    public Iterator&lt;E&gt; iterator() {
        return new Iterator&lt;E&gt;() {
            int p = head;

            @Override
            public boolean hasNext() {
                return p != tail;
            }

            @Override
            public E next() {
                E value = array[p &amp; capacity - 1];
                p++;
                return value;
            }
        };
    }
}
复制<br><br><br>计算机科学中，stack 是一种线性的数据结构，只能在其一端添加数据和移除数据。习惯来说，这一端称之为栈顶，另一端不能操作数据的称之为栈底，就如同生活中的一摞书<br>先提供一个栈接口<br>public interface Stack&lt;E&gt; {
    /**
     * 向栈顶压入元素
     * @param value 待压入值
     * @return 压入成功返回 true, 否则返回 false
     */
    boolean push(E value);

    /**
     * 从栈顶弹出元素
     * @return 栈非空返回栈顶元素, 栈为空返回 null
     */
    E pop();

    /**
     * 返回栈顶元素, 不弹出
     * @return 栈非空返回栈顶元素, 栈为空返回 null
     */
    E peek();

    /**
     * 判断栈是否为空
     * @return 空返回 true, 否则返回 false
     */
    boolean isEmpty();

    /**
     * 判断栈是否已满
     * @return 满返回 true, 否则返回 false
     */
    boolean isFull();
}
复制<br><br>public class LinkedListStack&lt;E&gt; implements Stack&lt;E&gt;, Iterable&lt;E&gt; {

    private final int capacity;
    private int size;
    private final Node&lt;E&gt; head = new Node&lt;&gt;(null, null);

    public LinkedListStack(int capacity) {
        this.capacity = capacity;
    }

    @Override
    public boolean push(E value) {
        if (isFull()) {
            return false;
        }
        head.next = new Node&lt;&gt;(value, head.next);
        size++;
        return true;
    }

    @Override
    public E pop() {
        if (isEmpty()) {
            return null;
        }
        Node&lt;E&gt; first = head.next;
        head.next = first.next;
        size--;
        return first.value;
    }

    @Override
    public E peek() {
        if (isEmpty()) {
            return null;
        }
        return head.next.value;
    }

    @Override
    public boolean isEmpty() {
        return head.next == null;
    }

    @Override
    public boolean isFull() {
        return size == capacity;
    }

    @Override
    public Iterator&lt;E&gt; iterator() {
        return new Iterator&lt;E&gt;() {
            Node&lt;E&gt; p = head.next;
            @Override
            public boolean hasNext() {
                return p != null;
            }

            @Override
            public E next() {
                E value = p.value;
                p = p.next;
                return value;
            }
        };
    }

    static class Node&lt;E&gt; {
        E value;
        Node&lt;E&gt; next;

        public Node(E value, Node&lt;E&gt; next) {
            this.value = value;
            this.next = next;
        }
    }
}
复制<br><br>public class ArrayStack&lt;E&gt; implements Stack&lt;E&gt;, Iterable&lt;E&gt;{
    private final E[] array;
    private int top = 0;

    @SuppressWarnings("all")
    public ArrayStack(int capacity) {
        this.array = (E[]) new Object[capacity];
    }

    @Override
    public boolean push(E value) {
        if (isFull()) {
            return false;
        }
        array[top++] = value;
        return true;
    }

    @Override
    public E pop() {
        if (isEmpty()) {
            return null;
        }
        return array[--top];
    }

    @Override
    public E peek() {
        if (isEmpty()) {
            return null;
        }
        return array[top-1];
    }

    @Override
    public boolean isEmpty() {
        return top == 0;
    }

    @Override
    public boolean isFull() {
        return top == array.length;
    }

    @Override
    public Iterator&lt;E&gt; iterator() {
        return new Iterator&lt;E&gt;() {
            int p = top;
            @Override
            public boolean hasNext() {
                return p &gt; 0;
            }

            @Override
            public E next() {
                return array[--p];
            }
        };
    }
}
复制<br><br>模拟如下方法调用<br>public static void main(String[] args) {
    System.out.println("main1");
    System.out.println("main2");
    method1();
    method2();
    System.out.println("main3");
}

public static void method1() {
    System.out.println("method1");
    method3();
}

public static void method2() {
    System.out.println("method2");
}

public static void method3() {
    System.out.println("method3");
}
复制<br>模拟代码<br>public class CPU {
    static class Frame {
        int exit;

        public Frame(int exit) {
            this.exit = exit;
        }
    }
    static int pc = 1; // 模拟程序计数器 Program counter
    static ArrayStack&lt;Frame&gt; stack = new ArrayStack&lt;&gt;(100); // 模拟方法调用栈

    public static void main(String[] args) {
        stack.push(new Frame(-1));
        while (!stack.isEmpty()) {
            switch (pc) {
                case 1 -&gt; {
                    System.out.println("main1");
                    pc++;
                }
                case 2 -&gt; {
                    System.out.println("main2");
                    pc++;
                }
                case 3 -&gt; {
                    stack.push(new Frame(pc + 1));
                    pc = 100;
                }
                case 4 -&gt; {
                    stack.push(new Frame(pc + 1));
                    pc = 200;
                }
                case 5 -&gt; {
                    System.out.println("main3");
                    pc = stack.pop().exit;
                }
                case 100 -&gt; {
                    System.out.println("method1");
                    stack.push(new Frame(pc + 1));
                    pc = 300;
                }
                case 101 -&gt; {
                    pc = stack.pop().exit;
                }
                case 200 -&gt; {
                    System.out.println("method2");
                    pc = stack.pop().exit;
                }
                case 300 -&gt; {
                    System.out.println("method3");
                    pc = stack.pop().exit;
                }
            }
        }
    }
}
复制<br><br><br>双端队列、队列、栈对比<br><br>
注1：

<br>Java 中 LinkedList 即为典型双端队列实现，不过它同时实现了 Queue 接口，也提供了栈的 push pop 等方法

注2：

<br>
不同语言，操作双端队列的方法命名有所不同，参见下表


<br>
吐槽一下 leetCode 命名比较 low

<br>
常见的单词还有 enqueue 入队、dequeue 出队


<br>接口定义<br>public interface Deque&lt;E&gt; {

    boolean offerFirst(E e);

    boolean offerLast(E e);

    E pollFirst();

    E pollLast();

    E peekFirst();

    E peekLast();
    
    boolean isEmpty();

    boolean isFull();
}
复制<br><br>/**
 * 基于环形链表的双端队列
 * @param &lt;E&gt; 元素类型
 */
public class LinkedListDeque&lt;E&gt; implements Deque&lt;E&gt;, Iterable&lt;E&gt; {

    @Override
    public boolean offerFirst(E e) {
        if (isFull()) {
            return false;
        }
        size++;
        Node&lt;E&gt; a = sentinel;
        Node&lt;E&gt; b = sentinel.next;
        Node&lt;E&gt; offered = new Node&lt;&gt;(a, e, b);
        a.next = offered;
        b.prev = offered;
        return true;
    }

    @Override
    public boolean offerLast(E e) {
        if (isFull()) {
            return false;
        }
        size++;
        Node&lt;E&gt; a = sentinel.prev;
        Node&lt;E&gt; b = sentinel;
        Node&lt;E&gt; offered = new Node&lt;&gt;(a, e, b);
        a.next = offered;
        b.prev = offered;
        return true;
    }

    @Override
    public E pollFirst() {
        if (isEmpty()) {
            return null;
        }
        Node&lt;E&gt; a = sentinel;
        Node&lt;E&gt; polled = sentinel.next;
        Node&lt;E&gt; b = polled.next;
        a.next = b;
        b.prev = a;
        size--;
        return polled.value;
    }

    @Override
    public E pollLast() {
        if (isEmpty()) {
            return null;
        }
        Node&lt;E&gt; polled = sentinel.prev;
        Node&lt;E&gt; a = polled.prev;
        Node&lt;E&gt; b = sentinel;
        a.next = b;
        b.prev = a;
        size--;
        return polled.value;
    }

    @Override
    public E peekFirst() {
        if (isEmpty()) {
            return null;
        }
        return sentinel.next.value;
    }

    @Override
    public E peekLast() {
        if (isEmpty()) {
            return null;
        }
        return sentinel.prev.value;
    }

    @Override
    public boolean isEmpty() {
        return size == 0;
    }

    @Override
    public boolean isFull() {
        return size == capacity;
    }

    @Override
    public Iterator&lt;E&gt; iterator() {
        return new Iterator&lt;E&gt;() {
            Node&lt;E&gt; p = sentinel.next;
            @Override
            public boolean hasNext() {
                return p != sentinel;
            }

            @Override
            public E next() {
                E value = p.value;
                p = p.next;
                return value;
            }
        };
    }

    static class Node&lt;E&gt; {
        Node&lt;E&gt; prev;
        E value;
        Node&lt;E&gt; next;

        public Node(Node&lt;E&gt; prev, E value, Node&lt;E&gt; next) {
            this.prev = prev;
            this.value = value;
            this.next = next;
        }
    }

    Node&lt;E&gt; sentinel = new Node&lt;&gt;(null, null, null);
    int capacity;
    int size;

    public LinkedListDeque(int capacity) {
        sentinel.next = sentinel;
        sentinel.prev = sentinel;
        this.capacity = capacity;
    }
}
复制<br><br>/**
 * 基于循环数组实现, 特点
 * &lt;ul&gt;
 *     &lt;li&gt;tail 停下来的位置不存储, 会浪费一个位置&lt;/li&gt;
 * &lt;/ul&gt;
 * @param &lt;E&gt;
 */
public class ArrayDeque1&lt;E&gt; implements Deque&lt;E&gt;, Iterable&lt;E&gt; {

    /*
                    h
            t
        0   1   2   3
        b           a
     */
    @Override
    public boolean offerFirst(E e) {
        if (isFull()) {
            return false;
        }
        head = dec(head, array.length);
        array[head] = e;
        return true;
    }

    @Override
    public boolean offerLast(E e) {
        if (isFull()) {
            return false;
        }
        array[tail] = e;
        tail = inc(tail, array.length);
        return true;
    }

    @Override
    public E pollFirst() {
        if (isEmpty()) {
            return null;
        }
        E e = array[head];
        array[head] = null;
        head = inc(head, array.length);
        return e;
    }

    @Override
    public E pollLast() {
        if (isEmpty()) {
            return null;
        }
        tail = dec(tail, array.length);
        E e = array[tail];
        array[tail] = null;
        return e;
    }

    @Override
    public E peekFirst() {
        if (isEmpty()) {
            return null;
        }
        return array[head];
    }

    @Override
    public E peekLast() {
        if (isEmpty()) {
            return null;
        }
        return array[dec(tail, array.length)];
    }

    @Override
    public boolean isEmpty() {
        return head == tail;
    }

    @Override
    public boolean isFull() {
        if (tail &gt; head) {
            return tail - head == array.length - 1;
        } else if (tail &lt; head) {
            return head - tail == 1;
        } else {
            return false;
        }
    }

    @Override
    public Iterator&lt;E&gt; iterator() {
        return new Iterator&lt;E&gt;() {
            int p = head;
            @Override
            public boolean hasNext() {
                return p != tail;
            }

            @Override
            public E next() {
                E e = array[p];
                p = inc(p, array.length);
                return e;
            }
        };
    }

    E[] array;
    int head;
    int tail;

    @SuppressWarnings("unchecked")
    public ArrayDeque1(int capacity) {
        array = (E[]) new Object[capacity + 1];
    }

    static int inc(int i, int length) {
        if (i + 1 &gt;= length) {
            return 0;
        }
        return i + 1;
    }

    static int dec(int i, int length) {
        if (i - 1 &lt; 0) {
            return length - 1;
        }
        return i - 1;
    }
}
复制<br>数组实现中，如果存储的是基本类型，那么无需考虑内存释放，例如<br>“imgs/image-20230110084245095.png” could not be found.<br>但如果存储的是引用类型，应当设置该位置的引用为 null，以便内存及时释放<br>“imgs/image-20230110084632543.png” could not be found.<br><br><br>要点<br>
<br>入队保持顺序
<br>出队前找到优先级最高的出队，相当于一次选择排序
<br>public class PriorityQueue1&lt;E extends Priority&gt; implements Queue&lt;E&gt; {

    Priority[] array;
    int size;

    public PriorityQueue1(int capacity) {
        array = new Priority[capacity];
    }

    @Override // O(1)
    public boolean offer(E e) {
        if (isFull()) {
            return false;
        }
        array[size++] = e;
        return true;
    }

    // 返回优先级最高的索引值
    private int selectMax() {
        int max = 0;
        for (int i = 1; i &lt; size; i++) {
            if (array[i].priority() &gt; array[max].priority()) {
                max = i;
            }
        }
        return max;
    }

    @Override // O(n)
    public E poll() {
        if (isEmpty()) {
            return null;
        }
        int max = selectMax();
        E e = (E) array[max];
        remove(max);
        return e;
    }

    private void remove(int index) {
        if (index &lt; size - 1) {
            System.arraycopy(array, index + 1,
                    array, index, size - 1 - index);
        }
        array[--size] = null; // help GC
    }

    @Override
    public E peek() {
        if (isEmpty()) {
            return null;
        }
        int max = selectMax();
        return (E) array[max];
    }

    @Override
    public boolean isEmpty() {
        return size == 0;
    }

    @Override
    public boolean isFull() {
        return size == array.length;
    }
}
复制<br>
<br>视频中忘记了 help GC，注意一下
<br><br>要点<br>
<br>入队后排好序，优先级最高的排列在尾部
<br>出队只需删除尾部元素即可
<br>public class PriorityQueue2&lt;E extends Priority&gt; implements Queue&lt;E&gt; {

    Priority[] array;
    int size;

    public PriorityQueue2(int capacity) {
        array = new Priority[capacity];
    }

    // O(n)
    @Override
    public boolean offer(E e) {
        if (isFull()) {
            return false;
        }
        insert(e);
        size++;
        return true;
    }

    // 一轮插入排序
    private void insert(E e) {
        int i = size - 1;
        while (i &gt;= 0 &amp;&amp; array[i].priority() &gt; e.priority()) {
            array[i + 1] = array[i];
            i--;
        }
        array[i + 1] = e;
    }

    // O(1)
    @Override
    public E poll() {
        if (isEmpty()) {
            return null;
        }
        E e = (E) array[size - 1];
        array[--size] = null; // help GC
        return e;
    }

    @Override
    public E peek() {
        if (isEmpty()) {
            return null;
        }
        return (E) array[size - 1];
    }

    @Override
    public boolean isEmpty() {
        return size == 0;
    }

    @Override
    public boolean isFull() {
        return size == array.length;
    }
}
复制<br><br>计算机科学中，堆是一种基于树的数据结构，通常用完全二叉树实现。堆的特性如下<br>
<br>在大顶堆中，任意节点 C 与它的父节点 P 符合 
<br>而小顶堆中，任意节点 C 与它的父节点 P 符合 
<br>最顶层的节点（没有父亲）称之为 root 根节点
<br>
In computer science, a heap is a specialized tree-based data structure which is essentially an almost complete tree that satisfies the heap property: in a max heap, for any given node C, if P is a parent node of C, then the key (the value) of P is greater than or equal to the key of C. In a min heap, the key of P is less than or equal to the key of C. The node at the "top" of the heap (with no parents) is called the root node
<br>例1 - 满二叉树（Full Binary Tree）特点：每一层都是填满的<br>“imgs/image-20230112171444699.png” could not be found.<br>例2 - 完全二叉树（Complete Binary Tree）特点：最后一层可能未填满，靠左对齐<br>“imgs/image-20230112171917135.png” could not be found.<br>例3 - 大顶堆<br>“imgs/image-20230112170242265.png” could not be found.<br>例4 - 小顶堆<br>“imgs/image-20230112171236067.png” could not be found.<br>完全二叉树可以使用数组来表示<br>“imgs/image-20230112174351649.png” could not be found.<br>特征<br>
<br>如果从索引 0 开始存储节点数据

<br>节点  的父节点为 ，当  时
<br>节点  的左子节点为 ，右子节点为 ，当然它们得 


<br>如果从索引 1 开始存储节点数据

<br>节点  的父节点为 ，当  时
<br>节点  的左子节点为 ，右子节点为 ，同样得 


<br>代码<br>public class PriorityQueue4&lt;E extends Priority&gt; implements Queue&lt;E&gt; {

    Priority[] array;
    int size;

    public PriorityQueue4(int capacity) {
        array = new Priority[capacity];
    }

    @Override
    public boolean offer(E offered) {
        if (isFull()) {
            return false;
        }
        int child = size++;
        int parent = (child - 1) / 2;
        while (child &gt; 0 &amp;&amp; offered.priority() &gt; array[parent].priority()) {
            array[child] = array[parent];
            child = parent;
            parent = (child - 1) / 2;
        }
        array[child] = offered;
        return true;
    }


    private void swap(int i, int j) {
        Priority t = array[i];
        array[i] = array[j];
        array[j] = t;
    }

    @Override
    public E poll() {
        if (isEmpty()) {
            return null;
        }
        swap(0, size - 1);
        size--;
        Priority e = array[size];
        array[size] = null;
        
        shiftDown(0);        
        return (E) e;
    }

    void shiftDown(int parent) {
        int left = 2 * parent + 1;
        int right = left + 1;
        int max = parent;
        if (left &lt; size &amp;&amp; array[left].priority() &gt; array[max].priority()) {
            max = left;
        }
        if (right &lt; size &amp;&amp; array[right].priority() &gt; array[max].priority()) {
            max = right;
        }
        if (max != parent) {
            swap(max, parent);
            shiftDown(max);
        }
    }

    @Override
    public E peek() {
        if (isEmpty()) {
            return null;
        }
        return (E) array[0];
    }

    @Override
    public boolean isEmpty() {
        return size == 0;
    }

    @Override
    public boolean isFull() {
        return size == array.length;
    }
}
复制<br><br>之前的队列在很多场景下都不能很好地工作，例如<br>
<br>大部分场景要求分离向队列放入（生产者）、从队列拿出（消费者）两个角色、它们得由不同的线程来担当，而之前的实现根本没有考虑线程安全问题
<br>队列为空，那么在之前的实现里会返回 null，如果就是硬要拿到一个元素呢？只能不断循环尝试
<br>队列为满，那么再之前的实现里会返回 false，如果就是硬要塞入一个元素呢？只能不断循环尝试
<br>因此我们需要解决的问题有<br>
<br>用锁保证线程安全
<br>用条件变量让等待非空线程与等待不满线程进入等待状态，而不是不断循环尝试，让 CPU 空转
<br>有同学对线程安全还没有足够的认识，下面举一个反例，两个线程都要执行入队操作（几乎在同一时刻）<br>public class TestThreadUnsafe {
    private final String[] array = new String[10];
    private int tail = 0;

    public void offer(String e) {
        array[tail] = e;
        tail++;
    }

    @Override
    public String toString() {
        return Arrays.toString(array);
    }

    public static void main(String[] args) {
        TestThreadUnsafe queue = new TestThreadUnsafe();
        new Thread(()-&gt; queue.offer("e1"), "t1").start();
        new Thread(()-&gt; queue.offer("e2"), "t2").start();
    }
}
复制<br>执行的时间序列如下，假设初始状态 tail = 0，在执行过程中由于 CPU 在两个线程之间切换，造成了指令交错<br><br>糟糕的是，由于指令交错的顺序不同，得到的结果不止以上一种，宏观上造成混乱的效果<br><br>Java 中要防止代码段交错执行，需要使用锁，有两种选择<br>
<br>synchronized 代码块，属于关键字级别提供锁保护，功能少
<br>ReentrantLock 类，功能丰富
<br>以 ReentrantLock 为例<br>ReentrantLock lock = new ReentrantLock();

public void offer(String e) {
    lock.lockInterruptibly();
    try {
        array[tail] = e;
        tail++;
    } finally {
        lock.unlock();
    }
}
复制<br>只要两个线程执行上段代码时，锁对象是同一个，就能保证 try 块内的代码的执行不会出现指令交错现象，即执行顺序只可能是下面两种情况之一<br><br>
<br>另一种情况是线程2 先获得锁，线程1 被挡在外面
<br>要明白保护的本质，本例中是保护的是 tail 位置读写的安全
<br>事情还没有完，上面的例子是队列还没有放满的情况，考虑下面的代码（这回锁同时保护了 tail 和 size 的读写安全）<br>ReentrantLock lock = new ReentrantLock();
int size = 0;

public void offer(String e) {
    lock.lockInterruptibly();
    try {
        if(isFull()) {
            // 满了怎么办?
        }
        array[tail] = e;
        tail++;
        
        size++;
    } finally {
        lock.unlock();
    }
}

private boolean isFull() {
    return size == array.length;
}
复制<br>之前是返回 false 表示添加失败，前面分析过想达到这么一种效果：<br>
<br>在队列满时，不是立刻返回，而是当前线程进入等待
<br>什么时候队列不满了，再唤醒这个等待的线程，从上次的代码处继续向下运行
<br>ReentrantLock 可以配合条件变量来实现，代码进化为<br>ReentrantLock lock = new ReentrantLock();
Condition tailWaits = lock.newCondition(); // 条件变量
int size = 0;

public void offer(String e) {
    lock.lockInterruptibly();
    try {
        while (isFull()) {
            tailWaits.await();	// 当队列满时, 当前线程进入 tailWaits 等待
        }
        array[tail] = e;
        tail++;
        
        size++;
    } finally {
        lock.unlock();
    }
}

private boolean isFull() {
    return size == array.length;
}
复制<br>
<br>条件变量底层也是个队列，用来存储这些需要等待的线程，当队列满了，就会将 offer 线程加入条件队列，并暂时释放锁
<br>将来我们的队列如果不满了（由 poll 线程那边得知）可以调用 tailWaits.signal() 来唤醒 tailWaits 中首个等待的线程，被唤醒的线程会再次抢到锁，从上次 await 处继续向下运行
<br>思考为何要用 while 而不是 if，设队列容量是 3<br><br>关键点：<br>
<br>从 tailWaits 中唤醒的线程，会与新来的 offer 的线程争抢锁，谁能抢到是不一定的，如果后者先抢到，就会导致条件又发生变化
<br>这种情况称之为虚假唤醒，唤醒后应该重新检查条件，看是不是得重新进入等待
<br>最后的实现代码<br>/**
 * 单锁实现
 * @param &lt;E&gt; 元素类型
 */
public class BlockingQueue1&lt;E&gt; implements BlockingQueue&lt;E&gt; {
    private final E[] array;
    private int head = 0;
    private int tail = 0;
    private int size = 0; // 元素个数

    @SuppressWarnings("all")
    public BlockingQueue1(int capacity) {
        array = (E[]) new Object[capacity];
    }

    ReentrantLock lock = new ReentrantLock();
    Condition tailWaits = lock.newCondition();
    Condition headWaits = lock.newCondition();

    @Override
    public void offer(E e) throws InterruptedException {
        lock.lockInterruptibly();
        try {
            while (isFull()) {
                tailWaits.await();
            }
            array[tail] = e;
            if (++tail == array.length) {
                tail = 0;
            }
            size++;
            headWaits.signal();
        } finally {
            lock.unlock();
        }
    }

    @Override
    public void offer(E e, long timeout) throws InterruptedException {
        lock.lockInterruptibly();
        try {
            long t = TimeUnit.MILLISECONDS.toNanos(timeout);
            while (isFull()) {
                if (t &lt;= 0) {
                    return;
                }
                t = tailWaits.awaitNanos(t);
            }
            array[tail] = e;
            if (++tail == array.length) {
                tail = 0;
            }
            size++;
            headWaits.signal();
        } finally {
            lock.unlock();
        }
    }

    @Override
    public E poll() throws InterruptedException {
        lock.lockInterruptibly();
        try {
            while (isEmpty()) {
                headWaits.await();
            }
            E e = array[head];
            array[head] = null; // help GC
            if (++head == array.length) {
                head = 0;
            }
            size--;
            tailWaits.signal();
            return e;
        } finally {
            lock.unlock();
        }
    }

    private boolean isEmpty() {
        return size == 0;
    }

    private boolean isFull() {
        return size == array.length;
    }
}
复制<br>
<br>public void offer(E e, long timeout) throws InterruptedException 是带超时的版本，可以只等待一段时间，而不是永久等下去，类似的 poll 也可以做带超时的版本，这个留给大家了
<br>
注意

<br>JDK 中 BlockingQueue 接口的方法命名与我的示例有些差异

<br>方法 offer(E e) 是非阻塞的实现，阻塞实现方法为 put(E e)
<br>方法 poll() 是非阻塞的实现，阻塞实现方法为 take()



<br><br>单锁的缺点在于：<br>
<br>生产和消费几乎是不冲突的，唯一冲突的是生产者和消费者它们有可能同时修改 size
<br>冲突的主要是生产者之间：多个 offer 线程修改 tail
<br>冲突的还有消费者之间：多个 poll 线程修改 head
<br>如果希望进一步提高性能，可以用两把锁<br>
<br>一把锁保护 tail
<br>另一把锁保护 head
<br>ReentrantLock headLock = new ReentrantLock();  // 保护 head 的锁
Condition headWaits = headLock.newCondition(); // 队列空时，需要等待的线程集合

ReentrantLock tailLock = new ReentrantLock();  // 保护 tail 的锁
Condition tailWaits = tailLock.newCondition(); // 队列满时，需要等待的线程集合
复制<br>先看看 offer 方法的初步实现<br>@Override
public void offer(E e) throws InterruptedException {
    tailLock.lockInterruptibly();
    try {
        // 队列满等待
        while (isFull()) {
            tailWaits.await();
        }
        
        // 不满则入队
        array[tail] = e;
        if (++tail == array.length) {
            tail = 0;
        }
        
        // 修改 size （有问题）
        size++;
        
    } finally {
        tailLock.unlock();
    }
}
复制<br>上面代码的缺点是 size 并不受 tailLock 保护，tailLock 与 headLock 是两把不同的锁，并不能实现互斥的效果。因此，size 需要用下面的代码保证原子性<br>AtomicInteger size = new AtomicInteger(0);	   // 保护 size 的原子变量

size.getAndIncrement(); // 自增
size.getAndDecrement(); // 自减
复制<br>代码修改为<br>@Override
public void offer(E e) throws InterruptedException {
    tailLock.lockInterruptibly();
    try {
        // 队列满等待
        while (isFull()) {
            tailWaits.await();
        }
        
        // 不满则入队
        array[tail] = e;
        if (++tail == array.length) {
            tail = 0;
        }
        
        // 修改 size
        size.getAndIncrement();
        
    } finally {
        tailLock.unlock();
    }
}
复制<br>对称地，可以写出 poll 方法<br>@Override
public E poll() throws InterruptedException {
    E e;
    headLock.lockInterruptibly();
    try {
        // 队列空等待
        while (isEmpty()) {
            headWaits.await();
        }
        
        // 不空则出队
        e = array[head];
        if (++head == array.length) {
            head = 0;
        }
        
        // 修改 size
        size.getAndDecrement();
        
    } finally {
        headLock.unlock();
    }
    return e;
}
复制<br>下面来看一个难题，就是如何通知 headWaits 和 tailWaits 中等待的线程，比如 poll 方法拿走一个元素，通知 tailWaits：我拿走一个，不满了噢，你们可以放了，因此代码改为<br>@Override
public E poll() throws InterruptedException {
    E e;
    headLock.lockInterruptibly();
    try {
        // 队列空等待
        while (isEmpty()) {
            headWaits.await();
        }
        
        // 不空则出队
        e = array[head];
        if (++head == array.length) {
            head = 0;
        }
        
        // 修改 size
        size.getAndDecrement();
        
        // 通知 tailWaits 不满（有问题）
        tailWaits.signal();
        
    } finally {
        headLock.unlock();
    }
    return e;
}
复制<br>问题在于要使用这些条件变量的 await()， signal() 等方法需要先获得与之关联的锁，上面的代码若直接运行会出现以下错误<br>java.lang.IllegalMonitorStateException
复制<br>那有同学说，加上锁不就行了吗，于是写出了下面的代码<br>“imgs/image-20230208160343493.png” could not be found.<br>发现什么问题了？两把锁这么嵌套使用，非常容易出现死锁，如下所示<br>“imgs/image-20230208160143386.png” could not be found.<br>因此得避免嵌套，两段加锁的代码变成了下面平级的样子<br>“imgs/image-20230208162857435.png” could not be found.<br>性能还可以进一步提升<br>
<br>
代码调整后 offer 并没有同时获取 tailLock 和 headLock 两把锁，因此两次加锁之间会有空隙，这个空隙内可能有其它的 offer 线程添加了更多的元素，那么这些线程都要执行 signal()，通知 poll 线程队列非空吗？

<br>每次调用 signal() 都需要这些 offer 线程先获得 headLock 锁，成本较高，要想法减少 offer 线程获得 headLock 锁的次数
<br>可以加一个条件：当 offer 增加前队列为空，即从 0 变化到不空，才由此 offer 线程来通知 headWaits，其它情况不归它管


<br>
队列从 0 变化到不空，会唤醒一个等待的 poll 线程，这个线程被唤醒后，肯定能拿到 headLock 锁，因此它具备了唤醒 headWaits 上其它 poll 线程的先决条件。如果检查出此时有其它 offer 线程新增了元素（不空，但不是从0变化而来），那么不妨由此 poll 线程来唤醒其它 poll 线程

<br>这个技巧被称之为级联通知（cascading notifies），类似的原因<br>
<br>在 poll 时队列从满变化到不满，才由此 poll 线程来唤醒一个等待的 offer 线程，目的也是为了减少 poll 线程对 tailLock 上锁次数，剩下等待的 offer 线程由这个 offer 线程间接唤醒
<br>最终的代码为<br>public class BlockingQueue2&lt;E&gt; implements BlockingQueue&lt;E&gt; {

    private final E[] array;
    private int head = 0;
    private int tail = 0;
    private final AtomicInteger size = new AtomicInteger(0);
    ReentrantLock headLock = new ReentrantLock();
    Condition headWaits = headLock.newCondition();
    ReentrantLock tailLock = new ReentrantLock();
    Condition tailWaits = tailLock.newCondition();

    public BlockingQueue2(int capacity) {
        this.array = (E[]) new Object[capacity];
    }

    @Override
    public void offer(E e) throws InterruptedException {
        int c;
        tailLock.lockInterruptibly();
        try {
            while (isFull()) {
                tailWaits.await();
            }
            array[tail] = e;
            if (++tail == array.length) {
                tail = 0;
            }            
            c = size.getAndIncrement();
            // a. 队列不满, 但不是从满-&gt;不满, 由此offer线程唤醒其它offer线程
            if (c + 1 &lt; array.length) {
                tailWaits.signal();
            }
        } finally {
            tailLock.unlock();
        }
        // b. 从0-&gt;不空, 由此offer线程唤醒等待的poll线程
        if (c == 0) {
            headLock.lock();
            try {
                headWaits.signal();
            } finally {
                headLock.unlock();
            }
        }
    }

    @Override
    public E poll() throws InterruptedException {
        E e;
        int c;
        headLock.lockInterruptibly();
        try {
            while (isEmpty()) {
                headWaits.await(); 
            }
            e = array[head]; 
            if (++head == array.length) {
                head = 0;
            }
            c = size.getAndDecrement();
            // b. 队列不空, 但不是从0变化到不空，由此poll线程通知其它poll线程
            if (c &gt; 1) {
                headWaits.signal();
            }
        } finally {
            headLock.unlock();
        }
        // a. 从满-&gt;不满, 由此poll线程唤醒等待的offer线程
        if (c == array.length) {
            tailLock.lock();
            try {
                tailWaits.signal();
            } finally {
                tailLock.unlock();
            }
        }
        return e;
    }

    private boolean isEmpty() {
        return size.get() == 0;
    }

    private boolean isFull() {
        return size.get() == array.length;
    }

}
复制<br>双锁实现的非常精巧，据说作者 Doug Lea 花了一年的时间才完善了此段代码<br><br>以大顶堆为例，相对于之前的优先级队列，增加了堆化等方法<br>public class MaxHeap {
    int[] array;
    int size;

    public MaxHeap(int capacity) {
        this.array = new int[capacity];
    }

    /**
     * 获取堆顶元素
     *
     * @return 堆顶元素
     */
    public int peek() {
        return array[0];
    }

    /**
     * 删除堆顶元素
     *
     * @return 堆顶元素
     */
    public int poll() {
        int top = array[0];
        swap(0, size - 1);
        size--;
        down(0);
        return top;
    }

    /**
     * 删除指定索引处元素
     *
     * @param index 索引
     * @return 被删除元素
     */
    public int poll(int index) {
        int deleted = array[index];
        swap(index, size - 1);
        size--;
        down(index);
        return deleted;
    }

    /**
     * 替换堆顶元素
     * @param replaced 新元素
     */
    public void replace(int replaced) {
        array[0] = replaced;
        down(0);
    }

    /**
     * 堆的尾部添加元素
     *
     * @param offered 新元素
     * @return 是否添加成功
     */
    public boolean offer(int offered) {
        if (size == array.length) {
            return false;
        }
        up(offered);
        size++;
        return true;
    }

    // 将 offered 元素上浮: 直至 offered 小于父元素或到堆顶
    private void up(int offered) {
        int child = size;
        while (child &gt; 0) {
            int parent = (child - 1) / 2;
            if (offered &gt; array[parent]) {
                array[child] = array[parent];
            } else {
                break;
            }
            child = parent;
        }
        array[child] = offered;
    }

    public MaxHeap(int[] array) {
        this.array = array;
        this.size = array.length;
        heapify();
    }

    // 建堆
    private void heapify() {
        // 如何找到最后这个非叶子节点  size / 2 - 1
        for (int i = size / 2 - 1; i &gt;= 0; i--) {
            down(i);
        }
    }

    // 将 parent 索引处的元素下潜: 与两个孩子较大者交换, 直至没孩子或孩子没它大
    private void down(int parent) {
        int left = parent * 2 + 1;
        int right = left + 1;
        int max = parent;
        if (left &lt; size &amp;&amp; array[left] &gt; array[max]) {
            max = left;
        }
        if (right &lt; size &amp;&amp; array[right] &gt; array[max]) {
            max = right;
        }
        if (max != parent) { // 找到了更大的孩子
            swap(max, parent);
            down(max);
        }
    }

    // 交换两个索引处的元素
    private void swap(int i, int j) {
        int t = array[i];
        array[i] = array[j];
        array[j] = t;
    }

    public static void main(String[] args) {

        int[] array = {1, 2, 3, 4, 5, 6, 7};
        MaxHeap maxHeap = new MaxHeap(array);
        System.out.println(Arrays.toString(maxHeap.array));
    }
}
复制<br>建堆<br>Floyd 建堆算法作者（也是之前龟兔赛跑判环作者）：<br>“imgs/image-20230213095110902.png” could not be found.<br>
<br>找到最后一个非叶子节点
<br>从后向前，对每个节点执行下潜
<br>一些规律<br>
<br>一棵满二叉树节点个数为 ，如下例中高度  节点数是 
<br>非叶子节点范围为 
<br>算法时间复杂度分析<br>“imgs/image-20230213114024607.png” could not be found.<br>下面看交换次数的推导：设节点高度为 3<br><br>每一层的交换次数为：，总的交换次数为<br><br>即<br><br>在 <a rel="noopener" class="external-link" href="https://www.wolframalpha.com/" target="_blank">https://www.wolframalpha.com/</a> 输入<br>Sum[\(40)Divide[Power[2,x],Power[2,i]]*\(40)i-1\(41)\(41),{i,1,x}]
复制<br>推导出 <br><br>其中 ，，因此有时间复杂度 <br><br>二叉树是这么一种树状结构：每个节点最多有两个孩子，左孩子和右孩子<br>重要的二叉树结构<br>
<br>完全二叉树（complete binary tree）是一种二叉树结构，除最后一层以外，每一层都比填满，填充时要遵从先左后右
<br>平衡二叉树（balance binary tree）是一种二叉树结构，其中每个节点的左右子树高度相差不超过1
<br><br>存储方式分为两种<br>
<br>定义树节点与左、右孩子引用
<br>使用数组，前面讲堆时用过，若以 0 作为树的根，索引可以通过如下方式计算

<br>父 = floor((子 - 1) / 2)
<br>左孩子 = 父 * 2 + 1
<br>右孩子 = 父 * 2 + 2


<br><br>遍历也分为两种<br>
<br>广度优先遍历（Breadth-first order）：尽可能先访问距离根最近的节点，也称为层序遍历
<br>深度优先遍历（Depth-first order）：对于二叉树，可以进一步分成三种

<br>pre-order 前序遍历，对于每一棵子树，先访问该节点，然后是左子树，最后是右子树
<br>in-order 中序遍历，对于每一棵子树，先访问左子树，然后是该节点，最后是右子树
<br>post-order 后续遍历，对于每一棵子树，先访问左子树，然后是右子树，最后是该节点


<br><br>“imgs/image-20230216153607396.png” could not be found.<br><br>本轮开始未遍历的节点<br>遍历 1 时，记录它的两个孩子 2，3<br>遍历 2 时，记录它<br><br>“imgs/image-20230216170808368.png” could not be found.<br><br><br>/**
 * &lt;h3&gt;前序遍历&lt;/h3&gt;
 * @param node 节点
 */
static void preOrder(TreeNode node) {
    if (node == null) {
        return;
    }
    System.out.print(node.val + "\t"); // 值
    preOrder(node.left); // 左
    preOrder(node.right); // 右
}

/**
 * &lt;h3&gt;中序遍历&lt;/h3&gt;
 * @param node 节点
 */
static void inOrder(TreeNode node) {
    if (node == null) {
        return;
    }
    inOrder(node.left); // 左
    System.out.print(node.val + "\t"); // 值
    inOrder(node.right); // 右
}

/**
 * &lt;h3&gt;后序遍历&lt;/h3&gt;
 * @param node 节点
 */
static void postOrder(TreeNode node) {
    if (node == null) {
        return;
    }
    postOrder(node.left); // 左
    postOrder(node.right); // 右
    System.out.print(node.val + "\t"); // 值
}
复制<br><br>前序遍历<br>LinkedListStack&lt;TreeNode&gt; stack = new LinkedListStack&lt;&gt;();
TreeNode curr = root;

while (!stack.isEmpty() || curr != null) {
    if (curr != null) {
        stack.push(curr);
        System.out.println(curr);
        curr = curr.left;
    } else {
        TreeNode pop = stack.pop();
        curr = pop.right;
    }

}
复制<br>中序遍历<br>LinkedListStack&lt;TreeNode&gt; stack = new LinkedListStack&lt;&gt;();
TreeNode curr = root;

while (!stack.isEmpty() || curr != null) {
    if (curr != null) {
        stack.push(curr);
        curr = curr.left;
    } else {
        TreeNode pop = stack.pop();
        System.out.println(pop);
        curr = pop.right;
    }
}
复制<br>后序遍历<br>LinkedListStack&lt;TreeNode&gt; stack = new LinkedListStack&lt;&gt;();
TreeNode curr = root;
TreeNode pop = null;

while (!stack.isEmpty() || curr != null) {
    if (curr != null) {
        stack.push(curr);
        curr = curr.left;
    } else {
        TreeNode peek = stack.peek();
        if (peek.right == null || peek.right == pop) {
            pop = stack.pop();
            System.out.println(pop);
        } else {
            curr = peek.right;
        }
    }
}
复制<br>对于后序遍历，向回走时，需要处理完右子树才能 pop 出栈。如何知道右子树处理完成呢？<br>
<br>
如果栈顶元素的  表示没啥可处理的，可以出栈

<br>
如果栈顶元素的 ，

<br>那么使用 lastPop 记录最近出栈的节点，即表示从这个节点向回走
<br>如果栈顶元素的  此时应当出栈


<br>对于前、中两种遍历，实际以上代码从右子树向回走时，并未走完全程（stack 提前出栈了）后序遍历以上代码是走完全程了<br>统一写法<br>下面是一种统一的写法，依据后序遍历修改<br>LinkedList&lt;TreeNode&gt; stack = new LinkedList&lt;&gt;();

TreeNode curr = root; // 代表当前节点
TreeNode pop = null; // 最近一次弹栈的元素
while (curr != null || !stack.isEmpty()) {
    if (curr != null) {
        colorPrintln("前: " + curr.val, 31);
        stack.push(curr); // 压入栈，为了记住回来的路
        curr = curr.left;
    } else {
        TreeNode peek = stack.peek();
        // 右子树可以不处理, 对中序来说, 要在右子树处理之前打印
        if (peek.right == null) {
            colorPrintln("中: " + peek.val, 36);
            pop = stack.pop();
            colorPrintln("后: " + pop.val, 34);
        }
        // 右子树处理完成, 对中序来说, 无需打印
        else if (peek.right == pop) {
            pop = stack.pop();
            colorPrintln("后: " + pop.val, 34);
        }
        // 右子树待处理, 对中序来说, 要在右子树处理之前打印
        else {
            colorPrintln("中: " + peek.val, 36);
            curr = peek.right;
        }
    }
}

public static void colorPrintln(String origin, int color) {
    System.out.printf("\033[%dm%s\033[0m%n", color, origin);
}
复制<br><br><br>用函数  表示算法效率与数据规模的关系，假设每次解决问题需要 1 微秒（ 秒），进行估算：<br>
<br>如果  那么 1 秒能解决多少次问题？1 天呢？
<br>如果   那么 1 秒能解决多少次问题？1 天呢？
<br>如果  那么 1 秒能解决多少次问题？1 天呢？
<br>参考解答<br>
<br>1秒  次，1 天  次
<br>1秒 
<br>推算如下

<br> 1秒能解决  次，因此次数为 9 次
<br>，一天能解决  次，因此次数为 13 次


<br><br><br>要点：减而治之，可以用递归或非递归实现<br>给定一个 n 个元素有序的（升序）整型数组 nums 和一个目标值 target  ，写一个函数搜索 nums 中的 target，如果目标值存在返回下标，否则返回 -1<br>例如<br>输入: nums = [-1,0,3,5,9,12], target = 9
输出: 4
解释: 9 出现在 nums 中并且下标为 4
    
输入: nums = [-1,0,3,5,9,12], target = 2
输出: -1
解释: 2 不存在 nums 中因此返回 -1    
复制<br>参考答案：略，可以用讲过的任意一种二分求解<br><br>要点：理解谁代表插入位置<br>给定一个排序数组和一个目标值<br>
<br>在数组中找到目标值，并返回其索引
<br>如果目标值不存在于数组中，返回它将会被按顺序插入的位置
<br>例如<br>输入: nums = [1,3,5,6], target = 5
输出: 2

输入: nums = [1,3,5,6], target = 2
输出: 1

输入: nums = [1,3,5,6], target = 7
输出: 4
复制<br>参考答案1：用二分查找基础版代码改写，基础版中，找到返回 m，没找到 i 代表插入点，因此有<br>public int searchInsert(int[] a, int target) {
    int i = 0, j = a.length - 1;
    while (i &lt;= j) {
        int m = (i + j) &gt;&gt;&gt; 1;
        if (target &lt; a[m]) {
            j = m - 1;
        } else if (a[m] &lt; target) {
            i = m + 1;
        } else {
            return m;
        }
    }
    return i; // 原始 return -1
}
复制<br>参考答案2：用二分查找平衡版改写，平衡版中<br>
<br>如果 target == a[i] 返回 i 表示找到
<br>如果 target &lt; a[i]，例如 target = 2，a[i] = 3，这时就应该在 i 位置插入 2
<br>如果 a[i] &lt; target，例如 a[i] = 3，target = 4，这时就应该在 i+1 位置插入 4
<br>public static int searchInsert(int[] a, int target) {
    int i = 0, j = a.length;
    while (1 &lt; j - i) {
        int m = (i + j) &gt;&gt;&gt; 1;
        if (target &lt; a[m]) {
            j = m;
        } else {
            i = m;
        }
    }
    return (target &lt;= a[i]) ? i : i + 1;
    // 原始 (target == a[i]) ? i : -1;
}
复制<br>参考答案3：用 leftmost 版本解，返回值即为插入位置（并能处理元素重复的情况）<br>public int searchInsert(int[] a, int target) {
    int i = 0, j = a.length - 1;
    while(i &lt;= j) {
        int m = (i + j) &gt;&gt;&gt; 1;
        if(target &lt;= a[m]) {
            j = m - 1;
        } else {
            i = m + 1;
        } 
    }
    return i;
}
复制<br><br>给你一个按照非递减顺序排列的整数数组 nums，和一个目标值 target。请你找出给定目标值在数组中的开始位置和结束位置。<br>如果数组中不存在目标值 target，返回 [-1, -1]。<br>你必须设计并实现时间复杂度为 O(log n) 的算法解决此问题<br>例如<br>输入：nums = [5,7,7,8,8,10], target = 8
输出：[3,4]

输入：nums = [5,7,7,8,8,10], target = 6
输出：[-1,-1]

输入：nums = [], target = 0
输出：[-1,-1]
复制<br>参考答案<br>public static int left(int[] a, int target) {
    int i = 0, j = a.length - 1;
    int candidate = -1;
    while (i &lt;= j) {
        int m = (i + j) &gt;&gt;&gt; 1;
        if (target &lt; a[m]) {
            j = m - 1;
        } else if (a[m] &lt; target) {
            i = m + 1;
        } else {
            candidate = m;
            j = m - 1;
        }
    }
    return candidate;
}

public static int right(int[] a, int target) {
    int i = 0, j = a.length - 1;
    int candidate = -1;
    while (i &lt;= j) {
        int m = (i + j) &gt;&gt;&gt; 1;
        if (target &lt; a[m]) {
            j = m - 1;
        } else if (a[m] &lt; target) {
            i = m + 1;
        } else {
            candidate = m;
            i = m + 1;
        }
    }
    return candidate;
}

public static int[] searchRange(int[] nums, int target) {
    int x = left(nums, target);
    if(x == -1) {
        return new int[] {-1, -1};
    } else {
        return new int[] {x, right(nums, target)};
    }
}
复制<br><br><br>public static int binarySearch(int[] a, int target) {
    return recursion(a, target, 0, a.length - 1);
}

public static int recursion(int[] a, int target, int i, int j) {
    if (i &gt; j) {
        return -1;
    }
    int m = (i + j) &gt;&gt;&gt; 1;
    if (target &lt; a[m]) {
        return recursion(a, target, i, m - 1);
    } else if (a[m] &lt; target) {
        return recursion(a, target, m + 1, j);
    } else {
        return m;
    }
}
复制<br><br>public static void main(String[] args) {
    int[] a = {3, 2, 6, 1, 5, 4, 7};
    bubble(a, 0, a.length - 1);
    System.out.println(Arrays.toString(a));
}

private static void bubble(int[] a, int low, int high) {
    if(low == high) {
        return;
    }
    int j = low;
    for (int i = low; i &lt; high; i++) {
        if (a[i] &gt; a[i + 1]) {
            swap(a, i, i + 1);
            j = i;
        }
    }
    bubble(a, low, j);
}

private static void swap(int[] a, int i, int j) {
    int t = a[i];
    a[i] = a[j];
    a[j] = t;
}
复制<br>
<br>low 与 high 为未排序范围
<br>j 表示的是未排序的边界，下一次递归时的 high

<br>发生交换，意味着有无序情况
<br>最后一次交换（以后没有无序）时，左侧 i 仍是无序，右侧 i+1 已然有序


<br>视频中讲解的是只考虑 high 边界的情况，参考以上代码，理解在 low .. high 范围内的处理方法
<br><br>public static void main(String[] args) {
    int[] a = {3, 2, 6, 1, 5, 7, 4};
    insertion(a, 1, a.length - 1);
    System.out.println(Arrays.toString(a));
}

private static void insertion(int[] a, int low, int high) {
    if (low &gt; high) {
        return;
    }
    int i = low - 1;
    int t = a[low];
    while (i &gt;= 0 &amp;&amp; a[i] &gt; i) {
        a[i + 1] = a[i];
        i--;
    }
    if(i + 1 != low) {
        a[i + 1] = t;
    }    
    insertion(a, low + 1, high);
}
复制<br>
<br>已排序区域：[0 .. i .. low-1]
<br>未排序区域：[low .. high]
<br>视频中讲解的是只考虑 low 边界的情况，参考以上代码，理解 low-1 ..  high 范围内的处理方法
<br>扩展：利用二分查找 leftmost 版本，改进寻找插入位置的代码
<br><br> 个人排成圆圈，从头开始报数，每次数到第  个人（ 从  开始）杀之，继续从下一个人重复以上过程，求最后活下来的人是谁？<br>方法1<br>根据最后的存活者 a 倒推出它在上一轮的索引号<br><br>方法2<br>设 n 为总人数，m 为报数次数，解返回的是这些人的索引，从0开始<br><br>一. 找出等价函数<br>规律：下次报数的起点为 <br>
<br>首次出列人的序号是 ，剩下的的  个人重新组成约瑟夫环
<br>下次从  开始数，序号如下

<br>，如上例中 


<br>这个函数称之为 ，它的最终结果与  是相同的。<br>二. 找到映射函数<br>现在想办法找到  与  的对应关系，即<br><br>映射函数为<br><br>等价于下面函数<br><br>代入测试一下<br><br>综上有<br><br>三. 求逆映射函数<br>映射函数是根据 x 计算 y，逆映射函数即根据 y 得到 x<br><br>代入测试一下<br><br>因此可以求得<br><br>四. 递推式<br>代入推导<br><br>最后一步化简是利用了模运算法则<br>  例如 <br>
<br>
<br>
<br>
<br>最终递推式<br><br><br><br>Tower of Hanoi，是一个源于印度古老传说：大梵天创建世界时做了三根金刚石柱，在一根柱子从下往上按大小顺序摞着 64 片黄金圆盘，大梵天命令婆罗门把圆盘重新摆放在另一根柱子上，并且规定<br>
<br>一次只能移动一个圆盘
<br>小圆盘上不能放大圆盘
<br>下面的动图演示了4片圆盘的移动方法<br>“imgs/Tower_of_Hanoi_4.gif” could not be found.<br>使用程序代码模拟圆盘的移动过程，并估算出时间复杂度<br>思路<br>
<br>
假设每根柱子标号 a，b，c，每个圆盘用 1，2，3 ... 表示其大小，圆盘初始在 a，要移动到的目标是 c

<br>
如果只有一个圆盘，此时是最小问题，可以直接求解

<br>移动圆盘1   

<img style="zoom:50%;" alt="image-20221219090741078" src="\imgs\image-20221219090741078.png" referrerpolicy="no-referrer">

<br>
如果有两个圆盘，那么

<br>圆盘1  
<br>圆盘2 
<br>圆盘1 

<img style="zoom:50%;" alt="image-20221219091316225" src="\imgs\image-20221219091316225.png" referrerpolicy="no-referrer">

<br>
如果有三个圆盘，那么

<br>圆盘12 
<br>圆盘3 
<br>圆盘12 

<img style="zoom:50%;" alt="image-20221219091930614" src="\imgs\image-20221219091930614.png" referrerpolicy="no-referrer">

<br>
如果有四个圆盘，那么

<br>圆盘 123 
<br>圆盘4 
<br>圆盘 123 


<br><img style="zoom:50%;" alt="image-20221219092537323" src="\imgs\image-20221219092537323.png" referrerpolicy="no-referrer"><br>题解<br>public class E02HanoiTower {


    /*
             源 借 目
        h(4, a, b, c) -&gt; h(3, a, c, b)
                         a -&gt; c
                         h(3, b, a, c)
     */
    static LinkedList&lt;Integer&gt; a = new LinkedList&lt;&gt;();
    static LinkedList&lt;Integer&gt; b = new LinkedList&lt;&gt;();
    static LinkedList&lt;Integer&gt; c = new LinkedList&lt;&gt;();

    static void init(int n) {
        for (int i = n; i &gt;= 1; i--) {
            a.add(i);
        }
    }

    static void h(int n, LinkedList&lt;Integer&gt; a, 
                  LinkedList&lt;Integer&gt; b, 
                  LinkedList&lt;Integer&gt; c) {
        if (n == 0) {
            return;
        }
        h(n - 1, a, c, b);
        c.addLast(a.removeLast());
        print();
        h(n - 1, b, a, c);
    }

    private static void print() {
        System.out.println("-----------------------");
        System.out.println(a);
        System.out.println(b);
        System.out.println(c);
    }

    public static void main(String[] args) {
        init(3);
        print();
        h(3, a, b, c);
    }
}
复制<br><br>“imgs/image-20221219172514410.png” could not be found.<br>分析<br>把它斜着看<br>        1
      1   1
    1   2   1
  1   3   3   1
1   4   6   4   1
复制<br>
<br>行 ，列 ，那么  的取值应为 
<br>当  或  时， 取值为 
<br>题解<br>public static void print(int n) {
    for (int i = 0; i &lt; n; i++) {
        if (i &lt; n - 1) {
            System.out.printf("%" + 2 * (n - 1 - i) + "s", " ");
        }

        for (int j = 0; j &lt; i + 1; j++) {
            System.out.printf("%-4d", element(i, j));
        }
        System.out.println();
    }
}

public static int element(int i, int j) {
    if (j == 0 || i == j) {
        return 1;
    }
    return element(i - 1, j - 1) + element(i - 1, j);
}
复制<br>优化1<br>是 multiple recursion，因此很多递归调用是重复的，例如<br>
<br>recursion(3, 1) 分解为

<br>recursion(2, 0) + recursion(2, 1) 


<br>而 recursion(3, 2) 分解为

<br>recursion(2, 1) + recursion(2, 2)


<br>这里 recursion(2, 1) 就重复调用了，事实上它会重复很多次，可以用 static AtomicInteger counter = new AtomicInteger(0) 来查看递归函数的调用总次数<br>事实上，可以用 memoization 来进行优化：<br>public static void print1(int n) {
    int[][] triangle = new int[n][];
    for (int i = 0; i &lt; n; i++) {
        // 打印空格
        triangle[i] = new int[i + 1];
        for (int j = 0; j &lt;= i; j++) {
            System.out.printf("%-4d", element1(triangle, i, j));
        }
        System.out.println();
    }
}

public static int element1(int[][] triangle, int i, int j) {
    if (triangle[i][j] &gt; 0) {
        return triangle[i][j];
    }

    if (j == 0 || i == j) {
        triangle[i][j] = 1;
        return triangle[i][j];
    }
    triangle[i][j] = element1(triangle, i - 1, j - 1) + element1(triangle, i - 1, j);
    return triangle[i][j];
}
复制<br>
<br>将数组作为递归函数内可以访问的遍历，如果  已经有值，说明该元素已经被之前的递归函数计算过，就不必重复计算了
<br>优化2<br>public static void print2(int n) {
    int[] row = new int[n];
    for (int i = 0; i &lt; n; i++) {
        // 打印空格
        createRow(row, i);
        for (int j = 0; j &lt;= i; j++) {
            System.out.printf("%-4d", row[j]);
        }
        System.out.println();
    }
}

private static void createRow(int[] row, int i) {
    if (row[i] &gt; 0) { // 表示这一整行已经计算过
        return;
    }
    if (i == 0) {
        row[0] = 1;
        return;
    }
    createRow(row, i - 1);
    for (int j = i; j &gt; 0; j--) {
        row[j] = row[j - 1] + row[j];
    }
}
复制<br>
注意：还可以通过每一行的前一项计算出下一项，不必借助上一行，这与杨辉三角的另一个特性有关，暂不展开了
<br>力扣对应题目，但递归不适合在力扣刷高分，因此只列出相关题目，不做刷题讲解了<br>
<br><a data-tooltip-position="top" aria-label="https://leetcode.cn/problems/pascals-triangle/" rel="noopener" class="external-link" href="https://leetcode.cn/problems/pascals-triangle/" target="_blank">118. 杨辉三角 - 力扣（LeetCode）</a>
<br><a data-tooltip-position="top" aria-label="https://leetcode.cn/problems/pascals-triangle-ii/solution/yang-hui-san-jiao-ii-by-leetcode-solutio-shuk/" rel="noopener" class="external-link" href="https://leetcode.cn/problems/pascals-triangle-ii/solution/yang-hui-san-jiao-ii-by-leetcode-solutio-shuk/" target="_blank">119. 杨辉三角 II - 力扣（LeetCode）</a>
<br><br><br>对应力扣题目 <a data-tooltip-position="top" aria-label="https://leetcode.cn/problems/reverse-linked-list/" rel="noopener" class="external-link" href="https://leetcode.cn/problems/reverse-linked-list/" target="_blank">206. 反转链表 - 力扣（LeetCode）</a><br>输入：head = [1,2,3,4,5]
输出：[5,4,3,2,1]

输入：[1,2]
输出：[2,1]

输入：[]
输出：[]
复制<br>方法1<br>构造一个新链表，从旧链表依次拿到每个节点，创建新节点添加至新链表头部，完成后新链表即是倒序的<br>public ListNode reverseList(ListNode o1) {
    ListNode n1 = null;
    ListNode p = o1;
    while (p != null) {
        n1 = new ListNode(p.val, n1);
        p = p.next;
    }
    return n1;
}
复制<br>评价：简单直白，就是得新创建节点对象<br>方法2<br>与方法1 类似，构造一个新链表，从旧链表头部移除节点，添加到新链表头部，完成后新链表即是倒序的，区别在于原题目未提供节点外层的容器类，这里提供一个，另外一个区别是并不去构造新节点<br>static class List {
    ListNode head;

    public List(ListNode head) {
        this.head = head;
    }

    public ListNode removeFirst(){
        ListNode first = head;
        if (first != null) {
            head = first.next;
        }
        return first;
    }

    public void addFirst(ListNode first) {
        first.next = head;
        head = first;
    }
}
复制<br>代码<br>public ListNode reverseList(ListNode head) {
    List list1 = new List(head);
    List list2 = new List(null);
    ListNode first;
    while ((first = list1.removeFirst()) != null) {
        list2.addFirst(first);
    }
    return list2.head;
}
复制<br>评价：更加面向对象，如果实际写代码而非刷题，更多会这么做<br>方法3<br>递归，在归时让 ， ...<br>首先，写一个递归方法，返回值用来拿到最后一个节点<br>public ListNode reverseList(ListNode p) {
    if (p == null || p.next == null) { // 不足两个节点
        return p; // 最后一个节点
    }
    ListNode last = reverseList(p.next);
    return last;
}
复制<br>
<br>注意1：递归终止条件是 curr.next == null，目的是到最后一个节点就结束递归，与之前递归遍历不一样
<br>注意2：需要考虑空链表即 p == null 的情况
<br>可以先测试一下<br>ListNode o5 = new ListNode(5, null);
ListNode o4 = new ListNode(4, o5);
ListNode o3 = new ListNode(3, o4);
ListNode o2 = new ListNode(2, o3);
ListNode o1 = new ListNode(1, o2);
ListNode n1 = new E01Leetcode206().reverseList(o1);
System.out.println(n1);
复制<br>会打印<br>[5]
复制<br>下面为伪码调用过程，假设节点分别是 ，先忽略返回值<br>reverseList(ListNode p = 1) {
    reverseList(ListNode p = 2) {
    	reverseList(ListNode p = 3) {
    		reverseList(ListNode p = 4) {
    			reverseList(ListNode p = 5) {
    				if (p == null || p.next == null) {
                        return p; // 返回5
                    }
				}
                // 此时p是4, p.next是5
			}
            // 此时p是3, p.next是4
		}
        // 此时p是2, p.next是3
	}
    // 此时p是1, p.next是2
}
复制<br>接下来，从 p = 4 开始，要让 ， ...<br>reverseList(ListNode p = 1) {
    reverseList(ListNode p = 2) {
    	reverseList(ListNode p = 3) {
    		reverseList(ListNode p = 4) {
    			reverseList(ListNode p = 5) {
    				if (p == null || p.next == null) {
                        return p; // 返回5
                    }
				}
                // 此时p是4, p.next是5, 要让5指向4,代码写成 p.next.next=p
                // 还要注意4要指向 null, 否则就死链了
			}
            // 此时p是3, p.next是4
		}
        // 此时p是2, p.next是3
	}
    // 此时p是1, p.next是2
}
复制<br>最终代码为：<br>public ListNode reverseList(ListNode p) {    
    if (p == null || p.next == null) { // 不足两个节点
        return p; // 最后一个节点
    }
    ListNode last = reverseList(p.next);
    p.next.next = p;
    p.next = null;
    return last;
}
复制<br>Q：为啥不能在递的过程中倒序？<br>A：比如<br>
<br>$ 1 \rightarrow 2 \rightarrow 3 $ 如果递的过程中让  那么此时  就被覆盖，不知道接下来递给谁
<br>而归的时候让  不会影响上一层的 
<br>评价：单向链表没有 prev 指针，但利用递归的特性【记住了】链表每次调用时相邻两个节点是谁<br>方法4<br>从链表每次拿到第二个节点，将其从链表断开，插入头部，直至它为 null 结束<br>
<br>设置指针 o1(旧头)、n1(新头)、o2(旧老二)，分别指向第一，第一，第二节点
<br><br>
<br>将 o2 节点从链表断开，即 o1 节点指向第三节点
<br>$ \frac{n1 \ o1}{1} \rightarrow 3 \rightarrow 4 \rightarrow 5 \rightarrow null$ ，<br>
<br>o2 节点链入链表头部，即
<br><br>
<br>n1 指向 o2
<br><br>
<br>o2 指向 o1 的下一个节点，即
<br><br>
<br>
重复以上  步，直到 o2 指向 null

<br>
还应当考虑边界条件，即链表中不满两个元素时，无需走以上逻辑

<br>参考答案<br>public ListNode reverseList(ListNode o1) {    
    if (o1 == null || o1.next == null) { // 不足两个节点
        return o1;
    }
    ListNode o2 = o1.next;
    ListNode n1 = o1;
    while (o2 != null) {
        o1.next = o2.next; 
        o2.next = n1;
        n1 = o2;
        o2 = o1.next;
    }
    return n1;
}
复制<br>方法5<br>要点：把链表分成两部分，思路就是不断从链表2的头，往链表1的头搬移<br>
<br>n1 指向 null，代表新链表一开始没有元素，o1 指向原链表的首节点
<br>，<br>
<br>开始循环，o2 指向原链表次节点
<br>，<br>
<br>搬移
<br>  ， <br>
<br>指针复位
<br> ， <br>
<br>重复  步
<br>当 o1 = null 时退出循环
<br>参考答案<br>public ListNode reverseList(ListNode o1) {
    if (o1 == null || o1.next == null) {
        return o1;
    }
    ListNode n1 = null;
    while (o1 != null) {
        ListNode o2 = o1.next;
        o1.next = n1;
        n1 = o1;
        o1 = o2;
    }
    return n1;
}
复制<br>评价：本质上与方法2 相同，只是方法2更为面向对象<br><br>例如<br>输入：head = [1,2,6,3,6], val = 6
输出：[1,2,3]

输入：head = [], val = 1
输出：[]

输入：head = [7,7,7,7], val = 7
输出：[]
复制<br>方法1<br>图中 s 代表 sentinel 哨兵（如果不加哨兵，则删除第一个节点要特殊处理），例如要删除 6<br>p1   p2
s -&gt; 1 -&gt; 2 -&gt; 6 -&gt; 3 -&gt; 6 -&gt; null
复制<br>
<br>如果 p2 不等于目标，则 p1，p2 不断后移
<br>	 p1   p2
s -&gt; 1 -&gt; 2 -&gt; 6 -&gt; 3 -&gt; 6 -&gt; null

	 	  p1   p2
s -&gt; 1 -&gt; 2 -&gt; 6 -&gt; 3 -&gt; 6 -&gt; null
复制<br>
<br>p2 == 6，删除它，注意 p1 此时保持不变，p2 后移
<br>	 	  p1   p2
s -&gt; 1 -&gt; 2 -&gt; 3 -&gt; 6 -&gt; null
复制<br>
<br>p2 不等于目标，则 p1，p2 不断后移
<br>	 	  	   p1   p2
s -&gt; 1 -&gt; 2 -&gt; 3 -&gt; 6 -&gt; null
复制<br>
<br>p2 == 6，删除它，注意 p1 此时保持不变，p2 后移
<br>	 	  	   p1   p2
s -&gt; 1 -&gt; 2 -&gt; 3 -&gt; null
复制<br>
<br>p2 == null 退出循环
<br>最后代码<br>public ListNode removeElements(ListNode head, int val) {
    ListNode sentinel = new ListNode(-1, head);
    ListNode p1 = sentinel;
    ListNode p2;
    while ((p2 = p1.next) != null) {
        if (p2.val == val) {
            p1.next = p2.next;
        } else {
            p1 = p1.next;
        }
    }
    return sentinel.next;
}
复制<br>方法2<br>思路，递归函数负责返回：从当前节点（我）开始，完成删除的子链表<br>
<br>若我与 v 相等，应该返回下一个节点递归结果
<br>若我与 v 不等，应该返回我，但我的 next 应该更新（让我能带上后续删过的子链表）
<br>removeElements(ListNode p=1, int v=6){
    1.next=removeElements(ListNode p=2, int v=6){
    	2.next=removeElements(ListNode p=6, int v=6){
    		removeElements(ListNode p=3, int v=6){
    			3.next=removeElements(ListNode p=6, int v=6){
    				removeElements(ListNode p=null, int v=6){
    					// 没有节点,返回
                        return null
					}
				}
                return 3
			}
		}
        return 2
    }
    return 1
}
复制<br>代码<br>public ListNode removeElements(ListNode head, int val) {
    if (head == null) {
        return null;
    }
    if (head.val == val) {
        return removeElements(head.next, val);
    } else {
        head.next = removeElements(head.next, val);
        return head;
    }
}
复制<br><br>例如<br>输入：head = [1,2,3,4,5], n = 2
输出：[1,2,3,5]

输入：head = [1], n = 1
输出：[]

输入：head = [1,2], n = 1
输出：[1]
复制<br>另外题目提示<br>
<br>链表至少一个节点
<br>n 只会在合理范围
<br>方法1<br>思路，写一个递归函数，用来返回下一个节点的倒数序号<br>recursion(ListNode p=1, int n=2) {
    recursion(ListNode p=2, int n=2) {
    	recursion(ListNode p=3, int n=2) {
    		recursion(ListNode p=4, int n=2) {
    			recursion(ListNode p=5, int n=2) {
    				recursion(ListNode p=null, int n=2) {
    					return 0; // 最内层序号0
					}
                    return 1; // 上一次返回值+1
				}
                return 2;
			}
            if(返回值 == n == 2) {
                // 删除 next
            }
            return 3;
		}
        return 4;
	}
    return 5;
}
复制<br>但上述代码有一个问题，就是若删除的是第一个节点，它没有上一个节点，因此可以加一个哨兵来解决<br>代码<br>public ListNode removeNthFromEnd(ListNode head, int n) {
    ListNode sentinel = new ListNode(-1, head);
    recursion(sentinel, n);
    return sentinel.next;
}

public int recursion(ListNode p, int n) {
    if (p == null) {
        return 0;
    }
    int nth = recursion(p.next, n);
    if (nth == n) {
        p.next = p.next.next;
    }
    return nth + 1;
}
复制<br>Q：p.next.next 不怕空指针吗？<br>A：<br>
<br>p 是待删除节点的上一个节点，如果能递归回到 p，那么 p.next 肯定有值，不会是 null
<br>且题目说明了 n &gt;=1，不会因为 nth == 0 而让 p.next 指向最后的 null
<br>方法2<br>快慢指针，p1 指向待删节点的上一个，p2 先走 n + 1 步<br>i=0
p2
s -&gt; 1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; 5 -&gt; null

     i=1
     p2
s -&gt; 1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; 5 -&gt; null

          i=2
          p2
s -&gt; 1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; 5 -&gt; null

               i=3 从此开始 p1 p2 依次向右平移, 直到 p2 移动到末尾
p1             p2
s -&gt; 1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; 5 -&gt; null

               p1             p2
s -&gt; 1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; 5 -&gt; null
复制<br>代码<br>public ListNode removeNthFromEnd(ListNode head, int n) {
    ListNode s = new ListNode(-1, head);
    ListNode p1 = s;
    ListNode p2 = s;
    for (int i = 0; i &lt; n + 1; i++) {
        p2 = p2.next;
    }
    while (p2 != null) {
        p1 = p1.next;
        p2 = p2.next;
    }
    p1.next = p1.next.next;
    return s.next;
}
复制<br>方法3<br>public ListNode removeNthFromEnd(ListNode head, int n) {
    Composite c = recursion(head, n);
    return c.node;
}

static class Composite {
    ListNode node;
    int nth;

    public Composite(ListNode node, int nth) {
        this.node = node;
        this.nth = nth;
    }
}

public Composite recursion(ListNode p, int n) {
    if (p == null) {
        return new Composite(null, 1);
    }
    Composite c = recursion(p.next, n);
    if (c.nth != n) {
        p.next = c.node;
        c.node = p;
    }
    c.nth +=1;
    return c;
}
复制<br><br>例如<br>输入：head = [1,1,2]
输出：[1,2]

输入：head = [1,1,2,3,3]
输出：[1,2,3]
复制<br>注意：重复元素保留一个<br>方法1<br>p1   p2
1 -&gt; 1 -&gt; 2 -&gt; 3 -&gt; 3 -&gt; null
复制<br>
<br>p1.val == p2.val 那么删除 p2，注意 p1 此时保持不变
<br>p1   p2
1 -&gt; 2 -&gt; 3 -&gt; 3 -&gt; null
复制<br>
<br>p1.val != p2.val 那么 p1，p2 向后移动
<br>     p1   p2
1 -&gt; 2 -&gt; 3 -&gt; 3 -&gt; null
         
          p1   p2
1 -&gt; 2 -&gt; 3 -&gt; 3 -&gt; null     
复制<br>
<br>p1.val == p2.val 那么删除 p2
<br>          p1   p2
1 -&gt; 2 -&gt; 3 -&gt; null   
复制<br>
<br>当 p2 == null 退出循环
<br>代码<br>public ListNode deleteDuplicates(ListNode head) {
    // 链表节点 &lt; 2
    if (head == null || head.next == null) {
        return head;
    }
    // 链表节点 &gt;= 2
    ListNode p1 = head;
    ListNode p2;
    while ((p2 = p1.next) != null) {
        if (p1.val == p2.val) {
            p1.next = p2.next;
        } else {
            p1 = p1.next;
        }
    }
    return head;
}
复制<br>方法2<br>递归函数负责返回：从当前节点（我）开始，完成去重的链表<br>
<br>若我与 next 重复，返回 next
<br>若我与 next 不重复，返回我，但 next 应当更新
<br>deleteDuplicates(ListNode p=1) {
    deleteDuplicates(ListNode p=1) {
        1.next=deleteDuplicates(ListNode p=2) {
            2.next=deleteDuplicates(ListNode p=3) {
                deleteDuplicates(ListNode p=3) {
					// 只剩一个节点，返回
                    return 3
                }                
            }
            return 2
        }
        return 1
    }
}
复制<br>代码<br>public ListNode deleteDuplicates(ListNode p) {
    if (p == null || p.next == null) {
        return p;
    }
    if(p.val == p.next.val) {
        return deleteDuplicates(p.next);
    } else {
        p.next = deleteDuplicates(p.next);
        return p;
    }
}
复制<br><br>例如<br>输入：head = [1,2,3,3,4,4,5]
输出：[1,2,5]

输入：head = [1,1,1,2,3]
输出：[2,3]
复制<br>注意：重复元素一个不留<br>方法1<br>递归函数负责返回：从当前节点（我）开始，完成去重的链表<br>
<br>若我与 next 重复，一直找到下一个不重复的节点，以它的返回结果为准
<br>若我与 next 不重复，返回我，同时更新 next
<br>deleteDuplicates(ListNode p = 1) {
    // 找下个不重复的
	deleteDuplicates(ListNode p = 1) {
        deleteDuplicates(ListNode p = 1) {
			deleteDuplicates(ListNode p = 2) {
                2.next=deleteDuplicates(ListNode p = 3) {
					// 只剩一个节点，返回
                    return 3
                }
                return 2
			}
        }
    }
}
复制<br>代码<br>public ListNode deleteDuplicates(ListNode p) {
    if (p == null || p.next == null) {
        return p;
    }
    if (p.val == p.next.val) {
        ListNode x = p.next.next;
        while (x != null &amp;&amp; x.val == p.val) {
            x = x.next;
        }
        return deleteDuplicates(x);
    } else {
        p.next = deleteDuplicates(p.next);
        return p;
    }
}
复制<br>方法2<br>p1 是待删除的上一个节点，每次循环对比 p2、p3 的值<br>
<br>如果 p2 与 p3 的值重复，那么 p3 继续后移，直到找到与 p2 不重复的节点，p1 指向 p3 完成删除
<br>如果 p2 与 p3 的值不重复，p1，p2，p3 向后平移一位，继续上面的操作
<br>p2 或 p3 为 null 退出循环

<br>p2 为 null 的情况，比如链表为 1 1 1 null


<br>p1 p2 p3
s, 1, 1, 1, 2, 3, null

p1 p2    p3
s, 1, 1, 1, 2, 3, null

p1 p2       p3
s, 1, 1, 1, 2, 3, null

p1 p3
s, 2, 3, null

p1 p2 p3
s, 2, 3, null

   p1 p2 p3
s, 2, 3, null
复制<br>代码<br>public ListNode deleteDuplicates(ListNode head) {
    if (head == null || head.next == null) {
        return head;
    }

    ListNode s = new ListNode(-1, head);
    ListNode p1 = s;
    ListNode p2;
    ListNode p3;
    while ((p2 = p1.next) != null &amp;&amp; (p3 = p2.next) != null) {
        if (p2.val == p3.val) {
            while ((p3 = p3.next) != null 
                   &amp;&amp; p3.val == p2.val) {
            }
            p1.next = p3;
        } else {
            p1 = p1.next;
        }
    }
    return s.next;
}
复制<br><br>例<br>输入：l1 = [1,2,4], l2 = [1,3,4]
输出：[1,1,2,3,4,4]
    
输入：l1 = [], l2 = []
输出：[]

输入：l1 = [], l2 = [0]
输出：[0]
复制<br>方法1<br>
<br>谁小，把谁链给 p，p 和小的都向后平移一位
<br>当 p1、p2 有一个为 null，退出循环，把不为 null 的链给 p
<br>p1
1	3	8	9	null

p2
2	4	null

p		
s	null
复制<br>代码<br>public ListNode mergeTwoLists(ListNode p1, ListNode p2) {
    ListNode s = new ListNode(-1, null);
    ListNode p = s;
    while (p1 != null &amp;&amp; p2 != null) {
        if (p1.val &lt; p2.val) {
            p.next = p1;
            p1 = p1.next;
        } else {
            p.next = p2;
            p2 = p2.next;
        }
        p = p.next;
    }
    if (p1 != null) {
        p.next = p1;
    }
    if (p2 != null) {
        p.next = p2;
    }
    return s.next;
}
复制<br>
<br>可以自行验证例中后两种情况
<br>方法2<br>递归函数应该返回<br>
<br>更小的那个链表节点，并把它剩余节点与另一个链表再次递归
<br>返回之前，更新此节点的 next
<br>mergeTwoLists(p1=[1,3,8,9], p2=[2,4]) {
    1.next=mergeTwoLists(p1=[3,8,9], p2=[2,4]) {
        2.next=mergeTwoLists(p1=[3,8,9], p2=[4]) {            
            3.next=mergeTwoLists(p1=[8,9], p2=[4]) {
                4.next=mergeTwoLists(p1=[8,9], p2=null) {
                    return [8,9]
                }
                return 4
            }
            return 3
        }
        return 2
    }
	return 1
}
复制<br><br>例<br>输入：lists = [[1,4,5],[1,3,4],[2,6]]
输出：[1,1,2,3,4,4,5,6]
解释：链表数组如下：
[
  1-&gt;4-&gt;5,
  1-&gt;3-&gt;4,
  2-&gt;6
]
将它们合并到一个有序链表中得到。
1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4-&gt;5-&gt;6
复制<br>方法1<br>递归<br>public ListNode mergeKLists(ListNode[] lists) {
    if (lists.length == 0) {
        return null;
    }
    return merge(lists, 0, lists.length - 1);
}

public ListNode split(ListNode[] lists, int i, int j) {
    System.out.println(i + " " + j);
    if (j == i) {
        return lists[i];
    }
    int m = (i + j) &gt;&gt;&gt; 1;
    return mergeTwoLists(
        split(lists, i, m),
        split(lists, m + 1, j)
    );
}
复制<br>还可以用优先级队列求解，这个放在后面讲<br><br>例如<br>输入：[1,2,3,4,5]
输出：此列表中的结点 3 (序列化形式：[3,4,5])

输入：[1,2,3,4,5,6]
输出：此列表中的结点 4 (序列化形式：[4,5,6])
复制<br>
<br>偶数节点时，中间点是靠右的那个
<br>解法：快慢指针，快指针一次走两步，慢指针一次走一步，当快指针到链表结尾时，慢指针恰好走到链表的一半<br>public ListNode middleNode(ListNode head) {
    ListNode p1 = head;	// 慢指针，中间点
    ListNode p2 = head;	// 快指针
    while (p2 != null &amp;&amp; p2.next != null) {
        p1 = p1.next;
        p2 = p2.next;
        p2 = p2.next;
    }
    return p1;
}
复制<br><br>所谓回文指正着读、反着读，结果一样，例如<br>[1,2,2,1]
[1,2,3,2,1]
复制<br>它们都是回文链表，不是回文的例子<br>[1,2,3,1]  --反过来--&gt;  [1,3,2,1]
复制<br>解法<br>/*
    步骤1. 找中间点
    步骤2. 中间点后半个链表反转
    步骤3. 反转后链表与原链表逐一比较
*/
public boolean isPalindrome(ListNode head) {
    ListNode middle = middle(head);
    ListNode newHead = reverse(middle);
    while (newHead != null) {
        if (newHead.val != head.val) {
            return false;
        }
        newHead = newHead.next;
        head = head.next;
    }
    return true;
}

private ListNode reverse(ListNode o1) {
    ListNode n1 = null;
    while (o1 != null) {
        ListNode o2 = o1.next;
        o1.next = n1;
        n1 = o1;
        o1 = o2;
    }
    return n1;
}

private ListNode middle(ListNode head) {
    ListNode p1 = head; // 慢
    ListNode p2 = head; // 快
    while (p2 != null &amp;&amp; p2.next != null) {
        p1 = p1.next;
        p2 = p2.next.next;
    }
    return p1;
}
复制<br>优化后解法<br>public boolean isPalindrome(ListNode h1) {
    if (h1 == null || h1.next == null) {
        return true;
    }
    ListNode p1 = h1; 	// 慢指针，中间点
    ListNode p2 = h1; 	// 快指针
    ListNode n1 = null;	// 新头
    ListNode o1 = h1;	// 旧头
    // 快慢指针找中间点
    while (p2 != null &amp;&amp; p2.next != null) {
        p1 = p1.next;
        p2 = p2.next.next;

        // 反转前半部分
        o1.next = n1;
        n1 = o1;
        o1 = p1;
    }
    if (p2 != null) { // 节点数为奇数
        p1 = p1.next;
    }
    // 同步比较新头和后半部分
    while (n1 != null) {
        if (n1.val != p1.val) {
            return false;
        }
        p1 = p1.next;
        n1 = n1.next;
    }
    return true;
}
复制<br><br>本题以及下题，实际是 Floyd's Tortoise and Hare Algorithm （Floyd 龟兔赛跑算法）<a href="\#fn-15-33dbe2937a530ff5" class="footnote-link" target="_self" rel="noopener">[15]</a><br>
除了 Floyd 判环算法外，还有其它的判环算法，详见 <a rel="noopener" class="external-link" href="https://en.wikipedia.org/wiki/Cycle_detection" target="_blank">https://en.wikipedia.org/wiki/Cycle_detection</a>
<br><img style="zoom: 50%;" alt="image-20221229190646563" src="\imgs\image-20221229190646563.png" referrerpolicy="no-referrer"><br>如果链表上存在环，那么在环上以不同速度前进的两个指针必定会在某个时刻相遇。算法分为两个阶段<br>阶段1<br>
<br>龟一次走一步，兔子一次走两步
<br>当兔子能走到终点时，不存在环
<br>当兔子能追上龟时，可以判断存在环
<br>阶段2<br>
<br>从它们第一次相遇开始，龟回到起点，兔子保持原位不变
<br>龟和兔子一次都走一步
<br>当再次相遇时，地点就是环的入口
<br>为什么呢？<br>
<br>设起点到入口走 a 步（本例是 7），绕环一圈长度为 b（本例是 5），
<br>那么从起点开始，走 a + 绕环 n 圈，都能找到环入口
<br>第一次相遇时

<br>兔走了 a + 绕环 n 圈（本例 2 圈） + k，k 是它们相遇距环入口位置（本例 3，不重要）
<br>龟走了 a + 绕环 n 圈（本例 0 圈） + k，当然它绕的圈数比兔少
<br>兔走的距离是龟的两倍，所以龟走的 = 兔走的 - 龟走的 = 绕环 n 圈


<br>而前面分析过，如果走 a + 绕环 n 圈，都能找到环入口，因此从相遇点开始，再走 a 步，就是环入口
<br>阶段1 参考代码（判断是否有环）<br>public boolean hasCycle(ListNode head) {
    ListNode h = head; // 兔
    ListNode t = head; // 龟
    while (h != null &amp;&amp; h.next != null) {
        t = t.next;
        h = h.next.next;
        if(h == t){
            return true;
        }
    }
    return false;
}
复制<br><br>阶段2 参考代码（找到环入口）<br>public ListNode detectCycle(ListNode head) {
    ListNode t = head; // 龟
    ListNode h = head; // 兔
    while (h != null &amp;&amp; h.next != null) {
        t = t.next;
        h = h.next.next;
        if (h == t) {
            t = head;
            while (true) {
                if (h == t) {
                    return h;
                }
                h = h.next;
                t = t.next;
            }
        }
    }
    return null;
}
复制<br><br>这道题目比较简单，留给大家自己练习<br>例如<br>输入：head = [4,5,1,9], node = 5
输出：[4,1,9]


输入：head = [4,5,1,9], node = 1
输出：[4,5,9]
复制<br>注意：被删除的节点不是末尾节点<br>参考答案<br>public class Ex1Leetcode237 {
    /**
     *
     * @param node 待删除节点, 题目已说明肯定不是最后一个节点
     */
    public void deleteNode(ListNode node) {
        node.val = node.next.val;		// 下一个节点值赋值给待"删除"节点
        node.next = node.next.next;		// 把下一个节点删除
    }

    public static void main(String[] args) {
        ListNode o5 = new ListNode(5, null);
        ListNode o4 = new ListNode(4, o5);
        ListNode o3 = new ListNode(3, o4);
        ListNode o2 = new ListNode(2, o3);
        ListNode o1 = new ListNode(1, o2);
        System.out.println(o1);
        new E0xLeetcode237().deleteNode(o3);
        System.out.println(o1);
    }
}
复制<br>输出<br>[1,2,3,4,5]
[1,2,4,5]
复制<br><br>原题叫做相交链表，个人觉得用共尾链表更形象些，此题更像是一道脑筋急转弯，留给大家练习<br>例如，下图的两个链表 [1, 2, 4, 5] 与 [3, 4, 5] 它们中 [4, 5] 是相同的，此时应返回节点 4<br>“imgs/image-20221228081715799.png” could not be found.<br>非共尾的情况，如下图所示，此时返回 null<br>“imgs/image-20221228082002730.png” could not be found.<br>思路，称两个链表为 a=[1, 2, 4, 5]，b=[3, 4, 5]，图中用 N 代表 null<br>
<br>遍历 a，遇到 null 时改道遍历 b
<br>与此同时，遍历 b，遇到 null 时改道遍历 a
<br>在此过程中，如果遇到相同的节点，即为找寻目标，返回即可，如下图中的第二次出现的 4
<br>相同节点应该比较其引用值，图中数字只是为了便于区分
<br>1	2	4	5	N	3	4	5	N
3	4	5	N	1	2	4	5	N
复制<br>如果两个链表长度相同，则可以更早找到目标，例如 a=[1, 4, 5]，b=[3, 4, 5]，第一次出现 4 时，即可返回<br>1	4	5	N	3	4	5	N
3	4	5	N	1	4	5	N
复制<br>如果是非共尾的情况，如 a=[1, 2, 4]，b=[3, 5]，可以看到，唯一相等的情况，是遍历到最后那个 N 此时退出循环<br>1	2	4	N	3	5	N
3	5	N	1	2	4	N
复制<br>代码<br>public ListNode getIntersectionNode(ListNode a, ListNode b) {
    ListNode p1 = a;
    ListNode p2 = b;
    while (true) {
        if (p1 == p2) {
            return p1;
        }
        if (p1 == null) {
            p1 = b;
        } else {
            p1 = p1.next;
        }
        if (p2 == null) {
            p2 = a;
        } else {
            p2 = p2.next;
        }            
    }
}
复制<br><br><br>将数组内两个区间内的有序元素合并<br>例<br>[1, 5, 6, 2, 4, 10, 11]
复制<br>可以视作两个有序区间<br>[1, 5, 6] 和 [2, 4, 10, 11]
复制<br>合并后，结果仍存储于原有空间<br>[1, 2, 4, 5, 6, 10, 11]
复制<br>方法1<br>递归<br>
<br>每次递归把更小的元素复制到结果数组
<br>merge(left=[1,5,6],right=[2,4,10,11],a2=[]){
    merge(left=[5,6],right=[2,4,10,11],a2=[1]){
        merge(left=[5,6],right=[4,10,11],a2=[1,2]){
            merge(left=[5,6],right=[10,11],a2=[1,2,4]){
                merge(left=[6],right=[10,11],a2=[1,2,4,5]){
                    merge(left=[],right=[10,11],a2=[1,2,4,5,6]){
						// 拷贝10，11
                    }
                }
            }
        }
    }
}
复制<br>代码<br>public static void merge(int[] a1, int i, int iEnd, int j, int jEnd,
                              int[] a2, int k) {
    if (i &gt; iEnd) {
        System.arraycopy(a1, j, a2, k, jEnd - j + 1);
        return;
    }
    if (j &gt; jEnd) {
        System.arraycopy(a1, i, a2, k, iEnd - i + 1);
        return;
    }
    if (a1[i] &lt; a1[j]) {
        a2[k] = a1[i];
        merge(a1, i + 1, iEnd, j, jEnd, a2, k + 1);
    } else {
        a2[k] = a1[j];
        merge(a1, i, iEnd, j + 1, jEnd, a2, k + 1);
    }
}
复制<br>测试<br>int[] a1 = {1, 5, 6, 2, 4, 10, 11};
int[] a2 = new int[a1.length];
merge(a1, 0, 2, 3, 6, a2, 0);
复制<br>方法2<br>代码<br>public static void merge(int[] a1, int i, int iEnd,
                             int j, int jEnd,
                             int[] a2) {
    int k = i;
    while (i &lt;= iEnd &amp;&amp; j &lt;= jEnd) {
        if (a1[i] &lt; a1[j]) {
            a2[k] = a1[i];
            i++;
        } else {
            a2[k] = a1[j];
            j++;
        }
        k++;
    }
    if (i &gt; leftEnd) {
        System.arraycopy(a1, j, a2, k, jEnd - j + 1);
    }
    if (j &gt; rightEnd) {
        System.arraycopy(a1, i, a2, k, iEnd - i + 1);
    }
}
复制<br>测试<br>int[] a1 = {1, 5, 6, 2, 4, 10, 11};
int[] a2 = new int[a3.length];
merge(a1, 0, 2, 3, 6, a2);
复制<br>归并排序代码备份<br>public static void split(int[] a1, int i, int j, int[] a2) {
    System.out.println("i=" + i + " j=" + j + " a1=" + Arrays.toString(Arrays.copyOfRange(a1, i, j + 1)));
    if (i == j) {
        return;
    }
    int m = (i + j) &gt;&gt;&gt; 1;
    split(a1, i, m, a2);
    split(a1, m + 1, j, a2);
    //merge(a1, i, m, m+1, j, a2); // 非递归
    //merge(a1, i, m, m + 1, j, a2, i); // 递归
    System.arraycopy(a2, i, a1, i, (j - i + 1));
    System.out.println("i=" + i + " m=" + m + " j=" + j + " a1=" + Arrays.toString(a1) + " a2=" + Arrays.toString(a2));
}


int[] a1 = {1, 5, 6, 2, 4, 10, 11};
int[] a2 = new int[a1.length];
split(a1, 0, a1.length - 1, a2);
System.out.println(Arrays.toString(a1));
复制<br><br><br>class Solution {
    public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) {
        List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;();
        if(root == null) {
            return result;
        }
        LinkedListQueue&lt;TreeNode&gt; queue = new LinkedListQueue&lt;&gt;();
        queue.offer(root);
        int c1 = 1;		// 本层节点个数
        while (!queue.isEmpty()) {
            int c2 = 0; 	// 下层节点个数
            List&lt;Integer&gt; level = new ArrayList&lt;&gt;();
            for (int i = 0; i &lt; c1; i++) {
                TreeNode node = queue.poll();
                level.add(node.val);
                if (node.left != null) {
                    queue.offer(node.left);
                    c2++;
                }
                if (node.right != null) {
                    queue.offer(node.right);
                    c2++;
                }
            }
            c1 = c2;
            result.add(level);
        }
        return result;
    }

    // 自定义队列
    static class LinkedListQueue&lt;E&gt; {

        private static class Node&lt;E&gt; {
            E value;
            Node&lt;E&gt; next;

            public Node(E value, Node&lt;E&gt; next) {
                this.value = value;
                this.next = next;
            }
        }

        private final Node&lt;E&gt; head = new Node&lt;&gt;(null, null);
        private Node&lt;E&gt; tail = head;
        int size = 0;
        private int capacity = Integer.MAX_VALUE;

        {
            tail.next = head;
        }

        public LinkedListQueue() {
        }

        public LinkedListQueue(int capacity) {
            this.capacity = capacity;
        }

        public boolean offer(E value) {
            if (isFull()) {
                return false;
            }
            Node&lt;E&gt; added = new Node&lt;&gt;(value, head);
            tail.next = added;
            tail = added;
            size++;
            return true;
        }

        public E poll() {
            if (isEmpty()) {
                return null;
            }
            Node&lt;E&gt; first = head.next;
            head.next = first.next;
            if (first == tail) {
                tail = head;
            }
            size--;
            return first.value;
        }

        public E peek() {
            if (isEmpty()) {
                return null;
            }
            return head.next.value;
        }

        public boolean isEmpty() {
            return head == tail;
        }

        public boolean isFull() {
            return size == capacity;
        }
    }
}
复制<br><br>由于与课堂例题差别不大，这里只给出参考解答<br>基于链表的实现<br>public class Ex1Leetcode622 {

    private static class Node {
        int value;
        Node next;
        Node(int value, Node next) {
            this.value = value;
            this.next = next;
        }
    }
    private final Node head = new Node(-1, null);
    private Node tail = head;
    private int size = 0;
    private int capacity = 0;

    {
        tail.next = head;
    }

    public Ex1Leetcode622(int capacity) {
        this.capacity = capacity;
    }

    public boolean enQueue(int value) {
        if(isFull()) {
            return false;
        }
        Node added = new Node(value, head);
        tail.next = added;
        tail = added;
        size++;
        return true;
    }

    public boolean deQueue() {
        if(isEmpty()) {
            return false;
        }
        Node first = head.next;
        head.next = first.next;
        if (first == tail) {
            tail = head;
        }
        size--;
        return true;
    }

    public int Front() {
        if(isEmpty()) {
            return -1;
        }
        return head.next.value;
    }

    public int Rear() {
        if(isEmpty()) {
            return -1;
        }
        return tail.value;
    }

    public boolean isEmpty() {
        return head == tail;
    }

    public boolean isFull() {
        return size == capacity;
    }
}
复制<br>注意：<br>
<br>Leetcode 的实现里 deQueue（出队）返回值是布尔值，并不会返回队头元素
<br>它期望用法是先用 Front 返回对头元素，再 deQueue 出队
<br><br><br>一个字符串中可能出现 [] () 和 {} 三种括号，判断该括号是否有效<br>有效的例子<br>()[]{}

([{}])

()
复制<br>无效的例子<br>[)

([)]

([]
复制<br>思路<br>
<br>遇到左括号, 把要配对的右括号放入栈顶
<br>遇到右括号, 若此时栈为空, 返回 false，否则把它与栈顶元素对比

<br>若相等, 栈顶元素弹出, 继续对比下一组
<br>若不等, 无效括号直接返回 false


<br>循环结束

<br>若栈为空, 表示所有括号都配上对, 返回 true
<br>若栈不为空, 表示右没配对的括号, 应返回 false


<br>答案（用到了课堂案例中的 ArrayStack 类）<br>public boolean isValid(String s) {
    ArrayStack&lt;Character&gt; stack = new ArrayStack&lt;&gt;(s.length() / 2 + 1);
    for (int i = 0; i &lt; s.length(); i++) {
        char c = s.charAt(i);
        if (c == '(') {
            stack.push(')');
        } else if (c == '[') {
            stack.push(']');
        } else if (c == '{') {
            stack.push('}');
        } else {
            if (!stack.isEmpty() &amp;&amp; stack.peek() == c) {
                stack.pop();
            } else {
                return false;
            }
        }
    }
    return stack.isEmpty();
}
复制<br><br>后缀表达式也称为逆波兰表达式，即运算符写在后面<br>
<br>从左向右进行计算
<br>不必考虑运算符优先级，即不用包含括号
<br>示例<br>输入：tokens = ["2","1","+","3","*"]
输出：9
即：(2 + 1) * 3

输入：tokens = ["4","13","5","/","+"]
输出：6
即：4 + (13 / 5)
复制<br>题目假设<br>
<br>数字都视为整数
<br>数字和运算符个数给定正确，不会有除零发生
<br>代码<br>public int evalRPN(String[] tokens) {
    LinkedList&lt;Integer&gt; numbers = new LinkedList&lt;&gt;();
    for (String t : tokens) {
        switch (t) {
            case "+" -&gt; {
                Integer b = numbers.pop();
                Integer a = numbers.pop();
                numbers.push(a + b);
            }
            case "-" -&gt; {
                Integer b = numbers.pop();
                Integer a = numbers.pop();
                numbers.push(a - b);
            }
            case "*" -&gt; {
                Integer b = numbers.pop();
                Integer a = numbers.pop();
                numbers.push(a * b);
            }
            case "/" -&gt; {
                Integer b = numbers.pop();
                Integer a = numbers.pop();
                numbers.push(a / b);
            }
            default -&gt; numbers.push(Integer.parseInt(t));
        }
    }
    return numbers.pop();
}
复制<br><br>public class E03InfixToSuffix {
    /*
        思路
        1. 遇到数字, 拼串
        2. 遇到 + - * /
            - 优先级高于栈顶运算符 入栈
            - 否则将栈中高级或平级运算符出栈拼串, 本运算符入栈
        3. 遍历完成, 栈中剩余运算符出栈拼串
            - 先出栈,意味着优先运算
        4. 带 ()
            - 左括号直接入栈
            - 右括号要将栈中直至左括号为止的运算符出栈拼串

        |   |
        |   |
        |   |
        _____

        a+b
        a+b-c
        a+b*c
        a*b+c
        (a+b)*c

     */
    public static void main(String[] args) {
        System.out.println(infixToSuffix("a+b"));
        System.out.println(infixToSuffix("a+b-c"));
        System.out.println(infixToSuffix("a+b*c"));
        System.out.println(infixToSuffix("a*b-c"));
        System.out.println(infixToSuffix("(a+b)*c"));
        System.out.println(infixToSuffix("a+b*c+(d*e+f)*g"));
    }

    static String infixToSuffix(String exp) {
        LinkedList&lt;Character&gt; stack = new LinkedList&lt;&gt;();
        StringBuilder sb = new StringBuilder(exp.length());
        for (int i = 0; i &lt; exp.length(); i++) {
            char c = exp.charAt(i);
            switch (c) {
                case '+', '-', '*', '/' -&gt; {
                    if (stack.isEmpty()) {
                        stack.push(c);
                    } else {
                        if (priority(c) &gt; priority(stack.peek())) {
                            stack.push(c);
                        } else {
                            while (!stack.isEmpty() 
                                   &amp;&amp; priority(stack.peek()) &gt;= priority(c)) {
                                sb.append(stack.pop());
                            }
                            stack.push(c);
                        }
                    }
                }
                case '(' -&gt; {
                    stack.push(c);
                }
                case ')' -&gt; {
                    while (!stack.isEmpty() &amp;&amp; stack.peek() != '(') {
                        sb.append(stack.pop());
                    }
                    stack.pop();
                }
                default -&gt; {
                    sb.append(c);
                }
            }
        }
        while (!stack.isEmpty()) {
            sb.append(stack.pop());
        }
        return sb.toString();
    }

    static int priority(char c) {
        return switch (c) {
            case '(' -&gt; 0;
            case '*', '/' -&gt; 2;
            case '+', '-' -&gt; 1;
            default -&gt; throw new IllegalArgumentException("不合法字符:" + c);
        };
    }
}
复制<br><br>给力扣题目用的自实现栈，可以定义为静态内部类<br>class ArrayStack&lt;E&gt; {

    private E[] array;
    private int top; // 栈顶指针

    @SuppressWarnings("all")
    public ArrayStack(int capacity) {
        this.array = (E[]) new Object[capacity];
    }

    public boolean push(E value) {
        if (isFull()) {
            return false;
        }
        array[top++] = value;
        return true;
    }

    public E pop() {
        if (isEmpty()) {
            return null;
        }
        return array[--top];
    }

    public E peek() {
        if (isEmpty()) {
            return null;
        }
        return array[top - 1];
    }

    public boolean isEmpty() {
        return top == 0;
    }

    public boolean isFull() {
        return top == array.length;
    }
}
复制<br>参考解答，注意：题目已说明<br>
<br>调用 push、pop 等方法的次数最多 100
<br>public class E04Leetcode232 {

    /*
        队列头      队列尾
        s1       s2
        顶   底   底   顶
                 abc

        push(a)
        push(b)
        push(c)
        pop()
     */
    ArrayStack&lt;Integer&gt; s1 = new ArrayStack&lt;&gt;(100);
    ArrayStack&lt;Integer&gt; s2 = new ArrayStack&lt;&gt;(100);

    public void push(int x) {
        s2.push(x);
    }

    public int pop() {
        if (s1.isEmpty()) {
            while (!s2.isEmpty()) {
                s1.push(s2.pop());
            }
        }
        return s1.pop();
    }

    public int peek() {
        if (s1.isEmpty()) {
            while (!s2.isEmpty()) {
                s1.push(s2.pop());
            }
        }
        return s1.peek();
    }

    public boolean empty() {
        return s1.isEmpty() &amp;&amp; s2.isEmpty();
    }

}
复制<br><br>给力扣题目用的自实现队列，可以定义为静态内部类<br>public class ArrayQueue3&lt;E&gt; {

    private final E[] array;
    int head = 0;
    int tail = 0;

    @SuppressWarnings("all")
    public ArrayQueue3(int c) {
        c -= 1;
        c |= c &gt;&gt; 1;
        c |= c &gt;&gt; 2;
        c |= c &gt;&gt; 4;
        c |= c &gt;&gt; 8;
        c |= c &gt;&gt; 16;
        c += 1;
        array = (E[]) new Object[c];
    }
    
    public boolean offer(E value) {
        if (isFull()) {
            return false;
        }        
        array[tail &amp; (array.length - 1)] = value;
        tail++;
        return true;
    }

    public E poll() {
        if (isEmpty()) {
            return null;
        }
        E value = array[head &amp; (array.length - 1)];
        head++;
        return value;
    }

    public E peek() {
        if (isEmpty()) {
            return null;
        }
        return array[head &amp; (array.length - 1)];
    }

    public boolean isEmpty() {
        return head == tail;
    }

    public boolean isFull() {
        return tail - head == array.length;
    }
}
复制<br>参考解答，注意：题目已说明<br>
<br>调用 push、pop 等方法的次数最多 100
<br>每次调用 pop 和 top 都能保证栈不为空
<br>public class E05Leetcode225 {
    /*
        队列头     队列尾
        cba
        顶           底

        queue.offer(a)
        queue.offer(b)
        queue.offer(c)
     */
    ArrayQueue3&lt;Integer&gt; queue = new ArrayQueue3&lt;&gt;(100);
    int size = 0;
    public void push(int x) {
        queue.offer(x);
        for (int i = 0; i &lt; size; i++) {
            queue.offer(queue.poll());
        }
        size++;
    }

    public int pop() {
        size--;
        return queue.poll();
    }

    public int top() {
        return queue.peek();
    }

    public boolean empty() {
        return queue.isEmpty();
    }
}
复制<br><br><br>public class E01Leetcode103 {
    public List&lt;List&lt;Integer&gt;&gt; zigzagLevelOrder(TreeNode root) {
        List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;();
        if (root == null) {
            return result;
        }
        LinkedList&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;();
        queue.offer(root);
        boolean leftToRight = true;
        int c1 = 1;
        while (!queue.isEmpty()) {
            int c2 = 0;
            LinkedList&lt;Integer&gt; deque = new LinkedList&lt;&gt;();
            for (int i = 0; i &lt; c1; i++) {
                TreeNode n = queue.poll();
                if (leftToRight) {
                    deque.offerLast(n.val);
                } else {
                    deque.offerFirst(n.val);
                }
                if (n.left != null) {
                    queue.offer(n.left);
                    c2++;
                }
                if (n.right != null) {
                    queue.offer(n.right);
                    c2++;
                }
            }
            c1 = c2;
            leftToRight = !leftToRight;
            result.add(deque);
        }

        return result;
    }

    public static void main(String[] args) {
        TreeNode root = new TreeNode(
                new TreeNode(
                        new TreeNode(4),
                        2,
                        new TreeNode(5)
                ),
                1,
                new TreeNode(
                        new TreeNode(6),
                        3,
                        new TreeNode(7)
                )
        );
        List&lt;List&lt;Integer&gt;&gt; lists = new E01Leetcode103().zigzagLevelOrder(root);
        for (List&lt;Integer&gt; list : lists) {
            System.out.println(list);
        }
    }
}
复制<br><br>与课堂例题也是差别不大，请参考<br><br><br>这道题目之前解答过，现在用刚学的优先级队列来实现一下<br>题目中要从小到大排列，因此选择用小顶堆来实现，自定义小顶堆如下<br>public class MinHeap {

    ListNode[] array;
    int size;

    public MinHeap(int capacity) {
        array = new ListNode[capacity];
    }

    public void offer(ListNode offered) {
        int child = size++;
        int parent = (child - 1) / 2;
        while (child &gt; 0 &amp;&amp; offered.val &lt; array[parent].val) {
            array[child] = array[parent];
            child = parent;
            parent = (child - 1) / 2;
        }
        array[child] = offered;
    }

    public ListNode poll() {
        if (isEmpty()) {
            return null;
        }
        swap(0, size - 1);
        size--;
        ListNode e = array[size];
        array[size] = null; // help GC

        down(0);

        return e;
    }

    private void down(int parent) {
        int left = 2 * parent + 1;
        int right = left + 1;
        int min = parent;
        if (left &lt; size &amp;&amp; array[left].val &lt; array[min].val) {
            min = left;
        }
        if (right &lt; size &amp;&amp; array[right].val &lt; array[min].val) {
            min = right;
        }
        if (min != parent) {
            swap(min, parent);
            down(min);
        }
    }

    private void swap(int i, int j) {
        ListNode t = array[i];
        array[i] = array[j];
        array[j] = t;
    }

    public boolean isEmpty() {
        return size == 0;
    }
}
复制<br>代码<br>public class E01Leetcode23 {
    public ListNode mergeKLists(ListNode[] lists) {
        // 1. 使用 jdk 的优先级队列实现
//        PriorityQueue&lt;ListNode&gt; queue = new PriorityQueue&lt;&gt;(Comparator.comparingInt(a -&gt; a.val));
        // 2. 使用自定义小顶堆实现
        MinHeap queue = new MinHeap(lists.length);
        for (ListNode head : lists) {
            if (head != null) {
                queue.offer(head);
            }
        }
        ListNode s = new ListNode(-1, null);
        ListNode p = s;
        while (!queue.isEmpty()) {
            ListNode node = queue.poll();
            p.next = node;
            p = node;
            if (node.next != null) {
                queue.offer(node.next);
            }
        }
        return s.next;
    }
}
复制<br>提问：<br>
<br>能否将每个链表的所有元素全部加入堆，再一个个从堆顶移除？
<br>回答：<br>
<br>可以是可以，但对空间占用就高了，堆的一个优点就是用有限的空间做事情
<br><br><br>算法描述<br>
<br>heapify 建立大顶堆
<br>将堆顶与堆底交换（最大元素被交换到堆底），缩小并下潜调整堆
<br>重复第二步直至堆里剩一个元素
<br>可以使用之前课堂例题的大顶堆来实现<br>int[] array = {1, 2, 3, 4, 5, 6, 7};
MaxHeap maxHeap = new MaxHeap(array);
System.out.println(Arrays.toString(maxHeap.array));

while (maxHeap.size &gt; 1) {
    maxHeap.swap(0, maxHeap.size - 1);
    maxHeap.size--;
    maxHeap.down(0);
}
System.out.println(Arrays.toString(maxHeap.array));
复制<br><br>小顶堆（可删去用不到代码）<br>class MinHeap {
    int[] array;
    int size;

    public MinHeap(int capacity) {
        array = new int[capacity];
    }

    private void heapify() {
        for (int i = (size &gt;&gt; 1) - 1; i &gt;= 0; i--) {
            down(i);
        }
    }

    public int poll() {
        swap(0, size - 1);
        size--;
        down(0);
        return array[size];
    }

    public int poll(int index) {
        swap(index, size - 1);
        size--;
        down(index);
        return array[size];
    }

    public int peek() {
        return array[0];
    }

    public boolean offer(int offered) {
        if (size == array.length) {
            return false;
        }
        up(offered);
        size++;
        return true;
    }

    public void replace(int replaced) {
        array[0] = replaced;
        down(0);
    }

    private void up(int offered) {
        int child = size;
        while (child &gt; 0) {
            int parent = (child - 1) &gt;&gt; 1;
            if (offered &lt; array[parent]) {
                array[child] = array[parent];
            } else {
                break;
            }
            child = parent;
        }
        array[child] = offered;
    }

    private void down(int parent) {
        int left = (parent &lt;&lt; 1) + 1;
        int right = left + 1;
        int min = parent;
        if (left &lt; size &amp;&amp; array[left] &lt; array[min]) {
            min = left;
        }
        if (right &lt; size &amp;&amp; array[right] &lt; array[min]) {
            min = right;
        }
        if (min != parent) {
            swap(min, parent);
            down(min);
        }
    }

    // 交换两个索引处的元素
    private void swap(int i, int j) {
        int t = array[i];
        array[i] = array[j];
        array[j] = t;
    }
}
复制<br>题解<br>public int findKthLargest(int[] numbers, int k) {
    MinHeap heap = new MinHeap(k);
    for (int i = 0; i &lt; k; i++) {
        heap.offer(numbers[i]);
    }
    for (int i = k; i &lt; numbers.length; i++) {
        if(numbers[i] &gt; heap.peek()){
            heap.replace(numbers[i]);
        }
    }
    return heap.peek();
}
复制<br>
求数组中的第 K 大元素，使用堆并不是最佳选择，可以采用快速选择算法
<br><br>上题的小顶堆加一个方法<br>class MinHeap {
    // ...
	public boolean isFull() {
        return size == array.length;
    }
}
复制<br>题解<br>class KthLargest {

    private MinHeap heap;

    public KthLargest(int k, int[] nums) {
        heap = new MinHeap(k);
        for(int i = 0; i &lt; nums.length; i++) {
            add(nums[i]);
        }
    }
    
    public int add(int val) {
        if(!heap.isFull()){
            heap.offer(val);
        } else if(val &gt; heap.peek()){
            heap.replace(val);
        }
        return heap.peek();
    }
    
}
复制<br>
求数据流中的第 K 大元素，使用堆最合适不过
<br><br>可以扩容的 heap, max 用于指定是大顶堆还是小顶堆<br>public class Heap {
    int[] array;
    int size;
    boolean max;

    public int size() {
        return size;
    }

    public Heap(int capacity, boolean max) {
        this.array = new int[capacity];
        this.max = max;
    }

    /**
     * 获取堆顶元素
     *
     * @return 堆顶元素
     */
    public int peek() {
        return array[0];
    }

    /**
     * 删除堆顶元素
     *
     * @return 堆顶元素
     */
    public int poll() {
        int top = array[0];
        swap(0, size - 1);
        size--;
        down(0);
        return top;
    }

    /**
     * 删除指定索引处元素
     *
     * @param index 索引
     * @return 被删除元素
     */
    public int poll(int index) {
        int deleted = array[index];
        swap(index, size - 1);
        size--;
        down(index);
        return deleted;
    }

    /**
     * 替换堆顶元素
     *
     * @param replaced 新元素
     */
    public void replace(int replaced) {
        array[0] = replaced;
        down(0);
    }

    /**
     * 堆的尾部添加元素
     *
     * @param offered 新元素
     */
    public void offer(int offered) {
        if (size == array.length) {
            grow();
        }
        up(offered);
        size++;
    }

    private void grow() {
        int capacity = size + (size &gt;&gt; 1);
        int[] newArray = new int[capacity];
        System.arraycopy(array, 0,
                newArray, 0, size);
        array = newArray;
    }

    // 将 offered 元素上浮: 直至 offered 小于父元素或到堆顶
    private void up(int offered) {
        int child = size;
        while (child &gt; 0) {
            int parent = (child - 1) / 2;
            boolean cmp = max ? offered &gt; array[parent] : offered &lt; array[parent];
            if (cmp) {
                array[child] = array[parent];
            } else {
                break;
            }
            child = parent;
        }
        array[child] = offered;
    }

    public Heap(int[] array, boolean max) {
        this.array = array;
        this.size = array.length;
        this.max = max;
        heapify();
    }

    // 建堆
    private void heapify() {
        // 如何找到最后这个非叶子节点  size / 2 - 1
        for (int i = size / 2 - 1; i &gt;= 0; i--) {
            down(i);
        }
    }

    // 将 parent 索引处的元素下潜: 与两个孩子较大者交换, 直至没孩子或孩子没它大
    private void down(int parent) {
        int left = parent * 2 + 1;
        int right = left + 1;
        int min = parent;
        if (left &lt; size &amp;&amp; (max ? array[left] &gt; array[min] : array[left] &lt; array[min])) {
            min = left;
        }
        if (right &lt; size &amp;&amp; (max ? array[right] &gt; array[min] : array[right] &lt; array[min])) {
            min = right;
        }
        if (min != parent) { // 找到了更大的孩子
            swap(min, parent);
            down(min);
        }
    }

    // 交换两个索引处的元素
    private void swap(int i, int j) {
        int t = array[i];
        array[i] = array[j];
        array[j] = t;
    }
}
复制<br>题解<br>private Heap left = new Heap(10, false);
private Heap right = new Heap(10, true);

/**
 为了保证两边数据量的平衡
 &lt;ul&gt;
  &lt;li&gt;两边数据一样时,加入左边&lt;/li&gt;
  &lt;li&gt;两边数据不一样时,加入右边&lt;/li&gt;
 &lt;/ul&gt;
 但是, 随便一个数能直接加入吗?
 &lt;ul&gt;
  &lt;li&gt;加入左边前, 应该挑右边最小的加入&lt;/li&gt;
  &lt;li&gt;加入右边前, 应该挑左边最大的加入&lt;/li&gt;
 &lt;/ul&gt;
 */
public void addNum(int num) {
    if (left.size() == right.size()) {
        right.offer(num);
        left.offer(right.poll());
    } else {
        left.offer(num);
        right.offer(left.poll());
    }
}

/**
 * &lt;ul&gt;
 *     &lt;li&gt;两边数据一致, 左右各取堆顶元素求平均&lt;/li&gt;
 *     &lt;li&gt;左边多一个, 取左边元素&lt;/li&gt;
 * &lt;/ul&gt;
 */
public double findMedian() {
    if (left.size() == right.size()) {
        return (left.peek() + right.peek()) / 2.0;
    } else {
        return left.peek();
    }
}
复制<br>
本题还可以使用平衡二叉搜索树求解，不过代码比两个堆复杂
<br><br><br>public boolean isSymmetric(TreeNode root) {
    return check(root.left, root.right);
}

public boolean check(TreeNode left, TreeNode right) {
    // 若同时为 null
    if (left == null &amp;&amp; right == null) {
        return true;
    }
    // 若有一个为 null (有上一轮筛选，另一个肯定不为 null)
    if (left == null || right == null) {
        return false;
    }
    if (left.val != right.val) {
        return false;
    }
    return check(left.left, right.right) &amp;&amp; check(left.right, right.left);
}
复制<br><br>后序遍历求解<br>/*
    思路：
    1. 得到左子树深度, 得到右子树深度, 二者最大者加一, 就是本节点深度
    2. 因为需要先得到左右子树深度, 很显然是后序遍历典型应用
    3. 关于深度的定义：从根出发, 离根最远的节点总边数,
        注意: 力扣里的深度定义要多一

        深度2         深度3         深度1
        1            1            1
       / \          / \
      2   3        2   3
                        \
                         4
 */
public int maxDepth(TreeNode node) {
    if (node == null) {
        return 0; // 非力扣题目改为返回 -1
    }
    int d1 = maxDepth(node.left);
    int d2 = maxDepth(node.right);
    return Integer.max(d1, d2) + 1;
}
复制<br>后序遍历求解-非递归<br>/*
    思路：
    1. 使用非递归后序遍历, 栈的最大高度即为最大深度
 */
public int maxDepth(TreeNode root) {
    TreeNode curr = root;
    LinkedList&lt;TreeNode&gt; stack = new LinkedList&lt;&gt;();
    int max = 0;
    TreeNode pop = null;
    while (curr != null || !stack.isEmpty()) {
        if (curr != null) {
            stack.push(curr);
            int size = stack.size();
            if (size &gt; max) {
                max = size;
            }
            curr = curr.left;
        } else {
            TreeNode peek = stack.peek();
            if(peek.right == null || peek.right == pop) {
                pop = stack.pop();
            } else {
                curr = peek.right;
            }
        }
    }
    return max;
}
复制<br>层序遍历求解<br>/*
    思路：
    1. 使用层序遍历, 层数即最大深度
 */
public int maxDepth(TreeNode root) {
    if(root == null) {
        return 0;
    }
    Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;();
    queue.offer(root);
    int level = 0;
    while (!queue.isEmpty()) {
        level++;
        int size = queue.size();
        for (int i = 0; i &lt; size; i++) {
            TreeNode node = queue.poll();
            if (node.left != null) {
                queue.offer(node.left);
            }
            if (node.right != null) {
                queue.offer(node.right);
            }
        }
    }
    return level;
}
复制<br><br>后序遍历求解<br>public int minDepth(TreeNode node) {
    if (node == null) {
        return 0;
    }
    int d1 = minDepth(node.left);
    int d2 = minDepth(node.right);
    if (d1 == 0 || d2 == 0) {
        return d1 + d2 + 1;
    }
    return Integer.min(d1, d2) + 1;
}
复制<br>相较于求最大深度，应当考虑：<br>
<br>当右子树为 null，应当返回左子树深度加一
<br>当左子树为 null，应当返回右子树深度加一
<br>上面两种情况满足时，不应该再把为 null 子树的深度 0 参与最小值比较，例如这样<br>    1
   /
  2
复制<br>
<br>正确深度为 2，若把为 null 的右子树的深度 0 考虑进来，会得到错误结果 1
<br>    1
     \
      3
       \
        4
复制<br>
<br>正确深度为 3，若把为 null 的左子树的深度 0 考虑进来，会得到错误结果 1
<br>层序遍历求解<br>遇到的第一个叶子节点所在层就是最小深度<br>例如，下面的树遇到的第一个叶子节点 3 所在的层就是最小深度，其他 4，7 等叶子节点深度更深，也更晚遇到<br>     1
    / \     
   2   3
  / \
 4   5 
    /
   7 
复制<br>代码<br>public int minDepth(TreeNode root) {
    if(root == null) {
        return 0;
    }
    Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;();
    queue.offer(root);
    int level = 0;
    while (!queue.isEmpty()) {
        level++;
        int size = queue.size();
        for (int i = 0; i &lt; size; i++) {
            TreeNode node = queue.poll();
            if (node.left == null &amp;&amp; node.right == null) {
                return level;
            }
            if (node.left != null) {
                queue.offer(node.left);
            }
            if (node.right != null) {
                queue.offer(node.right);
            }
        }
    }
    return level;
}
复制<br>效率会高于之前后序遍历解法，因为找到第一个叶子节点后，就无需后续的层序遍历了<br><br>public TreeNode invertTree(TreeNode root) {
    fn(root);
    return root;
}

private void fn(TreeNode node){
    if (node == null) {
        return;
    }
    TreeNode t = node.left;
    node.left = node.right;
    node.right = t;
    fn(node.left);
    fn(node.right);
}
复制<br>先交换、再递归或是先递归、再交换都可以<br><br>static class TreeNode {
    public String val;
    public TreeNode left;
    public TreeNode right;

    public TreeNode(String val) {
        this.val = val;
    }

    public TreeNode(TreeNode left, String val, TreeNode right) {
        this.left = left;
        this.val = val;
        this.right = right;
    }

    @Override
    public String toString() {
        return this.val;
    }
}

/*
    中缀表达式           (2-1)*3
    后缀（逆波兰）表达式   21-3*

    1.遇到数字入栈
    2.遇到运算符, 出栈两次, 与当前节点建立父子关系, 当前节点入栈

    栈
    |   |
    |   |
    |   |
    _____

    表达式树
        *
       / \
      -   3
     / \
    2   1

    21-3*
 */
public TreeNode constructExpressionTree(String[] tokens) {
    LinkedList&lt;TreeNode&gt; stack = new LinkedList&lt;&gt;();
    for (String t : tokens) {
        switch (t) {
            case "+", "-", "*", "/" -&gt; { // 运算符
                TreeNode right = stack.pop();
                TreeNode left = stack.pop();
                TreeNode parent = new TreeNode(t);
                parent.left = left;
                parent.right = right;
                stack.push(parent);
            }
            default -&gt; { // 数字
                stack.push(new TreeNode(t));
            }
        }
    }
    return stack.peek();
}
复制<br><br>
<br>先通过前序遍历结果定位根节点
<br>再结合中序遍历结果切分左右子树
<br>public class E09Leetcode105 {

    /*
        preOrder = {1,2,4,3,6,7}
        inOrder = {4,2,1,6,3,7}

        根 1
            pre         in
        左  2,4         4,2
        右  3,6,7       6,3,7


        根 2
        左 4

        根 3
        左 6
        右 7
     */

    public TreeNode buildTree(int[] preOrder, int[] inOrder) {
        if (preOrder.length == 0) {
            return null;
        }
        // 创建根节点
        int rootValue = preOrder[0];
        TreeNode root = new TreeNode(rootValue);
        // 区分左右子树
        for (int i = 0; i &lt; inOrder.length; i++) {
            if (inOrder[i] == rootValue) {
                // 0 ~ i-1 左子树
                // i+1 ~ inOrder.length -1 右子树
                int[] inLeft = Arrays.copyOfRange(inOrder, 0, i); // [4,2]
                int[] inRight = Arrays.copyOfRange(inOrder, i + 1, inOrder.length); // [6,3,7]

                int[] preLeft = Arrays.copyOfRange(preOrder, 1, i + 1); // [2,4]
                int[] preRight = Arrays.copyOfRange(preOrder, i + 1, inOrder.length); // [3,6,7]

                root.left = buildTree(preLeft, inLeft); // 2
                root.right = buildTree(preRight, inRight); // 3
                break;
            }
        }
        return root;
    }

}
复制<br>
<br>代码可以进一步优化，涉及新数据结构，以后实现
<br><br>
<br>先通过后序遍历结果定位根节点
<br>再结合中序遍历结果切分左右子树
<br>public TreeNode buildTree(int[] inOrder, int[] postOrder) {
    if (inOrder.length == 0) {
        return null;
    }
    // 根
    int rootValue = postOrder[postOrder.length - 1];
    TreeNode root = new TreeNode(rootValue);
    // 切分左右子树
    for (int i = 0; i &lt; inOrder.length; i++) {
        if (inOrder[i] == rootValue) {
            int[] inLeft = Arrays.copyOfRange(inOrder, 0, i);
            int[] inRight = Arrays.copyOfRange(inOrder, i + 1, inOrder.length);

            int[] postLeft = Arrays.copyOfRange(postOrder, 0, i);
            int[] postRight = Arrays.copyOfRange(postOrder, i, postOrder.length - 1);

            root.left = buildTree(inLeft, postLeft);
            root.right = buildTree(inRight, postRight);
            break;
        }
    }
    return root;
}
复制<br>
<br>代码可以进一步优化，涉及新数据结构，以后实现
<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>引用自 <a data-tooltip-position="top" aria-label="https://zhuanlan.zhihu.com/p/449686402" rel="noopener" class="external-link" href="https://zhuanlan.zhihu.com/p/449686402" target="_blank">面试最常考的 100 道算法题分类整理！ - 知乎 (zhihu.com)</a><br>
带 ✔️ 是本课程截至目前为止讲解过的
<br>
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/two-sum/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/two-sum/" target="_blank">1. Two Sum (两数之和)</a>, Easy, 11757 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/add-two-numbers/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/add-two-numbers/" target="_blank">2. Add Two Numbers (两数相加)</a>, Medium, 6524 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/longest-substring-without-repeating-characters/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/longest-substring-without-repeating-characters/" target="_blank">3. Longest Substring Without Repeating Characters (无重复字符的最长子串)</a>, Medium, 5845 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/median-of-two-sorted-arrays/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/median-of-two-sorted-arrays/" target="_blank">4. Median of Two Sorted Arrays (寻找两个正序数组的中位数)</a>, Hard, 4303 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/longest-palindromic-substring/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/longest-palindromic-substring/" target="_blank">5. Longest Palindromic Substring (最长回文子串)</a>, Medium, 3896 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/3sum/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/3sum/" target="_blank">15. 3Sum (三数之和)</a>, Medium, 3582 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/maximum-subarray/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/maximum-subarray/" target="_blank">53. Maximum Subarray (最大子序和)</a>, Easy, 3533 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/reverse-integer/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/reverse-integer/" target="_blank">7. Reverse Integer (整数反转)</a>, Easy, 2970 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/container-with-most-water/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/container-with-most-water/" target="_blank">11. Container With Most Water (盛最多水的容器)</a>, Medium, 2659 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/trapping-rain-water/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/trapping-rain-water/" target="_blank">42. Trapping Rain Water (接雨水)</a>, Hard, 2552 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/valid-parentheses/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/valid-parentheses/" target="_blank">20. Valid Parentheses (有效的括号)</a>, Easy, 2544 likes ✔️
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/regular-expression-matching/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/regular-expression-matching/" target="_blank">10. Regular Expression Matching (正则表达式匹配)</a>, Hard, 2273 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/remove-duplicates-from-sorted-array/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/remove-duplicates-from-sorted-array/" target="_blank">26. Remove Duplicates from Sorted Array (删除有序数组中的重复项)</a>, Easy, 2146 likes ✔️
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/single-number/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/single-number/" target="_blank">136. Single Number (只出现一次的数字)</a>, Easy, 1958 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/generate-parentheses/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/generate-parentheses/" target="_blank">22. Generate Parentheses (括号生成)</a>, Medium, 1946 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/reverse-linked-list/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/reverse-linked-list/" target="_blank">206. Reverse Linked List (反转链表)</a>, Easy, 1886 likes ✔️
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/merge-two-sorted-lists/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/merge-two-sorted-lists/" target="_blank">21. Merge Two Sorted Lists (合并两个有序链表)</a>, Easy, 1832 likes ✔️
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/climbing-stairs/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/climbing-stairs/" target="_blank">70. Climbing Stairs (爬楼梯)</a>, Easy, 1791 likes ✔️
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/longest-increasing-subsequence/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/longest-increasing-subsequence/" target="_blank">300. Longest Increasing Subsequence (最长递增子序列)</a>, Medium, 1773 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/best-time-to-buy-and-sell-stock/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/best-time-to-buy-and-sell-stock/" target="_blank">121. Best Time to Buy and Sell Stock (买卖股票的最佳时机)</a>, Easy, 1766 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/edit-distance/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/edit-distance/" target="_blank">72. Edit Distance (编辑距离)</a>, Hard, 1743 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/longest-common-prefix/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/longest-common-prefix/" target="_blank">14. Longest Common Prefix (最长公共前缀)</a>, Easy, 1707 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/house-robber/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/house-robber/" target="_blank">198. House Robber (打家劫舍)</a>, Medium, 1585 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/palindrome-number/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/palindrome-number/" target="_blank">9. Palindrome Number (回文数)</a>, Easy, 1568 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/lru-cache/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/lru-cache/" target="_blank">146. LRU Cache (LRU 缓存机制)</a>, Medium, 1544 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/remove-nth-node-from-end-of-list/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/remove-nth-node-from-end-of-list/" target="_blank">19. Remove Nth Node From End of List (删除链表的倒数第 N 个结点)</a>, Medium, 1494 likes ✔️
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/search-in-rotated-sorted-array/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/search-in-rotated-sorted-array/" target="_blank">33. Search in Rotated Sorted Array (搜索旋转排序数组)</a>, Medium, 1493 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/permutations/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/permutations/" target="_blank">46. Permutations (全排列)</a>, Medium, 1484 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/symmetric-tree/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/symmetric-tree/" target="_blank">101. Symmetric Tree (对称二叉树)</a>, Easy, 1483 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/largest-rectangle-in-histogram/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/largest-rectangle-in-histogram/" target="_blank">84. Largest Rectangle in Histogram (柱状图中最大的矩形)</a>, Hard, 1472 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/combination-sum/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/combination-sum/" target="_blank">39. Combination Sum (组合总和)</a>, Medium, 1466 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/roman-to-integer/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/roman-to-integer/" target="_blank">13. Roman to Integer (罗马数字转整数)</a>, Easy, 1436 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/merge-k-sorted-lists/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/merge-k-sorted-lists/" target="_blank">23. Merge k Sorted Lists (合并K个升序链表)</a>, Hard, 1436 likes ✔️
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/letter-combinations-of-a-phone-number/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/letter-combinations-of-a-phone-number/" target="_blank">17. Letter Combinations of a Phone Number (电话号码的字母组合)</a>, Medium, 1436 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/coin-change/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/coin-change/" target="_blank">322. Coin Change (零钱兑换)</a>, Medium, 1414 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/longest-valid-parentheses/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/longest-valid-parentheses/" target="_blank">32. Longest Valid Parentheses (最长有效括号)</a>, Hard, 1400 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/find-the-duplicate-number/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/find-the-duplicate-number/" target="_blank">287. Find the Duplicate Number (寻找重复数)</a>, Medium, 1325 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-ii/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-ii/" target="_blank">122. Best Time to Buy and Sell Stock II (买卖股票的最佳时机 II)</a>, Easy, 1306 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/intersection-of-two-linked-lists/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/intersection-of-two-linked-lists/" target="_blank">160. Intersection of Two Linked Lists (相交链表)</a>, Easy, 1302 likes ✔️
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/jump-game/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/jump-game/" target="_blank">55. Jump Game (跳跃游戏)</a>, Medium, 1292 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/minimum-window-substring/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/minimum-window-substring/" target="_blank">76. Minimum Window Substring (最小覆盖子串)</a>, Hard, 1280 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/number-of-islands/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/number-of-islands/" target="_blank">200. Number of Islands (岛屿数量)</a>, Medium, 1270 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/subsets/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/subsets/" target="_blank">78. Subsets (子集)</a>, Medium, 1269 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/next-permutation/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/next-permutation/" target="_blank">31. Next Permutation (下一个排列)</a>, Medium, 1260 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/unique-binary-search-trees/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/unique-binary-search-trees/" target="_blank">96. Unique Binary Search Trees (不同的二叉搜索树)</a>, Medium, 1257 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/sort-list/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/sort-list/" target="_blank">148. Sort List (排序链表)</a>, Medium, 1248 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/lowest-common-ancestor-of-a-binary-tree/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/lowest-common-ancestor-of-a-binary-tree/" target="_blank">236. Lowest Common Ancestor of a Binary Tree (二叉树的最近公共祖先)</a>, Medium, 1238 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/reverse-nodes-in-k-group/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/reverse-nodes-in-k-group/" target="_blank">25. Reverse Nodes in k-Group (K 个一组翻转链表)</a>, Hard, 1230 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/zigzag-conversion/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/zigzag-conversion/" target="_blank">6. ZigZag Conversion (Z 字形变换)</a>, Medium, 1226 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/maximum-product-subarray/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/maximum-product-subarray/" target="_blank">152. Maximum Product Subarray (乘积最大子数组)</a>, Medium, 1223 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/kth-largest-element-in-an-array/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/kth-largest-element-in-an-array/" target="_blank">215. Kth Largest Element in an Array (数组中的第K个最大元素)</a>, Medium, 1211 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/string-to-integer-atoi/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/string-to-integer-atoi/" target="_blank">8. String to Integer (atoi) (字符串转换整数 (atoi))</a>, Medium, 1168 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/first-missing-positive/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/first-missing-positive/" target="_blank">41. First Missing Positive (缺失的第一个正数)</a>, Hard, 1163 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/move-zeroes/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/move-zeroes/" target="_blank">283. Move Zeroes (移动零)</a>, Easy, 1162 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/linked-list-cycle/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/linked-list-cycle/" target="_blank">141. Linked List Cycle (环形链表)</a>, Easy, 1161 likes ✔️
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/validate-binary-search-tree/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/validate-binary-search-tree/" target="_blank">98. Validate Binary Search Tree (验证二叉搜索树)</a>, Medium, 1156 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/binary-tree-maximum-path-sum/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/binary-tree-maximum-path-sum/" target="_blank">124. Binary Tree Maximum Path Sum (二叉树中的最大路径和)</a>, Hard, 1152 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/construct-binary-tree-from-preorder-and-inorder-traversal/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/construct-binary-tree-from-preorder-and-inorder-traversal/" target="_blank">105. Construct Binary Tree from Preorder and Inorder Traversal (从前序与中序遍历序列构造二叉树)</a>, Medium, 1149 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/find-first-and-last-position-of-element-in-sorted-array/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/find-first-and-last-position-of-element-in-sorted-array/" target="_blank">34. Find First and Last Position of Element in Sorted Array (在排序数组中查找元素的第一个和最后一个位置)</a>, Medium, 1137 likes ✔️
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/sliding-window-maximum/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/sliding-window-maximum/" target="_blank">239. Sliding Window Maximum (滑动窗口最大值)</a>, Hard, 1114 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/linked-list-cycle-ii/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/linked-list-cycle-ii/" target="_blank">142. Linked List Cycle II (环形链表 II)</a>, Medium, 1097 likes ✔️
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/word-break/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/word-break/" target="_blank">139. Word Break (单词拆分)</a>, Medium, 1097 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/jump-game-ii/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/jump-game-ii/" target="_blank">45. Jump Game II (跳跃游戏 II)</a>, Medium, 1094 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/majority-element/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/majority-element/" target="_blank">169. Majority Element (多数元素)</a>, Easy, 1089 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/palindrome-linked-list/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/palindrome-linked-list/" target="_blank">234. Palindrome Linked List (回文链表)</a>, Easy, 1072 likes ✔️
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/unique-paths/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/unique-paths/" target="_blank">62. Unique Paths (不同路径)</a>, Medium, 1072 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/rotate-array/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/rotate-array/" target="_blank">189. Rotate Array (旋转数组)</a>, Medium, 1057 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/binary-tree-inorder-traversal/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/binary-tree-inorder-traversal/" target="_blank">94. Binary Tree Inorder Traversal (二叉树的中序遍历)</a>, Easy, 1052 likes ✔️
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/merge-intervals/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/merge-intervals/" target="_blank">56. Merge Intervals (合并区间)</a>, Medium, 1051 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/merge-sorted-array/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/merge-sorted-array/" target="_blank">88. Merge Sorted Array (合并两个有序数组)</a>, Easy, 1041 likes ✔️
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/subarray-sum-equals-k/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/subarray-sum-equals-k/" target="_blank">560. Subarray Sum Equals K (和为K的子数组)</a>, Medium, 1036 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/perfect-squares/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/perfect-squares/" target="_blank">279. Perfect Squares (完全平方数)</a>, Medium, 1035 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/search-insert-position/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/search-insert-position/" target="_blank">35. Search Insert Position (搜索插入位置)</a>, Easy, 1005 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/swap-nodes-in-pairs/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/swap-nodes-in-pairs/" target="_blank">24. Swap Nodes in Pairs (两两交换链表中的节点)</a>, Medium, 996 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/maximal-rectangle/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/maximal-rectangle/" target="_blank">85. Maximal Rectangle (最大矩形)</a>, Hard, 983 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/implement-strstr/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/implement-strstr/" target="_blank">28. Implement strStr() (实现 strStr())</a>, Easy, 982 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/reverse-linked-list-ii/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/reverse-linked-list-ii/" target="_blank">92. Reverse Linked List II (反转链表 II)</a>, Medium, 980 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/min-stack/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/min-stack/" target="_blank">155. Min Stack (最小栈)</a>, Easy, 979 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/word-search/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/word-search/" target="_blank">79. Word Search (单词搜索)</a>, Medium, 979 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/remove-element/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/remove-element/" target="_blank">27. Remove Element (移除元素)</a>, Easy, 967 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/n-queens/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/n-queens/" target="_blank">51. N-Queens (N 皇后)</a>, Hard, 965 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/sort-colors/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/sort-colors/" target="_blank">75. Sort Colors (颜色分类)</a>, Medium, 961 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/binary-tree-level-order-traversal/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/binary-tree-level-order-traversal/" target="_blank">102. Binary Tree Level Order Traversal (二叉树的层序遍历)</a>, Medium, 960 likes ✔️
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/rotate-image/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/rotate-image/" target="_blank">48. Rotate Image (旋转图像)</a>, Medium, 960 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/unique-binary-search-trees-ii/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/unique-binary-search-trees-ii/" target="_blank">95. Unique Binary Search Trees II (不同的二叉搜索树 II)</a>, Medium, 955 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/minimum-path-sum/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/minimum-path-sum/" target="_blank">64. Minimum Path Sum (最小路径和)</a>, Medium, 954 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/queue-reconstruction-by-height/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/queue-reconstruction-by-height/" target="_blank">406. Queue Reconstruction by Height (根据身高重建队列)</a>, Medium, 947 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/invert-binary-tree/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/invert-binary-tree/" target="_blank">226. Invert Binary Tree (翻转二叉树)</a>, Easy, 941 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/path-sum-iii/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/path-sum-iii/" target="_blank">437. Path Sum III (路径总和 III)</a>, Medium, 937 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/maximum-depth-of-binary-tree/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/maximum-depth-of-binary-tree/" target="_blank">104. Maximum Depth of Binary Tree (二叉树的最大深度)</a>, Easy, 937 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/delete-node-in-a-linked-list/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/delete-node-in-a-linked-list/" target="_blank">237. Delete Node in a Linked List (删除链表中的节点)</a>, Easy, 936 likes ✔️
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/house-robber-iii/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/house-robber-iii/" target="_blank">337. House Robber III (打家劫舍 III)</a>, Medium, 929 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/4sum/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/4sum/" target="_blank">18. 4Sum (四数之和)</a>, Medium, 918 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/decode-ways/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/decode-ways/" target="_blank">91. Decode Ways (解码方法)</a>, Medium, 904 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/course-schedule/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/course-schedule/" target="_blank">207. Course Schedule (课程表)</a>, Medium, 897 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/sudoku-solver/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/sudoku-solver/" target="_blank">37. Sudoku Solver (解数独)</a>, Hard, 897 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/combine-two-tables/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/combine-two-tables/" target="_blank">175. Combine Two Tables (组合两个表)</a>, Easy, 891 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/partition-equal-subset-sum/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/partition-equal-subset-sum/" target="_blank">416. Partition Equal Subset Sum (分割等和子集)</a>, Medium, 886 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/product-of-array-except-self/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/product-of-array-except-self/" target="_blank">238. Product of Array Except Self (除自身以外数组的乘积)</a>, Medium, 885 likes
<br><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/flatten-binary-tree-to-linked-list/" rel="noopener" class="external-link" href="https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/flatten-binary-tree-to-linked-list/" target="_blank">114. Flatten Binary Tree to Linked List (二叉树展开为链表)</a>, Medium, 877 likes
<br>
<br>
<br><a data-tooltip-position="top" aria-label="https://www.merriam-webster.com/dictionary/algorithm" rel="noopener" class="external-link" href="https://www.merriam-webster.com/dictionary/algorithm" target="_blank">"Definition of ALGORITHM"</a>. Merriam-Webster Online Dictionary. <a data-tooltip-position="top" aria-label="https://web.archive.org/web/20200214074446/https://www.merriam-webster.com/dictionary/algorithm" rel="noopener" class="external-link" href="https://web.archive.org/web/20200214074446/https://www.merriam-webster.com/dictionary/algorithm" target="_blank">Archived</a> from the original on February 14, 2020. Retrieved November 14, 2019.<a href="\#fnref-1-33dbe2937a530ff5" class="footnote-backref footnote-link" target="_self" rel="noopener">↩︎</a>
<br>Introduction to Algorithm 中文译作《算法导论》<a href="\#fnref-2-33dbe2937a530ff5" class="footnote-backref footnote-link" target="_self" rel="noopener">↩︎</a><a href="\#fnref-2-1-33dbe2937a530ff5" class="footnote-backref footnote-link" target="_self" rel="noopener">↩︎</a>
<br>主要参考文档 <a rel="noopener" class="external-link" href="https://en.wikipedia.org/wiki/Binary_search_algorithm" target="_blank">https://en.wikipedia.org/wiki/Binary_search_algorithm</a><a href="\#fnref-3-33dbe2937a530ff5" class="footnote-backref footnote-link" target="_self" rel="noopener">↩︎</a>
<br>图片及概念均摘自 Introduction to Algorithm 4th，3.1节，3.2 节<a href="\#fnref-4-33dbe2937a530ff5" class="footnote-backref footnote-link" target="_self" rel="noopener">↩︎</a>
<br>jdk 版本有关，64 位 jdk，按 8 字节对齐<a href="\#fnref-5-33dbe2937a530ff5" class="footnote-backref footnote-link" target="_self" rel="noopener">↩︎</a>
<br>图片引用自 wikipedia linkedlist 条目，<a rel="noopener" class="external-link" href="https://en.wikipedia.org/wiki/Linked_list" target="_blank">https://en.wikipedia.org/wiki/Linked_list</a><a href="\#fnref-6-33dbe2937a530ff5" class="footnote-backref footnote-link" target="_self" rel="noopener">↩︎</a>
<br>Fibonacci 介绍：<a rel="noopener" class="external-link" href="https://en.wikipedia.org/wiki/Fibonacci_number" target="_blank">https://en.wikipedia.org/wiki/Fibonacci_number</a><a href="\#fnref-7-33dbe2937a530ff5" class="footnote-backref footnote-link" target="_self" rel="noopener">↩︎</a><a href="\#fnref-7-1-33dbe2937a530ff5" class="footnote-backref footnote-link" target="_self" rel="noopener">↩︎</a>
<br><a data-tooltip-position="top" aria-label="https://zhuanlan.zhihu.com/p/165877869" rel="noopener" class="external-link" href="https://zhuanlan.zhihu.com/p/165877869" target="_blank">几种计算Fibonacci数列算法的时间复杂度比较 - 知乎 (zhihu.com)</a><a href="\#fnref-8-33dbe2937a530ff5" class="footnote-backref footnote-link" target="_self" rel="noopener">↩︎</a>
<br>几种斐波那契数列算法比较 <a data-tooltip-position="top" aria-label="https://www.nayuki.io/page/fast-fibonacci-algorithms" rel="noopener" class="external-link" href="https://www.nayuki.io/page/fast-fibonacci-algorithms" target="_blank">Fast Fibonacci algorithms (nayuki.io)</a><a href="\#fnref-9-33dbe2937a530ff5" class="footnote-backref footnote-link" target="_self" rel="noopener">↩︎</a>
<br>我知道的有 C++，Scala<a href="\#fnref-10-33dbe2937a530ff5" class="footnote-backref footnote-link" target="_self" rel="noopener">↩︎</a>
<br>与主定理类似的还有 Akra–Bazzi method，<a rel="noopener" class="external-link" href="https://en.wikipedia.org/wiki/Akra%E2%80%93Bazzi_method" target="_blank">https://en.wikipedia.org/wiki/Akra%E2%80%93Bazzi_method</a><a href="\#fnref-11-33dbe2937a530ff5" class="footnote-backref footnote-link" target="_self" rel="noopener">↩︎</a>
<br>Josephus problem 主要参考 <a rel="noopener" class="external-link" href="https://en.wikipedia.org/wiki/Josephus_problem" target="_blank">https://en.wikipedia.org/wiki/Josephus_problem</a><a href="\#fnref-12-33dbe2937a530ff5" class="footnote-backref footnote-link" target="_self" rel="noopener">↩︎</a>
<br>汉诺塔图片资料均来自 <a rel="noopener" class="external-link" href="https://en.wikipedia.org/wiki/Tower_of_Hanoi" target="_blank">https://en.wikipedia.org/wiki/Tower_of_Hanoi</a><a href="\#fnref-13-33dbe2937a530ff5" class="footnote-backref footnote-link" target="_self" rel="noopener">↩︎</a>
<br>也称为 Pascal's triangle <a rel="noopener" class="external-link" href="https://en.wikipedia.org/wiki/Pascal%27s_triangle" target="_blank">https://en.wikipedia.org/wiki/Pascal%27s_triangle</a><a href="\#fnref-14-33dbe2937a530ff5" class="footnote-backref footnote-link" target="_self" rel="noopener">↩︎</a>
<br>龟兔赛跑动画来自于 <a data-tooltip-position="top" aria-label="https://onestepcode.com/floyd-hare-tortoise-algorithm-demo/" rel="noopener" class="external-link" href="https://onestepcode.com/floyd-hare-tortoise-algorithm-demo/" target="_blank">Floyd's Hare and Tortoise Algorithm Demo - One Step! Code (onestepcode.com)</a><a href="\#fnref-15-33dbe2937a530ff5" class="footnote-backref footnote-link" target="_self" rel="noopener">↩︎</a>
]]></description><link>01、通用基础\04、数据结构算法\01、数据结构\03、ds-a-第一篇-基础数据结构.html</link><guid isPermaLink="false">01、通用基础/04、数据结构算法/01、数据结构/03、DS-A 第一篇 基础数据结构.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:44 GMT</pubDate><enclosure url="imgs\image-20221108095747933.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;imgs\image-20221108095747933.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[04、线性表 - 栈和队列]]></title><description><![CDATA[ 
 ]]></description><link>01、通用基础\04、数据结构算法\01、数据结构\04、线性表-栈和队列.html</link><guid isPermaLink="false">01、通用基础/04、数据结构算法/01、数据结构/04、线性表 - 栈和队列.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:44 GMT</pubDate></item><item><title><![CDATA[05、树 - 基础和Overview]]></title><description><![CDATA[ 
 ]]></description><link>01、通用基础\04、数据结构算法\01、数据结构\05、树-基础和overview.html</link><guid isPermaLink="false">01、通用基础/04、数据结构算法/01、数据结构/05、树 - 基础和Overview.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:43 GMT</pubDate></item><item><title><![CDATA[★ 常见排序算法 ★]]></title><description><![CDATA[ 
 <br><br><br><br><br>算法思想：<br>
从数组中第一个数开始，依次遍历数组中的每一个数，通过相邻比较交换，每一轮循环下来找出剩余未排序数的中的最大数并”冒泡”至数列的顶端。<br>算法步骤：<br>
<br>从数组中第一个数开始，依次与下一个数比较并次交换比自己小的数，直到最后一个数。如果发生交换，则继续下面的步骤，如果未发生交换，则数组有序，排序结束，此时时间复杂度为O(n)；
<br>每一轮”冒泡”结束后，最大的数将出现在乱序数列的最后一位。重复步骤（1）。
<br>稳定性： 稳定排序。<br>时间复杂度： O(n)至O(n2)，平均时间复杂度为O(n2)。<br>最好的情况： 如果待排序数据序列为正序，则一趟冒泡就可完成排序，排序码的比较次数为n-1次，且没有移动，时间复杂度为O(n)。<br>最坏的情况： 如果待排序数据序列为逆序，则冒泡排序需要n-1次趟起泡，每趟进行n-i次排序码的比较和移动，即比较和移动次数均达到最大值：<br>比较次数： Cmax=∑i=1n−1(n−i)=n(n−1)/2=O(n2)<br>
移动次数等于比较次数，因此最坏时间复杂度为O(n2)。<br><br>冒泡排序是在相邻的两个记录进行比较和交换，每次交换只能上移或下移一个位置，导致总的比较与移动次数较多。快速排序又称分区交换排序，是对冒泡排序的改进，快速排序采用的思想是分治思想。。<br>算法原理：<br>
<br>从待排序的n个记录中任意选取一个记录（通常选取第一个记录）为分区标准;
<br>把所有小于该排序列的记录移动到左边，把所有大于该排序码的记录移动到右边，中间放所选记录，称之为第一趟排序；
<br>然后对前后两个子序列分别重复上述过程，直到所有记录都排好序。
<br>稳定性： 不稳定排序。<br>时间复杂度： O（nlog2n）至O(n2)，平均时间复杂度为O（nlgn）。<br>最好的情况： 是每趟排序结束后，每次划分使两个子文件的长度大致相等，时间复杂度为O（nlog2n）。<br>最坏的情况： 是待排序记录已经排好序，第一趟经过n-1次比较后第一个记录保持位置不变，并得到一个n-1个元素的子记录；第二趟经过n-2次比较，将第二个记录定位在原来的位置上，并得到一个包括n-2个记录的子文件，依次类推，这样总的比较次数是：<br>
Cmax=∑i=1n−1(n−i)=n(n−1)/2=O(n2)<br><br><br>原理： 从待排序的n个记录中的第二个记录开始，依次与前面的记录比较并寻找插入的位置，每次外循环结束后，将当前的数插入到合适的位置。<br>稳定性：稳定排序。<br>时间复杂度： O(n)至O（n2），平均时间复杂度是O（n2）。<br>最好情况：当待排序记录已经有序，这时需要比较的次数是Cmin=n−1=O(n)。<br>最坏情况：如果待排序记录为逆序，则最多的比较次数为Cmax=∑i=1n−1(i)=n(n−1)2=O(n2)。<br><br><br><br>原理：从所有记录中选出最小的一个数据元素与第一个位置的记录交换；然后在剩下的记录当中再找最小的与第二个位置的记录交换，循环到只剩下最后一个数据元素为止。<br>稳定性：不稳定排序。<br>时间复杂度： 最坏、最好和平均复杂度均为O(n2)，因此，简单选择排序也是常见排序算法中性能最差的排序算法。简单选择排序的比较次数与文件的初始状态没有关系，在第i趟排序中选出最小排序码的记录，需要做n-i次比较，因此总的比较次数是：∑i=1n−1(n−i)=n(n−1)/2=O(n2)。<br><br><br>二路归并排序<br>多路归并排序<br><br><br><br>]]></description><link>01、通用基础\04、数据结构算法\02、算法\01、常见的排序算法.html</link><guid isPermaLink="false">01、通用基础/04、数据结构算法/02、算法/01、常见的排序算法.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:45 GMT</pubDate></item><item><title><![CDATA[一致性hash]]></title><description><![CDATA[ 
 ]]></description><link>01、通用基础\04、数据结构算法\03、其他领域算法\一致性hash.html</link><guid isPermaLink="false">01、通用基础/04、数据结构算法/03、其他领域算法/一致性hash.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Sat, 16 Mar 2024 09:00:22 GMT</pubDate></item><item><title><![CDATA[Raft算法]]></title><description><![CDATA[ 
 ]]></description><link>01、通用基础\04、数据结构算法\03、其他领域算法\raft算法.html</link><guid isPermaLink="false">01、通用基础/04、数据结构算法/03、其他领域算法/Raft算法.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Sat, 16 Mar 2024 07:35:05 GMT</pubDate></item><item><title><![CDATA[01、软件工程发展史]]></title><description><![CDATA[ 
 ]]></description><link>01、通用基础\05、软件设计基础\01、软件工程发展史.html</link><guid isPermaLink="false">01、通用基础/05、软件设计基础/01、软件工程发展史.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:45 GMT</pubDate></item><item><title><![CDATA[02、UML-统一建模软件]]></title><description><![CDATA[ 
 <br><br>统一建模语言（Unified Modeling Language，UML）是用来设计软件的可视化建模语言。它的特点是简单、统一、图形化、能表达软件设计中的动态与静态信息。<br>UML 从目标系统的不同角度出发，定义了用例图、类图、对象图、状态图、活动图、时序图、协作图、构件图、部署图等 9 种图。<br>类图(Class diagram)是显示了模型的静态结构，特别是模型中存在的类、类的内部结构以及它们与其他类的关系等。类图不显示暂时性的信息。类图是面向对象建模的主要组成部分。<br><br>在UML类图中，类使用包含类名、属性(field) 和方法(method) 且带有分割线的矩形来表示，比如下图表示一个Employee类，它包含name,age和address这3个属性，以及work()方法。<br><img src="https://bright-boy.gitee.io/technical-notes/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/img/Employee.jpg" referrerpolicy="no-referrer"><br>属性/方法名称前加的加号和减号表示了这个属性/方法的可见性，UML类图中表示可见性的符号有三种：<br>
<br>+ ：表示 public
<br>-：表示 private
<br>#：表示 protecte
<br>属性的完整表示方式是：&nbsp;可见性 名称 ：类型 [ = 缺省值]<br>方法的完整表示方式是：&nbsp;可见性 名称(参数列表) [ ： 返回类型]<br>
注意：<br>
​ 1，中括号中的内容表示是可选的<br>
​ 2，也有将类型放在变量名前面，返回值类型放在方法名前面
<br>举个栗子：<br><img src="https://bright-boy.gitee.io/technical-notes/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/img/demo.png" referrerpolicy="no-referrer"><br>上图Demo类定义了三个方法：<br>
<br>method()方法：修饰符为public，没有参数，没有返回值。
<br>method1()方法：修饰符为private，没有参数，返回值类型为String。
<br>method2()方法：修饰符为protected，接收两个参数，第一个参数类型为int，第二个参数类型为String，返回值类型是int。
<br><br><br>关联关系是对象之间的一种引用关系，用于表示一类对象与另一类对象之间的联系，如老师和学生、师傅和徒弟、丈夫和妻子等。关联关系是类与类之间最常用的一种关系，分为一般关联关系、聚合关系和组合关系。我们先介绍一般关联。<br>关联又可以分为单向关联，双向关联，自关联。<br><br><img src="\01、通用基础\05、软件设计基础\assets\02、uml-统一建模软件\img-20240311_205149.png"><br>在UML类图中单向关联用一个带箭头的实线表示。上图表示每个顾客都有一个地址，这通过让Customer类持有一个类型为Address的成员变量类实现。<br><br><img src="\01、通用基础\05、软件设计基础\assets\02、uml-统一建模软件\img-20240311_205218.png"><br>从上图中我们很容易看出，所谓的双向关联就是双方各自持有对方类型的成员变量。<br>在 UML 类图中，双向关联用一个不带箭头的直线表示。上图中在 Customer 类中维护一个 List&lt;Product&gt;，表示一个顾客可以购买多个商品；在 Product 类中维护一个 Customer 类型的成员变量表示这个产品被哪个顾客所购买。<br><br><img src="\01、通用基础\05、软件设计基础\assets\02、uml-统一建模软件\img-20240311_205227.png"><br>自关联在 UML 类图中用一个带有箭头且指向自身的线表示。上图的意思就是 Node 类包含类型为 Node 的成员变量，也就是“自己包含自己”。<br><br>聚合关系是关联关系的一种，是强关联关系，是整体和部分之间的关系。<br>聚合关系也是通过成员对象来实现的，其中成员对象是整体对象的一部分，但是成员对象可以脱离整体对象而独立存在。例如，学校与老师的关系，学校包含老师，但如果学校停办了，老师依然存在。<br>在 UML 类图中，聚合关系可以用带空心菱形的实线来表示，菱形指向整体。下图所示是大学和教师的关系图：<br><img src="\01、通用基础\05、软件设计基础\assets\02、uml-统一建模软件\img-20240311_205418.png"><br><br>组合表示类之间的整体与部分的关系，但它是一种更强烈的聚合关系。<br>在组合关系中，整体对象可以控制部分对象的生命周期，一旦整体对象不存在，部分对象也将不存在，部分对象不能脱离整体对象而存在。例如，头和嘴的关系，没有了头，嘴也就不存在了。<br>在 UML 类图中，组合关系用带实心菱形的实线来表示，菱形指向整体。下图所示是头和嘴的关系图：<br><img src="\01、通用基础\05、软件设计基础\assets\02、uml-统一建模软件\img-20240311_205443.png"><br><br>依赖关系是一种使用关系，它是对象之间耦合度最弱的一种关联方式，是临时性的关联。在代码中，某个类的方法通过局部变量、方法的参数或者对静态方法的调用来访问另一个类（被依赖类）中的某些方法来完成一些职责。<br>在 UML 类图中，依赖关系使用带箭头的虚线来表示，箭头从使用类指向被依赖的类。下图所示是司机和汽车的关系图，司机驾驶汽车：<br><img src="\01、通用基础\05、软件设计基础\assets\02、uml-统一建模软件\img-20240311_205653.png"><br><br>继承关系是对象之间耦合度最大的一种关系，表示一般与特殊的关系，是父类与子类之间的关系，是一种继承关系。<br>在 UML 类图中，泛化关系用带空心三角箭头的实线来表示，箭头从子类指向父类。在代码实现时，使用面向对象的继承机制来实现泛化关系。例如，Student 类和 Teacher 类都是 Person 类的子类，其类图如下图所示：<br><br>实现关系是接口与实现类之间的关系。在这种关系中，类实现了接口，类中的操作实现了接口中所声明的所有的抽象操作。<br>在 UML 类图中，实现关系使用带空心三角箭头的虚线来表示，箭头从实现类指向接口。例如，汽车和船实现了交通工具，其类图如图 9 所示。<br><img src="\01、通用基础\05、软件设计基础\assets\02、uml-统一建模软件\img-20240311_205752.png">]]></description><link>01、通用基础\05、软件设计基础\02、uml-统一建模软件.html</link><guid isPermaLink="false">01、通用基础/05、软件设计基础/02、UML-统一建模软件.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:45 GMT</pubDate><enclosure url="https://bright-boy.gitee.io/technical-notes/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/img/Employee.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://bright-boy.gitee.io/technical-notes/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/img/Employee.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[03、软件设计原则]]></title><description><![CDATA[ 
 <br><br>
面向对象的基本原则(solid)是五个，但是在经常被提到的除了这五个之外还有 迪米特法则和合成复用原则等， 所以在常见的文章中有表示写六大或七大原则的； 除此之外我还将给出一些其它相关书籍和互联网上出现的原则；
<br><br>
Single-Responsibility Principle, 一个类,最好只做一件事,只有一个引起它的变化。单一职责原则可以看做是低耦合,高内聚在面向对象原则的引申,将职责定义为引起变化的原因,以提高内聚性减少引起变化的原因。
<br><br>一个对象应该只包含单一的职责，并且该职责被完整地封装在一个类中。(Every object should have a single responsibility, and that responsibility should be entirely encapsulated by the class.)，即又定义有且仅有一个原因使类变更。<br><br>
<br>一个类(或者大到模块，小到方法)承担的职责越多，它被复用的可能性越小，而且如果一个类承担的职责过多，就相当于将这些职责耦合在一起，当其中一个职责变化时，可能会影响其他职责的运作。
<br>类的职责主要包括两个方面: 数据职责和行为职责，数据职责通过其属性来体现，而行为职责通过其方法来体现。
<br>单一职责原则是实现高内聚、低耦合的指导方针，在很多代码重构手法中都能找到它的存在，它是最简单但又最难运用的原则，需要设计人员发现类的不同职责并将其分离，而发现类的多重职责需要设计人员具有较强的分析设计能力和相关重构经验。
<br><br>
<br>降低类的复杂性，类的职责清晰明确。比如数据职责和行为职责清晰明确。
<br>提高类的可读性和维护性，
<br>变更引起的风险减低，变更是必不可少的，如果接口的单一职责做得好，一个接口修改只对相应的类有影响，对其他接口无影响，这对系统的扩展性、维护性都有非常大的帮助。
<br>
注意: 单一职责原则提出了一个编写程序的标准，用“职责”或“变化原因”来衡量接口或类设计得是否合理，但是“职责”和“变化原因”都是没有具体标准的，一个类到底要负责那些职责? 这些职责怎么细化? 细化后是否都要有一个接口或类? 这些都需从实际的情况考虑。因项目而异，因环境而异。
<br><br>SpringMVC 中 Entity,DAO,Service,Controller, Util 等的分离。<br><br>
Open - ClosedPrinciple ,OCP, 对扩展开放，对修改关闭(设计模式的核心原则)
<br><br>
一个软件实体(如类、模块和函数)应该对扩展开放，对修改关闭. 意思是,在一个系统或者模块中,对于扩展是开放的,对于修改是关闭的,一个 好的系统是在不修改源代码的情况下,可以扩展你的功能. 而实现开闭原则的关键就是抽象化.
<br><br>
<br>当软件实体因需求要变化时, 尽量通过扩展已有软件实体，可以提供新的行为，以满足对软件的新的需求，而不是修改已有的代码，使变化中的软件有一定的适应性和灵活性 。已有软件模块，特别是最重要的抽象层模块不能再修改，这使变化中的软件系统有一定的稳定性和延续性。<br>

<br>实现开闭原则的关键就是抽象化 :在"开-闭"原则中,不允许修改的是抽象的类或者接口,允许扩展的是具体的实现类,抽象类和接口在"开-闭"原则中扮演着极其重要的角色..即要预知可能变化的需求.又预见所有可能已知的扩展..所以在这里"抽象化"是关键!<br>

<br>可变性的封闭原则:找到系统的可变因素,将它封装起来. 这是对"开-闭"原则最好的实现. 不要把你的可变因素放在多个类中,或者散落在程序的各个角落. 你应该将可变的因素,封套起来..并且切忌不要把所用的可变因素封套在一起. 最好的解决办法是,分块封套你的可变因素!避免超大类,超长类,超长方法的出现!!给你的程序增加艺术气息,将程序艺术化是我们的目标!<br>

<br><br>设计模式中模板方法模式和观察者模式都是开闭原则的极好体现。<br><br>
Liskov Substitution Principle ,LSP: 任何基类可以出现的地方,子类也可以出现；这一思想表现为对继承机制的约束规范,只有子类能够替换其基类时,才能够保证系统在运行期内识别子类,这是保证继承复用的基础。
<br><br>第一种定义方式相对严格: 如果对每一个类型为S的对象o1，都有类型为T的对象o2，使得以T定义的所有程序P在所有的对象o1都代换成o2时，程序P的行为没有变化，那么类型S是类型T的子类型。<br>第二种更容易理解的定义方式: 所有引用基类(父类)的地方必须能透明地使用其子类的对象。即子类能够必须能够替换基类能够从出现的地方。子类也能在基类 的基础上新增行为。 (里氏代换原则由2008年图灵奖得主、美国第一位计算机科学女博士、麻省理工学院教授BarbaraLiskov和卡内基.梅隆大学Jeannette Wing教授于1994年提出。其原文如下: Let q(x) be a property provableabout objects x of type T. Then q(y) should be true for objects y of type Swhere S is a subtype of T. )<br><br>
<br>讲的是基类和子类的关系，只有这种关系存在时，里氏代换原则才存在。正方形是长方形是理解里氏代换原则的经典例子。
<br>里氏代换原则可以通俗表述为: 在软件中如果能够使用基类对象，那么一定能够使用其子类对象。把基类都替换成它的子类，程序将不会产生任何错误和异常，反过来则不成立，如果一个软件实体使用的是一个子类的话，那么它不一定能够使用基类。
<br>里氏代换原则是实现开闭原则的重要方式之一，由于使用基类对象的地方都可以使用子类对象，因此在程序中尽量使用基类类型来对对象进行定义，而在运行时再确定其子类类型，用子类对象来替换父类对象。
<br><br>
(Interface Segregation Principle，ISL): 客户端不应该依赖那些它不需要的接口。(这个法则与迪米特法则是相通的)
<br><br>客户端不应该依赖那些它不需要的接口。<br>另一种定义方法: 一旦一个接口太大，则需要将它分割成一些更细小的接口，使用该接口的客户端仅需知道与之相关的方法即可。 注意，在该定义中的接口指的是所定义的方法。例如外面调用某个类的public方法。这个方法对外就是接口。<br><br>
<br>接口隔离原则是指使用多个专门的接口，而不使用单一的总接口。每一个接口应该承担一种相对独立的角色，不多不少，不干不该干的事，该干的事都要干。

<br>一个接口就只代表一个角色，每个角色都有它特定的一个接口，此时这个原则可以叫做“角色隔离原则”。
<br>接口仅仅提供客户端需要的行为，即所需的方法，客户端不需要的行为则隐藏起来，应当为客户端提供尽可能小的单独的接口，而不要提供大的总接口。


<br>使用接口隔离原则拆分接口时，首先必须满足单一职责原则，将一组相关的操作定义在一个接口中，且在满足高内聚的前提下，接口中的方法越少越好。
<br>可以在进行系统设计时采用定制服务的方式，即为不同的客户端提供宽窄不同的接口，只提供用户需要的行为，而隐藏用户不需要的行为。
<br><br>
Dependency-Inversion Principle 要依赖抽象,而不要依赖具体的实现, 具体而言就是高层模块不依赖于底层模块,二者共同依赖于抽象。抽象不依赖于具体,具体依赖于抽象。
<br><br>高层模块不应该依赖低层模块，它们都应该依赖抽象。抽象不应该依赖于细节，细节应该依赖于抽象。简单的说，依赖倒置原则要求客户端依赖于抽象耦合。原则表述:<br>1)抽象不应当依赖于细节；细节应当依赖于抽象；<br>2)要针对接口编程，不针对实现编程。<br><br>
<br>如果说开闭原则是面向对象设计的目标,依赖倒转原则是到达面向设计"开闭"原则的手段..如果要达到最好的"开闭"原则,就要尽量的遵守依赖倒转原则. 可以说依赖倒转原则是对"抽象化"的最好规范! 我个人感觉,依赖倒转原则也是里氏代换原则的补充..你理解了里氏代换原则,再来理解依赖倒转原则应该是很容易的。<br>

<br>依赖倒转原则的常用实现方式之一是在代码中使用抽象类，而将具体类放在配置文件中。<br>

<br>类之间的耦合: 零耦合关系，具体耦合关系，抽象耦合关系。依赖倒转原则要求客户端依赖于抽象耦合，以抽象方式耦合是依赖倒转原则的关键。<br>

<br><br>理解这个依赖倒置，首先我们需要明白依赖在面向对象设计的概念:<br>依赖关系(Dependency): 是一种使用关系，特定事物的改变有可能会影响到使用该事物的其他事物，在需要表示一个事物使用另一个事物时使用依赖关系。(假设A类的变化引起了B类的变化，则说名B类依赖于A类。)大多数情况下，依赖关系体现在某个类的方法使用另一个类的对象作为参数。在UML中，依赖关系用带箭头的虚线表示，由依赖的一方指向被依赖的一方。<br>例子: 某系统提供一个数据转换模块，可以将来自不同数据源的数据转换成多种格式，如可以转换来自数据库的数据(DatabaseSource)、也可以转换来自文本文件的数据(TextSource)，转换后的格式可以是XML文件(XMLTransformer)、也可以是XLS文件(XLSTransformer)等。<br>“/images/dev_rules_d_1.png” could not be found.<br>由于需求的变化，该系统可能需要增加新的数据源或者新的文件格式，每增加一个新的类型的数据源或者新的类型的文件格式，客户类MainClass都需要修改源代码，以便使用新的类，但违背了开闭原则。现使用依赖倒转原则对其进行重构。<br>“/images/dev_rules_d_2.png” could not be found.<br>
<br>当然根据具体的情况，也可以将AbstractSource注入到AbstractStransformer，依赖注入的方式有以下三种:
<br>/** 
 * 依赖注入是依赖AbstractSource抽象注入的，而不是具体 
 * DatabaseSource 
 * 
 */  
abstract class AbstractStransformer {  
    private AbstractSource source;   
    /** 
     * 构造注入(Constructor Injection): 通过构造函数注入实例变量。 
     */  
    public void AbstractStransformer(AbstractSource source){  
        this.source = source;           
    }  
    /**      
     * 设值注入(Setter Injection): 通过Setter方法注入实例变量。 
     * @param source : the sourceto set        
     */       
    public void setSource(AbstractSource source) {            
        this.source = source;             
    }  
    /** 
     * 接口注入(Interface Injection): 通过接口方法注入实例变量。 
     * @param source 
     */  
    public void transform(AbstractSource source ) {    
        source.getSource();  
        System.out.println("Stransforming ...");    
    }      
}
复制<br><br><br>
(Composite/Aggregate ReusePrinciple ，CARP): 要尽量使用对象组合,而不是继承关系达到软件复用的目的
<br><br>经常又叫做合成复用原则(Composite ReusePrinciple或CRP)，尽量使用对象组合，而不是继承来达到复用的目的。<br>就是在一个新的对象里面使用一些已有的对象，使之成为新对象的一部分；新对象通过向这些对象的委派达到复用已有功能的目的。简而言之，要尽量使用合成/聚合，尽量不要使用继承。<br><br>
<br>在面向对象设计中，可以通过两种基本方法在不同的环境中复用已有的设计和实现，即通过组合/聚合关系或通过继承。

<br>继承复用: 实现简单，易于扩展。破坏系统的封装性；从基类继承而来的实现是静态的，不可能在运行时发生改变，没有足够的灵活性；只能在有限的环境中使用。(“白箱”复用)
<br>组合/聚合复用: 耦合度相对较低，选择性地调用成员对象的操作；可以在运行时动态进行。(“黑箱”复用)


<br>组合/聚合可以使系统更加灵活，类与类之间的耦合度降低，一个类的变化对其他类造成的影响相对较少，因此一般首选使用组合/聚合来实现复用；其次才考虑继承，在使用继承时，需要严格遵循里氏代换原则，有效使用继承会有助于对问题的理解，降低复杂度，而滥用继承反而会增加系统构建和维护的难度以及系统的复杂度，因此需要慎重使用继承复用。
<br>此原则和里氏代换原则氏相辅相成的,两者都是具体实现"开-闭"原则的规范。违反这一原则，就无法实现"开-闭"原则，首先我们要明白合成和聚合的概念:
<br>
注意: 聚合和组合的区别是什么?
<br>合成(组合): 表示一个整体与部分的关系，指一个依托整体而存在的关系(整体与部分不可以分开)；比如眼睛和嘴对于头来说就是组合关系，没有了头就没有眼睛和嘴，它们是不可分割的。在UML中，组合关系用带实心菱形的直线表示。<br>聚合:聚合是比合成关系的一种更强的依赖关系,也表示整体与部分的关系(整体与部分可以分开)；比如螺丝和汽车玩具的关系，螺丝脱离玩具依然可以用在其它设备之上。在UML中，聚合关系用带空心菱形的直线表示。<br><br>
Law of Demeter，LoD: 系统中的类,尽量不要与其他类互相作用,减少类之间的耦合度
<br><br>又叫最少知识原则(Least Knowledge Principle或简写为LKP)几种形式定义:<br>
<br>不要和“陌生人”说话。英文定义为: Don't talk to strangers.
<br>只与你的直接朋友通信。英文定义为: Talk only to your immediate friends.
<br>每一个软件单位对其他的单位都只有最少的知识，而且局限于那些与本单位密切相关的软件单位。
<br>简单地说，也就是，一个对象应当对其它对象有尽可能少的了解。一个类应该对自己需要耦合或调用的类知道得最少，你(被耦合或调用的类)的内部是如何复杂都和我没关系，那是你的事情，我就知道你提供的public方法，我就调用这么多，其他的一概不关心。<br><br>
<br>朋友类:
<br>在迪米特法则中，对于一个对象，其朋友包括以下几类:<br>
<br>当前对象本身(this)；
<br>以参数形式传入到当前对象方法中的对象；
<br>当前对象的成员对象；
<br>如果当前对象的成员对象是一个集合，那么集合中的元素也都是朋友；
<br>当前对象所创建的对象。
<br>任何一个对象，如果满足上面的条件之一，就是当前对象的“朋友”，否则就是“陌生人”。<br>
<br>狭义法则和广义法则:
<br>在狭义的迪米特法则中，如果两个类之间不必彼此直接通信，那么这两个类就不应当发生直接的相互作用，如果其中的一个类需要调用另一个类的某一个方法的话，可以通过第三者转发这个调用。<br>狭义的迪米特法则: 可以降低类之间的耦合，但是会在系统中增加大量的小方法并散落在系统的各个角落，它可以使一个系统的局部设计简化，因为每一个局部都不会和远距离的对象有直接的关联，但是也会造成系统的不同模块之间的通信效率降低，使得系统的不同模块之间不容易协调。<br>广义的迪米特法则: 指对对象之间的信息流量、流向以及信息的影响的控制，主要是对信息隐藏的控制。信息的隐藏可以使各个子系统之间脱耦，从而允许它们独立地被开发、优化、使用和修改，同时可以促进软件的复用，由于每一个模块都不依赖于其他模块而存在，因此每一个模块都可以独立地在其他的地方使用。一个系统的规模越大，信息的隐藏就越重要，而信息隐藏的重要性也就越明显。<br>
<br>迪米特法则的主要用途: 在于控制信息的过载。

<br>在类的划分上，应当尽量创建松耦合的类，类之间的耦合度越低，就越有利于复用，一个处在松耦合中的类一旦被修改，不会对关联的类造成太大波及；
<br>在类的结构设计上，每一个类都应当尽量降低其成员变量和成员函数的访问权限；
<br>在类的设计上，只要有可能，一个类型应当设计成不变类；
<br>在对其他类的引用上，一个对象对其他对象的引用应当降到最低。


<br><br>外观模式Facade(结构型)<br>迪米特法则与设计模式Facade模式、Mediator模式<br>
系统中的类,尽量不要与其他类互相作用,减少类之间的耦合度,因为在你的系统中,扩展的时候,你可能需要修改这些类,而类与类之间的关系,决定了修改的复杂度,相互作用越多,则修改难度就越大,反之,如果相互作用的越小,则修改起来的难度就越小..例如A类依赖B类,则B类依赖C类,当你在修改A类的时候,你要考虑B类是否会受到影响,而B类的影响是否又会影响到C类. 如果此时C类再依赖D类的话,呵呵,我想这样的修改有的受了。
<br><br><br>封装变化<br>少用继承 多用组合<br>针对接口编程 不针对实现编程<br>为交互对象之间的松耦合设计而努力<br>类应该对扩展开发 对修改封闭(开闭OCP原则)<br>依赖抽象，不要依赖于具体类(依赖倒置DIP原则)<br>密友原则: 只和朋友交谈(最少知识原则，迪米特法则)<br>说明: 一个对象应当对其他对象有尽可能少的了解，将方法调用保持在界限内，只调用属于以下范围的方法: 该对象本身(本地方法)对象的组件 被当作方法参数传进来的对象 此方法创建或实例化的任何对象<br>别找我(调用我) 我会找你(调用你)(好莱坞原则)<br>一个类只有一个引起它变化的原因(单一职责SRP原则)<br><br>严格定义: 如果对每一个类型为S的对象o1，都有类型为T的对象o2，使得以T定义的所有程序P在所有的对象用o1替换o2时，程序P的行为没有变化，那么类型S是类型T的子类型。<br>通俗表述: 所有引用基类(父类)的地方必须能透明地使用其子类的对象。也就是说子类可以扩展父类的功能，但不能改变父类原有的功能。它包含以下4层含义:<br>子类可以实现父类的抽象方法，但不能覆盖父类的非抽象方法。 子类中可以增加自己特有的方法。 当子类的方法重载父类的方法时，方法的前置条件(即方法的形参)要比父类方法的输入参数更宽松。 当子类的方法实现父类的抽象方法时，方法的后置条件(即方法的返回值)要比父类更严格。<br><br>迪米特法则建议“只和朋友说话，不要陌生人说话”，以此来减少类之间的耦合。<br><br>开闭原则要求你的代码对扩展开放，对修改关闭。这个意思就是说，如果你想增加一个新的功能，你可以很容易的在不改变已测试过的代码的前提下增加新的代码。有好几个设计模式是基于开闭原则的，如策略模式，如果你需要一个新的策略，只需要实现接口，增加配置，不需要改变核心逻辑。一个正在工作的例子是 Collections.sort() 方法，这就是基于策略模式，遵循开闭原则的，你不需为新的对象修改 sort() 方法，你需要做的仅仅是实现你自己的 Comparator 接口。<br><br>享元模式通过共享对象来避免创建太多的对象。为了使用享元模式，你需要确保你的对象是不可变的，这样你才能安全的共享。JDK 中 String 池、Integer 池以及 Long 池都是很好的使用了享元模式的例子。<br>]]></description><link>01、通用基础\05、软件设计基础\03、软件设计原则.html</link><guid isPermaLink="false">01、通用基础/05、软件设计基础/03、软件设计原则.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:45 GMT</pubDate></item><item><title><![CDATA[04、设计模式]]></title><description><![CDATA[ 
 <br><br>
<br>创建型模式
  用于描述“怎样创建对象”，它的主要特点是“将对象的创建与使用分离”。GoF（四人组）书中提供了单例、原型、工厂方法、抽象工厂、建造者等 5 种创建型模式。<br>

<br>结构型模式
  用于描述如何将类或对象按某种布局组成更大的结构，GoF（四人组）书中提供了代理、适配器、桥接、装饰、外观、享元、组合等 7 种结构型模式。<br>

<br>行为型模式
  用于描述类或对象之间怎样相互协作共同完成单个对象无法单独完成的任务，以及怎样分配职责。GoF（四人组）书中提供了模板方法、策略、命令、职责链、状态、观察者、中介者、迭代器、访问者、备忘录、解释器等 11 种行为型模式。
<br><br><br>单例设计模式分类两种：<br>​ 饿汉式：类加载就会导致该单实例对象被创建<br>​ 懒汉式：类加载不会导致该单实例对象被创建，而是首次使用该对象时才会创建<br><br>/**
 * 饿汉式
 *      静态变量创建类的对象
 */
public class Singleton {
    //私有构造方法
    private Singleton() {}

    //在成员位置创建该类的对象
    private static Singleton instance = new Singleton();

    //对外提供静态方法获取该对象
    public static Singleton getInstance() {
        return instance;
    }
}
复制<br>说明：<br>
​该方式在成员位置声明 Singleton 类型的静态变量，并创建 Singleton 类的对象 instance。<br>
instance 对象是随着类的加载而创建的。<br>
如果该对象足够大的话，而一直没有使用就会造成内存的浪费。<br><br>/**
 * 恶汉式
 *      在静态代码块中创建该类对象
 */
public class Singleton {

    //私有构造方法
    private Singleton() {}

    //在成员位置创建该类的对象
    private static Singleton instance;

    static {
        instance = new Singleton();
    }

    //对外提供静态方法获取该对象
    public static Singleton getInstance() {
        return instance;
    }
}
复制<br>该方式在成员位置声明 Singleton 类型的静态变量，而对象的创建是在静态代码块中，也是对着类的加载而创建。所以和饿汉式的方式1基本上一样，当然该方式也存在内存浪费问题。<br><br>/**
 * 懒汉式
 *  线程不安全
 */
public class Singleton {
    //私有构造方法
    private Singleton() {}

    //在成员位置创建该类的对象
    private static Singleton instance;

    //对外提供静态方法获取该对象
    public static Singleton getInstance() {

        if(instance == null) {
            instance = new Singleton();
        }
        return instance;
    }
}
复制<br>/**
 * 懒汉式
 *  线程安全
 */
public class Singleton {
    //私有构造方法
    private Singleton() {}

    //在成员位置创建该类的对象
    private static Singleton instance;

    //对外提供静态方法获取该对象
    public static synchronized Singleton getInstance() {

        if(instance == null) {
            instance = new Singleton();
        }
        return instance;
    }
}
复制<br><br>双重检查锁模式是一种非常好的单例实现模式，解决了单例、性能、线程安全问题，上面的双重检测锁模式看上去完美无缺，其实是存在问题，在多线程的情况下，可能会出现空指针问题，出现问题的原因是JVM在实例化对象的时候会进行优化和指令重排序操作。<br>要解决双重检查锁模式带来空指针异常的问题，只需要使用&nbsp;volatile&nbsp;关键字,&nbsp;volatile&nbsp;关键字可以保证可见性和有序性。<br>/**
 * 双重检查方式
 */
public class Singleton {

    //私有构造方法
    private Singleton() {}

    private static volatile Singleton instance;

   //对外提供静态方法获取该对象
    public static Singleton getInstance() {
        //第一次判断，如果instance不为null，不进入抢锁阶段，直接返回实际
        if(instance == null) {
            synchronized (Singleton.class) {
                //抢到锁之后再次判断是否为空
                if(instance == null) {
                    instance = new Singleton();
                }
            }
        }
        return instance;
    }
}
复制<br>添加&nbsp;volatile&nbsp;关键字之后的双重检查锁模式是一种比较好的单例实现模式，能够保证在多线程的情况下线程安全也不会有性能问题。<br><br>/**
 * 静态内部类方式
 */
public class Singleton {

    //私有构造方法
    private Singleton() {}

    private static class SingletonHolder {
        private static final Singleton INSTANCE = new Singleton();
    }

    //对外提供静态方法获取该对象
    public static Singleton getInstance() {
        return SingletonHolder.INSTANCE;
    }
}
复制<br><br>单例模式是极力推荐的单例实现模式，因为枚举类型是线程安全的，并且只会装载一次，设计者充分的利用了枚举的这个特性来实现单例模式，枚举的写法非常简单，而且枚举类型是所用单例实现中唯一一种不会被破坏的单例实现模式。<br>/**
 * 枚举方式
 */
public enum Singleton {
    INSTANCE;
}
复制<br><br>破坏单例模式：<br>使上面定义的单例类（Singleton）可以创建多个对象，枚举方式除外。有两种方式，分别是序列化和反射。<br><br>public class Singleton implements Serializable {

    //私有构造方法
    private Singleton() {}

    private static class SingletonHolder {
        private static final Singleton INSTANCE = new Singleton();
    }

    //对外提供静态方法获取该对象
    public static Singleton getInstance() {
        return SingletonHolder.INSTANCE;
    }
}
复制<br>public class Test {
    public static void main(String[] args) throws Exception {
        //往文件中写对象
        //writeObject2File();
        //从文件中读取对象
        Singleton s1 = readObjectFromFile();
        Singleton s2 = readObjectFromFile();

        //判断两个反序列化后的对象是否是同一个对象
        System.out.println(s1 == s2);
    }

    private static Singleton readObjectFromFile() throws Exception {
        //创建对象输入流对象
        ObjectInputStream ois = new ObjectInputStream(new FileInputStream("C:\\Users\\Think\\Desktop\\a.txt"));
        //第一个读取Singleton对象
        Singleton instance = (Singleton) ois.readObject();

        return instance;
    }

    public static void writeObject2File() throws Exception {
        //获取Singleton类的对象
        Singleton instance = Singleton.getInstance();
        //创建对象输出流
        ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream("C:\\Users\\Think\\Desktop\\a.txt"));
        //将instance对象写出到文件中
        oos.writeObject(instance);
    }
}
复制<br>上面代码运行结果是false，表明序列化和反序列化已经破坏了单例设计模式。<br><br>public class Singleton {

    //私有构造方法
    private Singleton() {}
    
    private static volatile Singleton instance;

    //对外提供静态方法获取该对象
    public static Singleton getInstance() {

        if(instance != null) {
            return instance;
        }

        synchronized (Singleton.class) {
            if(instance != null) {
                return instance;
            }
            instance = new Singleton();
            return instance;
        }
    }
}
复制<br>public class Test {
    public static void main(String[] args) throws Exception {
        //获取Singleton类的字节码对象
        Class clazz = Singleton.class;
        //获取Singleton类的私有无参构造方法对象
        Constructor constructor = clazz.getDeclaredConstructor();
        //取消访问检查
        constructor.setAccessible(true);

        //创建Singleton类的对象s1
        Singleton s1 = (Singleton) constructor.newInstance();
        //创建Singleton类的对象s2
        Singleton s2 = (Singleton) constructor.newInstance();

        //判断通过反射创建的两个Singleton对象是否是同一个对象
        System.out.println(s1 == s2);
    }
}
复制<br>上面代码运行结果是false，表明序列化和反序列化已经破坏了单例设计模式<br>
注意：枚举方式不会出现这两个问题。
<br><br>序列化、反序列方式破坏单例模式的解决方法<br>public class Singleton implements Serializable {

    //私有构造方法
    private Singleton() {}

    private static class SingletonHolder {
        private static final Singleton INSTANCE = new Singleton();
    }

    //对外提供静态方法获取该对象
    public static Singleton getInstance() {
        return SingletonHolder.INSTANCE;
    }
    
    /**
     * 下面是为了解决序列化反序列化破解单例模式
     */
    private Object readResolve() {
        return SingletonHolder.INSTANCE;
    }
}
复制<br>源码解析<br>ObjectInputStream 类<br>public final Object readObject() throws IOException, ClassNotFoundException{
    ...
    // if nested read, passHandle contains handle of enclosing object
    int outerHandle = passHandle;
    try {
        Object obj = readObject0(false);//重点查看readObject0方法
    .....
}
    
private Object readObject0(boolean unshared) throws IOException {
    ...
    try {
        switch (tc) {
            ...
            case TC_OBJECT:
                return checkResolve(readOrdinaryObject(unshared));//重点查看readOrdinaryObject方法
            ...
        }
    } finally {
        depth--;
        bin.setBlockDataMode(oldMode);
    }    
}
    
private Object readOrdinaryObject(boolean unshared) throws IOException {
    ...
    //isInstantiable 返回true，执行 desc.newInstance()，通过反射创建新的单例类，
    obj = desc.isInstantiable() ? desc.newInstance() : null; 
    ...
    // 在Singleton类中添加 readResolve 方法后 desc.hasReadResolveMethod() 方法执行结果为true
    if (obj != null &amp;&amp; handles.lookupException(passHandle) == null &amp;&amp; desc.hasReadResolveMethod()) {
        // 通过反射调用 Singleton 类中的 readResolve 方法，将返回值赋值给rep变量
        // 这样多次调用ObjectInputStream类中的readObject方法，继而就会调用我们定义的readResolve方法，所以返回的是同一个对象。
        Object rep = desc.invokeReadResolve(obj);
         ...
    }
    return obj;
}
复制<br>反射方式破解单例的解决方法<br>public class Singleton {

    //私有构造方法
    private Singleton() {
        /*
           反射破解单例模式需要添加的代码
        */
        if(instance != null) {
            throw new RuntimeException();
        }
    }
    
    private static volatile Singleton instance;

    //对外提供静态方法获取该对象
    public static Singleton getInstance() {

        if(instance != null) {
            return instance;
        }

        synchronized (Singleton.class) {
            if(instance != null) {
                return instance;
            }
            instance = new Singleton();
            return instance;
        }
    }
}
复制<br>这种方式比较好理解。当通过反射方式调用构造方法进行创建创建时，直接抛异常。不运行此中操作。<br><br>通过源代码查看使用的是哪儿种单例模式<br>public class Runtime {
    private static Runtime currentRuntime = new Runtime();

    /**
     * Returns the runtime object associated with the current Java application.
     * Most of the methods of class &lt;code&gt;Runtime&lt;/code&gt; are instance
     * methods and must be invoked with respect to the current runtime object.
     *
     * @return  the &lt;code&gt;Runtime&lt;/code&gt; object associated with the current
     *          Java application.
     */
    public static Runtime getRuntime() {
        return currentRuntime;
    }

    /** Don't let anyone else instantiate this class */
    private Runtime() {}
    ...
}
复制<br> 从上面源代码中可以看出Runtime类使用的是恶汉式（静态属性）方式来实现单例模式的。<br>使用 Runtime 类中的方法<br>public class RuntimeDemo {
    public static void main(String[] args) throws IOException {
        //获取Runtime类对象
        Runtime runtime = Runtime.getRuntime();

        //返回 Java 虚拟机中的内存总量。
        System.out.println(runtime.totalMemory());
        //返回 Java 虚拟机试图使用的最大内存量。
        System.out.println(runtime.maxMemory());

        //创建一个新的进程执行指定的字符串命令，返回进程对象
        Process process = runtime.exec("ipconfig");
        //获取命令执行后的结果，通过输入流获取
        InputStream inputStream = process.getInputStream();
        byte[] arr = new byte[1024 * 1024* 100];
        int b = inputStream.read(arr);
        System.out.println(new String(arr,0,b,"gbk"));
    }
}
复制<br><br>在java中，万物皆对象，这些对象都需要创建，如果创建的时候直接new该对象，就会对该对象耦合严重，假如我们要更换对象，所有new对象的地方都需要修改一遍，这显然违背了软件设计的开闭原则。如果我们使用工厂来生产对象，我们就只和工厂打交道就可以了，彻底和对象解耦，如果要更换对象，直接在工厂里更换该对象即可，达到了与对象解耦的目的；所以说，工厂模式最大的优点就是：解耦。<br>
<br>简单工厂模式（不属于GOF的23种经典设计模式）
<br>工厂方法模式
<br>抽象工厂模式
<br><br>public class SimpleCoffeeFactory {

    public Coffee createCoffee(String type) {
        Coffee coffee = null;
        if("americano".equals(type)) {
            coffee = new AmericanoCoffee();
        } else if("latte".equals(type)) {
            coffee = new LatteCoffee();
        }
        return coffee;
    }
}
复制<br>工厂（factory）处理创建对象的细节，一旦有了SimpleCoffeeFactory，CoffeeStore类中的orderCoffee()就变成此对象的客户，后期如果需要Coffee对象直接从工厂中获取即可。这样也就解除了和Coffee实现类的耦合，同时又产生了新的耦合，CoffeeStore对象和SimpleCoffeeFactory工厂对象的耦合，工厂对象和商品对象的耦合。<br>后期如果再加新品种的咖啡，我们势必要需求修改 SimpleCoffeeFactory 的代码，违反了开闭原则。工厂类的客户端可能有很多，比如创建美团外卖等，这样只需要修改工厂类的代码，省去其他的修改操作。<br><br>简单工厂不是一种设计模式，反而比较像是一种编程习惯。<br><br><br><br><br>结构型模式描述如何将类或对象按某种布局组成更大的结构。它分为类结构型模式和对象结构型模式，前者采用继承机制来组织接口和类，后者釆用组合或聚合来组合对象。<br>由于组合关系或聚合关系比继承关系耦合度低，满足“合成复用原则”，所以对象结构型模式比类结构型模式具有更大的灵活性。<br>结构型模式分为以下 7 种：<br>
<br>代理模式
<br>适配器模式
<br>装饰者模式
<br>桥接模式
<br>外观模式
<br>组合模式
<br>享元模式
<br><br><br><br><br><br><br><br><br>行为型模式用于描述程序在运行时复杂的流程控制，即描述多个类或对象之间怎样相互协作共同完成单个对象都无法单独完成的任务，它涉及算法与对象间职责的分配。<br>行为型模式分为类行为模式和对象行为模式，前者采用继承机制来在类间分派行为，后者采用组合或聚合在对象间分配行为。由于组合关系或聚合关系比继承关系耦合度低，满足“合成复用原则”，所以对象行为模式比类行为模式具有更大的灵活性。<br>行为型模式分为：<br>
<br>模板方法模式
<br>策略模式
<br>命令模式
<br>职责链模式
<br>状态模式
<br>观察者模式
<br>中介者模式
<br>迭代器模式
<br>访问者模式
<br>备忘录模式
<br>解释器模式
<br>以上 11 种行为型模式，除了模板方法模式和解释器模式是类行为型模式，其他的全部属于对象行为型模式。<br><br><br><br><br><br><br><br><br><br><br>]]></description><link>01、通用基础\05、软件设计基础\04、设计模式.html</link><guid isPermaLink="false">01、通用基础/05、软件设计基础/04、设计模式.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:45 GMT</pubDate></item><item><title><![CDATA[05、系统开发]]></title><description><![CDATA[ 
 ]]></description><link>01、通用基础\05、软件设计基础\05、系统开发.html</link><guid isPermaLink="false">01、通用基础/05、软件设计基础/05、系统开发.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:45 GMT</pubDate></item><item><title><![CDATA[06、立项到软件落地文档]]></title><description><![CDATA[ 
 ]]></description><link>01、通用基础\05、软件设计基础\06、立项到软件落地文档.html</link><guid isPermaLink="false">01、通用基础/05、软件设计基础/06、立项到软件落地文档.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:45 GMT</pubDate></item><item><title><![CDATA[01、编程语言对比]]></title><description><![CDATA[ 
 ]]></description><link>02、多编程语言\01、编程语言基础\01、编程语言对比.html</link><guid isPermaLink="false">02、多编程语言/01、编程语言基础/01、编程语言对比.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:45 GMT</pubDate></item><item><title><![CDATA[02、语言通用]]></title><description><![CDATA[ 
 <br><br>快速上手新的语言：<br>1、变量与赋值<br>
变量用于存储数据，而赋值是将数据存储到变量中的基本操作。<br>2、数据类型：<br>
基本数据类型，复杂数据类型<br>3、运算符<br>
加法、减法、乘法、除法等基本数学运算符<br>4、控制流结构<br>
条件语句（if-else）、循环语句（for、while）等结构在不同语言中有相似的用法。<br>5、函数与过程<br>
函数或过程是一组执行特定任务的代码块，几乎所有编程语言都支持这种组织代码的方式<br>6、数据结构（数组与集合）<br>
多个元素的集合，以及对这些元素进行操作的方法，在很多语言中都有对应的概念。<br>7、面向对象<br>
类、对象、继承、封装、多态等概念在许多编程语言中都有应用<br>8、异常处理<br>
处理程序运行时可能发生的错误或异常情况的机制，大多数编程语言都提供了相关的工具<br>9、文件操作<br>
读写文件、创建目录等文件操作也是各种编程语言通用的需求。<br>10、网络编程<br>
连接、发送和接收数据等网络相关的操作在很多编程语言中都有相似的实现。]]></description><link>02、多编程语言\01、编程语言基础\02、语言通用.html</link><guid isPermaLink="false">02、多编程语言/01、编程语言基础/02、语言通用.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:45 GMT</pubDate></item><item><title><![CDATA[00、★ Go语言基础 ★]]></title><description><![CDATA[ 
 <br><br><a class="internal-link" data-href="01、走进Go.md" href="\02、多编程语言\03、go语言\01、go语言基础\01、走进go.html" target="_self" rel="noopener">01、走进Go</a><br><a class="internal-link" data-href="02、Go 基础语法.md" href="\02、多编程语言\03、go语言\01、go语言基础\02、go-基础语法.html" target="_self" rel="noopener">02、Go 基础语法</a>]]></description><link>02、多编程语言\03、go语言\01、go语言基础\00、★-go语言基础-★.html</link><guid isPermaLink="false">02、多编程语言/03、Go语言/01、Go语言基础/00、★ Go语言基础 ★.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:43 GMT</pubDate></item><item><title><![CDATA[01、走进Go]]></title><description><![CDATA[ 
 <br><br><br>
<br>计算机硬件技术更新频繁，性能提高很快。目前主流的编程语言发展明显落后于硬件，不能合理利用多核多 CPU 的优势提升软件系统性能。
<br>软件系统复杂度越来越高，维护成本越来越高，目前缺乏一个足够简洁高效的编程语言。
<br>企业运行维护很多 c/c++的项目，c/c++程序运行速度虽然很快，但是编译速度确很慢，同时还存在内存泄漏的一系列的困扰需要解决。
<br><br>2007 年，谷歌工程师 Rob Pike, Ken Thompson 和 Robert Grisemer 开始设计一门全新的语言，这是 Go 语言的最初原型。<br>
2009 年 11 月，Google 将 Go 语言以开放源代码的方式向全球发布。<br>
2015 年 8 月，Go 1.5 版发布，本次更新中移除了"最后残余的 c 代码"<br>
2017 年 2 月, Go 语言 Go 1.8 版发布。<br>
2017 年 8 月，Go 语言 Go 1.9 版发布。<br>
2018 年 2 月，Go 语言 Go 1.10 版发布。<br>
2018 年 8 月，Go 语言 Go 1.11 版发布。<br>
2019 年 2 月，Go 语言 Go 1.12 版发布。<br>
2019 年 9 月，Go 语言 Go 1.13 版发布。<br>
2020 年 2 月，Go 语言 Go 1.14 版发布。<br>
2020 年 8 月，Go 语言 Go 1.15 版发布。<br>
.... 一直迭代<br><br>金花鼠 Gordon：<br>
<img alt="assets/101、Go语言基础2/img-20240111_204742.png" src="\02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240111_204742.png" style="width: 107px; max-width: 100%;"><br><br><br>
<br>Go 语言的官网为: <a data-tooltip-position="top" aria-label="https://go.dev/dl/" rel="noopener" class="external-link" href="https://go.dev/dl/" target="_blank">Go 官网</a> ，无法访问，需要翻墙。
<br>SDK 下载地址 : Golang 中文社区： <a data-tooltip-position="top" aria-label="https://studygolang.com/dl" rel="noopener" class="external-link" href="https://studygolang.com/dl" target="_blank">中文社区</a> ，有推荐稳定版本。
<br><img src="\02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240112_202244.png"><br><img src="\02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240112_202326.png"><br>Window 里面有一个 amd 和 arm 容易选错。<br>amd64 表示 64 位 x 86 架构，适用于大多数现代的 64 位 Windows 系统。<br>
arm64 表示 64 位 ARM 架构，适用于支持 ARM 架构的 Windows 系统。ARM 架构通常用于移动设备和嵌入式系统。<br><br>1）安装目录<br>
SDK 安装目录建议，把原目录中的 C 盘换成其他盘即可：<br>
D:\Program Files\Go<br>
请注意：安装路径不要有中文或者特殊符号如空格等<br>2）环境变量<br>
如果使用 msi 文件直接安装就能使用，如果是 zip 解压后需要安装环境变量。<br>
配置 path 环境变量：<br>
<img alt="assets/101、Go语言基础2/img-20240112_203627.png" src="\02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240112_203627.png" style="width: 425px; max-width: 100%;"><br>其他变量：<br>3）查看是否安装成功<br>go version 
复制<br><img src="\02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240112_203318.png"><br>go env 
复制<br><img src="\02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240112_211007.png"><br>go env&nbsp;是 Go 编程语言中的一个命令，用于显示与 Go 环境相关的配置信息。它提供了有关 Go 安装的各种路径、环境变量以及其他相关的配置选项。<br>当你在命令行中运行&nbsp;go env&nbsp;时，它会输出一系列键值对，每个键值对代表一个特定的环境变量或配置选项。以下是一些常见的&nbsp;go env&nbsp;输出项及其含义：<br>
<br>GOROOT：Go 根目录的路径，即 Go SDK 的安装路径。
<br>GOPATH：Go 工作区的路径，用于存放项目源代码和依赖包。
<br>GOBIN：Go 可执行文件的路径，包括编译后的可执行文件和安装的第三方工具。
<br>GOOS：目标操作系统的名称，例如 windows、linux 或 darwin。
<br>GOARCH：目标处理器架构的名称，例如 amd 64、386 或 arm。
<br>GOVERSION：安装的 Go 版本号。
<br>GOMOD：当前模块的 go. Mod 文件路径（如果你正在使用 Go 模块化开发）。
<br>GOPRIVATE：私有源代码仓库的列表，用于访问私有仓库的认证和权限。
<br>GOROOT_FINAL：安装的 Go 根目录的最终路径（用于在安装过程中更改根目录的情况）。
<br>通过运行&nbsp;go env&nbsp;命令，你可以查看这些配置选项的值，以便了解当前 Go 环境的设置和配置。这对于调试和排查与 Go 相关的问题，以及确保正确设置了相关的环境变量和路径非常有用。<br>4）目录解释<br>├── api\                    # 包含 Go 语言的 API 文档（HTML 格式）
│   └── ...                 # API 文档文件
├── bin\                    # 包含 Go 工具链的可执行文件
│   ├── go.exe/go           # Go 编译器和运行时
│   ├── gofmt.exe/gofmt     # Go 格式化工具
├── pkg\                    # 包含已编译的包对象文件（.a 文件）
│   ├── include\            # 包含 Go 头文件，用于与 C 和 C++ 代码进行交互
│   │   └── ...             # 预编译的包对象文件
│   └── ...                 # 其他平台和架构的预编译包对象文件
├── src\                    # 包含 Go 标准库和其他第三方包的源代码
└── VERSION                 # 当前 Go SDK 的版本信息
复制<br><br><br>1、Goland（JetBrains），旨在为 Go 开发者提供的一个符合人体工程学的商业 IDE；<br>2、LiteIDE，一款专门针对 Go 开发的集成开发环境；<br>3、VSCode，一个跨平台开源代码编辑器；<br>Goland 设置<br>
<img alt="assets/101、Go语言基础2/img-20240113_102210.png" src="\02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240113_102210.png" style="width: 500px; max-width: 100%;"><br><br>1）使用 dos：<br>在工作目录下CMD进入终端-输入命令

mkdir hello  新建项目文件
cd hello     进入项目文件
go mod init hello  初始化项目工程，mod是依赖管理的
dir  查看目录

echo. &gt; main.txt
复制<br><img alt="assets/101、Go语言基础2/img-20240112_210121.png" src="\02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240112_210121.png" style="width: 500px; max-width: 100%;"><br>2）写入代码<br>// package 定义包名 main 包名
package main

// import 引用库 fmt 库名
import "fmt"

// func 定义函数 main 函数名
func main() {
	// fmt 包名 . 调用 Print 函数,并且输出定义的字符串
	fmt.Print("Hello Golang !!")
}
复制<br>3）运行命令<br>go run main.go
复制<br><img alt="assets/101、Go语言基础2/img-20240112_210518.png" src="\02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240112_210518.png" style="width: 450px; max-width: 100%;"><br><br><img src="\02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240111_213502.png"><br><br>Go 语言提供了大量的标准库，因此 google 公司也为这些标准库提供了相应的 API 文档，用于告诉开发者如何使用这些标准库，以及标准库包含的方法。官方位置： <a rel="noopener" class="external-link" href="https://golang.org" target="_blank">https://golang.org</a><br>Golang 中文网在线标准库文档: <a rel="noopener" class="external-link" href="https://studygolang.com/pkgdoc" target="_blank">https://studygolang.com/pkgdoc</a><br>函数对应的源码查看：src 目录]]></description><link>02、多编程语言\03、go语言\01、go语言基础\01、走进go.html</link><guid isPermaLink="false">02、多编程语言/03、Go语言/01、Go语言基础/01、走进Go.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:45 GMT</pubDate><enclosure url="02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240111_204742.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240111_204742.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[02、Go 基础语法]]></title><description><![CDATA[ 
 <br><br><br>Go 语言的注释主要分成两类，分别是单行注释和多行注释。<br>
<br>单行注释简称行注释，是最常见的注释形式，可以在任何地方使用以 // 开头的单行注释；
<br>多行注释简称块注释，以 /* 开头，并以 */ 结尾，且不可以嵌套使用，多行注释一般用于包的文档描述或注释成块的代码片段。
<br>单行注释的格式如下所示<br>//单行注释
复制<br>多行注释的格式如下所示<br>/*
第一行注释
第二行注释
...
*/
复制<br>每一个包都应该有相关注释，在使用 package 语句声明包名之前添加相应的注释，用来对包的功能及作用进行简要说明。<br>同时，在 package 语句之前的注释内容将被默认认为是这个包的文档说明。一个包可以分散在多个文件中，但是只需要对其中一个进行注释说明即可。<br><br><br>关键字即是被 Go 语言赋予了特殊含义的单词，也可以称为保留字。<br>
Go 中一共有 25 个关键字：<br><br>之所以刻意地将 Go 语言中的关键字保持的这么少，是为了简化在编译过程中的代码解析。<br>
和其它语言一样，关键字不能够作标识符使用。：<br><br><br>标识符是指 Go 语言对各种变量、方法、函数等命名时使用的字符序列，标识符由若干个字母、下划线 _、和数字组成，且第一个字符必须是字母。<br>下划线 `` 是一个特殊的标识符，称为空白标识符_<br>标识符的命名需要遵守以下规则：<br>
<br>由 26 个英文字母、0~9、_ 组成；
<br>不能以数字开头，例如 var 1num int 是错误的；
<br>Go 语言中严格区分大小写；
<br>标识符不能包含空格；
<br>不能以系统保留关键字作为标识符，比如 break，if 等等。
<br>命名标识符时还需要注意以下几点：<br>
<br>标识符的命名要尽量采取简短且有意义；
<br>不能和标准库中的包名重复；
<br>为变量、函数、常量命名时采用驼峰命名法，例如 stuName、getVal；
<br>在 Go 语言中还存在着一些特殊的标识符，叫做预定义标识符，如下表所示：<br><br><br>以下 3 个不确定是否是：<br><br><br><br>
Go 语言是静态类型语言，因此变量（variable）是有明确类型的，编译器也会检查变量类型的正确性。
<br>从计算机系统的角度来讲，变量就是一段或者多段内存，用于存储数据。<br><br>var 变量名 变量类型

//变量声明以关键字 var 开头，变量类型后置，行尾无须分号。
//例子：声明了一个名为age的变量，类型为int
//变量的命名规则遵循驼峰命名法，即首个单词小写，每个新单词的首字母大写，例如： startDate
var age int
var startDate string

复制<br>
如果你学过 C 语言，就会体会到这样声明的好处，比如 C 语言这样声明：int a, b ，那么只有 a 是指针，b 不是，这样会使人迷惑，如果想要两个变量都为指针，需要这样定义：`int a,*b`。
在 go 语言中，我们使用这样的声明方式：var a,b *int，就可以轻松的将 a，b 都声明为指针。
<br><br>每行都用 var 声明变量比较烦琐？Go 语言提供了批量声明的方式<br>var (
    a int
    b string
    c []float32
)

//%d 整数占位符，%s 字符串占位符， %f 浮点数占位符(默认精度为6)
fmt.Printf("%d,%s,%f",a,b,c)//0,,[]
复制<br><br><br>这种声明变量的方式，并没有指明类型，Go 语言中，在编译时会自动推导类型<br>//设置游戏中角色的初始等级为1，但是需要赋值
var level = 1;
//不能写成下面，因为自动加;所以认为你第一个变量没有赋值，没办法类型推导
//var level  
//level= 1

//我们可以使用 %T 进行类型输出。
fmt.Printf("类型为：%T", level)  //类型为：int
复制<br><br>可以省略 var 关键字，这样写起来更加便捷。<br>
简短变量声明被广泛用于大部分的局部变量的声明和初始化，var 形式的声明语句往往用于需要显式指定变量类型的地方。<br>但是有以下要求：<br>
<br>定义变量，同时显式初始化
<br>不能提供数据类型
<br>只能用在函数内部
<br>package main  
import "fmt"  
  
// 不在局部方法内，不能使用简短格式  
// aa :=1  
func main() {  
    // i是变量名 1 是值（或者表达式）不指明类型，直接赋值，Go会自动推导类型  
    aa := 1  
    fmt.Println(aa)          //1  
    fmt.Printf("类型为：%T", aa) //类型为：int  
}
复制<br><br>//创建了一个游戏角色 初始等级为1，标准声明
var level int = 1

//短变量声明 
// level := 1
// level := 1再次声明并赋值,会报错
// no new variables on left side of := （左边的变量已经被声明了，不能重复声明)
level2 := 1  

fmt.Printf("类型为：%T", level) //类型为：int  
fmt.Printf("类型为：%T", level2) //类型为：int
复制<br>以上对同一变量重复声明报错，但是有特例：<br>❶  特例 1：获取到新的变量<br>比如：net.Dial 提供按指定协议和地址发起网络连接，这个函数有两个返回值，一个是 连接对象（conn），一个是 `错误对象（err）<br>正常的写法：<br>package main  
  
import (  
    "fmt"  
    "net")  
  
func main() {  
    var conn net.Conn  
    var err error  
    //net.Dial 是 Go 语言标准库中的一个函数，位于 net 包中。它用于建立与指定网络地址的连接。  
    //TCP 连接，"127.0.0.1:8080" 是远程主机的 IP 地址和端口号。  
    conn, err = net.Dial("tcp", "127.0.0.1:8080")  
    fmt.Println(conn) //无连接，&lt;nil&gt;  
    fmt.Println(err)  //链接失败，dial tcp 127.0.0.1:8080: connectex: No connection could be made because the target machine actively refused it.  
}
复制<br>短变量的写法：<br>package main

import (
	"fmt"
	"net"
)

func main() {  
    conn, err := net.Dial("tcp", "127.0.0.1:8080")  
    conn1, err := net.Dial("tcp", "127.0.0.1:8080")  //相当于一个新链接
    fmt.Println(conn) //&lt;nil&gt;  
    fmt.Println(conn1) //&lt;nil&gt;  
    fmt.Println(err) //dial tcp 127.0.0.1:8080: connectex: No connection could be made because the target machine actively refused it.  
}
复制<br>在多个短变量声明和赋值中，至少有一个新声明的变量出现在左值中，即便其他变量名可能是重复声明的，编译器也不会报错<br>❷ 特例 2：重写全局<br><br><br><br>
变量交换，比如 a=100，b=200，交换之后 a=200，b=100
<br>常用第三变量赋值，或者位运算，但是 Go 里面可以这样：<br>package main

import "fmt"

func main() {
	a := 100
	b := 200
	b,a = a,b
	fmt.Printf("a=%d,b=%d",a,b)
}
复制<br><br>使用 多重赋值 时，如果 不需要在左值中接受变量，可以使用匿名变量<br>    //conn, err := net.Dial("tcp", "127.0.0.1:8080")
    //如果不想接收err的值，那么可以使用_表示，这就是匿名变量
	conn, _ := net.Dial("tcp", "127.0.0.1:8080")
	
	//匿名变量可以重复声明
	conn1, _ := net.Dial("tcp", "127.0.0.1:8080")
	
	// 匿名变量不可以直接开头
	// _ :=1
	
	fmt.Println(conn)
	fmt.Println(conn1)
复制<br>
匿名变量以 _ 下划线表示
匿名变量不占用命名空间，也不会分配内存。匿名变量可以重复声明使用
_ 本身就是一个特殊的标识符，被称为空白标识符。它可以像其他标识符那样用于变量的声明或赋值（任何类型都可以赋值给它），但任何赋给这个标识符的值都将被抛弃，因此这些值不能在后续的代码中使用，也不可以使用这个标识符作为变量对其它变量进行赋值或运算。
<br><br>
一个变量（常量、类型或函数）在程序中都有一定的作用范围，称之为 作用域。
<br>了解变量的作用域对我们学习 Go 语言来说是比较重要的，因为 Go语言(静态语言)会在编译时检查每个变量是否使用过，一旦出现未使用的变量，就会报编译错误。<br>如果不能理解变量的作用域，就有可能会带来一些不明所以的编译错误。<br>根据变量定义位置的不同，可以分为以下三个类型：<br>
<br>函数内定义的变量称为局部变量
<br>函数外定义的变量称为全局变量
<br>函数定义中的变量称为形式参数
<br><br>在函数体外声明的变量称之为 全局变量，全局变量只需要在 一个源文件中定义，就可以在所有源文件中使用，当然，不包含这个全局变量的源文件需要使用“import”关键字引入全局变量所在的源文件之后才能使用这个全局变量。<br>全局变量声明 必须以 var 关键字开头，如果想要在外部包中使用全局变量的 首字母必须大写。<br>package main
import "fmt"
//声明全局变量
var c int
func main() {
    //声明局部变量
    var a, b int
    //初始化参数
    a = 3
    b = 4
    c = a + b
    fmt.Printf("a = %d, b = %d, c = %d\n", a, b, c)
}
复制<br>Go 语言程序中全局变量与局部变量名称可以相同，但是函数体内的局部变量会被优先考虑。<br>package main
import "fmt"
//声明全局变量
var bb float32 = 3.14
func main() {
	bb := 3
	fmt.Println(bb)
}
//执行结果 3
复制<br><br>在函数体内声明的变量称之为 局部变量，它们的作用域 只在函数体内，函数的参数和返回值变量都属于局部变量。<br>局部变量不是一直存在的，它只在定义它的函数被调用后存在，函数调用结束后这个局部变量就会被销毁。<br>package main
import (
    "fmt"
)
func main() {
    //声明局部变量 a 和 b 并赋值
    var a int = 3
    var b int = 4
    //声明局部变量 c 并计算 a 和 b 的和
    c := a + b
    fmt.Printf("a = %d, b = %d, c = %d\n", a, b, c)
}
复制<br><br>在定义函数时函数名后面括号中的变量叫做 形式参数（简称形参）。形式参数只在函数调用时才会生效，函数调用结束后就会被销毁，在函数未被调用时，函数的形参 并不占用实际的存储单元，也没有实际值。<br>形式参数会作为 函数的局部变量来使用。<br>package main
import (
    "fmt"
)
//全局变量 a
var a int = 13
func main() {
    //局部变量 a 和 b
    var a int = 3
    var b int = 4
    fmt.Printf("main() 函数中 a = %d\n", a)
    fmt.Printf("main() 函数中 b = %d\n", b)
    c := sum(a, b)
    fmt.Printf("main() 函数中 c = %d\n", c)
}
func sum(a, b int) int {
    fmt.Printf("sum() 函数中 a = %d\n", a)
    fmt.Printf("sum() 函数中 b = %d\n", b)
    num := a + b
    return num
}
复制<br><br>
变量的生命周期指的是在程序运行期间变量有效存在的时间间隔。
<br>变量的生命周期与变量的作用域有不可分割的联系：<br>
<br>全局变量：它的生命周期和整个程序的运行周期是一致的；
<br>局部变量：它的生命周期则是动态的，从创建这个变量的声明语句开始，到这个变量不再被引用为止；
<br>形式参数和函数返回值：它们都属于局部变量，在函数被调用的时候创建，函数调用结束后被销毁。
<br>Go 的内存中应用了两种数据结构用于存放变量：<br>
<br>堆（heap）：堆是用于存放进程执行中被动态分配的内存段。它的大小并不固定，可动态扩张或缩减。当进程调用 malloc 等函数分配内存时，新分配的内存就被动态加入到堆上（堆被扩张）。当利用 free 等函数释放内存时，被释放的内存从堆中被剔除（堆被缩减）；
<br>栈 (stack)：栈又称堆栈，用来存放程序暂时创建的局部变量，也就是我们函数的大括号 { } 中定义的局部变量。
<br>栈是先进后出，往栈中放元素的过程，称为入栈，取元素的过程称为出栈。<br>栈可用于内存分配，栈的分配和回收速度非常快<br>在程序的编译阶段，编译器会根据实际情况 自动选择 在 栈 或者 堆 上分配局部变量的存储空间，不论使用 var 还是 new 关键字声明变量都不会影响编译器的选择。<br>var global *int
func f() {
    var x int
    x = 1
    global = &amp;x
}
func g() {
    y := new(int)
    *y = 1
}
复制<br>上述代码中，函数 f 里的变量 x 必须在堆上分配，因为它在函数退出后依然可以通过包一级的 global 变量找到，虽然它是在函数内部定义的。<br>用Go语言的术语说，这个局部变量 x 从函数 f 中逃逸了。<br>相反，当函数 g 返回时，变量 y 不再被使用，也就是说可以马上被回收的。因此，y 并没有从函数 g 中逃逸，编译器可以选择在栈上分配 *y 的存储空间，也可以选择在堆上分配，然后由 Go 语言的 GC（垃圾回收机制）回收这个变量的内存空间。<br><br>Go 语言中的常量使用关键字 const 定义，用于存储不会改变的数据，常量是在编译时被创建的，即使定义在函数内部也是如此，并且只能是 布尔型、数字型（整数型、浮点型和复数）和 字符串型。<br>由于编译时的限制，定义常量的表达式必须为能被编译器求值的常量表达式。<br>声明格式：<br>const name [type] = value
复制<br>例如：<br>const pi = 3.14159
复制<br>type 可以省略<br>和变量声明一样，可以批量声明多个常量：<br>const (
    e  = 2.7182818
    pi = 3.1415926
)
复制<br>
所有常量的运算都可以在编译期完成，这样不仅可以减少运行时的工作，也方便其他代码的编译优化，当操作数是常量时，一些运行时的错误也可以在编译时被发现，例如整数除零、字符串索引越界、任何导致无效浮点数的操作等。
<br>常量间的所有算术运算、逻辑运算和比较运算的结果也是常量，对常量的类型转换操作或以下函数调用都是返回常量结果：len、cap、real、imag、complex 和 unsafe. Sizeof。<br>因为它们的值是在编译期就确定的，因此常量可以是构成类型的一部分<br>如果是批量声明的常量，除了第一个外其它的常量右边的初始化表达式都可以省略，如果省略初始化表达式则表示使用前面常量的初始化表达式，对应的常量类型也是一样的。例如：<br>const (
    a = 1
    b
    c = 2
    d
)
fmt.Println(a, b, c, d) // "1 1 2 2"
复制<br><br>
常量声明可以使用 iota 常量生成器初始化，它用于生成一组以相似规则初始化的常量，但是不用每行都写一遍初始化表达式。
<br>在一个 const 声明语句中，在第一个声明的常量所在的行，iota 将会被置为 0，然后在每一个有常量声明的行加 1<br>比如，定义星期日到星期六，从 0-6<br>const (
    Sunday  = iota //0
    Monday
    Tuesday
    Wednesday
    Thursday
    Friday
    Saturday  //6
)
复制<br><br><br>
计算机中数据存储的最小单位为 bit（位），0 或者 1。<br>
字节 byte：计算机中数据的基本单元，1 字节=8 bit，数据在计算机中存储或者计算，至少为 1 个字节
<br>整型<br>
<br>Int（随系统，一般是占用 4 个字节）、int 8 (占一个字节)、int 16 (占两个字节)、int 32 (占 4 个字节)、int 64（占 8 个字节）
<br>Uint（无符号整数）、uint 8、uint 16、uint 32、uint 64、uintptr<br>
字符
<br>byte // uint8 的别名
<br>rune // int32 的别名 代表一个 Unicode 码<br>
浮点型
<br>Float 32、float 64
<br>Complex 64、complex 128<br>
布尔型
<br>Bool<br>
字符串
<br>String
<br>
有符号和无符号的区别：int 8 范围 -128-127，uint 8 范围：0-255
<br>当一个变量被声明之后，系统自动赋予它该类型的零值：<br>
int 为 0，float 为 0.0，bool 为 false，string 为空字符串，指针为 nil<br><br>Go 语言同时提供了有符号和无符号的整数类型：<br><img alt="assets/101、Go语言基础2/img-20240112_214047.png" src="\02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240112_214047.png" style="width: 500px; max-width: 100%;"><br>
<img alt="assets/101、Go语言基础2/img-20240112_214101.png" src="\02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240112_214101.png" style="width: 500px; max-width: 100%;"><br>
<br>有符号整型：int、int 8、int 64、int 32、int 64
<br>无符号整型：uint、uint 8、uint 64、uint 32、uint 64、uintptr
<br>
有符号整型范围：-2^(n-1) 到 2^(n-1)-1<br>
无符号整型范围: 0 到 2^n-1
<br>实际开发中由于编译器和计算机硬件的不同，int 和 uint 所能表示的整数大小会在 32 bit 或 64 bit 之间变化。<br>其他整数类型：<br>
<img alt="assets/101、Go语言基础2/img-20240112_214319.png" src="\02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240112_214319.png" style="width: 400px; max-width: 100%;"><br>用来表示 Unicode 字符的 rune 类型 和 int32 类型 是等价的，通常用于表示一个 Unicode 码点。<br>
这两个名称可以互换使用。同样，byte 和 uint8 也是等价类型，byte 类型一般用于强调数值是一个 原始的数据 而不是一个小的整数。<br>
无符号的整数类型 uintptr，它没有指定具体的 bit 大小但是足以容纳指针。Uintptr 类型只有在 底层编程 时才需要，特别是 Go 语言和 C 语言函数库或操作系统接口相交互的地方。
<br>在二进制传输、读写文件的结构描述时，为了保持文件的结构不会受到不同编译目标平台字节长度的影响，不要使用 int 和 uint<br><br>Go 语言支持两种浮点型数：<br>
算术规范由 IEEE 754 浮点数国际标准定义，该浮点数规范被所有现代的 CPU 支持
<br>
<br>float32 ： 范围约 1.4 e-45 到约 3.4 e-38
<br>float64 ：范围约 4.9 e-324 到约 1.8 e-308
<br>floatStr1 := 3.2
//保留小数点位数
fmt.Printf("%.2f\n", floatStr1) //结果：3.20
复制<br>通常应该优先使用 float 64 类型，因为 float 32 类型的累计计算误差很容易扩散，并且 float 32 能精确表示的正整数并不是很大。<br>    var f float32 = 1 &lt;&lt; 24  
    fmt.Println(f)        // 1.6777216e+07  
    fmt.Println(f + 1)    // 1.6777216e+07  
    fmt.Println(f == f+1) // 结果确为true  
复制<br><img alt="assets/101、Go语言基础2/img-20240113_093823.png" src="\02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240113_093823.png" style="width: 750px; max-width: 100%;"><br>浮点数在声明的时候可以只写整数部分或者小数部分<br>
<br>var e = .71828 // 0.71828
var f = 1.     // 1
fmt.Printf("%.5f,%.1f",e,f)
复制<br>很小或很大的数最好用科学计数法书写，通过 e 或 E 来指定指数部分<br>var avogadro = 6.02214129e23  // 阿伏伽德罗常数
var planck   = 6.62606957e-34 // 普朗克常数
fmt.Printf("%f,%.35f",avogadro,planck)
复制<br><br>在 Go 语言中，以 bool 类型进行声明：<br>var 变量名 bool
复制<br>==, &gt;, &lt;，&lt;=, &gt;=, &amp;&amp;(AND), ||(OR) 等都会产生 bool 值Dataview (inline field '='): Error: 
-- PARSING FAILED --------------------------------------------------

&gt; 1 | =
    | ^

Expected one of the following: 

'(', 'null', boolean, date, duration, file link, list ('[1, 2, 3]'), negated field, number, object ('{ a: 1, b: 2 }'), string, variable
<br>var aVar = 10
aVar == 5  // false
aVar == 10 // true
aVar != 5  // true
aVar != 10 // false
复制<br>
Go 语言对于值之间的比较有非常严格的限制，只有两个相同类型的值才可以进行比较，如果值的类型是接口（interface），那么它们也必须都实现了相同的接口。
如果其中一个值是 常量，那么另外一个值可以不是常量，但是类型必须和该常量类型相同。
如果以上条件都不满足，则必须将其中一个值的类型转换为和另外一个值的类型相同之后才可以进行比较。
<br>&amp;&amp;(AND), ||(OR) 是具有短路行为的，如果运算符左边的值已经可以确定整个布尔表达式的值，那么运算符右边的值将不再被求值。(&amp;&amp;优先级高于||)<br>var a = 10
	//因为a&gt;11已经不满足了，所以a &lt; 30不会走，整个表达式为false
	if(a &gt; 11 &amp;&amp; a &lt; 30){
		fmt.Println("正确")
	}else{
		fmt.Println("错误")
	}

	//因为a &gt; 5已经满足了，所以a &lt; 30不会走，整个表达式为true
	if(a &gt; 5 || a &lt; 30){
		fmt.Println("正确")
	}else{
		fmt.Println("错误")
	}
复制<br>布尔型数据只有 true 和 false，且不能参与任何计算以及类型转换<br><br>Go 语言的字符有以下两种：<br>
<br>一种是 uint 8 类型，或者叫 byte 型，代表了 ASCII 码的一个字符。
<br>另一种是 rune 类型，代表一个 UTF-8 字符，当需要处理中文、日文或者其他复合字符时，则需要用到 rune 类型。Rune 类型等价于 int 32 类型。
<br>byte 类型是 uint 8 的别名，rune 类型是 int 32 的别名<br>
<img alt="assets/101、Go语言基础2/img-20240113_095314.png" src="\02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240113_095314.png" style="width: 425px; max-width: 100%;"><br>ASCII 码的一个字符占一个字节<br>ASCII 定义 128 个字符，由码位 0 – 127 标识。它涵盖英文字母，拉丁数字和其他一些字符。<br>字符的定义：<br>//使用单引号 表示一个字符  
var chA1 byte = 'A'  
fmt.Printf("%c", chA1)  
  
//在 ASCII 码表中，A 的值是 65,也可以这么定义  
var chA2 byte = 65  
fmt.Printf("%c", chA2)  
  
//65使用十六进制表示是41，所以也可以这么定义 \x 总是紧跟着长度为 2 的 16 进制数  
var chA3 byte = '\x41'  
fmt.Printf("%c", chA3)  
  
//65的八进制表示是101，所以使用八进制定义 \后面紧跟着长度为 3 的八进制数  
var chA4 byte = '\101'  
fmt.Printf("%c", chA4)
复制<br>Unicode 是 ASCII 的超集，它定义了 1,114,112 个代码点的代码空间。 Unicode 版本 10.0 涵盖 139 个现代和历史文本集（包括符文字母，但不包括 Klingon ）以及多个符号集。<br>Go 语言同样支持 Unicode（UTF-8）, 用rune来表示, 在内存中使用 int 来表示。<br>在书写 Unicode 字符时，需要在 16 进制数之前加上前缀 \u 或者 \U。<br>
如果需要使用到 4 字节，则使用 \u 前缀，如果需要使用到 8 个字节，则使用 \U 前缀。<br>var ch rune = '\u0041'  
var ch1 int64 = '\U00000041'  
//格式化说明符%c用于表示字符，%v或%d会输出用于表示该字符的整数，%U输出格式为 U+hhhh 的字符串。  
fmt.Printf("%c,%c,%U\n", ch, ch1, ch) //A,A,U+0041  
fmt.Printf("%v,%d\n", ch, ch1)        //65,65
复制<br>Unicode 包中内置了一些用于测试字符的函数，这些函数的返回值都是一个布尔值，如下所示（其中 ch 代表字符）：<br>
<br>判断是否为字母：unicode. IsLetter (ch)
<br>判断是否为数字：unicode. IsDigit (ch)
<br>判断是否为空白符号：unicode. IsSpace (ch)
<br>var chA rune = '\u0041'  
var ch2 rune = '\u0032'  
var space rune = '\u0020'  
  
fmt.Printf("%c,%v\n", chA, unicode.IsLetter(chA))    //A,true  
fmt.Printf("%c,%v\n", ch2, unicode.IsDigit(ch2))     //2,true  
fmt.Printf("%c,%v\n", space, unicode.IsSpace(space)) // ,true
复制<br><br>一个字符串是一个不可改变的字节序列，字符串可以包含任意的数据，但是通常是用来包含可读的文本，字符串是 UTF-8 字符的一个序列。<br>字符串的定义：<br>var mystr string = "hello"
复制<br>go 语言从底层就支持 UTF-8 编码。<br>
UTF-8 是一种被广泛使用的编码格式，是文本文件的标准编码。
由于该编码对占用字节长度的不定性，在 Go 语言中字符串也可能根据需要占用 1 至 4 个字节，这与其它编程语言不同。
Go 语言这样做不仅减少了内存和硬盘空间占用，同时也不用像其它语言那样需要对使用 UTF-8 字符集的文本进行编码和解码。
<br><br>字符串是一种值类型，且值不可变，即创建某个文本后将无法再次修改这个文本的内容。<br>当字符为 ASCII 码表上的字符时则占用 1 个字节<br>字符串中可以使用转义字符来实现换行、缩进等效果，常用的转义字符包括:<br>
<br>\n 换行符
<br>\r 回车符
<br>\t tab 键
<br>\u 或 \U Unicode 字符
<br>\ 反斜杠自身
<br>var str = "码神之路\nGo大法好"
fmt.Print(str)
复制<br>
如果使用``反引号，会被原样进行赋值和输出
<br> fmt.Println(`\t 码神之路Go大法好`)  // \t 码神之路Go大法好
 fmt.Println(`\t 码神之路
 Go大法好`) //使用反引号 可以进行字符串换行
//反引号一般用在 需要将内容进行原样输出的时候 使用
复制<br>字符串是字节的定长数组，byte 和 rune 都是字符类型，若多个字符放在一起，就组成了字符串<br>比如 hello ，对照 ascii 编码表，每个字母对应的编号是：104,101,108,108,111<br>var myStr01 string = "hello"  
var myStr02 [5]byte = [5]byte{104, 101, 108, 108, 111}  
fmt.Printf("myStr01: %s\n", myStr01) //myStr01: hello  
fmt.Printf("myStr02: %s", myStr02)   //myStr02: hello
复制<br><br>字符串的内容（纯字节）可以通过标准索引法来获取，在方括号 [ ] 内写入索引，索引从 0 开始计数，获取的是索引的字节：<br>
<br>字符串 str 的第 1 个字节：str[0]
<br>第 i 个字节：str[i - 1]
<br>最后 1 个字节：str[len (str)-1]
<br>这种转换方案只对纯 ASCII 码的字符串有效。<br>
对于有 Unicode 字符的，字符串中的字符可能由多个字节组成，使用下标就会出错。<br>
注意：获取字符串中某个字节的地址属于非法行为，例如 &amp;str[i]。
<br>一般的比较运算符（==、!=、&lt;、&lt;=、&gt;=、&gt;）是通过在内存中按字节比较，来实现字符串比较的，因此比较的结果是字符串自然编码的顺序。<br>从字符串 Hello, 世界 中获取 界 该如何方便获取呢？<br>直接索引对 rune 类型无效，可以使用 string 方法转换<br>//
fmt.Println(string([]rune(myStr)[10])) 
复制<br>str := "Hello, 我的世界"  
char := str[7]           // 想获取指定索引位置的字符  
fmt.Println(char)        //228  
fmt.Printf("%c\n", char) //发现不是想要的，结果：æ  
  
//  fmt.Println(&amp;str[7]) //非法行为，编译报错  
//  fmt.Println (&amp;char)   //不非法  
  
//获取指定字节范围的字符串或子串或字符  
slice := str[7:10]  
Fmt.Println (slice)        //我  
Fmt.Printf ("%v\n", slice) //我  
  
//想要获取指定字符  
Fmt.Println (string ([]rune (str)[9])) //世
复制<br><br>两个字符串 s 1 和 s 2 可以通过 s := s 1 + s 2 拼接在一起。将 s 2 追加到 s 1 尾部并生成一个新的字符串 s。<br>//最好放在一行，如果分行“+”必须放在第一行末尾。
//因为编译器会在行尾自动补全分号
Str = "第一部分 " + "第二部分"
Str = "第一部分 " +  
    "第二部分"  
复制<br><img alt="assets/101、Go语言基础2/img-20240113_104300.png" src="\02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240113_104300.png" style="width: 475px; max-width: 100%;"><br>也可以使用“+=”来对字符串进行拼接：<br>S := "hel" + "lo,"
S += "world!"
Fmt.Println (s) //输出 “hello, world!”
复制<br>除了使用 + 进行拼接，我们也可以使用 WriteString ()<br>Str 1 := "你好,"  
Str 2 := "码神之路"  
Var stringBuilder bytes. Buffer  
//节省内存分配，提高处理效率  
StringBuilder.WriteString (str 1)  
StringBuilder.WriteString (str 2)  
Fmt.Println (stringBuilder.String ())
复制<br><br>
<br>print ： 结果写到标准输出
<br>Sprint： 结果会以字符串形式返回
<br>Str 1 := "你好,"  
Str 2 := "码神之路"  
Var stringBuilder bytes. Buffer  
StringBuilder.WriteString (str 1)  
StringBuilder.WriteString (str 2)  
// Sprint 以字符串形式返回  
Result := fmt.Sprintf (stringBuilder.String ())   //你好, 码神之路
Fmt.Println (result)   //
复制<br>%c  单一字符
%T  动态类型
%v  本来值的输出
%+v 字段名+值打印
%d  十进制打印数字
%p  指针，十六进制
%f  浮点数
%b 二进制
%s string
复制<br><br><br>指针（pointer）在 Go 语言中可以被拆分为两个核心概念：<br>
<br>类型指针，允许对这个指针类型的数据进行修改，传递数据可以直接使用指针，而无须拷贝数据，类型指针不能进行偏移和运算。
<br>切片，由指向起始元素的原始指针、元素数量和容量组成。
<br>受益于这样的约束和拆分，Go 语言的指针类型变量即拥有指针高效访问的特点，又不会发生指针偏移，从而避免了非法修改关键性数据的问题。<br>同时，垃圾回收 也比较容易对不会发生偏移的指针进行检索和回收。<br>切片比原始指针具备更强大的特性，而且更为安全。<br>切片在发生越界时，运行时会报出宕机，并打出堆栈，而原始指针只会崩溃。<br><br>
Var a int = 10
解释：<br>
在内存中开辟了一片空间，空间内存放着数值 10，这片空间在整个内存当中，有一个唯一的地址，用来进行标识，指向这个地址的变量就称为指针。
如果用类比的说明：<br>
内存比作酒店，每个房间就是一块内存，上述代码表示为：定了一间房间 a，让 10 住进了房间，房间有一个门牌号 px，这个 px 就是房间的地址，房卡可以理解为就是指针，指向这个地址。
<br>每个变量在运行时都拥有一个地址，这个地址代表变量在内存中的位置。<br>
变量、指针和地址三者的关系是，每个变量都拥有地址，指针的值就是地址<br>
一个指针变量可以指向任何一个值的内存地址，它所指向的值的内存地址在 32 和 64 位机器上分别占用 4 或 8 个字节，占用字节的大小与所指向的值的大小无关。
<br><br>最重要的就是两个符号：<br>
&amp; 取内存地址<br>
* 根据地址取值<br>
取地址操作符 &amp; 和取值操作符 * 是一对互补操作符<br>样例如下：<br>//其中 v 代表被取地址的变量，变量 v 的地址使用变量 ptr 进行接收，ptr 的类型为*T，称做 T 的指针类型，*代表指针。
Var ptr *T = &amp;v

//简短格式
Ptr := &amp;v    // v 的类型为 T
复制<br>Package main

Import (
	"fmt"
)

Func main () {
	// 指针与变量
	Var room int = 10 // room 房间里面放的变量 10  
	Var ptr = &amp;room   // 门牌号 px  指针  0 xc 00000 a 0 b 8  
	Fmt.Printf ("变量的内存地址:%p\n", &amp;room) // 变量的内存地址: 0 xc 00000 a 0 b 8  
	Fmt.Printf ("%T, %p\n", ptr, ptr)  // *int, 0 xc 00000 a 0 b 8  
	  
	Fmt.Println ("指针地址: ", ptr)     // 指针地址: 0 xc 00000 a 0 a 8  
	Fmt.Println ("指针地址代表的值", *ptr) // 10
}
复制<br>变量、指针地址、指针变量、取地址、取值的相互关系和特性如下：<br>
<br>对变量进行取地址操作使用 &amp; 操作符，可以获得这个变量的指针变量。
<br>指针变量的值是指针地址。
<br>对指针变量进行取值操作使用 * 操作符，可以获得指针变量指向的原变量的值。
<br><br>通过指针不仅可以取值，也可以修改值。<br>Package main

Import "fmt"

Func main () {
	// 利用指针修改值
	Var num = 10
	ModifyFromPoint (num)
	Fmt.Println ("未使用指针，方法外", num) //未使用指针，方法外 10

	Var num 2 = 22
	NewModifyFromPoint (&amp;num 2)     // 传入指针
	Fmt.Println ("使用指针方法外", num 2) //使用指针方法外 1000
}

Func modifyFromPoint (num int) {
	// 未使用指针
	Num = 10000
	Fmt.Println ("未使用指针，方法内: ", num) //未使用指针，方法内: 10000
}

Func newModifyFromPoint (ptr *int) {
	// 使用指针
	*ptr = 1000                    // 修改指针地址指向的值
	Fmt.Println ("使用指针，方法内: ", *ptr) //使用指针，方法内: 1000

}
复制<br><br>Go 语言还提供了另外一种方法来创建指针变量，格式如下：<br>New (类型)
复制<br>Str := new (string)
*str = "码神之路 Go 语言教程"
Fmt.Println (*str)
复制<br>new () 函数可以创建一个对应类型的指针，创建过程会分配内存，被创建的指针指向默认值。<br><br>获取命令行的输入信息<br>Go 语言内置的 flag 包实现了对命令行参数的解析，flag 包使得开发命令行工具更为简单。<br>Package main
// 导入系统包
Import (
    "flag"
    "fmt"
)

// flag 包用于处理命令行参数
// 定义命令行参数 mode，在命令行中不指定 `-mode` 参数，那么 `mode` 变量将使用默认值（空字符串）
// "fast 模式能让程序运行的更快"这个是说明字符串，主要用于在用户使用 `-h` 或 `--help` 参数时显示帮助信息。
Var mode = flag.String ("mode", "", "fast 模式能让程序运行的更快")

Func main () {
	// 解析命令行参数
	Flag.Parse ()
	Fmt.Println (*mode)
}

复制<br>帮助提示如下：<br>
<img src="\02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240114_104359.png"><br>执行结果如下：<br>
<img src="\02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240114_104008.png"><br><br>A）当一个指针被定义后 没有分配到任何变量 时，它的默认值为 nil。<br>
B）指针变量接收的一定是地址值<br>Package main  
  
Import "fmt"  
  
Func main () {  
    Var room int = 10 // room 房间里面放的变量 10  
    Fmt.Println (room)  
  
    //var ptr *int = room 编译报错  
    Var ptr *int  
    Ptr = &amp;room  
    // println (ptr)  //由于 fmt.Println () 和 println () 是两个独立的函数调用，它们的执行顺序是不确定的，可能受到编译器优化、操作系统调度等因素的影响。  
  
    Fmt.Println (ptr)  
}
复制<br>C）基本数据类型（又叫值类型），都有对应的指针类型, 形式为 *数据类型 ，比如 int 的对应的指针就是 *int , float 32 对应的指针类型就是 *float 32。指针变量的地址不可以不匹配。<br>Var room int 32 = 10  
Var ptr *int = &amp;room //编译错误  
Fmt.Println (ptr)
复制<br><br>在必要以及可行的情况下，一个类型的值可以被转换成另一种类型的值。由于 Go 语言不存在隐式类型转换，因此所有的类型转换都必须显式的声明：<br>//类型 B 的值 = 类型 B (类型 A 的值)
ValueOfTypeB = type B (valueOfTypeA)
复制<br>示例：<br>A := 5.0
B := int (a)
复制<br><br>❶ 类型转换只能在定义正确的情况下转换成功<br>
例如从一个取值范围较小的类型转换到一个取值范围较大的类型（将 int 16 转换为 int 32）。<br>❷ 当从一个取值范围较大的类型转换到取值范围较小的类型时<br>
将 int 32 转换为 int 16 或将 float 32 转换为 int，会发生 精度丢失 的情况。<br>❸ 只有相同底层类型的变量之间可以进行相互转换<br>
如将 int 16 类型转换成 int 32 类型，不同底层类型的变量相互转换时会引发编译错误（如将 bool 类型转换为 int 类型）<br>Package main

Import (
	"fmt"
	"math"
)

Func main () {
	// 输出各数值范围
	Fmt.Println ("int 8 range: ", math. MinInt 8, math. MaxInt 8)    //int 8 range: -128 127
	Fmt.Println ("int 16 range: ", math. MinInt 16, math. MaxInt 16) //int 16 range: -32768 32767
	Fmt.Println ("int 32 range: ", math. MinInt 32, math. MaxInt 32) //int 32 range: -2147483648 2147483647
	Fmt.Println ("int 64 range: ", math. MinInt 64, math. MaxInt 64) //int 64 range: -9223372036854775808 9223372036854775807
	// 初始化一个 32 位整型值
	Var a int 32 = 1047483647  //变量 a 的值 1047483647 不在 int 16 范围内
	// 输出变量的十六进制形式和十进制值
	Fmt.Printf ("int 32: 0 x%x %d\n", a, a) //int 32: 0 x 3 e 6 f 54 ff 1047483647
	// 将 a 变量数值转换为十六进制, 发生数值截断
	B := int 16 (a)
	// 输出变量的十六进制形式和十进制值
	Fmt.Printf ("int 16: 0 x%x %d\n", b, b) //int 16: 0 x 54 ff 21759
	// 将常量保存为 float 32 类型
	Var c float 32 = math. Pi
	// 转换为 int 类型, 浮点发生精度丢失
	Fmt.Println (int (c)) //3
}

复制<br><br>❶ 整数与字符串<br>Package main  
  
Import (  
    "fmt"  
    "strconv" //string conversion  
)  
  
Func main () {  
    // 字符串与其他类型的转换  
    // str 转 int    newStr 1 := "1"  
    IntValue, _ := strconv.Atoi (newStr 1)      //Atoi 的全称是 "ASCII to integer"    fmt.Printf ("%T,%d\n", intValue, intValue) // int, 1  
  
    // int 转 str    intValue 2 := 1  
    StrValue := strconv.Itoa (intValue 2)        //Itoa 的全称是 "integer to ASCII"    fmt.Printf ("%T, %s\n", strValue, strValue) //string, 1  
}
复制<br>❷ 浮点数与字符串<br>// str 转  floatstring 3 := "3.1415926"  
F, _ := strconv.ParseFloat (string 3, 32)  
Fmt.Printf ("%T, %f\n", f, f) // float 64, 3.141593  
//float 转 stringfloatValue := 3.1415926  
//4 个参数，  
//1：要转换的浮点数  
//2. 格式标记（b、e、E、f、g、G）  
//3. 精度  
//4. 指定浮点类型（32: float 32、64: float 64）  
// 格式标记：  
// ‘b’ (-ddddp±ddd，二进制指数)  
// ‘e’ (-d.dddde±dd，十进制指数)  
// ‘E’ (-d.ddddE±dd，十进制指数)  
// ‘f’ (-ddd. Dddd，没有指数)  
// ‘g’ (‘e’: 大指数，‘f’: 其它情况)  
// ‘G’ (‘E’: 大指数，‘f’: 其它情况)  
//  
// 如果格式标记为‘e’，‘E’和’f’，则 prec 表示小数点后的数字位数  
// 如果格式标记为‘g’，‘G’，则 prec 表示总的数字位数（整数部分+小数部分）  
FormatFloat := strconv.FormatFloat (floatValue, 'f', 2, 64)  
Fmt.Printf ("%T,%s", formatFloat, formatFloat)
复制<br><br>运算符是—种特殊的符号，用以表示数据的运算、赋值和比较等。<br><img src="\02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240113_141917.png"><br>运算符优先级<br>
所谓优先级，就是当多个运算符出现在同一个表达式中时，先执行哪个运算符。
<br>Go 语言有几十种运算符，被分成十几个级别，有的运算符优先级不同，有的运算符优先级相同，请看下表。<br>
注意：优先级值越大，表示优先级越高。<br><br>一下子记住所有运算符的优先级并不容易，还好 Go 语言中大部分运算符的优先级和数学中是一样的，大家在以后的编程过程中也会逐渐熟悉起来。如果实在搞不清，可以加括号，就像下面这样：<br>D := a + (b * c)
复制<br>括号的优先级是最高的，括号中的表达式会优先执行，这样各个运算符的执行顺序就一目了然了。<br><br>【1】算术运算符：+ ，-，*，/，%，++，--<br>
【2】介绍：算术运算符是对数值类型的变量进行运算的，比如，加减乘除<br><br>【1】赋值运算符： =,+=，-=，*=，/=,%=<br>
【2】赋值运算符就是将某个运算后的值，赋给指定的变量。Dataview (inline field ',+=，-=，*=，/=,%='): Error: 
-- PARSING FAILED --------------------------------------------------

&gt; 1 | ,+=，-=，*=，/=,%=
    | ^

Expected one of the following: 

'(', 'null', boolean, date, duration, file link, list ('[1, 2, 3]'), negated field, number, object ('{ a: 1, b: 2 }'), string, variable
<br><br>【1】关系运算符：==,!=,&gt;,&lt;,&gt; =，&lt;=<br>
关系运算符的结果都是 bool 型，也就是要么是 true，要么是 falseDataview (inline field '=,!=,&gt;,&lt;,&gt; =，&lt;='): Error: 
-- PARSING FAILED --------------------------------------------------

&gt; 1 | =,!=,&gt;,&lt;,&gt; =，&lt;=
    | ^

Expected one of the following: 

'(', 'null', boolean, date, duration, file link, list ('[1, 2, 3]'), negated field, number, object ('{ a: 1, b: 2 }'), string, variable
<br>【2】关系表达式经常用在流程控制中<br><br>【1】逻辑运算符：&amp;&amp;(逻辑与/短路与)，||（逻辑或/短路或），!（逻辑非）<br>
【2】用来进行逻辑运算的<br><br>下面是常见的位运算符及其功能：<br>
<br>按位与（AND）：a &amp; b&nbsp;执行按位与操作，返回一个新的值，其中每个对应的位都是在&nbsp;a&nbsp;和&nbsp;b&nbsp;中对应位都为 1 时为 1，否则为 0。
<br>按位或（OR）：a | b&nbsp;执行按位或操作，返回一个新的值，其中每个对应的位都是在&nbsp;a&nbsp;和&nbsp;b&nbsp;中至少有一个对应位为 1 时为 1，否则为 0。
<br>按位异或（XOR）：a ^ b&nbsp;执行按位异或操作，返回一个新的值，其中每个对应的位都是在&nbsp;a&nbsp;和&nbsp;b&nbsp;中只有一个对应位为 1 时为 1，否则为 0。
<br>按位取反（NOT）：^a&nbsp;执行按位取反操作，返回一个新的值，其中每个对应的位都是&nbsp;a&nbsp;中对应位的补码（0 变为 1，1 变为 0）。
<br>左移（Left Shift）：a &lt;&lt; b&nbsp;执行左移操作，将&nbsp;a&nbsp;的二进制表示向左移动&nbsp;b&nbsp;位，并在右侧填充零。这相当于将&nbsp;a&nbsp;的值乘以 2 的&nbsp;b&nbsp;次幂。
<br>右移（Right Shift）：a &gt;&gt; b&nbsp;执行右移操作，将&nbsp;a&nbsp;的二进制表示向右移动&nbsp;b&nbsp;位。对于无符号整数，左侧插入 0；对于有符号整数，左侧插入符号位的副本。
<br><br>【1】其它运算符：&amp; *<br>
&amp; ：返回变量的存储地址<br>
* ：取指针变量对应的数值<br><br><br><br>在 Go 语言中，关键字 if 是用于测试某个条件（布尔型或逻辑型）的语句，如果该条件成立，则会执行 if 后由大括号 {} 括起来的代码块，否则就忽略该代码块继续执行后续的代码。<br>❶ 单分支<br>If condition {
    // 条件为真执行
}
复制<br>//样例
X := 0
If x &lt;= 0 {
	Fmt.Println ("为真进入这里")
}
复制<br>❷ 双分支<br>如果存在第二个分支，则可以在上面代码的基础上添加 else 关键字以及另一代码块，这个代码块中的代码只有在条件不满足时才会执行，if 和 else 后的两个代码块是相互独立的分支，只能执行其中一个。<br>If condition {
    // 条件为真执行
} else {
    // 条件不满足执行
}
复制<br>Var count int = 70
If count &lt; 30 { //这个条件表达式返回的是 true 的话，后面{}执行了
  Fmt.Println ("库存不足")
} else {//count &gt;= 30
  Fmt.Println ("库存充足")
}
复制<br>❸多分支<br>基本语法
If 条件表达式 1 {
    逻辑代码 1
} else if 条件表达式 2 {
    逻辑代码 2
}
.......
Else {
                逻辑代码 n
}
复制<br>Package main
Import "fmt"
Func main (){
        //实现功能：根据给出的学生分数，判断学生的等级：
        // &gt;=90  -----A
        // &gt;=80  -----B
        // &gt;=70  -----C
        // &gt;=60  -----D
        // &lt;60   -----E

        //多分支：优点：如果已经走了一个分支了，那么下面的分支就不会再去判断执行了
        If score &gt;= 90 {
        	Fmt.Println ("您的成绩为 A 级别")
        } else if score &gt;= 80 {//else 隐藏：score &lt; 90
        	Fmt.Println ("您的成绩为 B 级别")
        } else if score &gt;= 70 {//score &lt; 80
        	Fmt.Println ("您的成绩为 C 级别")
        } else if score &gt;= 60 {//score &lt; 70
        	Fmt.Println ("您的成绩为 D 级别")
        } else {//score &lt; 60
        	Fmt.Println ("您的成绩为 E 级别")
        } //建议你保证 else 的存在，只有有了 else 才会真正起到多选一的效果

}
复制<br>❹ If 嵌套<br>If 语句可以嵌套：<br>/* 定义局部变量 */
   Var a int = 100
   Var b int = 200
   /* 判断条件 */
   If a == 100 {
       /* if 条件语句为 true 执行 */
       If b == 200 {
          /* if 条件语句为 true 执行 */
          Fmt.Printf ("a 的值为 100 ， b 的值为 200\n" )
       }
   }
复制<br>❺ 特殊写法<br>If 还有一种特殊的写法，可以在 if 表达式之前添加一个执行语句，再根据变量值进行判断，代码如下：<br>If a := 10; a &gt;5 {
    Fmt.Println (a)
    Return
}
复制<br>这种写法可以将返回值与判断放在一行进行处理，而且返回值的作用范围被限制在 if、else 语句组合中。<br>
在编程中，变量的作用范围越小，所造成的问题可能性越小，每一个变量代表一个状态，有状态的地方，状态就会被修改，函数的局部变量只会影响一个函数的执行，但全局变量可能会影响所有代码的执行状态，因此限制变量的作用范围对代码的稳定性有很大的帮助。
<br><br>
Switch 语句用于基于不同条件执行不同动作，每一个 case 分支都是唯一的，从上至下逐一测试，直到匹配为止。
Switch 分支表达式可以是任意类型，不限于常量。可省略 break，默认自动终止。
<br>Switch 语句的语法如下：<br>Switch 表达式 var 1 {
	Case val 1, val 2,.….:
	  语句块 1
	Case 值 3, 值 4,...:
	  语句块 2
	....
	Default:
	 语句块
}
复制<br>变量 var 1 可以是任何类型，而 val 1 和 val 2 则可以是 同类型的任意值。<br>类型不被局限于常量或整数，但必须是相同的类型；或者最终结果为相同类型的表达式。<br>/* 定义局部变量 */
	Var grade string = "B"
	Var score int = 90

	Switch score {
		Case 90: grade = "A"
		Case 80: grade = "B"
		Case 50,60,70 : grade = "C"
		Default: grade = "D"
	}
	//swtich 后面如果没有条件表达式，则会对 true 进行匹配
	//swtich 后面如果没有条件表达式，则会对 true 进行匹配
	Switch {
		Case grade == "A" :
			Fmt.Printf ("优秀!\n" )
		Case grade == "B", grade == "C" :
			Fmt.Printf ("良好\n" )
		Case grade == "D" :
			Fmt.Printf ("及格\n" )
		Case grade == "F":
			Fmt.Printf ("不及格\n" )
		Default:
			Fmt.Printf ("差\n" )
	}
	Fmt.Printf ("你的等级是 %s\n", grade )
复制<br>
Go 里面 switch 默认相当于每个 case 最后带有 break，匹配成功后不会自动向下执行其他 case，而是跳出整个 switch<br>
如果想要进入下一个 case，使用 fallthrough 关键字。
<br>注意事项：<br>加了 fallthrough 后，会直接运行【紧跟的后一个】case 或 default 语句，不论条件是否满足都会执行<br>Var s = "hello"  
Switch {  
Case s == "hello":  
    Fmt.Println ("hello")  
    Fallthrough  
Case s == "world":  
    Fmt.Println ("world")  
}
// 结果：
// hello
// world
复制<br><br>
Go 语言中的循环语句只支持 for 关键字，这个其他语言是不同的。
<br><br>❶ 标准方式<br>//这是最常见的`for`循环形式。
//`initialization`是循环变量的初始表达式，
//`condition`是循环条件
//`post`是每次循环迭代完成后执行的语句 (迭代因子)。

For initialization; condition; post {
    // 循环体
}
// 初始表达式不能用 var 定义变量的形式，要用:=
复制<br>样例：<br>Sum := 0
//i := 0; 赋初值，i&lt;10 循环条件如果为真就继续执行；i++ 后置执行执行后继续循环
For i := 0; i &lt; 10; i++ {
    Sum += i
}
复制<br>❷ for 省略 <br>(A) 省略初始表达式<br>
For ; condition; post {
    // 循环体
}
复制<br>(B) 省略初始化、后置语句的形式<br>For condition {
    // 循环体
}
复制<br>(C) 无限循环形式<br>For {
    // 循环体
}

//或者
For ;; {
	// 循环体
 }
复制<br>❸  For range <br>
For range 结构是 Go 语言特有的一种的迭代结构，for range 可以遍历数组、切片、字符串、map 及管道（channel）<br>
语法上类似于其它语言中的 foreach 语句。
<br>一般形式为：<br>For key, val := range coll {
    ...
}
复制<br>Var str string = "hello golang 你好"
For i , value := range str {
	Fmt.Printf ("索引为：%d, 具体的值为：%c \n", i, value)
}
复制<br>val 始终为集合中对应索引的 值拷贝，因此它一般只具有只读性质，对它所做的任何修改都不会影响到集合中原有的值<br>字符串也可以使用 for range:<br>	Str := "码神之路"
	//因为一个字符串是 Unicode 编码的字符（或称之为 rune ）集合
	//char 实际类型是 rune 类型
	For pos, char := range str {
		Fmt.Println (pos, char)
	}
复制<br>每个 rune 字符和索引在 for range 循环中是一一对应的，它能够自动根据 UTF-8 规则识别 Unicode 编码的字符。<br>通过 for range 遍历的返回值有一定的规律：<br>
<br>数组、切片、字符串返回索引和值。
<br>Map 返回键和值。
<br>Channel 只返回管道内的值。
<br><br>  ❶ continue<br>Step := 100  
For step &gt; 0 {  
    Step--  
    Fmt.Println (step)  
    //结束本次循环，继续下一次循环  
    If step%6 != 0 {  
       Continue  
    }  
    //i % 6 == 0 下面这句才执行  
    Fmt.Println ("after continue" + strconv.Itoa (step))  
}  
//会执行  
Fmt.Println ("结束之后的语句....")

//结果：
//99
//98
//97
//96
//after continue 96
//.......

复制<br>Continue 的作用是结束离它近的那个循环，继续离它近的那个循环:<br>//双重循环：
For i := 0; i &lt;= 3; i++ {  
    For j := 10; j &lt;= 13; j++ {  
       If i == 2 || j == 12 {  
          Continue  
       }  
       Fmt.Printf ("i: %v, j: %v \n", i, j)  
    }  
}  
Fmt.Println ("-----ok")

//结果：
//i: 0, j: 10 
//i: 0, j: 11 
//i: 0, j: 13 
//i: 1, j: 10 
//i: 1, j: 11 
//i: 1, j: 13 
//i: 3, j: 10 
//i: 3, j: 11 
//i: 3, j: 13 
//-----ok

复制<br>
Continue 语句后添加 标签 时，表示开始 标签对应的循环
<br>//双重循环：
OuterLoop:  
    For i := 0; i &lt;= 3; i++ {  
       For j := 10; j &lt;= 13; j++ {  
          If i == 2 || j == 12 {  
             Continue outerLoop  
          }  
          Fmt.Printf ("i: %v, j: %v \n", i, j)  
       }  
    }  
    Fmt.Println ("-----ok")

//结果：
//i: 0, j: 10 
//i: 0, j: 11 
//i: 1, j: 10 
//i: 1, j: 11 
//i: 3, j: 10 
//i: 3, j: 11 
//-----ok

复制<br> ❷ break<br>Step := 100 
For step &gt; 0 {  
    Step--  
    Fmt.Println (step)  
    //跳出循环, 还会继续执行循环外的语句  
    Break  
}  
//会执行  
Fmt.Println ("结束之后的语句....")

//结果：
//99
//结束之后的语句....
复制<br>outerLoop&nbsp;是一个&nbsp;label，它被应用在外部的&nbsp;for&nbsp;循环上。当内部的&nbsp;if&nbsp;条件满足时，会执行&nbsp;break outerLoop&nbsp;语句，跳出外部的循环。这样可以实现在多层嵌套循环中直接跳出指定的循环。<br>Package main
Import "fmt"
Func main () {
OuterLoop:
    For i := 0; i &lt; 2; i++ {
        For j := 0; j &lt; 5; j++ {
            Switch j {
            Case 2:
                Fmt.Println (i, j)
                Break OuterLoop
            Case 3:
                Fmt.Println (i, j)
                Break OuterLoop
            }
        }
    }
}
复制<br>label 需和 continue 和 break 一起使用，不能单独使用。<br>
需要注意的是，label&nbsp;的使用是可选的，大多数情况下，我们可以通过适当的控制流程和条件语句来避免使用&nbsp;label。在实际编程中，过多或滥用&nbsp;label&nbsp;可能会导致代码变得难以理解和维护，因此需要慎重使用。<br>❸ Return<br>Step := 100
For step &gt; 0 {  
   Step--  
   Fmt.Println (step)  
   //执行一次就结束了  
   Return  
}  
//不会执行  
Fmt.Println ("结束之后的语句....")

//结果：
//99
复制<br>❹ Painc<br>Step := 2  
For step &gt; 0 {  
   Step--  
   Fmt.Println (step)  
   //报错了，直接结束  
   Panic ("出错了")  
}  
//不会执行  
Fmt.Println ("结束之后的语句....")	
复制<br>❺ Goto<br>
【1】Golang 的 goto 语句可以无条件地转移到程序中指定的行。<br>
【2】goto 语句通常与条件语句配合使用。可用来实现条件转移.<br>
【3】在 Go 程序设计中一般不建议使用 goto 语句，以免造成程序流程的混乱。
在 Java 编程语言中是没有&nbsp;goto&nbsp;关键字的。这也是因为&nbsp;goto&nbsp;语句会导致代码的控制流变得不清晰和难以理解，容易引发编程错误。
<br>Package main
Import "fmt"
Func main () {
    For x := 0; x &lt; 10; x++ {
        For y := 0; y &lt; 10; y++ {
            If y == 2 {
                // 跳转到标签
                Goto breakHere
            }
        }
    }
    // 手动返回, 避免执行进入标签
    Return
    // 标签
BreakHere:
    Fmt.Println ("done")
}
复制<br><br>Package main

Func length (s string) int {
	Println ("call length.")
	Return len (s)
}

Func main () {
	S := "abcd"
    // 这样写会多次调佣 length 函数
	For i:= 0; i &lt; length (s); i++ {     
		Println (i, s[i])
	}
}
复制<br>优化：<br>Package main

Func length (s string) int {
	Println ("call length.")
	Return len (s)
}

Func main () {
	S := "abcd"
    // 值调用一次
	For i, n:= 0,length (s); i &lt;n; i++ {     
		Println (i, s[i])
	}
}
复制]]></description><link>02、多编程语言\03、go语言\01、go语言基础\02、go-基础语法.html</link><guid isPermaLink="false">02、多编程语言/03、Go语言/01、Go语言基础/02、Go 基础语法.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:44 GMT</pubDate><enclosure url="02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240112_214047.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240112_214047.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[03、函数与过程]]></title><description><![CDATA[ 
 <br>函数是组织好的、可重复使用的、用来实现单一或相关联功能的代码段，其可以提高应用的模块性和代码的重复利用率。<br>Go 语言支持普通函数、匿名函数和闭包，从设计上对函数进行了优化和改进，让函数使用起来更加方便。<br>Go 语言的函数属于“一等公民”（first-class），也就是说：<br>
<br>函数本身可以作为值进行传递。
<br>支持匿名函数和闭包（closure）
<br>函数可以满足接口
<br>
【2】Golang 中函数不支持重载<br>
【3】Golang 中支持可变参数 (如果你希望函数带有可变数量的参数)<br>
【4】基本数据类型和数组默认都是值传递的，即进行值拷贝。在函数内修改，不会影响到原来的值<br>
以值传递方式的数据类型，如果希望在函数内的变量能修改函数外的变量，可以传入变量的地址&amp;，函数内以指针的方式操作变量。从效果来看类似引用传递。
<br><br>函数定义:<br>func function_name( [parameter list] ) [return_types] {
   函数体
}
复制<br>
<br>Func：函数由 func 开始声明
<br>Function_name：函数名称，函数名和参数列表一起构成了函数签名。<br>
首字母不能是数字<br>
首字母大写该函数可以被本包文件和其它包文件使用 (类似 public)<br>
首学母小写只能被本包文件使用，其它包文件不能使用 (类似 private)
<br>parameter list：参数列表，参数就像一个占位符，当函数被调用时，你可以将值传递给参数，这个值被称为 实际参数。<br>
参数列表指定的是参数类型、顺序、及参数个数。<br>
参数是可选的，函数可以不包含参数。
<br>return_types：返回类型，函数返回一列值。<br>
Return_types 是该函数的返回类型。<br>
返回值是可选的，函数可以不包含返回值。
<br>函数体：函数定义的代码集合。
<br>示例：<br>package main

import "fmt"

func main() {
	fmt.Println(max(1, 10))
	fmt.Println(max(-1, -2))
}
//类型相同的相邻参数，参数类型可合并。
func max(n1, n2 int) int {
	if n1 &gt; n2 {
		return n1
	}
	return n2
}
复制<br><br><br>函数和函数是并列的关系，所以我们定义的函数不能写到 main 函数中，且函数编写的顺序是无关紧要的。<br>鉴于可读性的需求，最好把 main () 函数写在文件的前面，其他函数按照一定逻辑顺序进行编写（例如函数被调用的顺序）。<br><br>package main  
  
import "fmt"  
  
func printMessage(message string) {  
    fmt.Println("Printing message:", message)  
}  
  
func printMessage(message int) {   //Goland这里会标红
    fmt.Println("Printing message:", message)  
}  
  
func main() {  
    printMessage("Hello") // 编译错误：duplicate function printMessage  
}
复制<br><br>函数也是一种数据类型，可以赋值给一个变量，则该变量就是一个函数类型的变量了。通过该变量可以对函数调用。<br>package main

import "fmt"

// 定义一个函数：
func test(num int) {
	fmt.Println(num)
}
func main() {
	//函数也是一种数据类型，可以赋值给一个变量
	a := test                                        //变量就是一个函数类型的变量
	fmt.Printf("a的类型是：%T,test函数的类型是：%T \n", a, test) //a的类型是：func(int),test函数的类型是：func(int)
	//通过该变量可以对函数调用
	a(10) //等价于  test(10)
}
复制<br><br>
函数定义时指出，函数定义时有参数，该变量可称为函数的形参。<br>
形参就像定义在函数体内的局部变量。
<br><br>但当 调用函数，传递过来的变量就是函数的 实参，函数可以通过两种方式来传递参数，值传递和引用传递。<br><br>指在调用函数时将实际参数复制一份传递到函数中，这样在函数中如果对参数进行修改，将不会影响到实际参数。<br>package main

import "fmt"

func modifyValue(x int, arr [3]int) {
	x = 100
	arr[0] = 999
}

func main() {
	value := 5
	array := [3]int{1, 2, 3}

	fmt.Println("Before function call:")
	fmt.Println("Value:", value) // 输出：Value: 5
	fmt.Println("Array:", array) // 输出：Array: [1 2 3]

	modifyValue(value, array)

	fmt.Println("After function call:")
	fmt.Println("Value:", value) // 输出：Value: 5
	fmt.Println("Array:", array) // 输出：Array: [1 2 3]
}
复制<br><br>是指在调用函数时将实际参数的地址传递到函数中，那么在函数中对参数所进行的修改，将影响到实际参数。<br>package main

import (
	"fmt"
)

/* 定义相互交换值的函数 */
func swap(x, y *int) {
	*x,*y = *y,*x
}

func main() {
	var a, b int = 1, 2
	/*
	   调用 swap() 函数
	   &amp;a 指向 a 指针，a 变量的地址
	   &amp;b 指向 b 指针，b 变量的地址
	*/
	swap(&amp;a, &amp;b)

	fmt.Println(a, b)
}
复制<br>
注意1： 无论是值传递，还是引用传递，传递给函数的都是变量的副本，不过，值传递是值的拷贝。引用传递是地址的拷贝，一般来说，地址拷贝更为高效。而值拷贝取决于拷贝的对象大小，对象越大，则性能越低。<br>
基本数据类型和数组默认都是值传递的，即进行值拷贝。在函数内修改，不会影响到原来的值。
注意2： map、slice、chan、指针、interface 默认以引用的方式传递。
<br><br>函数的参数不是固定的，后面的类型是固定的。（可变参数）<br>Golang 可变参数本质上就是 slice。<br>
只能有一个，且必须是最后一个。<br>在参数赋值时可以不用用一个一个的赋值，可以直接传递一个数组或者切片。<br>格式:<br>func myfunc(args ...int) {    //0个或多个参数  
}  
  
func add(a int, args ...int) int {    //1个或多个参数  
}  
  
func add2(a int, b int, args ...int) int {    //2个或多个参数  
}
复制<br>注意：其中 args 是一个 slice，我们可以通过 arg[index]依次访问所有参数, 通过 len (arg)来判断传递参数的个数.<br>package main  
  
import (  
    "fmt"  
)  
  
func test(s string, n ...int) string {  
    var x int  
    for _, i := range n {  
       x += i  
    }  
  
    return fmt.Sprintf(s, x)  
}  
  
func main() {  
    s := []int{1, 2, 3}  
    res := test("sum: %d", s...) // slice... 展开slice  
    println(res)  
}
复制<br><br>
函数做为一等公民，可以做为参数传递。
<br>//传入函数参数fn，返回类型要int
func test(fn func() int) int {
    return fn()
}

//定义一个函数 fn
func fn()  int{
	return 200
}

func main() {
    //这是直接使用匿名函数
    s1 := test(func() int { return 100 }) 
    //这是传入一个函数
    s1 := test(fn)
	fmt.Println(s1)
}
复制<br>在将函数做为参数的时候，我们可以使用类型定义，将函数定义为类型，这样便于阅读<br>package main

import (
	"fmt"
)

// FormatFunc 定义函数类型。
type FormatFunc func(s string, x, y int) string

// format方法，参数为type是：FormatFunc的func
func format(fn FormatFunc, s string, x, y int) string {
	return fn(s, x, y)
}

// 定义一个满足type是：FormatFunc的func
func formatFun(s string, x, y int) string {
	return fmt.Sprintf(s, x, y)
}

func main() {
	s2 := format(formatFun, "%d, %d", 10, 20)
	fmt.Println(s2)
}

复制<br>有返回值的函数，必须有明确的终止语句，否则会引发编译错误。<br><br><br>func greet(name string) {
	fmt.Println("Hello, " + name + "!")
}

func main() {
	greet("Alice")
	greet("Bob")
}
复制<br><br>函数返回值可以有多个，同时 Go 支持对返回值命名<br>//多个返回值 用括号扩起来
func sumSub(a, b int) (int, int) {  
    sum := a + b  
    sub := a - b  
    return sum, sub  
}  
  
func main() {  
    sum, sub := sumSub(2, 3)  
    fmt.Println(sum, sub)  
}
复制<br>对函数返回值命名，里面顺序就无所谓了，顺序不用对应<br>// 对函数返回值命名，里面顺序就无所谓了，顺序不用对应  
func multiplyDivide(a, b float64) (multiply, divide float64) {  
    divide = a / b  
    multiply = a * b  
    return  
}  
  
func main() {  
    q, r := multiplyDivide(10, 3)  
    fmt.Println("multiply:", q)  
    fmt.Println("divide:", r)  
}
复制<br><br>package main

import "fmt"

//默认值为类型零值,
//命名返回参数可看做与形参类似的局部变量
//由return隐式返回
func f1() (names []string, m map[string]int, num int) {
   m = make(map[string]int)
   m["k1"] = 2
   return
}

func main() {
   a, b, c := f1()
   fmt.Println(a, b, c)
}
复制<br><br>通过使用&nbsp;_，我们告诉编译器我们不打算使用该位置的值，从而避免编译时产生未使用变量的警告。<br>
在这个例子中，我们只打印出&nbsp;c，而忽略了其他两个返回值。<br>func main() {
	_, _, c := f1()
	fmt.Println(c)
}
复制<br><br>初始化函数，可以用来进行一些初始化的操作。<br>
每一个源文件都可以包含一个 init 函数，该函数会在 main 函数执行前，被 Go 运行框架调用。<br><br>init&nbsp;函数的执行流程如下：<br>
<br>Go 程序首先会初始化包级别的常量和变量。<br>
包级别的变量和常量声明通常在包的顶层，位于函数之外。
<br>如果包级别存在全局变量的初始化表达式，则会按照顺序执行这些初始化表达式。<br>
例如其他函数方法
<br>每个包可以有多个&nbsp;init&nbsp;函数<br>
会按照它们在源代码中的顺序依次执行。
<br>init&nbsp;函数在程序运行时只执行一次，<br>
在包被第一次导入时调用。多次导入同一个包，init&nbsp;函数只会执行一次。
<br>如果引入其他包，优先加载依赖包的常量、变量、init&nbsp;函数<br>
依赖包按照上面 1-4 的顺序。<br>
依赖多个包，按照包的顺序
<br>Go 语言中禁止循环依赖的存在<br>
但包的依赖关系可以是多层嵌套的<br>
如果包存在依赖，不同包的 init 函数按照包导入的依赖关系决定执行顺序。调用顺序为最后被依赖的最先被初始化，如导入顺序 main &gt; a &gt; b &gt; c，则初始化顺序为 c &gt; b &gt; a &gt; main，依次执行对应的 init 方法。
<br> 引入包（多层嵌套按初始化顺序，非多层按包引入顺序） -&gt; 全局变量&nbsp;-&gt;&nbsp;init() -&gt; main()<br>如图：<br>
<img src="\02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240113_213810.png"><br>单文件：<br>package main  
  
import (  
    "fmt"  
)  
  
var preference string = test()  
var message string  
  
// 被成员变量调用了，所以先执行  
func test() string {  
    fmt.Println("--------Test method--------")  
    //fmt.Println("Preference:", preference) //被循环初始化了 initialization cycle for preference    fmt.Println("Message:", message)  
    return "testString"  
}  
  
// 在调用init，preference已经被赋值  
func init() {  
    fmt.Println("--------First init--------")  
    fmt.Println("Preference:", preference)  
    fmt.Println("Message:", message)  
    message = "Hello, world!"  
}  
  
func init() {  
    fmt.Println("--------Second init--------")  
    fmt.Println("Preference:", preference)  
    fmt.Println("Message:", message)  
}  
  
// main 是最后调用的  
func main() {  
    fmt.Println("--------Main function--------")  
    fmt.Println("Preference:", preference)  
    fmt.Println("Message:", message)  
}


//结果：
//--------Test method--------
//Message: 
//--------First init--------
//Preference: testString
//Message: 
//--------Second init--------
//Preference: testString
//Message: Hello, world!
//--------Main function--------
//Preference: testString
//Message: Hello, world!

复制<br>多文件 init 方法顺序：<br><img src="\02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240113_213221.png"><br>package main  
  
import (  
    "awesomeProject/mypackage"  
    "fmt")  
  
var preference string = test()  
var message string  
  
// 被成员变量调用了，所以先执行  
func test() string {  
    fmt.Println("--------Test method--------")  
    //fmt.Println("Preference:", preference) //被循环初始化了 initialization cycle for preference    fmt.Println("Message:", message)  
    fmt.Println("File1 gol value:", mypackage.File1)  
    mypackage.File1 = "test()"  
    return "testString"  
}  
  
// 在调用init，preference已经被赋值  
func init() {  
    fmt.Println("--------First init--------")  
    fmt.Println("Preference:", preference)  
    fmt.Println("Message:", message)  
    message = "Hello, world!"  
}  
  
func init() {  
    fmt.Println("--------Second init--------")  
    fmt.Println("Preference:", preference)  
    fmt.Println("Message:", message)  
}  
  
// main 是最后调用的  
func main() {  
    fmt.Println("--------Main function--------")  
    fmt.Println("File1 gol value:", mypackage.File1)  
    fmt.Println("Preference:", preference)  
    fmt.Println("Message:", message)  
}

//Init in file1.go
//Init in file2.go
//--------Test method--------
//Message: 
//File1 gol value: 
//--------First init--------
//Preference: testString
//Message: 
//--------Second init--------
//Preference: testString
//Message: Hello, world!
//--------Main function--------
//File1 gol value: test()
//Preference: testString
//Message: Hello, world!

复制<br><br>匿名函数是指不需要定义函数名的函数，由一个不带函数名的函数声明和函数体组成。<br>
可以直接使用函数内的变量，不必声明。<br>在 Go 里面，函数可以像普通变量一样被传递或使用，支持随时在代码里定义匿名函数。<br>匿名函数的定义格式如下：<br>func(参数列表)(返回参数列表){
    函数体
}
复制<br><br>package main

import (
    "fmt"
    "math"
)

func main() {
    //这里将一个函数当做一个变量一样的操作。
    getSqrt := func(a float64) float64 {
        return math.Sqrt(a)
    }
    fmt.Println(getSqrt(4)) //2
}
复制<br>全局变量：<br>package main  
  
import "fmt"  
  
// FunMul 全局函数  
var FunMul = func(num1 int, num2 int) int {  
    return num1 * num2  
}  
  
func main() {  
    //定义匿名函数：定义的同时调用  
    result := func(num1 int, num2 int) int {  
       return num1 + num2  
    }(10, 20) //返回的直接是调用结果  
    fmt.Printf("类型：%T ,值：%v \n", result, result) //类型：int ,值：30  
  
    //将匿名函数赋给一个变量，这个变量实际就是函数类型的变量  
    //sub等价于匿名函数  
    sub := func(num1 int, num2 int) int {  
       return num1 - num2  
    }  
    //直接调用sub就是调用这个匿名函数了  
    result01 := sub(70, 30)  
    fmt.Println(result01) //40  
  
    result02 := FunMul(3, 4)  
    fmt.Println(result02) //12  
}
复制<br><br>匿名函数可以在声明后调用，例如：<br>func(data int) {
    fmt.Println("hello", data)
}(100) //(100)，表示对匿名函数进行调用，传递参数为 100。
复制<br><br>匿名函数作为回调函数的设计在 Go 语言也比较常见<br>package main  
import (  
    "fmt"  
)  
  

func visit(list []int, f func(int)) {
	// 遍历切片的每个元素, 通过给定函数进行元素访问  
    for _, v := range list {
       f(v)      // 使用匿名函数打印切片内容  
    }  
}  
  
func main() {  
	//传入一个数组和匿名的函数func
    visit([]int{1, 2, 3, 4}, func(v int) {  
       fmt.Println(v)  
    })  
}
复制<br><br>package main

import "fmt"

func FGen(x, y int) (func() int, func(int) int) {

	//求和的匿名函数
	sum := func() int {
		return x + y
	}

	// (x+y) *z 的匿名函数
	avg := func(z int) int {
		return (x + y) * z
	}
	return sum, avg
}

func main() {
	f1, f2 := FGen(1, 2)
	fmt.Println(f1())  //3
	fmt.Println(f2(3)) //9
}

复制<br><br>
闭包是指：一个函数可以访问并操作其绑定的外部作用域中的变量，即使在函数被调用之后，这些变量的生命周期仍然存在。<br>
闭包 = 函数 + 引用环境
<br>示例：<br>package main

import (
	"fmt"
)

// 创建一个玩家生成器, 输入名称, 输出生成器
func playerGen(name string) func() (string, int) {
	// 血量一直为150
	hp := 150
	// 返回创建的闭包
	return func() (string, int) {
		// 将变量引用到闭包中
		return name, hp
	}
}

func main() {
	// 创建一个玩家生成器
	generator := playerGen("码神")
	// 返回玩家的名字和血量
	name, hp := generator()
	// 打印值
	fmt.Println(name, hp)

	generator2 := playerGen("大佬")
	name2, hp2 := generator2()
	// 打印值
	fmt.Println(name2, hp2)
}
复制<br>被调用后，引用环境依旧存在：<br>package main  
  
import (  
    "fmt"  
)  
  
func adder() func(int) int {  
    sum := 0  
    // 返回一个内部函数，该函数捕获了外部函数的 `sum` 变量  
    return func(x int) int {  
       sum += x  
       return sum  
    }  
}  
  
func main() {  
    // 创建一个 `add` 函数，它是一个闭包  
    add := adder()  
  
    // 使用闭包 `add` 进行累加操作  
    fmt.Println(add(10)) // 输出: 10  
    fmt.Println(add(5))  // 输出: 15  
    fmt.Println(add(3))  // 输出: 18  
}
复制<br><br>❶ 返回的是一个匿名函数，但是这个匿名函数引用到函数外的变量/参数 ,因此这个匿名函数就和变量/参数形成一个整体，构成闭包。<br>❷ 闭包中使用的变量/参数会一直保存在内存中，所以会一直使用。意味着闭包不可滥用（对内存消耗大）<br>package main

import "fmt"

// 函数功能：求和  
// 函数的名字：getSum 参数为空  
// getSum函数返回值为一个函数，这个函数的参数是一个int类型的参数，返回值也是int类型  
func getSum() func(int) int {
	var sum int = 0
	return func(num int) int {
		sum = sum + num
		return sum
	}
}

func getSum01(sum int, num int) int {
	sum = sum + num
	return sum
}

// 闭包：返回的匿名函数+匿名函数以外的变量num  
func main() {
	f := getSum()
	fmt.Println(f(1)) //1  
	fmt.Println(f(2)) //3  
	fmt.Println(f(3)) //6  
	fmt.Println(f(4)) //10  
	fmt.Println("----------------------")

	//不使用闭包的时候：我想保留的值，不可以反复使用  
	//闭包应用场景：闭包可以保留上次引用的某个值，我们传入一次就可以反复使用了
	fmt.Println(getSum01(0, 1)) //1  
	fmt.Println(getSum01(1, 2)) //3  
	fmt.Println(getSum01(3, 3)) //6  
	fmt.Println(getSum01(6, 4)) //10  
}  
复制<br><br>
Go 语言的 defer 语句会将其后面跟随的语句进行延迟处理
<br>关键字 defer 用于注册延迟调用。<br>
所以产用于：<br>
<br>关闭文件句柄
<br>锁资源释放
<br>数据库连接释放
<br>defer 特性:<br>
<br>
多个 defer 语句，按先进后出的方式执行。

<br>
所有函数在执行 RET 返回指令之前，都会先检查是否存在 defer 语句，若存在则先逆序调用 defer 语句进行收尾工作再退出返回；

<br>
匿名返回值是在 return 执行时被声明，有名返回值则是在函数声明的同时被声明，因此在 defer 语句中只能访问有名返回值，而不能直接访问匿名返回值；<br>
Return 其实应该包含前后两个步骤：<br>
第一步是给返回值赋值（若为有名返回值则直接赋值，若为匿名返回值则先声明再赋值）；<br>
第二步是调用 RET 返回指令并传入返回值，而 RET 则会检查 defer 是否存在，若存在就先逆序插播 defer 语句，最后 RET 携带返回值退出函数；
Defer、return、返回值三者的执行顺序应该是：return 最先给返回值赋值；接着 defer 开始执行一些收尾工作；最后 RET 指令携带返回值退出函数。

<br>
Defer 语句中的变量，在 defer 声明时就决定了。

<br>package main  
  
import "fmt"  
  
func sum(n1 int, n2 int) int {  
    //当执行到defer时，暂时不执行，会将其压入一个独立的栈中  
    //和sum栈和main栈不在一个地方的栈  
    //当函数执行完毕后，再从defer栈中按照先入后出原则出栈  
    defer fmt.Println("ok1,n1=", n1)              //5.再执行这句  
    defer fmt.Println("ok2,n2=", n2)              //4.再执行这句  
    res := n1 + n2                                //1.先执行了这句  
    fmt.Println("ok3=", res, "n1=", n1, "n2", n2) //2.再执行这句  
    return res                                    //3.再执行这句  6.最后RET
}  
  
func main() {  
    res := sum(20, 30)  
    fmt.Println("res=", res) //7.再执行这句  
}
复制<br><br>go 语言的 defer 功能强大，对于资源管理非常方便，但是如果没用好，也会有陷阱。<br><br>package main

import "fmt"

func main() {  
    var whatever = [5]int{1, 2, 3, 4, 5}  
  
    for _, a := range whatever {  
       defer fmt.Print(a)  
    }  
}
//结果：
//54321
复制<br>关于内存泄漏的警告是由于&nbsp;defer&nbsp;语句在循环中被使用，导致在每次迭代时都会推迟执行操作，这些推迟的操作会在函数返回时才执行。这可能导致在函数执行期间积累大量的推迟操作，占用额外的内存。<br><br>❶ 基本类型入栈<br>func sum(n1 int, n2 int) int {  
    defer fmt.Println("ok1,n1=", n1)  
    defer fmt.Println("ok2,n2=", n2)  
    n1++  
    n2++  
    res := n1 + n2  
    fmt.Println("ok3=", res, "n1=", n1, "n2", n2)  
    return res  
}  
  
func main() {  
    res := sum(20, 30)  
    fmt.Println("res=", res)  
}

//ok3= 52 ,n1= 21 ,n2= 31
//ok2,n2= 30
//ok1,n1= 20
//res= 52
复制<br>❷ 引用类型入栈<br>func sum(n1 *int, n2 *int) int {  
    defer fmt.Println("ok1,n1=", *n1)  
    defer fmt.Println("ok2,n2=", *n2)  
    *n1++  
    *n2++  
    res := *n1 + *n2  
    fmt.Println("ok3=", res, "n1=", *n1, "n2", *n2)  
    return res  
}  
  
func main() {  
    n1 := 20  
    n2 := 30  
    var p1 *int = &amp;n1  
    var p2 *int = &amp;n2  
    res := sum(p1, p2)  
    fmt.Println("res=", res)  
}

//结果和上面一样！
//ok3= 52 n1= 21 n2 31
//ok2,n2= 30
//ok1,n1= 20
//res= 52
复制<br>❸ 例子三：<br>package main

import (
	"log"
	"time"
)

func main() {
	start := time.Now()
	log.Printf("开始时间为：%v", start)
  defer log.Printf("时间差：%v", time.Since(start))  // Now()此时已经copy进去了
    //不受这3秒睡眠的影响
	time.Sleep(3 * time.Second)
	log.Printf("函数结束")
}

//2024/01/14 15:01:56 开始时间为：2024-01-14 15:01:56.2283069 +0800 CST m=+0.005217101
//2024/01/14 15:01:59 函数结束
//2024/01/14 15:01:59 时间差：31.8719ms

复制<br>
<br>Go 语言中所有的 函数调用都是传值的
<br>调用 defer 关键字会 立刻拷贝函数中引用的外部参数 ，包括 start 和 time. Since 中的 Now
<br>defer 的函数在 压栈的时候也会保存参数的值，并非在执行时取值。
<br>如何解决上述问题：使用 defer fun ()，拷贝的是 函数指针<br>package main

import (
	"log"
	"time"
)

func main() {
	start := time.Now()
	log.Printf("开始时间为：%v", start)
	defer func() {
		log.Printf("开始调用defer")
		log.Printf("时间差：%v", time.Since(start))
		log.Printf("结束调用defer")
	}()
	time.Sleep(3 * time.Second)

	log.Printf("函数结束")
}

//2024/01/14 15:01:18 开始时间为：2024-01-14 15:01:18.3644022 +0800 CST m=+0.005763401
//2024/01/14 15:01:21 函数结束
//2024/01/14 15:01:21 开始调用defer
//2024/01/14 15:01:21 时间差：3.0330456s
//2024/01/14 15:01:21 结束调用defer
复制<br><br>package main

import "fmt"

func main() {  
    var whatever = [5]int{1, 2, 3, 4, 5}  
    for _, a := range whatever {  
       //函数正常执行,由于闭包用到的变量 a 在执行的时候已经变成5,所以输出全都是5.  
       defer func() { fmt.Print(a) }()  
    }  
}
//结果：
//55555
复制<br>怎么解决：<br>package main

import "fmt"

func main() {  
    var whatever = [5]int{1, 2, 3, 4, 5}  
    for _, a := range whatever {  
       a := a // 赋值  
       defer func() { fmt.Print(a) }()  
    }  
}
//结果：
//54321
复制<br><br>
和 java 中的 finally 有点像
<br>Java 中的 finally:<br>public class Main {
    public static void main(String[] args) {
        try {
            System.out.println("Hello");
            throw new Exception("Exception occurred");
        } catch (Exception e) {
            System.out.println("Exception caught");
        } finally {
            System.out.println("Finally block");
        }
    }
}

//Hello
//Exception caught
//Finally block

复制<br>Go 中的 Defer:<br>func main() {  
    defer fmt.Println("Defer(Like Finally block)")  
    defer func() {  
       if r := recover(); r != nil {  
          fmt.Println("Exception caught")  
       }  
    }()  
  
    fmt.Println("Hello")  
    panic("Exception occurred")  
}

//Hello
//Exception caught
//Defer(Like Finally block)
复制<br><br><br>Golang 设计者为了编程方便，提供了一些不用导包可以直接使用的函数，称为 Go 的内置函数/内建函数。<br>
存放位置：在 builtin 包下 `
<br>func main() {  
	//使用 len 获取字节长度
	str := "hello"
	length := len(str)
    fmt.Println(length) // 输出: 5  

    // 使用 new 创建指针  
    p := new(int)  
    fmt.Println(*p) // 输出: 0  


    // 使用 append 向切片追加元素  
    slice := []int{1, 2, 3}  
    slice = append(slice, 4, 5)  
    fmt.Println(slice) // 输出: [1 2 3 4 5]  
  
    // 使用 copy 复制切片  
    source := []int{1, 2, 3}  
    destination := make([]int, len(source))  
    copy(destination, source)  
    fmt.Println(destination) // 输出: [1 2 3]  
  
    // 使用 make 创建切片和映射  
    s := make([]int, 0, 5)  
    m := make(map[string]int)  
    fmt.Println(s, m) // 输出: [] map[]  
  

  
    // 使用 print 和 println 打印输出  
    print("Hello")  
    println(", Go!")  
  
    // 使用 close 关闭通道  
    ch := make(chan int)  
    close(ch)  
  
    // 使用 cap 返回切片的容量  
    slice = make([]int, 0, 10)  
    fmt.Println(cap(slice)) // 输出: 10  
  
    // 使用 delete 从映射中删除键值对  
    m = map[string]int{"apple": 5, "banana": 3, "cherry": 8}  
    delete(m, "banana")  
    fmt.Println(m) // 输出: map[apple:5 cherry:8]  
  
    // 使用 panic 和 recover 处理运行时恐慌  
    defer func() {  
       if err := recover(); err != nil {  
          fmt.Println("恐慌已恢复:", err)  
       }  
    }()  
  
    panic("发生错误！")  
  
}
复制<br><br><br>// 字符串是否为空  
isEmpty := strings.TrimSpace("") == ""  
fmt.Println("字符串是否为空:", isEmpty)  
  
// 字符串连接  
concatenated := strings.Join([]string{"hello", "world"}, " ")  
fmt.Println("字符串连接:", concatenated)  
  
// 字符串重复  
repeated := strings.Repeat("abc", 3)  
fmt.Println("字符串重复:", repeated)  
  
// 查找子串是否在指定的字符串中  
isCont := strings.Contains("javaandgolang", "go")  
fmt.Println("查找子串是否在指定的字符串中:", isCont)  
  
// 统计一个字符串中指定子串出现的次数  
count := strings.Count("javaandgolang", "a")  
fmt.Println("统计一个字符串有几个指定的子串:", count)  
  
// 不区分大小写的字符串比较  
equalFold := strings.EqualFold("go", "Go")  
fmt.Println("不区分大小写的字符串比较:", equalFold)  
  
// 返回子串在字符串中第一次出现的索引值，如果没有则返回-1  
index := strings.Index("javaandgolang", "a")  
fmt.Println("子串在字符串中第一次出现的索引值:", index)  
  
// 替换字符串中的子串，n可以指定替换的次数，-1表示全部替换  
replaced := strings.Replace("goandjavagogo", "go", "golang", 2)  
fmt.Println("替换后的字符串:", replaced)  
  
// 将字符串按指定字符为分割标识拆分成字符串数组  
split := strings.Split("go-python-java", "-")  
fmt.Printf("拆分后的字符串数组: %v\n", split)  
  
// 将字符串转换为小写和大写形式  
lower := strings.ToLower("Go")  
upper := strings.ToUpper("go")  
fmt.Println("将字符串转换为小写形式:", lower)  
fmt.Println("将字符串转换为大写形式:", upper)  
  
// 去除字符串左右两边的空格  
trimmedSpace := strings.TrimSpace("     go and java    ")  
fmt.Println("去除左右两边空格后的字符串:", trimmedSpace)  
  
// 去除字符串左右两边指定的字符  
trimmedChars := strings.Trim("~golang~ ", " ~")  
fmt.Println("去除左右两边指定字符后的字符串:", trimmedChars)  
  
// 去除字符串左边指定的字符  
trimmedLeft := strings.TrimLeft("~golang~", "~")  
fmt.Println("去除左边指定字符后的字符串:", trimmedLeft)  
  
// 去除字符串右边指定的字符  
trimmedRight := strings.TrimRight("~golang~", "~")  
fmt.Println("去除右边指定字符后的字符串:", trimmedRight)  
  
// 判断字符串是否以指定前缀开头  
hasPrefix := strings.HasPrefix (" http://java.sun.com/jsp/jstl/fmt" , "http")  
Fmt.Println ("判断字符串是否以指定前缀开头: ", hasPrefix)  
  
// 判断字符串是否以指定后缀结尾  
hasSuffix := strings.HasSuffix (" http://java.sun.com/jsp/jstl/fmt" , "fmt")  
Fmt.Println ("判断字符串是否以指定后缀结尾: ", hasSuffix)
复制<br><br>字符串所占的字节长度获取根据编码来定：<br>ASCII 字符使用 len () 函数<br>
Unicode 字符串长度使用 utf 8.RuneCountInString () 函数<br>//中文三字节，字母一个字节  
Var myStrHello string = "hello"  
Var myStrSpl string = ","  
Var myStrZw string = "码神之路"  
Var myStrAll = myStrHello + myStrSpl + myStrZw  
  
Fmt.Printf ("myStrHello: %d\n", len (myStrHello)) //myStrHello: 5  
Fmt.Printf ("myStrSpl: %d\n", len (myStrSpl))     //myStrSpl: 1  
Fmt.Printf ("myStrZw: %d\n", len (myStrZw))       //myStrZw: 12  
Fmt.Printf ("myStrAll: %d\n", len (myStrAll))     //myStrAll:18

//计算字符串的长度  
Fmt.Println (utf 8.RuneCountInString (myStrZw)) // 4
复制<br><br>Ascii 字符集可以使用 for range 或者 for 循环遍历<br>Var str 1 string = "hello"  

// 遍历  
For i := 0; i &lt; len (str 1); i++ {  
    Fmt.Printf ("ascii: %c %d\n", str 1[i], str 1[i])  
}  
For _, s := range str 1 {  
    Fmt.Printf ("unicode: %c %d\n ", s, s)  
}  

复制<br>Unicode 字符集使用 for range 进行遍历<br>Var str 2 string = "hello, 码神之路"  
// 中文只能用 for range

For _, s := range str 2 {  
    Fmt.Printf ("unicode: %c %d\n ", s, s)  
}
复制<br>转换 R:=[]rune (str)，也可以使用两种方式遍历<br>Var str 2 string = "hello, 码神之路"  
  
R := []rune (str 2)  
  
For i := 0; i &lt; len (r); i++ {  
    Fmt.Printf ("unicode: %c %d\n", r[i], r[i])  
}  
  
Fmt.Println ("-------------")  
  
For _, s := range r {  
    Fmt.Printf ("unicode: %c %d\n", s, s)  
}
复制<br><br>如何获取字符串中的某一段字符?<br>
<br>Strings. Index ()： 正向搜索子字符串
<br>Strings. LastIndex ()：反向搜索子字符串
<br>Package main

Import (
	"fmt"
	"strings"
)

Func main () {
	// 查找  
	Tracer := "码神来了, 码神 bye bye"  
	  
	// 正向搜索字符串  
	Comma := strings.Index (tracer, ",")  
	Fmt.Println (", 所在的位置: ", comma) //, 所在的位置: 12  
	Fmt.Println (tracer[comma+1:]) // 码神 bye bye  
	  
	Add := strings.Index (tracer, "+")  
	Fmt.Println ("+所在的位置: ", add) // +所在的位置: -1  
	  
	Pos := strings.Index (tracer[comma:], "码神")  
	Fmt.Println ("码神，所在的位置", pos) // 码神，所在的位置 1  
	Fmt.Println (comma, pos, tracer[5+pos:]) // 12 1 码神 bye bye
}
复制<br>返回的是单字节字符的位，如果想要的 unicode 字符的位置，需要封装<br>Package main

Import (
	"fmt"
	"strings"
	"unicode/utf 8"
)

// Utf 8 Index strings. Index 的 UTF-8 版本
// 即 Utf 8 Index ("Go 语言中文网", "中文") 返回 4，而不是 strings. Index 的 8

Func Utf 8 Index (str, substr string) int {
	Index := strings.Index (str, substr)
	If index &lt; 0 {
		Return -1
	}
	Return utf 8.RuneCountInString (str[: index])
}

Func Utf 8 Substring (str string, start int) string {
	//_, startBytes := utf 8.DecodeRuneInString (str[start:])
	//return str[start+startBytes:]

	Runes := []rune (str)
	If start &gt;= len (runes) {
		Return ""
	}
	Return string (runes[start:])
}

Func main () {
	// 查找
	Tracer := "码神来了, 码神 bye bye"

	Comma := Utf 8 Index (tracer, ",")
	Fmt.Println (", 所在的位置: ", comma) //, 所在的位置: 4

	Fmt.Println (Utf 8 Substring (tracer, comma+1)) // 码神 bye bye
}

复制<br><br>Golang 语言的字符串是 不可变的<br>修改字符串时，可以将字符串 转换为[]byte 进行修改<br>
[]byte 和 string 可以通过强制类型转换
<br>Package main

Import (
	"fmt"
)

Func main () {
	Str := "Hello, World!"
	StrBytes := []byte (str)

	// 修改第一个字符
	StrBytes[0] = 'M'

	// 将字节切片转换回字符串
	NewStr := string (strBytes)

	Fmt.Println (newStr) // Mello, World!
}
复制<br>
中文
<br>Package main

Import (
	"fmt"
)

Func main () {
	Str := "你好，世界！"
	Runes := []rune (str)

	// 修改第一个中文字符
	Runes[0] = '好'

	// 将 rune 切片转换回字符串
	NewStr := string (runes)

	Fmt.Println (newStr) // 好好，世界！
}
复制<br>
字符串替换
<br>Package main

Import (
	"fmt"
	"strings"
)

Func main () {
	// 查找
	Str := "Hello, World!"
	NewStr := strings.Replace (str, "Hello", "Hi", 1)
	Fmt.Println (newStr) // Hi, World!
}
复制<br>]]></description><link>02、多编程语言\03、go语言\01、go语言基础\03、函数与过程.html</link><guid isPermaLink="false">02、多编程语言/03、Go语言/01、Go语言基础/03、函数与过程.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:44 GMT</pubDate><enclosure url="02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240113_213810.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240113_213810.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[04、数据结构和处理]]></title><description><![CDATA[ 
 <br><br><br>数组是一个由固定长度的特定类型元素组成的序列，一个数组可以由零个或多个元素组成。<br>因为数组的长度是固定的，所以在 Go 语言中很少直接使用数组。<br><br>var 数组变量名 [元素数量]Type

//- 数组变量名：数组声明及使用时的变量名。
//- 元素数量：数组的元素数量，可以是一个表达式，但最终通过编译期计算的结果必须是整型数值，元素数量不能含有到运行时才能确认大小的数值。
//- Type：可以是任意基本类型，包括数组本身，类型为数组本身时，可以实现多维数组。

//默认数组中的值是类型的默认值
var arr [3]int

//××arr := [3]int
复制<br>
一定要注意，数组是定长的，不可更改，在编译阶段就决定了
<br><br>❶ 初始化赋值<br>//第一种：
var arr [3]int = [3]int{1,2,3}

//如果第三个不赋值，就是默认值0
var arr [3]int = [3]int{1,2}

//可以使用简短声明
arr := [3]int{1,2,3}

//如果不写数据数量，而使用...，表示数组的长度是根据初始化值的个数来计算
arr := [...]int{1,2,3}
复制<br>❷  通过索引下标赋值<br>  var arr [3]int
  arr[0] = 5
  arr[1] = 6
  arr[2] = 7
复制<br>❸ 只初始化第三个值怎么写？<br>//2 给索引为2的赋值 ，所以结果是 0,0,3
arr := [3]int{2:3}
for index,value := range arr{
	fmt.Printf("索引:%d,值：%d \n",index,value)
}
复制<br><br>
<br>通过索引下标取值，索引从 0 开始
```go
复制
fmt.Println(arr[0])<br>
fmt.Println(arr[1])<br>
fmt.Println(arr[2])<br>
```<br>

<br>For range 获取
```go
复制
var arr [3]int<br>
for index, value := range arr {<br>
fmt.Printf("索引:%d,值：%d \n", index, value)<br>
}<br>
```<br>

<br><br>小技巧： 如果觉的每次写 [3]int 有点麻烦，你可以为 [3]int 定义一个新的类型。<br>	type arr3 [3]int
	//这样每次用arr3 代替[3]int，注意前面学过 定义一个类型后 arr3就是一个新的类型
	var arr arr3
	arr[0] = 2
	for index,value := range arr{
		fmt.Printf("索引:%d,值：%d \n",index,value)
	}
复制<br><br>如果两个数组类型相同（包括数组的长度，数组中元素的类型）的情况下，我们可以直接通过较运算符（ == 和 !=）来判断两个数组是否相等，只有当两个数组的所有元素都是相等的时候数组才是相等的，不能比较两个类型不同的数组，否则程序将无法完成编译。Dataview (inline field '='): Error: 
-- PARSING FAILED --------------------------------------------------

&gt; 1 | =
    | ^

Expected one of the following: 

'(', 'null', boolean, date, duration, file link, list ('[1, 2, 3]'), negated field, number, object ('{ a: 1, b: 2 }'), string, variable
<br>a := [2]int{1, 2}  
//`...`来表示数组的长度，我们可以让编译器根据初始化值的数量自动确定数组的长度。  
b := [...]int{1, 2}  
c := [2]int{1, 3}  
fmt.Println(a == b, a == c, b == c) // "true false false"  

//d := [3]int{1, 2}  
//fmt.Println(a == d) // 编译错误：无法比较 [2]int == [3]int
复制<br><br>Go 语言中允许使用多维数组，因为数组属于值类型，所以多维数组的所有维度都会在创建时自动初始化零值，多维数组尤其适合管理具有父子关系或者与坐标系相关联的数据。<br>声明多维数组的语法如下所示：<br>//array_name 为数组的名字，array_type 为数组的类型，size1、size2 等等为数组每一维度的长度。
var array_name [size1][size2]...[sizen] array_type
复制<br>二维数组是最简单的多维数组，二维数组本质上是由多个一维数组组成的。<br>// 声明一个二维整型数组，两个维度的长度分别是 4 和 2
var array [4][2]int
// 使用数组字面量来声明并初始化一个二维整型数组
array = [4][2]int{{10, 11}, {20, 21}, {30, 31}, {40, 41}}
// 声明并初始化数组中索引为 1 和 3 的元素
array = [4][2]int{1: {20, 21}, 3: {40, 41}}
// 声明并初始化数组中指定的元素
array = [4][2]int{1: {0: 20}, 3: {1: 41}}
复制<br>取值：<br>
<br>通过索引下标取值
fmt.Println(array[1][0])
复制

<br>循环取值
```go
复制
array := [4][2]int{{10, 11}, {20, 21}, {30, 31}, {40, 41}}<br>
for index, value := range array {<br>
fmt.Printf("索引:%d,值：%d \n", index, value)<br>
}<br>
```<br>

<br>赋值：<br>// 声明一个 2×2 的二维整型数组
var array [2][2]int
// 设置每个元素的整型值
array[0][0] = 10
array[0][1] = 20
array[1][0] = 30
array[1][1] = 40
复制<br>只要类型一致，就可以将多维数组互相赋值，如下所示，多维数组的类型包括每一维度的长度以及存储在元素中数据的类型：<br>// 声明两个二维整型数组 [2]int [2]int
var array1 [2][2]int  
var array2 [2][2]int
// 为array2的每个元素赋值
array2[0][0] = 10
array2[0][1] = 20
array2[1][0] = 30
array2[1][1] = 40
// 将 array2 的值复制给 array1
array1 = array2
复制<br>因为数组中每个元素都是一个值，所以可以独立复制某个维度，如下所示：<br>array1 := [4][2]int{{10, 11}, {20, 21}, {30, 31}, {40, 41}}
// 将 array1 的索引为 1 的维度复制到一个同类型的新数组里  {20, 21} -&gt; array3
var array3 [2]int = array1[1]
// 将数组中指定的整型值复制到新的整型变量里
var value int = array1[1][0]
for i, v := range array3 {
	fmt.Printf("index:%d,value:%v", i, v)
	fmt.Println()
}
fmt.Println("array1 索引1的二维数组，第0个值:", value)
复制<br><br>切片（Slice） 与数组一样，也是可以容纳若干类型相同的元素的容器。每个切片值都会将数组作为其底层数据结构。<br>
我们也把这样的数组称为 切片的底层数组。与数组不同的是，无法通过切片类型来确定其值的长度。<br>切片（slice） 是对数组的一个连续片段的引用，所以切片是一个引用类型。<br>这个片段可以是 整个数组，也可以是由起始和终止索引标识的一些 项的子集，需要注意的是，终止索引标识的项 不包括在切片内 (左闭右开的区间)。<br>Go 语言中切片的内部结构包含 地址、大小 和 容量，切片一般用于快速地操作一块数据集合。<br><br>从连续内存区域生成切片是常见的操作，格式如下：<br>slice [开始位置 : 结束位置]
//- Slice：表示目标切片对象；
//- 开始位置：对应目标切片对象的索引；
//- 结束位置：对应目标切片的结束索引。
复制<br>从数组生成切片，代码如下：<br>var a  = [3]int{1, 2, 3}
//a[1:2] 生成了一个新的切片
fmt.Println(a, a[1:2])
复制<br>注意：超界会报运行时错误，比如数组长度为 3，则结束位置最大只能为 3<br>
切片在指针的基础上增加了大小，约束了切片对应的内存区域，切片使用中无法对切片内部的地址和大小进行手动调整，因此切片比指针更安全、强大。
<br>
切片和数组密不可分，如果将数组理解为一栋办公楼，那么切片就是把不同的连续楼层出租给使用者，出租的过程需要选择开始楼层和结束楼层，这个过程就会生成切片
<br>var highRiseBuilding [30]int  
for i := 0; i &lt; 30; i++ {  
    highRiseBuilding[i] = i + 1  
}  
//原切片  
fmt.Println(highRiseBuilding[:])  
// 区间  索引位置：10 - 15的元素，不包含索引15  
fmt.Println(highRiseBuilding[10:15])  
// 中间到尾部的所有元素  
fmt.Println(highRiseBuilding[20:])  
// 开头到中间指定位置的所有元素   索引位置为：0,1  
fmt.Println(highRiseBuilding[:2])

//[1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30]
//[11 12 13 14 15]
//[21 22 23 24 25 26 27 28 29 30]
//[1 2]
复制<br><br>除了可以从原有的数组或者切片中生成切片外，也可以 声明一个新的切片，每一种类型都可以拥有其切片类型，表示多个相同类型元素的连续集合。<br>切片类型声明格式如下：<br>var name []Type
//name 表示切片的变量名，Type 表示切片对应的元素类型。
复制<br>// 声明字符串切片
var strList []string
// 声明整型切片
var numList []int
// 声明一个空切片
var numListEmpty = []int{}
// 输出3个切片
fmt.Println(strList, numList, numListEmpty)
// 输出3个切片大小
fmt.Println(len(strList), len(numList), len(numListEmpty))
// 切片判定空的结果
fmt.Println(strList == nil)
fmt.Println(numList == nil)
fmt.Println(numListEmpty == nil)

//[] [] []
//0 0 0
//true
//true
//false  空切片和nil还是不一样的
复制<br>切片是动态结构，只能与 nil 判定相等，不能互相判定相等。声明新的切片后，可以使用 append () 函数向切片中添加元素。<br>var strList []string  
// 追加一个元素  
strList = append(strList, "码神之路")  
fmt.Println(strList)
复制<br><br>如果需要动态地创建一个切片，可以使用 make () 内建函数，格式如下：<br>make( []Type, size, cap )
//`Type` 是指切片的元素类型
//`size` 指的是为这个类型分配多少个元素
//`cap` 为预分配的元素数量
// 这个值设定后不影响 size，只是能提前分配空间，降低多次分配空间造成的性能问题。


a := make([]int, 2)
b := make([]int, 2, 10)
fmt.Println(a, b)
//容量不会影响当前的元素个数，因此 a 和 b 取 len 都是 2
//但如果我们给a 追加一个 a的长度就会变为3
fmt.Println(len(a), len(b))
复制<br>
使用 make () 函数生成的切片一定发生了内存分配操作，但给定开始与结束位置（包括切片复位）的切片只是将新的切片结构指向已经分配好的内存区域，设定开始与结束位置，不会发生内存分配操作。
<br>var numbers4 = [...]int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}
myslice := numbers4[4:6]
//打印出来长度为2=6-4
fmt.Printf("myslice为 %d, 其长度为: %d\n", myslice, len(myslice))
//打印出来cap是6=10-4，cap=`底层数组的长度`-`起始位置`。
fmt.Printf("cap: %d\n", cap(myslice))

//fmt.Printf("直接获取第四个元素异常，为: %d", myslice[3])

// 重新切片，获取第四个元素
myslice = myslice[:cap(myslice)]
fmt.Printf("myslice为 %d, 其长度为: %d\n", myslice, len(myslice))

fmt.Printf("myslice的第四个元素为: %d", myslice[3])
复制<br><br>从数组或切片生成新的切片拥有如下特性：<br>
<br>取出的元素数量为：结束位置 - 开始位置；
<br>取出元素不包含结束位置对应的索引，切片最后一个元素使用 slice[len (slice)] 获取；
<br>当缺省开始位置时，表示从连续区域开头到结束位置 (a[:2])；
<br>当缺省结束位置时，表示从开始位置到整个连续区域末尾 (a[0:])；
<br>两者同时缺省时，与切片本身等效 (a[:])；
<br>两者同时为 0 时，等效于空切片，一般用于切片复位 (a[0:0])。
<br>去除的容量 cap = 底层数组的长度 - 起始位置。
<br>数组切片区别：<br>
<br>片的长度是可变的，它是对数组的一个引用。数组的长度是固定的。
<br>切片的声明使用方括号&nbsp;[]&nbsp;表示切片类型，不指定长度。数组要指定。
<br>切片的长度可以通过内置函数&nbsp;len()&nbsp;来获取，数组直接能看到长度。
<br><br>Go 语言的内置函数 copy () 可以将一个数组切片复制到另一个数组切片中，如果加入的两个数组切片不一样大，就会按照其中较小的那个数组切片的元素个数进行复制。<br>Copy () 函数的使用格式如下：<br>copy( destSlice, srcSlice []T) int
复制<br>其中 srcSlice 为数据来源切片，destSlice 为复制的目标（也就是将 srcSlice 复制到 destSlice），目标切片必须分配过空间且足够承载复制的元素个数，并且来源和目标的 类型必须一致，copy () 函数的返回值表示实际发生复制的元素个数。<br>下面的代码展示了使用 copy () 函数将一个切片复制到另一个切片的过程：<br>slice1 := []int{1, 2, 3, 4, 5}  
slice2 := []int{5, 4, 3}  
//copy(slice2, slice1) // 只会复制slice1的前3个元素到slice2中  
copy(slice1, slice2) // 只会复制slice2的3个元素到slice1的前3个位置  
fmt.Println(slice1)  
fmt.Println(slice2)
复制<br>切片的引用和复制操作对切片元素的影响:<br>package main

import "fmt"

func main() {
	// 设置元素数量为1000
	const elementCount = 1000
	// 预分配足够多的元素切片
	srcData := make([]int, elementCount)
	// 将切片赋值
	for i := 0; i &lt; elementCount; i++ {
		srcData[i] = i
	}
	// 引用切片数据 切片不会因为等号操作进行元素的复制
	refData := srcData
	// 预分配足够多的元素切片
	copyData := make([]int, elementCount)
	// 将数据复制到新的切片空间中
	copy(copyData, srcData)
	// 修改原始数据的第一个元素
	srcData[0] = 999
	// 打印引用切片的第一个元素 引用数据的第一个元素将会发生变化
	fmt.Println("引用的发生变化了：", refData[0])
	// 打印复制切片的第一个和最后一个元素 由于数据是复制的，因此不会发生变化。
	fmt.Println("复制的未发生变化：", copyData[0], copyData[elementCount-1])
	// 复制原始数据从4到6(不包含6)，4，5替换0，1
	copy(copyData, srcData[4:6])
	for i := 0; i &lt; 5; i++ {
		fmt.Printf("%d ", copyData[i])
	}
}

复制<br><br>map 是一种无序的 键值对 的集合。<br>Map 最重要的一点是通过 key 来快速检索数据，key 类似于索引，指向数据的值。<br>Map 是一种集合，所以我们可以像迭代数组和切片那样迭代它。不过，map 是无序的，我们无法决定它的返回顺序，这是因为 map 是使用 hash 表来实现的。<br><br>Map 是引用类型，可以使用如下方式声明：<br>var mapname map[keytype]valuetype
//[keytype] 和 valuetype 之间允许有空格。
//Mapname 为 map 的变量名。
//Keytype 为键类型。
//Valuetype 是键对应的值类型。
复制<br>
声明不需要知道 map 的长度，Map 可以根据新增的 key-value 动态的伸缩，未初始化的 map 的值是 nil，使用函数 len () 可以获取 map 中键值对的数目。
<br>package main

import "fmt"

func main() {
	var mapLit map[string]int
	var mapAssigned map[string]int
	mapLit = map[string]int{"one": 1, "two": 2}
	mapAssigned = mapLit
	//mapAssigned 是 mapList 的引用，对 mapAssigned 的修改也会影响到 mapList 的值。
	mapAssigned["two"] = 3
	fmt.Printf("Map literal at \"one\" is: %d\n", mapLit["one"])
	fmt.Printf("Map assigned at \"two\" is: %d\n", mapLit["two"])
	fmt.Printf("Map literal at \"ten\" is: %d\n", mapLit["ten"])
	//没有会返回这个类型的初始值，所以要判断是否存在需要加exists
	value, exists := mapLit["ten"]
	if exists {
		fmt.Printf("Map literal at \"ten\" is: %d\n", value)
	} else {
		fmt.Println("Key 'ten' does not exist in the map.")
	}
}

//Map literal at "one" is: 1
//Map assigned at "two" is: 3
//Map literal at "ten" is: 0
//Key 'ten' does not exist in the map.
复制<br><br>Map 使用 make 创建方式：<br>make(map[keytype]valuetype)

//不存在固定长度或者最大限制，但是也可以选择标明 map 的初始容量 capacity
make(map[keytype]valuetype, cap)

//例子：
map2 := make(map[string]int, 100)
复制<br>切记不要使用 new 创建 map，否则会得到一个空引用的指针<br>当 map 增长到容量上限的时候，如果再增加新的 key-value，map 的大小会自动加 1，所以出于性能的考虑，对于大的 map 或者会快速扩张的 map，即使只是大概知道容量，也最好先标明。<br>3、Map 和切片结合<br>例：当我们要处理 unix 机器上的所有进程，以父进程（pid 为整形）作为 key，所有的子进程（以所有子进程的 pid 组成的切片）作为 value。<br>
通过将 value 定义为 []int 类型或者其他类型的切片，类似于 java 中的 Map&lt;Interger,List&lt;Interger&gt;。<br>示例代码如下所示：<br>//键的类型是 `int`，值的类型是 `[]int`，即整数切片。
//直接通过键来访问和修改整数切片的内容
mp1 := make(map[int][]int)

//键的类型是 `int`，值的类型是 `*[]int`，即指向整数切片的指针。
//先通过键获取指向整数切片的指针，然后再访问和修改切片的内容
mp2 := make(map[int]*[]int)
复制<br>使用：<br>// mp1 示例  
mp1 := make(map[int][]int)  
slice1 := []int{1, 2, 3}  
mp1[1] = slice1  
  
// 修改 mp1 中键为 1 的切片  
mp1[1][0] = 10  
fmt.Println(mp1[1]) // 输出: [10 2 3]  
  
// mp2 示例  
mp2 := make(map[int]*[]int)  
slice2 := []int{1, 2, 3}  
mp2[1] = &amp;slice2  
  
// 修改 mp2 中键为 1 的切片  
(*mp2[1])[0] = 10  
fmt.Println(*mp2[1]) // 输出: [10 2 3]
复制<br><br><br>Map 的遍历过程使用 for range 循环完成，代码如下：<br>scene := make(map[string]int)
scene["cat"] = 66
scene["dog"] = 4
scene["pig"] = 960
for k, v := range scene {
    fmt.Println(k, v)
}
复制<br>注意：map 是无序的，不要期望 map 在遍历时返回某种期望顺序的结果<br><br>使用 delete () 内建函数从 map 中删除一组键值对，delete () 函数的格式如下：<br>delete(map, 键)
复制<br>Map 为要删除的 map 实例，键为要删除的 map 中键值对的键。<br>scene := make(map[string]int)  
// 准备map数据  
scene["cat"] = 66  
scene["dog"] = 4  
scene["pig"] = 960  
delete(scene, "dog")  
for k, v := range scene {  
    fmt.Println(k, v)  
    delete(scene, k)  
}  
fmt.Println(scene)
复制<br>Go 语言中并没有为 map 提供任何清空所有元素的函数、方法，清空 map 的唯一办法就是重新 make 一个新的 map，不用担心垃圾回收的效率，Go 语言中的并行垃圾回收效率比写一个清空函数要高效的多。<br><br>注意 map 在并发情况下，只读是线程安全的，同时读写是线程不安全的。<br>并发情况下读写 map 时会出现问题，代码如下：<br>// 创建一个int到int的映射
m := make(map[int]int)
// 开启一段并发代码
go func() {
    // 不停地对map进行写入
    for {
        m[1] = 1
    }
}()
// 开启一段并发代码
go func() {
    // 不停地对map进行读取
    for {
        _ = m[1]
    }
}()
// 无限循环, 让并发程序在后台执行
for {
}

//编译不报错，但运行报错，报错输出：
//fatal error: concurrent map read and map write
//使用了两个并发函数不断地对 map 进行读和写而发生了竞态问题，map 内部会对这种并发操作进行检查并提前发现。

复制<br>需要并发读写时，一般的做法是加锁，但这样性能并不高，Go 语言在 1.9 版本中提供了一种效率较高的并发安全的 sync.Map，sync. Map 和 map 不同，不是以语言原生形态提供，而是在 sync 包下的特殊结构。<br>Sync. Map 有以下特性：<br>
<br>无须初始化，直接声明即可。
<br>Sync. Map 不能使用 map 的方式进行取值和设置等操作，而是使用 sync. Map 的方法进行调用，Store 表示存储，Load 表示获取，Delete 表示删除。
<br>使用 Range 配合一个回调函数进行遍历操作，通过回调函数返回内部遍历出来的值，Range 参数中回调函数的返回值在需要继续迭代遍历时，返回 true，终止迭代遍历时，返回 false。
<br>package main
import (
      "fmt"
      "sync"
)
func main() {
    //sync.Map 不能使用 make 创建
    var scene sync.Map
    // 将键值对保存到sync.Map
    //sync.Map 将键和值以 interface{} 类型进行保存。
    scene.Store("greece", 97)
    scene.Store("london", 100)
    scene.Store("egypt", 200)
    // 从sync.Map中根据键取值
    fmt.Println(scene.Load("london"))
    // 根据键删除对应的键值对
    scene.Delete("london")
    // 遍历所有sync.Map中的键值对
    //遍历需要提供一个匿名函数，参数为 k、v，类型为 interface{}，每次 Range() 在遍历一个元素时，都会调用这个匿名函数把结果返回。
    scene.Range(func(k, v interface{}) bool {
        fmt.Println("iterate:", k, v)
        return true
    })
}
复制<br>sync. Map 为了保证并发安全有一些性能损失，因此在非并发情况下，使用 map 相比使用 sync. Map 会有更好的性能。<br><br>零值是 Go 语言中变量在声明之后但是未初始化被赋予的该类型的一个默认值。<br>在 Go 语言中，布尔类型的零值（初始值）为 false，数值类型的零值为 0，字符串类型的零值为空字符串 ""。<br>
指针、切片、映射、通道、函数和接口的零值则是 nil 标识符。<br>Nil 和其他语言的 null 是不同的。<br>1、谨慎比较<br>nil&nbsp;只能与指针类型进行比较，而不能与其他类型的值进行直接比较（**包括 nil 本身）。<br>var sp []int  
fmt.Println(sp == nil) //true  
fmt.Println(nil == sp) //true  
  
//var ot int  
//fmt.Println(ot == nil)  
//编译时候就报错  
  
//fmt.Println(nil == nil)  
//运行直接报错 invalid operation: nil == nil (operator == not defined on untyped nil)
复制<br>2、不是关键字或保留字<br>Nil 并不是 Go 语言的关键字或者保留字，也就是说我们可以定义一个名称为 nil 的变量，比如下面这样：<br>//但不提倡这样做
var nil = errors.New("my god")
复制<br>3、没有默认类型<br>package main
import (
    "fmt"
)
func main() {
    //error :use of untyped nil
    fmt.Printf("%T", nil)
    print(nil)
}
复制<br>4、不同类型的 nil，指针的地址相同。<br>package main
import (
    "fmt"
)
func main() {
    var arr []int
    var num *int
    fmt.Printf("%p\n", arr)
    fmt.Printf("%p", num)
}

//0x0
//0x0
复制<br>5、nil 是 map、slice、pointer、channel、func、interface 的零值<br>package main
import (
    "fmt"
)
func main() {
    var m map[int]string
    var ptr *int
    var c chan int
    var sl []int
    var f func()
    var i interface{}
    fmt.Printf("%#v\n", m)
    fmt.Printf("%#v\n", ptr)
    fmt.Printf("%#v\n", c)
    fmt.Printf("%#v\n", sl)
    fmt.Printf("%#v\n", f)
    fmt.Printf("%#v\n", i)
}
复制<br> 6、不同类型的 nil 值占用的内存大小可能是不一样的<br>
具体的大小取决于编译器和架构<br>package main
import (
    "fmt"
    "unsafe"
)
func main() {
    var p *struct{}
    fmt.Println( unsafe.Sizeof( p ) ) // 8
    var s []int
    fmt.Println( unsafe.Sizeof( s ) ) // 24
    var m map[int]bool
    fmt.Println( unsafe.Sizeof( m ) ) // 8
    var c chan string
    fmt.Println( unsafe.Sizeof( c ) ) // 8
    var f func()
    fmt.Println( unsafe.Sizeof( f ) ) // 8
    var i interface{}
    fmt.Println( unsafe.Sizeof( i ) ) // 16
}
复制<br><br>Make 关键字的主要作用是创建 slice、map 和 Channel 等内置的数据结构，而 new 的主要作用是为类型申请一片内存空间，并返回指向这片内存的指针。<br>
<br>Make 分配空间后，会进行初始化，new 分配的空间被清零
<br>New 分配返回的是指针，即类型 *Type。Make 返回引用，即 Type；
<br>New 可以分配任意类型的数据；
]]></description><link>02、多编程语言\03、go语言\01、go语言基础\04、数据结构和处理.html</link><guid isPermaLink="false">02、多编程语言/03、Go语言/01、Go语言基础/04、数据结构和处理.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:44 GMT</pubDate></item><item><title><![CDATA[05、面向对象]]></title><description><![CDATA[ 
 <br><br>
Go 语言可以通过自定义的方式形成新的类型，结构体就是这些类型中的一种复合类型，结构体是由零个或多个任意类型的值聚合成的实体，每个值都可以称为结构体的成员。
<br>结构体成员也可以称为“字段”，这些字段有以下特性：<br>
<br>字段拥有自己的类型和值；
<br>字段名必须唯一；
<br>字段的类型也可以是结构体，甚至是字段所在结构体的类型。
<br>使用关键字 type 可以将各种基本类型定义为自定义类型，基本类型包括整型、字符串、布尔等。结构体是一种复合的基本类型，通过 type 定义为自定义类型后，使结构体更便于使用。<br>结构体的定义格式如下：<br>type 类型名 struct {
    字段1 字段1类型
    字段2 字段2类型
    …
}
复制<br>
<br>类型名：标识自定义结构体的名称，在同一个包内不能重复。
<br>struct{}：表示结构体类型，type 类型名 struct{} 可以理解为将 struct{} 结构体定义为类型名的类型。
<br>字段 1、字段 2……：表示结构体字段名，结构体中的字段名必须唯一。
<br>字段 1 类型、字段 2 类型……：表示结构体各个字段的类型。
<br>示例：<br>type Point struct {
    X int
    Y int
}
复制<br>颜色的红、绿、蓝 3 个分量可以使用 byte 类型:<br>type Color struct {
    R, G, B byte
}
复制<br>结构体的定义只是一种内存布局的描述，只有当结构体实例化时，才会真正地分配内存<br><br>实例化就是根据结构体定义的格式创建一份与格式一致的内存区域，结构体实例与实例间的内存是完全独立的。<br>基本的实例化形式:<br>结构体本身是一种类型，可以像整型、字符串等类型一样，以 var 的方式声明结构体即可完成实例化。<br>var ins T
复制<br>T 为结构体类型，ins 为结构体的实例。<br>package main

import "fmt"

type Point struct {
	X int
	Y int
}
func main() {
    //使用.来访问结构体的成员变量,结构体成员变量的赋值方法与普通变量一致。
	var p Point
	p.X = 1
	p.Y = 2
	fmt.Printf("%v,x=%d,y=%d",p,p.X,p.Y )
}

复制<br>package main

import "fmt"

type Point struct {
	X int
	Y int
}
func main() {

	var p Point
	//p.X = 1
	//p.Y = 2
    //如果不赋值 结构体中的变量会使用零值初始化
	fmt.Printf("%v,x=%d,y=%d",p,p.X,p.Y )
}

复制<br>package main

import "fmt"

type Point struct {
	X int
	Y int
}
func main() {
	//可以使用
	var p = Point{
		X: 1,
		Y: 2,
	}
    var p = Point{
		1,
		2,
	}
	fmt.Printf("%v,x=%d,y=%d",p,p.X,p.Y )
}

复制<br>创建指针类型的结构体：<br>Go 语言中，还可以使用 new 关键字对类型（包括结构体、整型、浮点数、字符串等）进行实例化，结构体在实例化后会形成指针类型的结构体。<br>ins := new(T)
复制<br>
<br>T 为类型，可以是结构体、整型、字符串等。
<br>Ins：T 类型被实例化后保存到 ins 变量中，ins 的类型为 *T，属于指针。
<br>下面的例子定义了一个玩家（Player）的结构，玩家拥有名字、生命值和魔法值：<br>type Player struct{
    Name string
    HealthPoint int
    MagicPoint int
}
tank := new(Player)
tank.Name = "码神"
tank.HealthPoint = 300
复制<br>new 实例化的结构体实例在成员赋值上与基本实例化的写法一致。<br>取结构体的地址实例化:<br>在 Go 语言中，对结构体进行 &amp; 取地址操作时，视为对该类型进行一次 new 的实例化操作，取地址格式如下：<br>ins := &amp;T{}
复制<br>其中：<br>
<br>T 表示结构体类型。
<br>Ins 为结构体的实例，类型为 *T，是指针类型。
<br>示例：<br>package main

import "fmt"

type Command struct {
	Name    string    // 指令名称
	Var     *int      // 指令绑定的变量
	Comment string    // 指令的注释
}

func newCommand(name string, varRef *int, comment string) *Command {
	return &amp;Command{
		Name:    name,
		Var:     varRef,
		Comment: comment,
	}
}

var version = 1
func main() {
	cmd := newCommand(
		"version",
		&amp;version,
		"show version",
	)
	fmt.Println(cmd)
}

复制<br><br>匿名结构体没有类型名称，无须通过 type 关键字定义就可以直接使用。<br>ins := struct {
    // 匿名结构体字段定义
    字段1 字段类型1
    字段2 字段类型2
    …
}{
    // 字段值初始化
    初始化字段1: 字段1的值,
    初始化字段2: 字段2的值,
    …
}
复制<br>
<br>字段 1、字段 2……：结构体定义的字段名。
<br>初始化字段 1、初始化字段 2……：结构体初始化时的字段名，可选择性地对字段初始化。
<br>字段类型 1、字段类型 2……：结构体定义字段的类型。
<br>字段 1 的值、字段 2 的值……：结构体初始化字段的初始值。
<br>package main
import (
	"fmt"
)
// 打印消息类型, 传入匿名结构体
func printMsgType(msg *struct {
	id   int
	data string
}) {
	// 使用动词%T打印msg的类型
	fmt.Printf("%T\n, msg:%v", msg,msg)
}
func main() {
	// 实例化一个匿名结构体
	msg := &amp;struct {  // 定义部分
		id   int
		data string
	}{  // 值初始化部分
		1024,
		"hello",
	}
	printMsgType(msg)
}
复制<br><br>在 Go 语言中，结构体就像是类的一种 简化形式，那么类的方法在哪里呢？<br>在 Go 语言中有一个概念，它和方法有着同样的名字，并且大体上意思相同，Go 方法是作用在接收器（receiver）上的一个函数，接收器是某种类型的变量，因此方法是一种特殊类型的函数。<br>接收器类型可以是（几乎）任何类型，不仅仅是结构体类型，任何类型都可以有方法，甚至可以是函数类型，可以是 int、bool、string 或数组的别名类型，但是接收器不能是一个接口类型，因为接口是一个抽象定义，而方法却是具体实现，如果这样做了就会引发一个编译错误 invalid receiver type…<br>接收器也不能是一个指针类型，但是它可以是任何其他允许类型的指针。<br>一个类型加上它的方法等价于面向对象中的一个类<br>在 Go 语言中，类型的 代码 和绑定在它上面的 方法 的代码可以 不放置在一起，它们可以存在不同的源文件中，唯一的要求是它们必须是 同一个包的。<br>
类型 T（或 T）上的所有方法的集合叫做类型 T（或 T）的方法集。
<br>在面向对象的语言中，类拥有的方法一般被理解为类可以做的事情。在 Go 语言中“方法”的概念与其他语言一致，只是 Go 语言建立的“接收器”强调方法的作用对象是接收器，也就是类实例，而函数没有作用对象。<br>为结构体添加方法：<br>
需求：将物品放入背包
<br>面向对象的写法：<br>​ 将背包做为一个对象，将物品放入背包的过程作为“方法”<br>package main

import "fmt"

type Bag struct {
	items []int
}
func (b *Bag) Insert(itemid int) {
	b.items = append(b.items, itemid)
}
func main() {
	b := new(Bag)
	b.Insert(1001)
	fmt.Println(b.items)
}
复制<br>(b *Bag)  表示接收器，即 Insert 作用的对象实例。每个方法只能有一个接收器。<br><br>接收器的格式如下：<br>func (接收器变量 接收器类型) 方法名(参数列表) (返回参数) {
    函数体
}
复制<br>
<br>接收器变量：接收器中的参数变量名在命名时，官方建议使用接收器类型名的第一个小写字母，而不是 self、this 之类的命名。例如，Socket 类型的接收器变量应该命名为 s，Connector 类型的接收器变量应该命名为 c 等。
<br>接收器类型：接收器类型和参数类似，可以是指针类型和非指针类型。
<br>方法名、参数列表、返回参数：格式与函数定义一致。
<br>接收器根据接收器的类型可以分为 指针接收器、非指针接收器，两种接收器在使用时会产生不同的效果，根据效果的不同，两种接收器会被用于不同性能和功能要求的代码中。<br>指针类型的接收器:<br>指针类型的接收器由一个结构体的指针组成，更接近于面向对象中的 this 或者 self。<br>由于指针的特性，调用方法时，修改接收器指针的任意成员变量，在方法结束后，修改都是有效的。<br>示例：<br>使用结构体定义一个属性（Property），为属性添加 SetValue () 方法以封装设置属性的过程，通过属性的 Value () 方法可以重新获得属性的数值，使用属性时，通过 SetValue () 方法的调用，可以达成修改属性值的效果：<br>package main
import "fmt"
// 定义属性结构
type Property struct {
    value int  // 属性值
}
// 设置属性值
func (p *Property) SetValue(v int) {
    // 修改p的成员变量
    p.value = v
}
// 取属性值
func (p *Property) Value() int {
    return p.value
}
func main() {
    // 实例化属性
    p := new(Property)
    // 设置值
    p.SetValue(100)
    // 打印值
    fmt.Println(p.Value())
}
复制<br>非指针类型的接收器:<br>当方法作用于非指针接收器时，Go 语言会在代码运行时将接收器的值复制一份，在非指针接收器的方法中可以获取接收器的成员值，但 修改后无效。<br>点（Point）使用结构体描述时，为点添加 Add () 方法，这个方法不能修改 Point 的成员 X、Y 变量，而是在计算后返回新的 Point 对象，Point 属于小内存对象，在函数返回值的复制过程中可以极大地提高代码运行效率:<br>package main
import (
    "fmt"
)
// 定义点结构
type Point struct {
    X int
    Y int
}
// 非指针接收器的加方法
func (p Point) Add(other Point) Point {
    // 成员值与参数相加后返回新的结构
    return Point{p.X + other.X, p.Y + other.Y}
}
func main() {
    // 初始化点
    p1 := Point{1, 1}
    p2 := Point{2, 2}
    // 与另外一个点相加
    result := p1.Add(p2)
    // 输出结果
    fmt.Println(result)
}
复制<br>在计算机中，小对象由于值复制时的速度较快，所以适合使用非指针接收器，大对象因为复制性能较低，适合使用指针接收器，在接收器和参数间传递时不进行复制，只是传递指针。<br><br>在游戏中，一般使用二维矢量保存玩家的位置，使用矢量运算可以计算出玩家移动的位置，本例子中，首先实现二维矢量对象，接着构造玩家对象，最后使用矢量对象和玩家对象共同模拟玩家移动的过程。<br>实现二维矢量结构:<br>矢量是数学中的概念，二维矢量拥有两个方向的信息，同时可以进行加、减、乘（缩放）、距离、单位化等计算，在计算机中，使用拥有 X 和 Y 两个分量的 Vec 2 结构体实现数学中二维向量的概念。<br>package main
import "math"
type Vec2 struct {
    X, Y float32
}
// 加
func (v Vec2) Add(other Vec2) Vec2 {
    return Vec2{
        v.X + other.X,
        v.Y + other.Y,
    }
}
// 减
func (v Vec2) Sub(other Vec2) Vec2 {
    return Vec2{
        v.X - other.X,
        v.Y - other.Y,
    }
}
// 乘 缩放或者叫矢量乘法，是对矢量的每个分量乘上缩放比，Scale() 方法传入一个参数同时乘两个分量，表示这个缩放是一个等比缩放
func (v Vec2) Scale(s float32) Vec2 {
    return Vec2{v.X * s, v.Y * s}
}
// 距离 计算两个矢量的距离，math.Sqrt() 是开方函数，参数是 float64，在使用时需要转换，返回值也是 float64，需要转换回 float32
func (v Vec2) DistanceTo(other Vec2) float32 {
    dx := v.X - other.X
    dy := v.Y - other.Y
    return float32(math.Sqrt(float64(dx*dx + dy*dy)))
}
// 矢量单位化
func (v Vec2) Normalize() Vec2 {
    mag := v.X*v.X + v.Y*v.Y
    if mag &gt; 0 {
        oneOverMag := 1 / float32(math.Sqrt(float64(mag)))
        return Vec2{v.X * oneOverMag, v.Y * oneOverMag}
    }
    return Vec2{0, 0}
}
复制<br>实现玩家对象：<br>玩家对象负责存储玩家的当前位置、目标位置和速度，使用 MoveTo () 方法为玩家设定移动的目标，使用 Update () 方法更新玩家位置，在 Update () 方法中，通过一系列的矢量计算获得玩家移动后的新位置。<br>
<br>使用矢量减法，将目标位置（targetPos）减去当前位置（currPos）即可计算出位于两个位置之间的新矢量
<br>使用 Normalize () 方法将方向矢量变为模为 1 的单位化矢量，这里需要将矢量单位化后才能进行后续计算
<br>获得方向后，将单位化方向矢量根据速度进行等比缩放，速度越快，速度数值越大，乘上方向后生成的矢量就越长（模很大）
<br>将缩放后的方向添加到当前位置后形成新的位置
<br>package main
type Player struct {
    currPos   Vec2    // 当前位置
    targetPos Vec2    // 目标位置
    speed     float32 // 移动速度
}
// 移动到某个点就是设置目标位置
//逻辑层通过这个函数告知玩家要去的目标位置，随后的移动过程由 Update() 方法负责
func (p *Player) MoveTo(v Vec2) {
    p.targetPos = v
}
// 获取当前的位置
func (p *Player) Pos() Vec2 {
    return p.currPos
}

//判断玩家是否到达目标点，玩家每次移动的半径就是速度（speed），因此，如果与目标点的距离小于速度，表示已经非常靠近目标，可以视为到达目标。
func (p *Player) IsArrived() bool {
    // 通过计算当前玩家位置与目标位置的距离不超过移动的步长，判断已经到达目标点
    return p.currPos.DistanceTo(p.targetPos) &lt; p.speed
}
// 逻辑更新
func (p *Player) Update() {
    if !p.IsArrived() {
        // 计算出当前位置指向目标的朝向
        //数学中，两矢量相减将获得指向被减矢量的新矢量
        dir := p.targetPos.Sub(p.currPos).Normalize()
        // 添加速度矢量生成新的位置
        newPos := p.currPos.Add(dir.Scale(p.speed))
        // 移动完成后，更新当前位置
        p.currPos = newPos
    }
}
// 创建新玩家
func NewPlayer(speed float32) *Player {
    return &amp;Player{
        speed: speed,
    }
}
复制<br>处理移动逻辑：<br>将 Player 实例化后，设定玩家移动的最终目标点，之后开始进行移动的过程，这是一个不断更新位置的循环过程，每次检测玩家是否靠近目标点附近，如果还没有到达，则不断地更新位置，让玩家朝着目标点不停的修改当前位置，如下代码所示：<br>package main
import "fmt"

func main() {
	// 实例化玩家对象，并设速度为0.5
	p := NewPlayer(0.5)
	// 让玩家移动到3,1点
	p.MoveTo(Vec2{3, 1})
	// 如果没有到达就一直循环
	for !p.IsArrived() {
		// 更新玩家位置
		p.Update()
		// 打印每次移动后的玩家位置
		fmt.Println(p.Pos())
	}
	fmt.Printf("到达了：%v",p.Pos())
}
复制<br>给任意类型添加方法<br>Go 语言可以对任何类型添加方法，给一种类型添加方法就像给结构体添加方法一样，因为结构体也是一种类型。<br>为基本类型添加方法：<br>在 Go 语言中，使用 type 关键字可以定义出新的自定义类型，之后就可以为自定义类型添加各种方法了。我们习惯于使用面向过程的方式判断一个值是否为 0，例如：<br>if  v == 0 {
    // v等于0
}
复制<br>如果将 v 当做整型对象，那么判断 v 值就可以增加一个 IsZero () 方法，通过这个方法就可以判断 v 值是否为 0，例如：<br>if  v.IsZero() {
    // v等于0
}
复制<br>为基本类型添加方法的详细实现流程如下：<br>package main
import (
    "fmt"
)
// 将int定义为MyInt类型
type MyInt int
// 为MyInt添加IsZero()方法
func (m MyInt) IsZero() bool {
    return m == 0
}
// 为MyInt添加Add()方法
func (m MyInt) Add(other int) int {
    return other + int(m)
}
func main() {
    var b MyInt
    fmt.Println(b.IsZero())
    b = 1
    fmt.Println(b.Add(2))
}
复制<br><br>结构体可以包含匿名字段。匿名字段是指在结构体中声明的字段没有具体的字段名，只有字段的类型。<br>通过使用匿名字段，可以将其他类型的字段嵌入到结构体中，从而实现代码复用和组合的效果。这种方式有时也被称为"嵌入字段"或"嵌入结构体"。<br>Go 语言中的继承通常是通过内嵌或组合来实现的。<br>package main

import "fmt"

type User struct {
    id   int
    name string
}

type Manager struct {
    User
}

func (self *User) ToString() string { // receiver = &amp;(Manager.User)
    return fmt.Sprintf("User: %p, %v", self, self)
}

func main() {
    m := Manager{User{1, "Tom"}}
    fmt.Printf("Manager: %p\n", &amp;m)
    fmt.Println(m.ToString())
}
复制<br>类似于重写的功能：<br>package main

import "fmt"

type User struct {
    id   int
    name string
}

type Manager struct {
    User
    title string
}

func (self *User) ToString() string {
    return fmt.Sprintf("User: %p, %v", self, self)
}

func (self *Manager) ToString() string {
    return fmt.Sprintf("Manager: %p, %v", self, self)
}

func main() {
    m := Manager{User{1, "Tom"}, "Administrator"}

    fmt.Println(m.ToString())

    fmt.Println(m.User.ToString())
}
复制<br><br>在 Go 语言中接口（interface）是一种类型，一种抽象的类型。<br>Interface 是一组 method 的集合，接口做的事情就像是定义一个协议（规则），只要一台机器有洗衣服和甩干的功能，我就称它为洗衣机。不关心属性（数据），只关心行为（方法）。<br>接口（interface）是一种类型<br>接口类型是对其它类型行为的抽象和概括；因为接口类型不会和特定的实现细节绑定在一起，通过这种抽象的方式我们可以让我们的函数更加灵活和更具有适应能力。<br>接口是双方约定的一种合作协议。接口实现者不需要关心接口会被怎样使用，调用者也不需要关心接口的实现细节。接口是一种类型，也是一种抽象结构，不会暴露所含数据的格式、类型及结构。<br><br>
Go 语言提倡面向接口编程。
<br>每个接口类型由数个方法组成。接口的形式代码如下：<br>type 接口类型名 interface{
    方法名1( 参数列表1 ) 返回值列表1
    方法名2( 参数列表2 ) 返回值列表2
    …
}

//接口类型名：使用 type 将接口定义为自定义的类型名。Go 语言的接口在命名时，一般会在单词后面添加 er，如有写操作的接口叫 Writer，有字符串功能的接口叫 Stringer，有关闭功能的接口叫 Closer 等。
//方法名：当方法名首字母是大写时，且这个接口类型名首字母也是大写时，这个方法可以被接口所在的包（package）之外的代码访问。
//参数列表、返回值列表：参数列表和返回值列表中的参数变量名可以被忽略

复制<br>type Writer interface{
    //大写字母开头 意味着别的包 也可以访问
    Write([]byte) error
}
复制<br><br>在 Go 语言中，要实现一个接口，需要满足以下条件：<br>
<br>方法集匹配：类型必须实现接口中的所有方法。

<br>方法集是指类型中可以被直接调用的方法集合。如果一个任意类型 T 的方法集为一个接口类型的方法集的超集，则我们说类型 T 实现了此接口类型。
<br>T 可以是一个非接口类型，也可以是一个接口类型。


<br>隐式实现：Go 语言中没有类似于 implements 的关键字，接口的实现是隐式的，无需显式声明。只要类型的方法集匹配接口的方法集，就视为实现了该接口。
<br>示例：<br>package main
import (
    "fmt"
)
// 定义一个数据写入器
type DataWriter interface {
    WriteData(data interface{}) error
}
// 定义文件结构，用于实现DataWriter
type file struct {
}
// 实现DataWriter接口的WriteData方法
func (d *file) WriteData(data interface{}) error {
    // 模拟写入数据
    fmt.Println("WriteData:", data)
    return nil
}
func main() {
    // 实例化file
    f := new(file)
    // 声明一个DataWriter的接口
    var writer DataWriter
    // 将接口赋值f，也就是*file类型
    writer = f
    // 使用DataWriter接口进行数据写入
    writer.WriteData("data")
}
复制<br>接口定义后，需要实现接口，才能正确编译通过并使用接口。<br>❶ 实现方法必须和接口方法格式完全一致<br>
在类型中添加与接口签名一致的方法就可以实现该方法。签名包括方法中的名称、参数列表、返回参数列表。<br>
只要实现接口类型中的方法的名称、参数列表、返回参数列表中的任意一项与接口要实现的方法不一致，那么接口的这个方法就不会被实现。<br>示例：<br>package main  
  
import "fmt"  
  
type Printer interface {  
    Print(message string)  
}  
  
type MyPrinter struct{}  
  
// 错误的实现方法，参数列表不匹配  
func (mp MyPrinter) Print() {  
    fmt.Println("Printing...")  
}  
  
func main() {  
    var p Printer  
    p = MyPrinter{} // 编译错误：MyPrinter.Print method has different signature than Printer.Print  
    p.Print("Hello")  
}
复制<br>❷ 必须实现接口所有方法<br>
当一个接口中有多个方法时，只有这些方法都被实现了，接口才能被正确编译并使用。<br>type DataWriter interface {  
    WriteData(data interface{}) error  
}  
  
type FileWriter struct {  
    FilePath string  
}  

//func (f FileWriter) WriteData(data interface{}) error {  
//  //TODO implement me  
//  panic("implement me")  
//}
  
func main() {  
    var writer DataWriter  
    writer = FileWriter{FilePath: "data.txt"} // 编译错误：FileWriter does not implement DataWriter (missing WriteData method)  
    err := writer.WriteData("Hello")  
    if err != nil {  
       return  
    }  
}
复制<br>但是如果 main 方法根本没有使用到接口，那不会编译报错。 <br>package main  
  
import "fmt"  

//此接口根本没有人用
type DataWriter interface {  
    WriteData(data interface{}) error  
}  
  
type FileWriter struct {  
    FilePath string  
}  
  
func main() {  
    var writer FileWriter  
    writer = FileWriter{FilePath: "data.txt"} // 编译错误：FileWriter does not implement DataWriter (missing WriteData method)  
    fmt.Print(writer)  
}
复制<br><br>
在 Go 语言中类型和接口之间有一对多和多对一的关系
<br>❶ 一个类型可以实现多个接口<br>一个类型可以同时实现多个接口，而接口间彼此独立，不知道对方的实现。<br>例如，狗可以叫，也可以动。<br>我们就分别定义 Sayer 接口和 Mover 接口，如下：<br>// Sayer 接口
type Sayer interface {
    say()
}

// Mover 接口
type Mover interface {
    move()
}
复制<br>Dog 既可以实现 Sayer 接口，也可以实现 Mover 接口。<br>type dog struct {
    name string
}

// 实现Sayer接口
func (d dog) say() {
    fmt.Printf("%s会叫汪汪汪\n", d.name)
}

// 实现Mover接口
func (d dog) move() {
    fmt.Printf("%s会动\n", d.name)
}

func main() {
    var x Sayer
    var y Mover

    var a = dog{name: "旺财"}
    x = a
    y = a
    x.say()
    y.move()
}
复制<br>❷ 多个类型实现同一接口<br>Go 语言中不同的类型还可以实现同一接口首先我们定义一个 Mover 接口，它要求必须有一个 move 方法。<br>// Mover 接口
type Mover interface {
    move()
}
复制<br>例如狗可以动，汽车也可以动，可以使用如下代码实现这个关系：<br>type dog struct {
    name string
}

type car struct {
    brand string
}

// dog类型实现Mover接口
func (d dog) move() {
    fmt.Printf("%s会跑\n", d.name)
}

// car类型实现Mover接口
func (c car) move() {
    fmt.Printf("%s速度70迈\n", c.brand)
}
复制<br>这个时候我们在代码中就可以把狗和汽车当成一个会动的物体来处理了，不再需要关注它们具体是什么，只需要调用它们的 move 方法就可以了。<br>func main() {
    var x Mover
    var a = dog{name: "旺财"}
    var b = car{brand: "保时捷"}
    x = a
    x.move()
    x = b
    x.move()
}
复制<br>并且一个接口的方法，不一定需要由一个类型完全实现，接口的方法可以通过在类型中嵌入其他类型或者结构体来实现。<br>// WashingMachine 洗衣机
type WashingMachine interface {
    wash()
    dry()
}

// 甩干器
type dryer struct{}

// 实现WashingMachine接口的dry()方法
func (d dryer) dry() {
    fmt.Println("甩一甩")
}

// 海尔洗衣机
type haier struct {
    dryer //嵌入甩干器
}

// 实现WashingMachine接口的wash()方法
func (h haier) wash() {
    fmt.Println("洗刷刷")
}
复制<br>❸ 接口嵌套<br>接口与接口间可以通过嵌套创造出新的接口<br>// Sayer 接口
type Sayer interface {
    say()
}

// Mover 接口
type Mover interface {
    move()
}

// 接口嵌套
type animal interface {
    Sayer
    Mover
}
复制<br>嵌套得到的接口的使用与普通接口一样，这里我们让 cat 实现 animal 接口：<br>type cat struct {
    name string
}

func (c cat) say() {
    fmt.Println("喵喵喵")
}

func (c cat) move() {
    fmt.Println("猫会动")
}

func main() {
    var x animal
    x = cat{name: "花花"}
    x.move()
    x.say()
}
复制<br><br>空接口是指没有定义任何方法的接口，因此任何类型都实现了空接口。<br>
可以接收任意类型的值作为参数，可以存储任意类型的变量。<br>
类似于其他编程语言中的泛型概念。
<br>func main() {
    // 定义一个空接口x
    var x interface{}
    s := "码神之路"
    x = s
    fmt.Printf("type:%T value:%v\n", x, x)
    i := 100
    x = i
    fmt.Printf("type:%T value:%v\n", x, x)
    b := true
    x = b
    fmt.Printf("type:%T value:%v\n", x, x)
}
复制<br><br>空接口作为函数的参数<br>使用空接口实现可以接收任意类型的函数参数。<br>// 空接口作为函数参数
func show(a interface{}) {
    fmt.Printf("type:%T value:%v\n", a, a)
}
复制<br>空接口作为 map 的值<br>使用空接口实现可以保存任意值的字典。<br>// 空接口作为map值
    var studentInfo = make(map[string]interface{})
    studentInfo["name"] = "李白"
    studentInfo["age"] = 18
    studentInfo["married"] = false
    fmt.Println(studentInfo)
复制<br><br>空接口可以存储任意类型的值，那我们如何获取其存储的具体数据呢？<br>接口值<br>一个接口的值（简称接口值）是由一个具体类型和具体类型的值两部分组成的。<br>这两部分分别称为 接口的动态类型 和 动态值。<br>想要判断空接口中的值这个时候就可以使用类型断言，其语法格式：<br>x.(T)
复制<br>其中：<br>
<br>X：表示类型为 interface{}的变量
<br>T：表示断言 x 可能是的类型。
<br>该语法返回两个参数，第一个参数是 x 转化为 T 类型后的变量，第二个值是一个布尔值，若为 true 则表示断言成功，为 false 则表示断言失败。<br>func main() {
 var x interface{}
 x = "码神之路"
 v, ok := x.(string)
 if ok {
     fmt.Println(v)
 } else {
     fmt.Println("类型断言失败")
 }
}
复制<br>上面的示例中如果要断言多次就需要写多个 if 判断，这个时候我们可以使用 switch 语句来实现：<br>func justifyType(x interface{}) {
    switch v := x.(type) {
    case string:
        fmt.Printf("x is a string，value is %v\n", v)
    case int:
        fmt.Printf("x is a int is %v\n", v)
    case bool:
        fmt.Printf("x is a bool is %v\n", v)
    default:
        fmt.Println("unsupport type！")
    }
}
复制<br>因为空接口可以存储任意类型值的特点，所以空接口在 Go 语言中的使用十分广泛。<br>
关于接口需要注意的是，只有当有两个或两个以上的具体类型必须以相同的方式进行处理时才需要定义接口。不要为了接口而写接口，那样只会增加不必要的抽象，导致不必要的运行时损耗。
]]></description><link>02、多编程语言\03、go语言\01、go语言基础\05、面向对象.html</link><guid isPermaLink="false">02、多编程语言/03、Go语言/01、Go语言基础/05、面向对象.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:45 GMT</pubDate></item><item><title><![CDATA[06、异常处理]]></title><description><![CDATA[ 
 <br>
Go 语言中使用 panic 抛出错误，recover 捕获错误。
<br>异常的使用场景简单描述：Go 中可以抛出一个 panic 的异常，然后在 defer 中通过 recover 捕获这个异常，然后正常处理。<br>panic：<br>
<br>内置函数
<br>假如函数 F 中书写了 panic 语句，会终止其后要执行的代码，在 panic 所在函数 F 内如果存在要执行的 defer 函数列表，按照 defer 的逆序执行
<br>返回函数 F 的调用者 G，在 G 中，调用函数 F 语句之后的代码不会执行，假如函数 G 中存在要执行的 defer 函数列表，按照 defer 的逆序执行
<br>直到 goroutine 整个退出，并报告错误
<br>recover：<br>
<br>内置函数
<br>用来捕获 panic，从而影响应用的行为
<br>
Golang 的错误处理流程：当一个函数在执行过程中出现了异常或遇到 panic ()，正常语句就会立即终止，然后执行 defer 语句，再报告异常信息，最后退出 goroutine。如果在 defer 中使用了 recover () 函数, 则会捕获错误信息，使该错误信息终止报告。
<br>注意:<br>
<br>利用 recover 处理 panic 指令，defer 必须放在 panic 之前定义，另外 recover 只有在 defer 调用的函数中才有效。否则当 panic 时，recover 无法捕获到 panic，无法防止 panic 扩散。
<br>Recover 处理异常后，逻辑并不会恢复到 panic 那个点去，函数跑到 defer 之后的那个点。
<br>多个 defer 会形成 defer 栈，后定义的 defer 语句会被最先调用。
<br>package main

func main() {
    test()
}

func test() {
    defer func() {
        if err := recover(); err != nil {
            println(err.(string)) // 将 interface{} 转型为具体类型。
        }
    }()

    panic("panic error!")
}
复制<br>由于 panic、recover 参数类型为 interface{}，因此可抛出任何类型对象。<br> func panic(v interface{})
 func recover() interface{}
复制<br>延迟调用中引发的错误，可被后续延迟调用捕获，但仅最后一个错误可被捕获:<br>package main

import "fmt"

func test() {
    defer func() {
        // defer panic 会打印
        fmt.Println(recover())
    }()

    defer func() {
        panic("defer panic")
    }()

    panic("test panic")
}

func main() {
    test()
}
复制<br>如果需要保护代码段，可将代码块重构成匿名函数，如此可确保后续代码被执 ：<br>package main

import "fmt"

func test(x, y int) {
    var z int

    func() {
        defer func() {
            if recover() != nil {
                z = 0
            }
        }()
        panic("test panic")
        z = x / y
        return
    }()

    fmt.Printf("x / y = %d\n", z)
}

func main() {
    test(2, 1)
}
复制<br>除用 panic 引发中断性错误外，还可返回 error 类型错误对象来表示函数调用状态:<br>type error interface {
    Error() string
}
复制<br>标准库 errors.New 和 fmt.Errorf 函数用于创建实现 error 接口的错误对象。通过判断错误对象实例来确定具体错误类型。<br>package main

import (
    "errors"
    "fmt"
)

var ErrDivByZero = errors.New("division by zero")

func div(x, y int) (int, error) {
    if y == 0 {
        return 0, ErrDivByZero
    }
    return x / y, nil
}

func main() {
    defer func() {
        fmt.Println(recover())
    }()
    switch z, err := div(10, 0); err {
    case nil:
        println(z)
    case ErrDivByZero:
        panic(err)
    }
}
复制<br>Go 实现类似 try catch 的异常处理:<br>package main

import "fmt"

func Try(fun func(), handler func(interface{})) {
    defer func() {
        if err := recover(); err != nil {
            handler(err)
        }
    }()
    fun()
}

func main() {
    Try(func() {
        panic("test panic")
    }, func(err interface{}) {
        fmt.Println(err)
    })
}
复制<br>如何区别使用 panic 和 error 两种方式?<br>惯例是: 导致关键流程出现不可修复性错误的使用 panic，其他使用 error。]]></description><link>02、多编程语言\03、go语言\01、go语言基础\06、异常处理.html</link><guid isPermaLink="false">02、多编程语言/03、Go语言/01、Go语言基础/06、异常处理.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:45 GMT</pubDate></item><item><title><![CDATA[07、包管理]]></title><description><![CDATA[ 
 <br><br>Go 语言是使用包来组织和封装代码的，包（package）是多个 Go 源码的集合，是一组相关的函数、变量、类型和其他代码的集合，以便在程序中进行模块化和重用。<br>Go 语言中为我们提供了很多内置包，如 fmt、os、io 等。<br><br>使用事项：<br>
<br>任何源代码文件必须属于某个包。
<br>同时源码文件的第一行有效代码必须是 package pacakgeName 语句（通过该语句声明自己所在的包）。
<br>为了代码的清晰性和一致性，建议包名与所在目录名保持一致（Go 语言没有强制要求包名必须和其所在的目录名同名）
<br>包可以定义在很深的目录中，包名的定义是不包括目录路径的，但是包在引用时一般使用全路径引用。
<br>一个文件夹下的所有源码文件只能属于同一个包，同样属于同一个包的源码文件不能放在多个文件夹下。
<br>命名规范：<br>
<br>包名一般是小写的，使用一个简短且有意义的名称。
<br>包名一般要和所在的目录同名（虽可以不同），推荐使用小写字母和单词之间的下划线（snake_case）来命名包，包名中不能包含 - 等其他特殊符号。
<br>包名为 main 的包为应用程序的入口包，编译不包含 main 包的源码文件时不会得到可执行文件。
<br><br>要在代码中引用其他包的内容，需要使用 import 关键字导入使用的包。具体语法如下：<br>import "包的路径"
复制<br>注意事项：<br>
<br>Import 导入语句通常放在源码文件开头包声明语句的下面；
<br>导入的包名需要使用双引号包裹起来；
<br>包的导入有两种写法，分别是单行导入和多行导入。<br>单行导入<br>import "包 1 的路径"
import "包 2 的路径"
复制<br>多行导入<br>import (
    "包 1 的路径"
    "包 2 的路径"
)
复制<br><br>包的绝对路径就是 GOROOT/src/ 或 GOPATH 后面包的存放路径，如下所示：<br>import "lab/test"
import "database/sql/driver"
import "database/sql"
复制<br>上面代码的含义如下：<br>
<br>test 包是自定义的包，其源码位于 GOPATH/lab/test 目录下；
<br>driver 包的源码位于 GOROOT/src/database/sql/driver 目录下；
<br>sql 包的源码位于 GOROOT/src/database/sql 目录下。
<br><br>包的引用有四种格式，下面以 fmt 包为例来分别演示一下这四种格式。<br>
<br>
标准引用格式
```go
复制
import "fmt"<br>
```
此时可以用 `fmt.` 作为前缀来使用 fmt 包中的方法，这是常用的一种方式。

```go
复制
package main<br>
import "fmt"<br>
func main() {<br>
fmt.Println("码神之路")<br>
}<br>
```<br>


<br>
自定义别名引用格式
在导入包的时候，我们还可以为导入的包设置别名，如下所示：
import F "fmt"
复制
其中 F 就是 fmt 包的别名，使用时我们可以使用 F. 来代替标准引用格式的 fmt. 来作为前缀使用 fmt 包中的方法
package main
import F "fmt"
func main() {
    F.Println("码神之路")
}
复制

<br>
省略引用格式
import . "fmt"
复制
这种格式相当于把 fmt 包直接合并到当前程序中，在使用 fmt 包内的方法是可以不用加前缀 fmt.，直接引用。
package main
import . "fmt"
func main() {
    //不需要加前缀 fmt.
    Println("码神之路")
}
复制

<br>
匿名引用格式
在引用某个包时，如果只是希望执行包初始化的 init 函数，而不使用包内部的数据时，可以使用匿名引用格式，如下所示：
import _ "fmt"
复制
匿名导入的包与其他方式导入的包一样都会被编译到可执行文件中。
使用标准格式引用包，但是代码中却没有使用包，编译器会报错。如果包中有 init 初始化函数，则通过 import _ "包的路径" 这种方式引用包，仅执行包的初始化函数，即使包没有 init 初始化函数，也不会引发编译器报错。
package main
import (
    _ "database/sql"
    "fmt"
)
func main() {
    fmt.Println("码神之路")
}
复制

<br>注意：<br>
<br>一个包可以有多个 init 函数，包加载时会执行全部的 init 函数，但并不能保证执行顺序，所以不建议在一个包中放入多个 init 函数，将需要初始化的逻辑放到一个 init 函数里面。
<br>包不能出现环形引用的情况，比如包 a 引用了包 b，包 b 引用了包 c，如果包 c 又引用了包 a，则编译不能通过。
<br>包的重复引用是允许的，比如包 a 引用了包 b 和包 c，包 b 和包 c 都引用了包 d。这种场景相当于重复引用了 d，这种情况是允许的，并且 Go 编译器保证包 d 的 init 函数只会执行一次。
<br><br>Go module 是 Go 语言从 1.11 版本之后官方推出的版本管理工具，并且从 Go 1.13 版本开始，go module 成为了 Go 语言默认的依赖管理工具。<br>Modules 官方定义为：<br>
Modules 是相关 Go 包的集合，是源代码交换和版本控制的单元。Go 语言命令直接支持使用 Modules，包括记录和解析对其他模块的依赖性，Modules 替换旧的基于 GOPATH 的方法，来指定使用哪些源文件。
<br><br>使用 go module 之前需要设置环境变量：<br>
<br>GO 111 MODULE=on
<br>GOPROXY= <a data-tooltip-position="top" aria-label="https://goproxy.io%2cdirect/" rel="noopener" class="external-link" href="https://goproxy.io%2cdirect/" target="_blank">https://goproxy.io,direct</a>
<br>GOPROXY= <a rel="noopener" class="external-link" href="https://goproxy.cn" target="_blank">https://goproxy.cn</a> , direct (国内的七牛云提供)
<br>GO 111 MODULE 有三个值：off, on 和 auto（默认值）。<br>
<br>GO 111 MODULE=off，go 命令行将不会支持 module 功能，寻找依赖包的方式将会沿用旧版本那种通过 vendor 目录或者 GOPATH 模式来查找。
<br>GO 111 MODULE=on，go 命令行会使用 modules，而一点也不会去 GOPATH 目录下查找。
<br>GO 111 MODULE=auto，默认值，go 命令行将会根据当前目录来决定是否启用 module 功能。这种情况下可以分为两种情形：

<br>当前目录在 GOPATH 之外且该目录包含 go. Mod 文件开启
<br>当处于 GOPATH 内且没有 go. Mod 文件存在时其行为会等同于 GO 111 MODULE=off


<br>如果不使用 Go Modules, go get 将会从模块代码的 master 分支拉取
<br>而若使用 Go Modules 则你可以利用 Git Tag 手动选择一个特定版本的模块代码
<br><br>go mod 有以下命令：<br><br>
<br>常用的有 init tdiy edit
<br>使用 go get 命令下载指定版本的依赖包：<br>执行 go get 命令，在下载依赖包的同时还可以指定依赖包的版本。<br>
<br>运行 go get -u 命令会将项目中的包升级到最新的次要版本或者修订版本；
<br>运行 go get -u=patch 命令会将项目中的包升级到最新的修订版本；
<br>运行 go get [包名]@[版本号] 命令会下载对应包的指定版本或者将对应包升级到指定的版本。
<br>
提示：go get [包名]@[版本号] 命令中版本号可以是 x.y.z 的形式，例如 go get <a data-tooltip-position="top" aria-label="mailto:foo@v1.2.3" rel="noopener" class="external-link" href="mailto:foo@v1.2.3" target="_blank">foo@v1.2.3</a> ，也可以是 git 上的分支或 tag，例如 go get foo@master ，还可以是 git 提交时的哈希值，例如 go get foo@e3702bed2 。
<br><br>
<br>
在 GOPATH 目录下新建一个目录，并使用 go mod init 初始化生成 go. Mod 文件。
go. Mod 文件一旦创建后，它的内容将会被 go toolchain 全面掌控，go toolchain 会在各类命令执行时，比如 go get、go build、go mod 等修改和维护 go. Mod 文件。
Go. Mod 提供了 module、require、replace 和 exclude 四个命令：

<br>Module 语句指定包的名字（路径）；
<br>Require 语句指定的依赖项模块；
<br>Replace 语句可以替换依赖项模块；
<br>Exclude 语句可以忽略依赖项模块。

初始化生成的 go. Mod 文件如下所示：
module hello

go 1.13
复制

<br>
添加依赖。
新建一个 main. Go 文件，写入以下代码：
package main
import (
    "net/http"
    "github.com/labstack/echo"
)
func main() {
    e := echo.New()
    e.GET("/", func(c echo.Context) error {
        return c.String(http.StatusOK, "Hello, World!")
    })
    e.Logger.Fatal(e.Start(":1323"))
}
复制
执行 go mod tidy 运行代码会发现 go mod 会自动查找依赖自动下载
go: finding module for package github.com/labstack/echo
go: found github.com/labstack/echo in github.com/labstack/echo v3.3.10+incompatible
go: finding module for package github.com/stretchr/testify/assert
go: finding module for package github.com/labstack/gommon/log
go: finding module for package github.com/labstack/gommon/color
go: finding module for package golang.org/x/crypto/acme/autocert
go: found github.com/labstack/gommon/color in github.com/labstack/gommon v0.3.1
go: found github.com/labstack/gommon/log in github.com/labstack/gommon v0.3.1
go: found golang.org/x/crypto/acme/autocert in golang.org/x/crypto v0.0.0-20220112180741-5e0467b6c7ce
go: found github.com/stretchr/testify/assert in github.com/stretchr/testify v1.7.0

复制
Go. Mod 中的内容：
module learning09

go 1.17

require github.com/labstack/echo v3.3.10+incompatible

require (
	github.com/labstack/gommon v0.3.1 // indirect
	github.com/mattn/go-colorable v0.1.11 // indirect
	github.com/mattn/go-isatty v0.0.14 // indirect
	github.com/valyala/bytebufferpool v1.0.0 // indirect
	github.com/valyala/fasttemplate v1.2.1 // indirect
	golang.org/x/crypto v0.0.0-20220112180741-5e0467b6c7ce // indirect
	golang.org/x/net v0.0.0-20211112202133-69e39bad7dc2 // indirect
	golang.org/x/sys v0.0.0-20211103235746-7861aae1554b // indirect
	golang.org/x/text v0.3.6 // indirect
)

复制
go module 安装 package 的原则是先拉取最新的 release tag，若无 tag 则拉取最新的 commit
Go 会自动生成一个 go. Sum 文件来记录 dependency tree。
执行脚本 go run main.go，就可以运行项目。
可以使用命令 go list -m -u all 来检查可以升级的 package，使用 go get -u need-upgrade-package 升级后会将新的依赖版本更新到 go. Mod ，
比如：go get -u github.com/labstack/gommon
也可以使用 go get -u 升级所有依赖。

<br>
一般使用包之前，是首先执行 go get 命令，先下载依赖。比如 github.com/labstack/echo

<br>使用 replace 替换无法直接获取的 package：<br>由于某些已知的原因，并不是所有的 package 都能成功下载，比如：golang. Org 下的包。<br>Modules 可以通过在 go. Mod 文件中使用 replace 指令替换成 github 上对应的库，比如：<br>replace (
    golang.org/x/crypto v0.0.0-20190313024323-a1f597ede03a =&gt; github.com/golang/crypto v0.0.0-20190313024323-a1f597ede03a
)
复制<br>或者<br>replace golang.org/x/crypto v0.0.0-20190313024323-a1f597ede03a =&gt; github.com/golang/crypto v0.0.0-20190313024323-a1f597ede03a
复制<br>
go install 命令将项目打包安装为可执行文件，在安装在 GOPATH 的 bin 目录下，go install 执行的项目必须有 main 方法
<br><br>Go 语言提供了一种根据文件后缀名自动选择不同平台实现的机制。这个机制被称为"Build Constraints"（构建约束）。<br>示例：创建多个不同平台的文件：<br># 文件名: platform_impl_windows.go
package main

import "fmt"

func main() {
    fmt.Println("Running on Windows")
}
复制<br># 文件名: platform_impl_linux.go
package main

import "fmt"

func main() {
    fmt.Println("Running on Linux")
}
复制<br># 文件名: platform_impl_darwin.go
package main

import "fmt"

func main() {
    fmt.Println("Running on macOS")
}
复制<br>执行程序时，Go 编译器会根据当前操作系统的不同选择性地编译和执行对应的文件：<br>go run main.go
复制<br>在这个示例中，根据文件名后缀自动选择了不同平台的文件进行编译。根据当前操作系统的不同，将使用对应的文件进行编译和执行。]]></description><link>02、多编程语言\03、go语言\01、go语言基础\07、包管理.html</link><guid isPermaLink="false">02、多编程语言/03、Go语言/01、Go语言基础/07、包管理.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:45 GMT</pubDate></item><item><title><![CDATA[100、Go语言基础]]></title><description><![CDATA[ 
 <br><br><br>
<br>官网下载-安装到D盘-下一步-安装成功
<br>配置环境变量
<br>在变量中添加--用于go全局命令
GOROOT
D:\go

在变量path中添加--用bin下的一堆命令
%GOROOT%\bin

在变量中添加--工程目录 
GOPATH
D:\go_project

在变量中添加--go代理
GOPOXY
HTTPS://goproxy.io.direct
https://proxy.golang.com.cn,direct

地址：https://goproxy.io/zh 可以看文档
复制<br><br><br>
类型别名是 Go 1.9 版本添加的新功能，主要用于解决代码升级、迁移中存在的类型兼容性问题。
<br>格式：<br>//TypeAlias 只是 Type 的别名，本质上 TypeAlias 与 Type 是同一个类型，就像一个孩子小时候有小名、乳名，上学后用学名，英语老师又会给他起英文名，但这些名字都指的是他本人。
type TypeAlias = Type
复制<br>还有一种是类型定义：<br>//定义Name为Type类型 ,定义之后 Name为一种新的类型
type Name Type
复制<br>类型别名与类型定义表面上看只有一个等号的差异，那么它们之间实际的区别有哪些呢？<br>package main
import (
    "fmt"
)
// 将NewInt定义为int类型
type NewInt int
// 将int取一个别名叫IntAlias
type IntAlias = int
func main() {
    // 将a声明为NewInt类型
    var a NewInt
    // 查看a的类型名 main.NewInt
    fmt.Printf("a type: %T\n", a)
    // 将a2声明为IntAlias类型
    var a2 IntAlias
    // 查看a2的类型名 int 
    //IntAlias 类型只会在代码中存在，编译完成时，不会有 IntAlias 类型。
    fmt.Printf("a2 type: %T\n", a2)
}
复制<br><br>
​ //捕获标准输入，并转换为字符串<br>
​ reader := bufio.NewReader(os.Stdin)<br>
​ input, err := reader.ReadString('\n')
​ if err != nil {
​ //如果有错误 退出
​ panic(err)<br>
​ }
需求：能打怪升级
<br>package main

import (
 "bufio"
 "fmt"
 "os"
)

var level = 1
var ex = 0
func main()  {
 fmt.Println("请输入你的角色名字")
 //捕获标准输入，并转换为字符串
 reader := bufio.NewReader(os.Stdin)
 input, err := reader.ReadString('\n')
 if err != nil {
 	panic(err)
 }
 //删除最后的\n
 name := input[:len(input)-1]
 fmt.Printf("角色创建成功,%s,欢迎你来到码神游戏,目前角色等级%d \n",name,level)
 s := `你遇到了一个怪物，请选择是战斗还是逃跑?
 1.战斗
 2.逃跑`
 fmt.Printf("%s \n",s)
 for {
 	input, err := reader.ReadString('\n')
 	if err != nil {
 		panic(err)
 	}
 	selector := input[:len(input)-1]
 	switch selector {
 	case "1":
 		ex += 10
 		fmt.Printf("杀死了怪物，获得了%d经验 \n",ex)
 		computeLevel()
 		fmt.Printf("您现在的等级为%d \n",level)
 	case "2":
 		fmt.Printf("你选择了逃跑\n")
 		fmt.Printf("%s \n",s)
 	case "exit":
 		fmt.Println("你退出了游戏")
 		//退出
 		os.Exit(1)
 	default:
 		fmt.Println("你的输入我不认识，请重新输入")
 	}
 }
}

func computeLevel() {
 if ex &lt; 20 {
 	level = 1
 }else if ex &lt; 40{
 	level = 2
 }else if ex &lt; 200{
 	level = 3
 }else {
 	level = 4
 }
}

复制<br><br><br>I/O操作也叫输入输出操作。其中I是指Input，O是指Output，用于读或者写数据的，有些语言中也叫流操作，是指数据通信的通道。<br>Golang 标准库对 IO 的抽象非常精巧，各个组件可以随意组合，可以作为接口设计的典范。<br>io包中提供I/O原始操作的一系列接口。<br>它主要包装了一些已有的实现，如 os 包中的那些，并将这些抽象成为实用性的功能和一些其他相关的接口。<br>由于这些接口和原始的操作以不同的实现包装了低级操作，客户不应假定它们对于并行执行是安全的。<br>io库比较常用的接口有三个，分别是Reader，Writer和Closer。<br><br>Reader接口的定义，Read()方法用于读取数据。<br>type Reader interface {
        Read(p []byte) (n int, err error)
}
复制<br>io.Reader 表示一个读取器，它将数据从某个资源读取到传输缓冲区。在缓冲区中，数据可以被流式传输和使用。<br>
<br>对于要用作读取器的类型，它必须实现 io.Reader 接口的唯一一个方法 Read(p []byte)。
<br>换句话说，只要实现了 Read(p []byte) ，那它就是一个读取器。
<br>Read() 方法有两个返回值，一个是读取到的字节数，一个是发生错误时的错误。
<br>通过 string.NewReader(string) 创建一个字符串读取器，然后流式地按字节读取：<br>package main

import (
	"io"
	"log"
	"os"
	"strings"
)

func main() {

	reader := strings.NewReader("mszlu test123 123")
	// 每次读取4个字节
	p := make([]byte, 4)
	for {

		n, err := reader.Read(p)
		if err != nil {
			if err == io.EOF {
				log.Printf("读完了:eof错误 :%d", n)
				break
			}
			log.Printf("其他错误:%v", err)
			os.Exit(2)
		}
		log.Printf("[读取到的字节数为:%d][内容:%v]", n, string(p[:n]))
	}

}
复制<br> [读取到的字节数为:4][内容:mszl]
 [读取到的字节数为:4][内容:u te]
 [读取到的字节数为:4][内容:st12]
 [读取到的字节数为:4][内容:3 12]
 [读取到的字节数为:1][内容:3]
 读完了:eof错误 :0
复制<br>
<br>最后一次返回的 n 值有可能小于缓冲区大小。
<br>io.EOF 来表示输入流已经读取到头
<br>strings.Reader.Read方法:<br>func (r *Reader) Read(b []byte) (n int, err error) {
	if r.i &gt;= int64(len(r.s)) {
		return 0, io.EOF
	}
	r.prevRune = -1
	n = copy(b, r.s[r.i:])
	r.i += int64(n)
	return
}
复制<br><br>
<br>
  func Create(name string) (file *File, err Error)
复制

<br>根据提供的文件名创建新的文件，返回一个文件对象，默认权限是0666


<br>
  func NewFile(fd uintptr, name string) *File
复制

<br>根据文件描述符创建相应的文件，返回一个文件对象


<br>
  func Open(name string) (file *File, err Error)
复制

<br>只读方式打开一个名称为name的文件


<br>
  func OpenFile(name string, flag int, perm uint32) (file *File, err Error)
复制

<br>打开名称为name的文件，flag是打开的方式，只读、读写等，perm是权限


<br>
  func (file *File) Write(b []byte) (n int, err Error)
复制

<br>写入byte类型的信息到文件


<br>
  func (file *File) WriteAt(b []byte, off int64) (n int, err Error)
复制

<br>在指定位置开始写入byte类型的信息


<br>
  func (file *File) WriteString(s string) (ret int, err Error)
复制

<br>写入string信息到文件


<br>
  func (file *File) Read(b []byte) (n int, err Error)
复制

<br>读取数据到b中


<br>
  func (file *File) ReadAt(b []byte, off int64) (n int, err Error)
复制

<br>从off开始读取数据到b中


<br>
  func Remove(name string) Error
复制

<br>删除文件名为name的文件


<br><br>type Closer interface {
    Close() error
}
复制<br>os.Open()函数能够打开一个文件，返回一个*File和一个err。对得到的文件实例调用Close()方法能够关闭文件。<br>文件读取可以用file.Read()，读到文件末尾会返回io.EOF的错误<br>package main

import (
    "fmt"
    "io"
    "os"
)

func main() {
    // 打开文件
    file, err := os.Open("./xxx.txt")
    if err != nil {
        fmt.Println("open file err :", err)
        return
    }
    defer file.Close()
    // 定义接收文件读取的字节数组
    var buf [128]byte
    var content []byte
    for {
        n, err := file.Read(buf[:])
        if err == io.EOF {
            // 读取结束
            break
        }
        if err != nil {
            fmt.Println("read file err ", err)
            return
        }
        content = append(content, buf[:n]...)
    }
    fmt.Println(string(content))
}
复制<br><br>type Writer interface {
    //Write() 方法有两个返回值，一个是写入到目标资源的字节数，一个是发生错误时的错误。
    Write(p []byte) (n int, err error)
}
复制<br>
<br>io.Writer 表示一个写入器，它从缓冲区读取数据，并将数据写入目标资源。
<br>对于要用作编写器的类型，必须实现 io.Writer 接口的唯一一个方法 Write(p []byte)
<br>同样，只要实现了 Write(p []byte) ，那它就是一个编写器。
<br>写文件：<br>package main

import (
    "fmt"
    "os"
)

func main() {
    // 新建文件
    file, err := os.Create("./test.txt")
    if err != nil {
        fmt.Println(err)
        return
    }
    defer file.Close()
    for i := 0; i &lt; 5; i++ {
        file.WriteString("ab\n")
        file.Write([]byte("cd\n"))
    }
}
复制<br><br>
<br>bufio包实现了带缓冲区的读写，是对文件读写的封装
<br>bufio缓冲写数据
<br><br>bufio读写数据<br>package main

import (
    "bufio"
    "fmt"
    "io"
    "os"
)

func wr() {
    // 参数2：打开模式，所有模式d都在上面
    // 参数3是权限控制
    // w写 r读 x执行   w  2   r  4   x  1
    //特殊权限位，拥有者位，同组用户位，其余用户位
    file, err := os.OpenFile("./xxx.txt", os.O_CREATE|os.O_WRONLY, 0666)
    if err != nil {
        return
    }
    defer file.Close()
    // 获取writer对象
    writer := bufio.NewWriter(file)
    for i := 0; i &lt; 10; i++ {
        writer.WriteString("hello\n")
    }
    // 刷新缓冲区，强制写出
    writer.Flush()
}

func re() {
    file, err := os.Open("./xxx.txt")
    if err != nil {
        return
    }
    defer file.Close()
    reader := bufio.NewReader(file)
    for {
        line, _, err := reader.ReadLine()
        if err == io.EOF {
            break
        }
        if err != nil {
            return
        }
        fmt.Println(string(line))
    }

}

func main() {
    re()
}
复制<br><br>
<br>ioutil库包含在io目录下，它的主要作用是作为一个工具包，里面有一些比较实用的函数
<br>比如 ReadAll(从某个源读取数据)、ReadFile（读取文件内容）、WriteFile（将数据写入文件）、ReadDir（获取目录）
<br>package main

import (
   "fmt"
   "io/ioutil"
)

func wr() {
   err := ioutil.WriteFile("./yyy.txt", []byte("码神之路"), 0666)
   if err != nil {
      fmt.Println(err)
      return
   }
}

func re() {
   content, err := ioutil.ReadFile("./yyy.txt")
   if err != nil {
      fmt.Println(err)
      return
   }
   fmt.Println(string(content))
}

func main() {
   re()
}
复制<br><br>使用文件操作相关知识，模拟实现linux平台cat命令的功能。<br>package main

import (
    "bufio"
    "flag"
    "fmt"
    "io"
    "os"
)

// cat命令实现
func cat(r *bufio.Reader) {
    for {
        buf, err := r.ReadBytes('\n') //注意是字符
        if err == io.EOF {
            break
        }
        fmt.Fprintf(os.Stdout, "%s", buf)
    }
}

func main() {
    flag.Parse() // 解析命令行参数
    if flag.NArg() == 0 {
        // 如果没有参数默认从标准输入读取内容
        cat(bufio.NewReader(os.Stdin))
    }
    // 依次读取每个指定文件的内容并打印到终端
    for i := 0; i &lt; flag.NArg(); i++ {
        f, err := os.Open(flag.Arg(i))
        if err != nil {
            fmt.Fprintf(os.Stdout, "reading from %s failed, err:%v\n", flag.Arg(i), err)
            continue
        }
        cat(bufio.NewReader(f))
    }
}
复制<br><br>
有人把Go语言比作 21 世纪的C语言，第一是因为Go语言设计简单，第二则是因为 21 世纪最重要的就是并发程序设计，而 Go 从语言层面就支持并发。同时实现了自动垃圾回收机制。
<br>先来了解一些概念：<br>进程/线程<br>进程是程序在操作系统中的一次执行过程，系统进行资源分配和调度的一个独立单位。<br>线程是进程的一个执行实体，是 CPU 调度和分派的基本单位，它是比进程更小的能独立运行的基本单位。<br>一个进程可以创建和撤销多个线程，同一个进程中的多个线程之间可以并发执行。<br>并发/并行<br>多线程程序在单核心的 cpu 上运行，称为并发；<br>多线程程序在多核心的 cpu 上运行，称为并行。<br>并发与并行并不相同，并发主要由切换时间片来实现“同时”运行，并行则是直接利用多核实现多线程的运行，Go程序可以设置使用核心数，以发挥多核计算机的能力。<br>协程/线程<br>协程：独立的栈空间，共享堆空间，调度由用户自己控制，本质上有点类似于用户级线程，这些用户级线程的调度也是自己实现的。<br>线程：一个线程上可以跑多个协程，协程是轻量级的线程。<br><br>
Goroutine 一般将其翻译为Go协程，也就是说Go语言在语言层面就实现了协程的支持。
<br>在java/c++中我们要实现并发编程的时候，我们通常需要自己维护一个线程池，并且需要自己去包装一个又一个的任务，同时需要自己去调度线程执行任务并维护上下文切换，这一切通常会耗费程序员大量的心智。那么能不能有一种机制，程序员只需要定义很多个任务，让系统去帮助我们把这些任务分配到CPU上实现并发执行呢？<br>Go语言中的goroutine就是这样一种机制， goroutine是由Go的运行时（runtime）调度和管理的。<br>Go程序会智能地将 goroutine 中的任务合理地分配给每个CPU。<br>Go语言之所以被称为现代化的编程语言，就是因为它在语言层面已经内置了调度和上下文切换的机制。<br>在Go语言编程中你不需要去自己写进程、线程、协程，你的技能包里只有一个技能–goroutine，当你需要让某个任务并发执行的时候，你只需要把这个任务包装成一个函数，开启一个goroutine去执行这个函数就可以了，就是这么简单粗暴。<br><br>Go语言中使用goroutine非常简单，只需要在调用函数的时候在前面加上go关键字，就可以为一个函数创建一个goroutine。<br>一个goroutine必定对应一个函数，可以创建多个goroutine去执行相同的函数。<br>go 函数名( 参数列表 )
复制<br>
<br>函数名：要调用的函数名。
<br>参数列表：调用函数需要传入的参数。
<br>启动单个goroutine<br>func hello() {
    fmt.Println("Hello Goroutine!")
}
func main() {
    hello()
    fmt.Println("main goroutine done!")
}
复制<br>这个示例中hello函数和下面的语句是串行的，执行的结果是打印完Hello Goroutine!后打印main goroutine done!。<br>接下来我们在调用hello函数前面加上关键字go，也就是启动一个goroutine去执行hello这个函数。<br>func main() {
    go hello() // 启动一个goroutine去执行hello函数
    fmt.Println("main goroutine done!")
}
复制<br>这一次的执行结果只打印了main goroutine done!，并没有打印Hello Goroutine!。<br>为什么呢？<br>在程序启动时，Go程序就会为main()函数创建一个默认的goroutine。<br>当main()函数返回的时候该goroutine就结束了，所有在main()函数中启动的goroutine会一同结束，main函数所在的goroutine就像是权利的游戏中的夜王，其他的goroutine都是异鬼，夜王一死它转化的那些异鬼也就全部GG了。<br>所以我们要想办法让main函数等一等hello函数，最简单粗暴的方式就是time.Sleep了。<br>func main() {
    go hello() // 启动一个goroutine去执行hello函数
    fmt.Println("main goroutine done!")
    time.Sleep(time.Second)
}
复制<br>执行上面的代码你会发现，这一次先打印main goroutine done!，然后紧接着打印Hello Goroutine!。<br>首先为什么会先打印main goroutine done!是因为我们在创建新的goroutine的时候需要花费一些时间，而此时main函数所在的goroutine是继续执行的。<br>启动多个goroutine<br>package main

import (
	"fmt"
	"time"
)

func hello(i int) {
	fmt.Println("Hello Goroutine!" , i)
}

func main()  {
	for i := 0; i &lt; 10; i++ {
		go hello(i)
	}
	fmt.Println("main goroutine done!")
	time.Sleep(time.Second * 2)
}

复制<br>多次执行上面的代码，会发现每次打印的数字的顺序都不一致。这是因为10个goroutine是并发执行的，而goroutine的调度是随机的。<br>
问题：主协程 退出了，子协程还会执行吗？
<br>OS线程（操作系统线程）一般都有固定的栈内存（通常为2MB）,一个goroutine的栈在其生命周期开始时只有很小的栈（典型情况下2KB），goroutine的栈不是固定的，他可以按需增大和缩小，goroutine的栈大小限制可以达到1GB，虽然极少会用到这个大。所以在Go语言中一次创建十万左右的goroutine也是可以的。<br><br>GPM是Go语言运行时（runtime）层面的实现，是go语言自己实现的一套调度系统。区别于操作系统调度OS线程。<br>
<br>G很好理解，就是个goroutine的，里面除了存放本goroutine信息外 还有与所在P的绑定等信息。
<br>P管理着一组goroutine队列，P里面会存储当前goroutine运行的上下文环境（函数指针，堆栈地址及地址边界），P会对自己管理的goroutine队列做一些调度（比如把占用CPU时间较长的goroutine暂停、运行后续的goroutine等等）当自己的队列消费完了就去全局队列里取，如果全局队列里也消费完了会去其他P的队列里抢任务。
<br>M是Go运行时（runtime）对操作系统内核线程的虚拟， M与内核线程一般是一一映射的关系， 一个groutine最终是要放到M上执行的；
<br>P与M一般也是一一对应的。他们关系是： P管理着一组G挂载在M上运行。当一个G长久阻塞在一个M上时，runtime会新建一个M，阻塞G所在的P会把其他的G 挂载在新建的M上。当旧的G阻塞完成或者认为其已经死掉时 回收旧的M。<br>P的个数是通过runtime.GOMAXPROCS设定（最大256），Go1.5版本之后默认为物理线程数。 在并发量大的时候会增加一些P和M，但不会太多，切换太频繁的话得不偿失。<br>单从线程调度讲，Go语言相比起其他语言的优势在于OS线程是由OS内核来调度的，goroutine则是由Go运行时（runtime）自己的调度器调度的，这个调度器使用一个称为m:n调度的技术（复用/调度m个goroutine到n个OS线程）。 其一大特点是goroutine的调度是在用户态下完成的， 不涉及内核态与用户态之间的频繁切换，包括内存的分配与释放，都是在用户态维护着一块大的内存池， 不直接调用系统的malloc函数（除非内存池需要改变），成本比调度OS线程低很多。 另一方面充分利用了多核的硬件资源，近似的把若干goroutine均分在物理线程上， 再加上本身goroutine的超轻量，以上种种保证了go调度方面的性能。<br><br>runtime.Gosched()<br>让出CPU时间片，重新等待安排任务(大概意思就是本来计划的好好的周末出去烧烤，但是你妈让你去相亲,两种情况第一就是你相亲速度非常快，见面就黄不耽误你继续烧烤，第二种情况就是你相亲速度特别慢，见面就是你侬我侬的，耽误了烧烤，但是还馋就是耽误了烧烤你还得去烧烤)<br>package main

import (
    "fmt"
    "runtime"
)

func main() {
    go func(s string) {
        for i := 0; i &lt; 2; i++ {
            fmt.Println(s)
        }
    }("world")
    // 主协程
    for i := 0; i &lt; 2; i++ {
        // 切一下，再次分配任务
        runtime.Gosched()
        fmt.Println("hello")
    }
}
复制<br>runtime.Goexit()<br>退出当前协程(一边烧烤一边相亲，突然发现相亲对象太丑影响烧烤，果断让她滚蛋，然后也就没有然后了)<br>package main

import (
    "fmt"
    "runtime"
)

func main() {
    go func() {
        defer fmt.Println("A.defer")
        func() {
            defer fmt.Println("B.defer")
            // 结束协程
            runtime.Goexit()
            defer fmt.Println("C.defer")
            fmt.Println("B")
        }()
        fmt.Println("A")
    }()
    for {
    }
}
复制<br>runtime.GOMAXPROCS<br>Go运行时的调度器使用GOMAXPROCS参数来确定需要使用多少个OS线程来同时执行Go代码。默认值是机器上的CPU核心数。例如在一个8核心的机器上，调度器会把Go代码同时调度到8个OS线程上（GOMAXPROCS是m:n调度中的n）。<br>Go语言中可以通过runtime.GOMAXPROCS()函数设置当前程序并发时占用的CPU逻辑核心数。<br>Go1.5版本之前，默认使用的是单核心执行。Go1.5版本之后，默认使用全部的CPU逻辑核心数。<br>我们可以通过将任务分配到不同的CPU逻辑核心上实现并行的效果，这里举个例子：<br>func a() {
    for i := 1; i &lt; 10; i++ {
        fmt.Println("A:", i)
    }
}

func b() {
    for i := 1; i &lt; 10; i++ {
        fmt.Println("B:", i)
    }
}

func main() {
    runtime.GOMAXPROCS(1)
    go a()
    go b()
    time.Sleep(time.Second)
}
复制<br>两个任务只有一个逻辑核心，此时是做完一个任务再做另一个任务。<br>将逻辑核心数设为2，此时两个任务并行执行，代码如下。<br>func a() {
    for i := 1; i &lt; 10; i++ {
        fmt.Println("A:", i)
    }
}

func b() {
    for i := 1; i &lt; 10; i++ {
        fmt.Println("B:", i)
    }
}

func main() {
    runtime.GOMAXPROCS(2)
    go a()
    go b()
    time.Sleep(time.Second)
}
复制<br>Go语言中的操作系统线程和goroutine的关系：<br>
<br>1.一个操作系统线程对应用户态多个goroutine。
<br>2.go程序可以同时使用多个操作系统线程。
<br>3.goroutine和OS线程是多对多的关系，即m:n。
<br><br>单纯地将函数并发执行是没有意义的。函数与函数间需要交换数据才能体现并发执行函数的意义。<br>虽然可以使用共享内存进行数据交换，但是共享内存在不同的goroutine中容易发生竞态问题。为了保证数据交换的正确性，必须使用互斥量对内存进行加锁，这种做法势必造成性能问题。<br>Go语言的并发模型是CSP（Communicating Sequential Processes），提倡通过通信共享内存而不是通过共享内存而实现通信。<br>如果说goroutine是Go程序并发的执行体，channel就是它们之间的连接。channel是可以让一个goroutine发送特定值到另一个goroutine的通信机制。<br>Go 语言中的通道（channel）是一种特殊的类型。通道像一个传送带或者队列，总是遵循先入先出（First In First Out）的规则，保证收发数据的顺序。每一个通道都是一个具体类型的导管，也就是声明channel的时候需要为其指定元素类型。<br>channel是一种类型，一种引用类型。声明通道类型的格式如下：<br>  var 变量 chan 类型
复制<br> var ch1 chan int   // 声明一个传递整型的通道
    var ch2 chan bool  // 声明一个传递布尔型的通道
    var ch3 chan []int // 声明一个传递int切片的通道
复制<br><br>通道是引用类型，通道类型的空值是nil。<br>var ch chan int
fmt.Println(ch) // &lt;nil&gt;
复制<br>声明通道后需要使用make函数初始化之后才能使用。<br>创建channel的格式如下：<br>  make(chan 元素类型, [缓冲大小])
复制<br>channel的缓冲大小是可选的。<br>ch4 := make(chan int)
ch5 := make(chan bool)
ch6 := make(chan []int)
复制<br><br>通道有发送（send）、接收(receive）和关闭（close）三种操作。<br>发送和接收都使用&lt;-符号。<br>现在我们先使用以下语句定义一个通道：<br>ch := make(chan int)
复制<br>发送：<br>将一个值发送到通道中。<br>ch &lt;- 10 // 把10发送到ch中
复制<br>接收:<br>从一个通道中接收值。<br>x := &lt;- ch // 从ch中接收值并赋值给变量x
&lt;-ch       // 从ch中接收值，忽略结果
复制<br>关闭：<br>我们通过调用内置的close函数来关闭通道。<br>close(ch)
复制<br>关于关闭通道需要注意的事情是，只有在通知接收方goroutine所有的数据都发送完毕的时候才需要关闭通道。通道是可以被垃圾回收机制回收的，它和关闭文件是不一样的，在结束操作之后关闭文件是必须要做的，但关闭通道不是必须的。<br>关闭后的通道有以下特点：<br>
<br>对一个关闭的通道再发送值就会导致panic。
<br>对一个关闭的通道进行接收会一直获取值直到通道为空。
<br>对一个关闭的并且没有值的通道执行接收操作会得到对应类型的零值。
<br>关闭一个已经关闭的通道会导致panic。
<br><br>无缓冲的通道又称为阻塞的通道。我们来看一下下面的代码：<br>func main() {
    ch := make(chan int)
    ch &lt;- 10
    fmt.Println("发送成功")
}
复制<br>上面这段代码能够通过编译，但是执行的时候会出现以下错误：<br>fatal error: all goroutines are asleep - deadlock!
复制<br>为什么会出现deadlock错误呢？<br>因为我们使用ch := make(chan int)创建的是无缓冲的通道，无缓冲的通道只有在有人接收值的时候才能发送值。就像你住的小区没有快递柜和代收点，快递员给你打电话必须要把这个物品送到你的手中，简单来说就是无缓冲的通道必须有接收才能发送。<br>上面的代码会阻塞在ch &lt;- 10这一行代码形成死锁，那如何解决这个问题呢？<br>一种方法是启用一个goroutine去接收值，例如：<br>func recv(c chan int) {
    ret := &lt;-c
    fmt.Println("接收成功", ret)
}
func main() {
    ch := make(chan int)
    go recv(ch) // 启用goroutine从通道接收值
    ch &lt;- 10
    fmt.Println("发送成功")
}
复制<br>无缓冲通道上的发送操作会阻塞，直到另一个goroutine在该通道上执行接收操作，这时值才能发送成功，两个goroutine将继续执行。相反，如果接收操作先执行，接收方的goroutine将阻塞，直到另一个goroutine在该通道上发送一个值。<br>使用无缓冲通道进行通信将导致发送和接收的goroutine同步化。因此，无缓冲通道也被称为同步通道。<br><br>我们可以在使用make函数初始化通道的时候为其指定通道的容量，例如：<br>func main() {
    ch := make(chan int, 1) // 创建一个容量为1的有缓冲区通道
    ch &lt;- 10
    fmt.Println("发送成功")
}
复制<br>只要通道的容量大于零，那么该通道就是有缓冲的通道，通道的容量表示通道中能存放元素的数量。就像你小区的快递柜只有那么个多格子，格子满了就装不下了，就阻塞了，等到别人取走一个快递员就能往里面放一个。<br>我们可以使用内置的len函数获取通道内元素的数量，使用cap函数获取通道的容量，虽然我们很少会这么做。<br><br>可以通过内置的close()函数关闭channel（如果你的管道不往里存值或者取值的时候一定记得关闭管道）<br>package main

import "fmt"

func main() {
    c := make(chan int)
    go func() {
        for i := 0; i &lt; 5; i++ {
            c &lt;- i
        }
        close(c)
    }()
    for {
        if data, ok := &lt;-c; ok {
            fmt.Println(data)
        } else {
            break
        }
    }
    fmt.Println("main结束")
}
复制<br>注意:关闭已经关闭的channel会引发panic。<br><br>当通过通道发送有限的数据时，我们可以通过close函数关闭通道来告知从该通道接收值的goroutine停止等待。当通道被关闭时，往该通道发送值会引发panic，从该通道里接收的值一直都是类型零值。那如何判断一个通道是否被关闭了呢？<br>我们来看下面这个例子：<br>func main() {
    ch1 := make(chan int)
    ch2 := make(chan int)
    // 开启goroutine将0~100的数发送到ch1中
    go func() {
        for i := 0; i &lt; 100; i++ {
            ch1 &lt;- i
        }
        close(ch1)
    }()
    // 开启goroutine从ch1中接收值，并将该值的平方发送到ch2中
    go func() {
        for {
            i, ok := &lt;-ch1 // 通道关闭后再取值ok=false
            if !ok {
                break
            }
            ch2 &lt;- i * i
        }
        close(ch2)
    }()
    // 在主goroutine中从ch2中接收值打印
    for i := range ch2 { // 通道关闭后会退出for range循环
        fmt.Println(i)
    }
}
复制<br>从上面的例子中我们看到有两种方式在接收值的时候判断通道是否被关闭，我们通常使用的是for range的方式。<br><br>有的时候我们会将通道作为参数在多个任务函数间传递，很多时候我们在不同的任务函数中使用通道都会对其进行限制，比如限制通道在函数中只能发送或只能接收。<br>Go语言中提供了单向通道来处理这种情况。例如，我们把上面的例子改造如下：<br>func counter(out chan&lt;- int) {
    for i := 0; i &lt; 100; i++ {
        out &lt;- i
    }
    close(out)
}

func squarer(out chan&lt;- int, in &lt;-chan int) {
    for i := range in {
        out &lt;- i * i
    }
    close(out)
}
func printer(in &lt;-chan int) {
    for i := range in {
        fmt.Println(i)
    }
}

func main() {
    ch1 := make(chan int)
    ch2 := make(chan int)
    go counter(ch1)
    go squarer(ch2, ch1)
    printer(ch2)
}
复制<br>
<br>chan&lt;- int是一个只能发送的通道，可以发送但是不能接收；
<br>&lt;-chan int是一个只能接收的通道，可以接收但是不能发送。
<br>在函数传参及任何赋值操作中将双向通道转换为单向通道是可以的，但反过来是不可以的。<br><br>在某些场景下我们需要同时从多个通道接收数据。通道在接收数据时，如果没有数据可以接收将会发生阻塞。你也许会写出如下代码使用遍历的方式来实现：<br>for{
    // 尝试从ch1接收值
    data, ok := &lt;-ch1
    // 尝试从ch2接收值
    data, ok := &lt;-ch2
    …
}
复制<br>这种方式虽然可以实现从多个通道接收值的需求，但是运行性能会差很多。为了应对这种场景，Go内置了select关键字，可以同时响应多个通道的操作。<br>select的使用类似于switch语句，它有一系列case分支和一个默认的分支。每个case会对应一个通道的通信（接收或发送）过程。select会一直等待，直到某个case的通信操作完成时，就会执行case分支对应的语句。具体格式如下：<br>select {
    case &lt;-chan1:
       // 如果chan1成功读到数据，则进行该case处理语句
    case chan2 &lt;- 1:
       // 如果成功向chan2写入数据，则进行该case处理语句
    default:
       // 如果上面都没有成功，则进入default处理流程
    }
复制<br>select可以同时监听一个或多个channel，直到其中一个channel ready<br>package main

import (
   "fmt"
   "time"
)

func test1(ch chan string) {
   time.Sleep(time.Second * 5)
   ch &lt;- "test1"
}
func test2(ch chan string) {
   time.Sleep(time.Second * 2)
   ch &lt;- "test2"
}

func main() {
   // 2个管道
   output1 := make(chan string)
   output2 := make(chan string)
   // 跑2个子协程，写数据
   go test1(output1)
   go test2(output2)
   // 用select监控
   select {
   case s1 := &lt;-output1:
      fmt.Println("s1=", s1)
   case s2 := &lt;-output2:
      fmt.Println("s2=", s2)
   }
}
复制<br>如果多个channel同时ready，则随机选择一个执行<br>package main

import (
	"fmt"
)

func main() {
	// 创建2个管道
	intChan := make(chan int, 1)
	stringChan := make(chan string, 1)
	go func() {
		//time.Sleep(2 * time.Second)
		intChan &lt;- 1
	}()
	go func() {
		stringChan &lt;- "hello"
	}()
	select {
	case value := &lt;-intChan:
		fmt.Println("int:", value)
	case value := &lt;-stringChan:
		fmt.Println("string:", value)
	}
	fmt.Println("main结束")
}
复制<br>可以用于判断管道是否存满<br>package main

import (
   "fmt"
   "time"
)

// 判断管道有没有存满
func main() {
   // 创建管道
   output1 := make(chan string, 10)
   // 子协程写数据
   go write(output1)
   // 取数据
   for s := range output1 {
      fmt.Println("res:", s)
      time.Sleep(time.Second)
   }
}

func write(ch chan string) {
   for {
      select {
      // 写数据
      case ch &lt;- "hello":
         fmt.Println("write hello")
      default:
         fmt.Println("channel full")
      }
      time.Sleep(time.Millisecond * 500)
   }
}
复制<br><br>有时候在Go代码中可能会存在多个goroutine同时操作一个资源（临界区），这种情况会发生竞态问题（数据竞态）。类比现实生活中的例子有十字路口被各个方向的的汽车竞争；还有火车上的卫生间被车厢里的人竞争。<br>举个例子：<br>var x int64
var wg sync.WaitGroup

func add() {
    for i := 0; i &lt; 5000; i++ {
        x = x + 1
    }
    wg.Done()
}
func main() {
    wg.Add(2)
    go add()
    go add()
    wg.Wait()
    fmt.Println(x)
}
复制<br>上面的代码中我们开启了两个goroutine去累加变量x的值，这两个goroutine在访问和修改x变量的时候就会存在数据竞争，导致最后的结果与期待的不符。<br><br>互斥锁是一种常用的控制共享资源访问的方法，它能够保证同时只有一个goroutine可以访问共享资源。Go语言中使用sync包的Mutex类型来实现互斥锁。<br>使用互斥锁来修复上面代码的问题：<br>var x int64
var wg sync.WaitGroup
var lock sync.Mutex

func add() {
    for i := 0; i &lt; 5000; i++ {
        lock.Lock() // 加锁
        x = x + 1
        lock.Unlock() // 解锁
    }
    wg.Done()
}
func main() {
    wg.Add(2)
    go add()
    go add()
    wg.Wait()
    fmt.Println(x)
}
复制<br>使用互斥锁能够保证同一时间有且只有一个goroutine进入临界区，其他的goroutine则在等待锁；当互斥锁释放后，等待的goroutine才可以获取锁进入临界区，多个goroutine同时等待一个锁时，唤醒的策略是随机的。<br><br>互斥锁是完全互斥的，但是有很多实际的场景下是读多写少的，当我们并发的去读取一个资源不涉及资源修改的时候是没有必要加锁的，这种场景下使用读写锁是更好的一种选择。读写锁在Go语言中使用sync包中的RWMutex类型。<br>读写锁分为两种：读锁和写锁。当一个goroutine获取读锁之后，其他的goroutine如果是获取读锁会继续获得锁，如果是获取写锁就会等待；当一个goroutine获取写锁之后，其他的goroutine无论是获取读锁还是写锁都会等待。<br>读写锁示例：<br>var (
    x      int64
    wg     sync.WaitGroup
    lock   sync.Mutex
    rwlock sync.RWMutex
)

func write() {
    // lock.Lock()   // 加互斥锁
    rwlock.Lock() // 加写锁
    x = x + 1
    time.Sleep(10 * time.Millisecond) // 假设读操作耗时10毫秒
    rwlock.Unlock()                   // 解写锁
    // lock.Unlock()                     // 解互斥锁
    wg.Done()
}

func read() {
    // lock.Lock()                  // 加互斥锁
    rwlock.RLock()               // 加读锁
    time.Sleep(time.Millisecond) // 假设读操作耗时1毫秒
    rwlock.RUnlock()             // 解读锁
    // lock.Unlock()                // 解互斥锁
    wg.Done()
}

func main() {
    start := time.Now()
    for i := 0; i &lt; 10; i++ {
        wg.Add(1)
        go write()
    }

    for i := 0; i &lt; 1000; i++ {
        wg.Add(1)
        go read()
    }

    wg.Wait()
    end := time.Now()
    fmt.Println(end.Sub(start))
}
复制<br>需要注意的是读写锁非常适合读多写少的场景，如果读和写的操作差别不大，读写锁的优势就发挥不出来。<br><br>代码中的加锁操作因为涉及内核态的上下文切换会比较耗时、代价比较高。针对基本数据类型我们还可以使用原子操作来保证并发安全，因为原子操作是Go语言提供的方法它在用户态就可以完成，因此性能比加锁操作更好。Go语言中原子操作由内置的标准库sync/atomic提供。<br>atomic包<br><br>比较下互斥锁和原子操作的性能：<br>var x int64
var l sync.Mutex
var wg sync.WaitGroup

// 普通版加函数
func add() {
    // x = x + 1
    x++ // 等价于上面的操作
    wg.Done()
}

// 互斥锁版加函数
func mutexAdd() {
    l.Lock()
    x++
    l.Unlock()
    wg.Done()
}

// 原子操作版加函数
func atomicAdd() {
    atomic.AddInt64(&amp;x, 1)
    wg.Done()
}

func main() {
    start := time.Now()
    for i := 0; i &lt; 10000; i++ {
        wg.Add(1)
        // go add()       // 普通版add函数 不是并发安全的
        // go mutexAdd()  // 加锁版add函数 是并发安全的，但是加锁性能开销大
        go atomicAdd() // 原子操作版add函数 是并发安全，性能优于加锁版
    }
    wg.Wait()
    end := time.Now()
    fmt.Println(x)
    fmt.Println(end.Sub(start))
}
复制<br>atomic包提供了底层的原子级内存操作，对于同步算法的实现很有用。这些函数必须谨慎地保证正确使用。除了某些特殊的底层应用，使用通道或者sync包的函数/类型实现同步更好。<br><br><br>单进程时代不需要调度器<br>我们知道，一切的软件都是跑在操作系统上，真正用来干活 (计算) 的是 CPU。早期的操作系统每个程序就是一个进程，直到一个程序运行完，才能进行下一个进程，就是 “单进程时代”<br>一切的程序只能串行发生。<br><img alt="image" src="https://img2022.cnblogs.com/blog/2559761/202205/2559761-20220510144059735-334112554.png" referrerpolicy="no-referrer"><br>早期的单进程操作系统，面临 2 个问题：<br>
<br>单一的执行流程，计算机只能一个任务一个任务处理。
<br>进程阻塞所带来的 CPU 时间浪费。
<br>那么能不能有多个进程来宏观一起来执行多个任务呢？<br>后来操作系统就具有了最早的并发能力：多进程并发，当一个进程阻塞的时候，切换到另外等待执行的进程，这样就能尽量把 CPU 利用起来，CPU 就不浪费了。<br>多进程 / 线程时代有了调度器需求<br><img alt="image" src="https://img2022.cnblogs.com/blog/2559761/202205/2559761-20220510144110232-1451731799.png" referrerpolicy="no-referrer"><br>在多进程 / 多线程的操作系统中，就解决了阻塞的问题，因为一个进程阻塞 cpu 可以立刻切换到其他进程中去执行，而且调度 cpu 的算法可以保证在运行的进程都可以被分配到 cpu 的运行时间片。这样从宏观来看，似乎多个进程是在同时被运行。<br>但新的问题就又出现了，进程拥有太多的资源，进程的创建、切换、销毁，都会占用很长的时间，CPU 虽然利用起来了，但如果进程过多，CPU 有很大的一部分都被用来进行进程调度了。<br>怎么才能提高 CPU 的利用率呢？<br>对于 Linux 操作系统来讲，cpu 对进程的态度和线程的态度是一样的。<br><img alt="image" src="https://img2022.cnblogs.com/blog/2559761/202205/2559761-20220510144141151-1211956653.png" referrerpolicy="no-referrer"><br>很明显，CPU 调度切换的是进程和线程。尽管线程看起来很美好，但实际上多线程开发设计会变得更加复杂，要考虑很多同步竞争等问题，如锁、竞争冲突等。<br>协程来提高 CPU 利用率<br>多进程、多线程已经提高了系统的并发能力，但是在当今互联网高并发场景下，为每个任务都创建一个线程是不现实的，因为会消耗大量的内存 (进程虚拟内存会占用 4GB [32 位操作系统], 而线程也要大约 4MB)。<br>大量的进程 / 线程出现了新的问题<br>
<br>高内存占用
<br>调度的高消耗 CPU
<br>好了，然后工程师们就发现，其实一个线程分为 “内核态 “线程和” 用户态 “线程。<br>一个 “用户态线程” 必须要绑定一个 “内核态线程”，但是 CPU 并不知道有 “用户态线程” 的存在，它只知道它运行的是一个 “内核态线程”(Linux 的 PCB 进程控制块)。<br><img alt="image" src="https://img2022.cnblogs.com/blog/2559761/202205/2559761-20220510144221169-487517835.png" referrerpolicy="no-referrer"><br>我们再去细化去分类一下，内核线程依然叫 “线程 (thread)”，用户线程叫 “协程 (co-routine)”.<br><img alt="image" src="https://img2022.cnblogs.com/blog/2559761/202205/2559761-20220510144246514-852246867.png" referrerpolicy="no-referrer"><br>既然一个协程 (co-routine) 可以绑定一个线程 (thread)，那么能不能多个协程 (co-routine) 绑定一个或者多个线程 (thread) 上呢。<br>有 三种协程和线程的映射关系：<br>
<br>
N:1 关系
N 个协程绑定 1 个线程，优点就是协程在用户态线程即完成切换，不会陷入到内核态，这种切换非常的轻量快速。但也有很大的缺点，1 个进程的所有协程都绑定在 1 个线程上
缺点：

<br>某个程序用不了硬件的多核加速能力
<br>一旦某协程阻塞，造成线程阻塞，本进程的其他协程都无法执行了，根本就没有并发的能力了。


<br><img alt="image" src="https://img2022.cnblogs.com/blog/2559761/202205/2559761-20220510144315811-365228618.png" referrerpolicy="no-referrer"><br>
<br>
1:1 关系
1 个协程绑定 1 个线程，这种最容易实现。协程的调度都由 CPU 完成了，不存在 N:1 缺点，
缺点：

<br>协程的创建、删除和切换的代价都由 CPU 完成，有点略显昂贵了。


<br><img alt="image" src="https://img2022.cnblogs.com/blog/2559761/202205/2559761-20220510144343746-234719371.png" referrerpolicy="no-referrer"><br>
<br>
M:N 关系
M 个协程绑定 N 个线程，是 N:1 和 1:1 类型的结合，克服了以上 2 种模型的缺点，但实现起来最为复杂。

<br><img alt="image" src="https://img2022.cnblogs.com/blog/2559761/202205/2559761-20220510144426153-1724936781.png" referrerpolicy="no-referrer"><br>协程跟线程是有区别的，线程由 CPU 调度是抢占式的，协程由用户态调度是协作式的，一个协程让出 CPU 后，才执行下一个协程。
复制<br><br>Go 为了提供更容易使用的并发方法，使用了 goroutine 和 channel。goroutine 来自协程的概念，让一组可复用的函数运行在一组线程之上，即使有协程阻塞，该线程的其他协程也可以被 runtime 调度，转移到其他可运行的线程上。最关键的是，程序员看不到这些底层的细节，这就降低了编程的难度，提供了更容易的并发。<br>Go 中，协程被称为 goroutine，它非常轻量，一个 goroutine 只占几 KB，并且这几 KB 就足够 goroutine 运行完，这就能在有限的内存空间内支持大量 goroutine，支持了更多的并发。虽然一个 goroutine 的栈只占几 KB，但实际是可伸缩的，如果需要更多内容，runtime 会自动为 goroutine 分配。<br>Goroutine 特点：<br>
<br>占用内存更小（几 kb）
<br>调度更灵活 (runtime 调度)
<br>被废弃的 goroutine 调度器<br>Go 目前使用的调度器是 2012 年重新设计的，因为之前的调度器性能存在问题，所以使用 4 年就被废弃了，那么我们先来分析一下被废弃的调度器是如何运作的？<br><img alt="image" src="https://img2022.cnblogs.com/blog/2559761/202205/2559761-20220510144516199-1549173185.png" referrerpolicy="no-referrer"><br>来看看被废弃的 golang 调度器是如何实现的？<br><img alt="image" src="https://img2022.cnblogs.com/blog/2559761/202205/2559761-20220510144544187-2056131252.png" referrerpolicy="no-referrer"><br>M 想要执行、放回 G 都必须访问全局 G 队列，并且 M 有多个，即多线程访问同一资源需要加锁进行保证互斥 / 同步，所以全局 G 队列是有互斥锁进行保护的。<br>老调度器有几个缺点：<br>
<br>创建、销毁、调度 G 都需要每个 M 获取锁，这就形成了激烈的锁竞争。
<br>M 转移 G 会造成延迟和额外的系统负载。比如当 G 中包含创建新协程的时候，M 创建了 G’，为了继续执行 G，需要把 G’交给 M’执行，也造成了很差的局部性，因为 G’和 G 是相关的，最好放在 M 上执行，而不是其他 M’。
<br>系统调用 (CPU 在 M 之间的切换) 导致频繁的线程阻塞和取消阻塞操作增加了系统开销。
<br><br>新调度器中，除了 M (thread) 和 G (goroutine)，又引进了 P (Processor)。<br><img alt="image" src="https://img2022.cnblogs.com/blog/2559761/202205/2559761-20220510144620764-621736108.png" referrerpolicy="no-referrer"><br>Processor，它包含了运行 goroutine 的资源，如果线程想运行 goroutine，必须先获取 P，P 中还包含了可运行的 G 队列。<br>GMP 模型<br>在 Go 中，线程是运行 goroutine 的实体，调度器的功能是把可运行的 goroutine 分配到工作线程上。<br><img alt="image" src="https://img2022.cnblogs.com/blog/2559761/202205/2559761-20220510144643312-1422372735.png" referrerpolicy="no-referrer"><br>
<br>全局队列（Global Queue）：存放等待运行的 G。
<br>P 的本地队列：同全局队列类似，存放的也是等待运行的 G，存的数量有限，不超过 256 个。新建 G’时，G’优先加入到 P 的本地队列，如果队列满了，则会把本地队列中一半的 G 移动到全局队列。
<br>P 列表：所有的 P 都在程序启动时创建，并保存在数组中，最多有 GOMAXPROCS(可配置) 个。
<br>M：线程想运行任务就得获取 P，从 P 的本地队列获取 G，P 队列为空时，M 也会尝试从全局队列拿一批 G 放到 P 的本地队列，或从其他 P 的本地队列偷一半放到自己 P 的本地队列。M 运行 G，G 执行之后，M 会从 P 获取下一个 G，不断重复下去。
<br>Goroutine 调度器和 OS 调度器是通过 M 结合起来的，每个 M 都代表了 1 个内核线程，OS 调度器负责把内核线程分配到 CPU 的核上执行。<br>有关 P 和 M 的个数问题<br>
<br>P 的数量：
<br>
<br>由启动时环境变量 $GOMAXPROCS 或者是由 runtime 的方法 GOMAXPROCS() 决定。这意味着在程序执行的任意时刻都只有 $GOMAXPROCS 个 goroutine 在同时运行。
<br>
<br>M 的数量:
<br>
<br>go 语言本身的限制：go 程序启动时，会设置 M 的最大数量，默认 10000. 但是内核很难支持这么多的线程数，所以这个限制可以忽略。
<br>runtime/debug 中的 SetMaxThreads 函数，设置 M 的最大数量
<br>一个 M 阻塞了，会创建新的 M。
<br>M 与 P 的数量没有绝对关系，一个 M 阻塞，P 就会去创建或者切换另一个 M，所以，即使 P 的默认数量是 1，也有可能会创建很多个 M 出来。<br>P 和 M 何时会被创建<br>
<br>P 何时创建：在确定了 P 的最大数量 n 后，运行时系统会根据这个数量创建 n 个 P。
<br>M 何时创建：没有足够的 M 来关联 P 并运行其中的可运行的 G。比如所有的 M 此时都阻塞住了，而 P 中还有很多就绪任务，就会去寻找空闲的 M，而没有空闲的，就会去创建新的 M。
<br>调度器的设计策略<br>复用线程：避免频繁的创建、销毁线程，而是对线程的复用。<br>
<br>work stealing 机制
<br>当本线程无可运行的 G 时，尝试从其他线程绑定的 P 偷取 G，而不是销毁线程。<br>
<br>hand off 机制
<br>当本线程因为 G 进行系统调用阻塞时，线程释放绑定的 P，把 P 转移给其他空闲的线程执行。<br>利用并行：GOMAXPROCS 设置 P 的数量，最多有 GOMAXPROCS 个线程分布在多个 CPU 上同时运行。GOMAXPROCS 也限制了并发的程度，比如 GOMAXPROCS = 核数/2，则最多利用了一半的 CPU 核进行并行。<br>抢占：在 coroutine 中要等待一个协程主动让出 CPU 才执行下一个协程，在 Go 中，一个 goroutine 最多占用 CPU 10ms，防止其他 goroutine 被饿死，这就是 goroutine 不同于 coroutine 的一个地方。<br>全局 G 队列：在新的调度器中依然有全局 G 队列，但功能已经被弱化了，当 M 执行 work stealing 从其他 P 偷不到 G 时，它可以从全局 G 队列获取 G。<br>go func () 调度流程<br><img alt="image" src="https://img2022.cnblogs.com/blog/2559761/202205/2559761-20220510144720144-418683377.png" referrerpolicy="no-referrer"><br>从上图我们可以分析出几个结论：<br>
<br>我们通过 go func () 来创建一个 goroutine；
<br>有两个存储 G 的队列，一个是局部调度器 P 的本地队列、一个是全局 G 队列。新创建的 G 会先保存在 P 的本地队列中，如果 P 的本地队列已经满了就会保存在全局的队列中；
<br>G 只能运行在 M 中，一个 M 必须持有一个 P，M 与 P 是 1：1 的关系。M 会从 P 的本地队列弹出一个可执行状态的 G 来执行，如果 P 的本地队列为空，就会想其他的 MP 组合偷取一个可执行的 G 来执行；
<br>一个 M 调度 G 执行的过程是一个循环机制；
<br>当 M 执行某一个 G 时候如果发生了 syscall 或则其余阻塞操作，M 会阻塞，如果当前有一些 G 在执行，runtime 会把这个线程 M 从 P 中摘除 (detach)，然后再创建一个新的操作系统的线程 (如果有空闲的线程可用就复用空闲线程) 来服务于这个 P；
<br>当 M 系统调用结束时候，这个 G 会尝试获取一个空闲的 P 执行，并放入到这个 P 的本地队列。如果获取不到 P，那么这个线程 M 变成休眠状态， 加入到空闲线程中，然后这个 G 会被放入全局队列中。
<br>调度器的生命周期<br><img alt="image" src="https://img2022.cnblogs.com/blog/2559761/202205/2559761-20220510144747934-2046879880.png" referrerpolicy="no-referrer"><br><br>互联网的核心是一系列协议，总称为”互联网协议”（Internet Protocol Suite），正是这一些协议规定了电脑如何连接和组网。我们理解了这些协议，就理解了互联网的原理。<br><br><br>Socket是BSD UNIX的进程通信机制，通常也称作”套接字”，用于描述IP地址和端口，是一个通信链的句柄。Socket可以理解为TCP/IP网络的API，它定义了许多函数或例程，程序员可以用它们来开发TCP/IP网络上的应用程序。电脑上运行的应用程序通常通过”套接字”向网络发出请求或者应答网络请求。<br><br>Socket是应用层与TCP/IP协议族通信的中间软件抽象层。在设计模式中，Socket其实就是一个门面模式，它把复杂的TCP/IP协议族隐藏在Socket后面，对用户来说只需要调用Socket规定的相关函数，让Socket去组织符合指定的协议数据然后进行通信。<br><img alt="image" src="https://img2022.cnblogs.com/blog/2559761/202205/2559761-20220510145524983-1198479126.png" referrerpolicy="no-referrer"><br>
<br>Socket又称“套接字”，应用程序通常通过“套接字”向网络发出请求或者应答网络请求
<br>常用的Socket类型有两种：流式Socket和数据报式Socket，流式是一种面向连接的Socket，针对于面向连接的TCP服务应用，数据报式Socket是一种无连接的Socket，针对于无连接的UDP服务应用
<br>TCP：比较靠谱，面向连接，比较慢
<br>UDP：不是太靠谱，比较快
<br><br>TCP/IP(Transmission Control Protocol/Internet Protocol) 即传输控制协议/网间协议，是一种面向连接（连接导向）的、可靠的、基于字节流的传输层（Transport layer）通信协议，因为是面向连接的协议，数据像水流一样传输，会存在黏包问题。<br>TCP服务端<br>一个TCP服务端可以同时连接很多个客户端，例如世界各地的用户使用自己电脑上的浏览器访问淘宝网。因为Go语言中创建多个goroutine实现并发非常方便和高效，所以我们可以每建立一次连接就创建一个goroutine去处理。<br>TCP服务端程序的处理流程：<br>
<br>监听端口
<br>接收客户端请求建立连接
<br>创建goroutine处理连接。
<br>我们使用Go语言的net包实现的TCP服务端代码如下：<br>// 处理函数
func process(conn net.Conn) {
    defer conn.Close() // 关闭连接
    for {
        reader := bufio.NewReader(conn)
        var buf [128]byte
        n, err := reader.Read(buf[:]) // 读取数据
        if err != nil {
            fmt.Println("read from client failed, err:", err)
            break
        }
        recvStr := string(buf[:n])
        fmt.Println("收到client端发来的数据：", recvStr)
        conn.Write([]byte(recvStr)) // 发送数据
    }
}

func main() {
    listen, err := net.Listen("tcp", "127.0.0.1:20000")
    if err != nil {
        fmt.Println("listen failed, err:", err)
        return
    }
    for {
        conn, err := listen.Accept() // 建立连接
        if err != nil {
            fmt.Println("accept failed, err:", err)
            continue
        }
        go process(conn) // 启动一个goroutine处理连接
    }
}
复制<br>TCP客户端<br>一个TCP客户端进行TCP通信的流程如下：<br>
<br>建立与服务端的连接
<br>进行数据收发
<br>关闭连接
<br>使用Go语言的net包实现的TCP客户端代码如下：<br>// 客户端
func main() {
    conn, err := net.Dial("tcp", "127.0.0.1:20000")
    if err != nil {
        fmt.Println("err :", err)
        return
    }
    defer conn.Close() // 关闭连接
    inputReader := bufio.NewReader(os.Stdin)
    for {
        input, _ := inputReader.ReadString('\n') // 读取用户输入
        inputInfo := strings.Trim(input, "\r\n")
        if strings.ToUpper(inputInfo) == "Q" { // 如果输入q就退出
            return
        }
        _, err = conn.Write([]byte(inputInfo)) // 发送数据
        if err != nil {
            return
        }
        buf := [512]byte{}
        n, err := conn.Read(buf[:])
        if err != nil {
            fmt.Println("recv failed, err:", err)
            return
        }
        fmt.Println(string(buf[:n]))
    }
}
复制<br><br>UDP协议（User Datagram Protocol）中文名称是用户数据报协议，是OSI（Open System Interconnection，开放式系统互联）参考模型中一种无连接的传输层协议，不需要建立连接就能直接进行数据发送和接收，属于不可靠的、没有时序的通信，但是UDP协议的实时性比较好，通常用于视频直播相关领域。<br>UDP服务端<br>使用Go语言的net包实现的UDP服务端代码如下：<br>// UDP server端
func main() {
    listen, err := net.ListenUDP("udp", &amp;net.UDPAddr{
        IP:   net.IPv4(0, 0, 0, 0),
        Port: 30000,
    })
    if err != nil {
        fmt.Println("listen failed, err:", err)
        return
    }
    defer listen.Close()
    for {
        var data [1024]byte
        n, addr, err := listen.ReadFromUDP(data[:]) // 接收数据
        if err != nil {
            fmt.Println("read udp failed, err:", err)
            continue
        }
        fmt.Printf("data:%v addr:%v count:%v\n", string(data[:n]), addr, n)
        _, err = listen.WriteToUDP(data[:n], addr) // 发送数据
        if err != nil {
            fmt.Println("write to udp failed, err:", err)
            continue
        }
    }
}
复制<br>UDP客户端<br>使用Go语言的net包实现的UDP客户端代码如下：<br>// UDP 客户端
func main() {
    socket, err := net.DialUDP("udp", nil, &amp;net.UDPAddr{
        IP:   net.IPv4(0, 0, 0, 0),
        Port: 30000,
    })
    if err != nil {
        fmt.Println("连接服务端失败，err:", err)
        return
    }
    defer socket.Close()
    sendData := []byte("Hello server")
    _, err = socket.Write(sendData) // 发送数据
    if err != nil {
        fmt.Println("发送数据失败，err:", err)
        return
    }
    data := make([]byte, 4096)
    n, remoteAddr, err := socket.ReadFromUDP(data) // 接收数据
    if err != nil {
        fmt.Println("接收数据失败，err:", err)
        return
    }
    fmt.Printf("recv:%v addr:%v count:%v\n", string(data[:n]), remoteAddr, n)
}
复制<br><br><br>
<br>Web服务器的工作原理可以简单地归纳为

<br>客户机通过TCP/IP协议建立到服务器的TCP连接
<br>客户端向服务器发送HTTP协议请求包，请求服务器里的资源文档
<br>服务器向客户机发送HTTP协议应答包，如果请求的资源包含有动态语言的内容，那么服务器会调用动态语言的解释引擎负责处理“动态内容”，并将处理得到的数据返回给客户端
<br>客户机与服务器断开。由客户端解释HTML文档，在客户端屏幕上渲染图形结果


<br><br>
<br>超文本传输协议(HTTP，HyperText Transfer Protocol)是互联网上应用最为广泛的一种网络协议，它详细规定了浏览器和万维网服务器之间互相通信的规则，通过因特网传送万维网文档的数据传送协议
<br>HTTP协议通常承载于TCP协议之上
<br>HTTP服务端<br>package main

import (
    "fmt"
    "net/http"
)

func main() {
    //http://127.0.0.1:8000/go
    // 单独写回调函数
    http.HandleFunc("/go", myHandler)
    // addr：监听的地址
    // handler：回调函数
    http.ListenAndServe("127.0.0.1:8000", nil)
}

// handler函数
func myHandler(w http.ResponseWriter, r *http.Request) {
    fmt.Println(r.RemoteAddr, "连接成功")
    // 请求方式：GET POST DELETE PUT UPDATE
    fmt.Println("method:", r.Method)
    // /go
    fmt.Println("url:", r.URL.Path)
    fmt.Println("header:", r.Header)
    fmt.Println("body:", r.Body)
    // 回复
    w.Write([]byte("你好，码神之路"))
}
复制<br>HTTP客户端<br>package main

import (
    "fmt"
    "io"
    "net/http"
)

func main() {
    //resp, _ := http.Get("http://www.baidu.com")
    //fmt.Println(resp)
    resp, _ := http.Get("http://127.0.0.1:8000/go")
    defer resp.Body.Close()
    // 200 OK
    fmt.Println(resp.Status)
    fmt.Println(resp.Header)

    buf := make([]byte, 1024)
    for {
        // 接收服务端信息
        n, err := resp.Body.Read(buf)
        if err != nil &amp;&amp; err != io.EOF {
            fmt.Println(err)
            return
        } else {
            fmt.Println("读取完毕")
            res := string(buf[:n])
            fmt.Println(res)
            break
        }
    }
}
复制<br><br>
<br>WebSocket是一种在单个TCP连接上进行全双工通信的协议
<br>WebSocket使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据
<br>在WebSocket API中，浏览器和服务器只需要完成一次握手，两者之间就直接可以创建持久性的连接，并进行双向数据传输
<br>需要安装第三方包：

<br>cmd中：go get -u -v github.com/gorilla/websocket


<br><br>在同一级目录下新建四个go文件connection.go|data.go|hub.go|server.go<br>运行<br>go run server.go hub.go data.go connection.go
复制<br>运行之后执行local.html文件<br>
<br>server.go文件代码
<br>package main

import (
    "fmt"
    "net/http"

    "github.com/gorilla/mux"
)

func main() {
    router := mux.NewRouter()
    go h.run()
    router.HandleFunc("/ws", myws)
    if err := http.ListenAndServe("127.0.0.1:8080", router); err != nil {
        fmt.Println("err:", err)
    }
}
复制<br>
<br>hub.go文件代码
<br>package main

import "encoding/json"

var h = hub{
    c: make(map[*connection]bool),
    u: make(chan *connection),
    b: make(chan []byte),
    r: make(chan *connection),
}

type hub struct {
    c map[*connection]bool
    b chan []byte
    r chan *connection
    u chan *connection
}

func (h *hub) run() {
    for {
        select {
        case c := &lt;-h.r:
            h.c[c] = true
            c.data.Ip = c.ws.RemoteAddr().String()
            c.data.Type = "handshake"
            c.data.UserList = user_list
            data_b, _ := json.Marshal(c.data)
            c.sc &lt;- data_b
        case c := &lt;-h.u:
            if _, ok := h.c[c]; ok {
                delete(h.c, c)
                close(c.sc)
            }
        case data := &lt;-h.b:
            for c := range h.c {
                select {
                case c.sc &lt;- data:
                default:
                    delete(h.c, c)
                    close(c.sc)
                }
            }
        }
    }
}
复制<br>
<br>data.go文件代码
<br>package main

type Data struct {
    Ip       string   `json:"ip"`
    User     string   `json:"user"`
    From     string   `json:"from"`
    Type     string   `json:"type"`
    Content  string   `json:"content"`
    UserList []string `json:"user_list"`
}
复制<br>
<br>connection.go文件代码
<br>package main

import (
    "encoding/json"
    "fmt"
    "net/http"

    "github.com/gorilla/websocket"
)

type connection struct {
    ws   *websocket.Conn
    sc   chan []byte
    data *Data
}

var wu = &amp;websocket.Upgrader{ReadBufferSize: 512,
    WriteBufferSize: 512, CheckOrigin: func(r *http.Request) bool { return true }}

func myws(w http.ResponseWriter, r *http.Request) {
    ws, err := wu.Upgrade(w, r, nil)
    if err != nil {
        return
    }
    c := &amp;connection{sc: make(chan []byte, 256), ws: ws, data: &amp;Data{}}
    h.r &lt;- c
    go c.writer()
    c.reader()
    defer func() {
        c.data.Type = "logout"
        user_list = del(user_list, c.data.User)
        c.data.UserList = user_list
        c.data.Content = c.data.User
        data_b, _ := json.Marshal(c.data)
        h.b &lt;- data_b
        h.r &lt;- c
    }()
}

func (c *connection) writer() {
    for message := range c.sc {
        c.ws.WriteMessage(websocket.TextMessage, message)
    }
    c.ws.Close()
}

var user_list = []string{}

func (c *connection) reader() {
    for {
        _, message, err := c.ws.ReadMessage()
        if err != nil {
            h.r &lt;- c
            break
        }
        json.Unmarshal(message, &amp;c.data)
        switch c.data.Type {
        case "login":
            c.data.User = c.data.Content
            c.data.From = c.data.User
            user_list = append(user_list, c.data.User)
            c.data.UserList = user_list
            data_b, _ := json.Marshal(c.data)
            h.b &lt;- data_b
        case "user":
            c.data.Type = "user"
            data_b, _ := json.Marshal(c.data)
            h.b &lt;- data_b
        case "logout":
            c.data.Type = "logout"
            user_list = del(user_list, c.data.User)
            data_b, _ := json.Marshal(c.data)
            h.b &lt;- data_b
            h.r &lt;- c
        default:
            fmt.Print("========default================")
        }
    }
}

func del(slice []string, user string) []string {
    count := len(slice)
    if count == 0 {
        return slice
    }
    if count == 1 &amp;&amp; slice[0] == user {
        return []string{}
    }
    var n_slice = []string{}
    for i := range slice {
        if slice[i] == user &amp;&amp; i == count {
            return slice[:count]
        } else if slice[i] == user {
            n_slice = append(slice[:i], slice[i+1:]...)
            break
        }
    }
    fmt.Println(n_slice)
    return n_slice
}
复制<br>
<br>local.html文件代码
<br>&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
    &lt;title&gt;&lt;/title&gt;
    &lt;meta http-equiv="content-type" content="text/html;charset=utf-8"&gt;
    &lt;style&gt;
        p {
            text-align: left;
            padding-left: 20px;
        }
    &lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;div style="width: 800px;height: 600px;margin: 30px auto;text-align: center"&gt;
    &lt;h1&gt;演示聊天室&lt;/h1&gt;
    &lt;div style="width: 800px;border: 1px solid gray;height: 300px;"&gt;
        &lt;div style="width: 200px;height: 300px;float: left;text-align: left;"&gt;
            &lt;p&gt;&lt;span&gt;当前在线:&lt;/span&gt;&lt;span id="user_num"&gt;0&lt;/span&gt;&lt;/p&gt;
            &lt;div id="user_list" style="overflow: auto;"&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div id="msg_list" style="width: 598px;border:  1px solid gray; height: 300px;overflow: scroll;float: left;"&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;br&gt;
    &lt;textarea id="msg_box" rows="6" cols="50" onkeydown="confirm(event)"&gt;&lt;/textarea&gt;&lt;br&gt;
    &lt;input type="button" value="发送" onclick="send()"&gt;
&lt;/div&gt;
&lt;/body&gt;
&lt;/html&gt;
&lt;script type="text/javascript"&gt;
    var uname = prompt('请输入用户名', 'user' + uuid(8, 16));
    var ws = new WebSocket("ws://127.0.0.1:8080/ws");
    ws.onopen = function () {
        var data = "系统消息：建立连接成功";
        listMsg(data);
    };
    ws.onmessage = function (e) {
        var msg = JSON.parse(e.data);
        var sender, user_name, name_list, change_type;
        switch (msg.type) {
            case 'system':
                sender = '系统消息: ';
                break;
            case 'user':
                sender = msg.from + ': ';
                break;
            case 'handshake':
                var user_info = {'type': 'login', 'content': uname};
                sendMsg(user_info);
                return;
            case 'login':
            case 'logout':
                user_name = msg.content;
                name_list = msg.user_list;
                change_type = msg.type;
                dealUser(user_name, change_type, name_list);
                return;
        }
        var data = sender + msg.content;
        listMsg(data);
    };
    ws.onerror = function () {
        var data = "系统消息 : 出错了,请退出重试.";
        listMsg(data);
    };
    function confirm(event) {
        var key_num = event.keyCode;
        if (13 == key_num) {
            send();
        } else {
            return false;
        }
    }
    function send() {
        var msg_box = document.getElementById("msg_box");
        var content = msg_box.value;
        var reg = new RegExp("\r\n", "g");
        content = content.replace(reg, "");
        var msg = {'content': content.trim(), 'type': 'user'};
        sendMsg(msg);
        msg_box.value = '';
    }
    function listMsg(data) {
        var msg_list = document.getElementById("msg_list");
        var msg = document.createElement("p");
        msg.innerHTML = data;
        msg_list.appendChild(msg);
        msg_list.scrollTop = msg_list.scrollHeight;
    }
    function dealUser(user_name, type, name_list) {
        var user_list = document.getElementById("user_list");
        var user_num = document.getElementById("user_num");
        while(user_list.hasChildNodes()) {
            user_list.removeChild(user_list.firstChild);
        }
        for (var index in name_list) {
            var user = document.createElement("p");
            user.innerHTML = name_list[index];
            user_list.appendChild(user);
        }
        user_num.innerHTML = name_list.length;
        user_list.scrollTop = user_list.scrollHeight;
        var change = type == 'login' ? '上线' : '下线';
        var data = '系统消息: ' + user_name + ' 已' + change;
        listMsg(data);
    }
    function sendMsg(msg) {
        var data = JSON.stringify(msg);
        ws.send(data);
    }
    function uuid(len, radix) {
        var chars = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'.split('');
        var uuid = [], i;
        radix = radix || chars.length;
        if (len) {
            for (i = 0; i &lt; len; i++) uuid[i] = chars[0 | Math.random() * radix];
        } else {
            var r;
            uuid[8] = uuid[13] = uuid[18] = uuid[23] = '-';
            uuid[14] = '4';
            for (i = 0; i &lt; 36; i++) {
                if (!uuid[i]) {
                    r = 0 | Math.random() * 16;
                    uuid[i] = chars[(i == 19) ? (r &amp; 0x3) | 0x8 : r];
                }
            }
        }
        return uuid.join('');
    }
&lt;/script&gt;
复制]]></description><link>02、多编程语言\03、go语言\01、go语言基础\100、go语言基础.html</link><guid isPermaLink="false">02、多编程语言/03、Go语言/01、Go语言基础/100、Go语言基础.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:44 GMT</pubDate><enclosure url="https://img2022.cnblogs.com/blog/2559761/202205/2559761-20220510144059735-334112554.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://img2022.cnblogs.com/blog/2559761/202205/2559761-20220510144059735-334112554.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[101、Go语言基础2]]></title><description><![CDATA[ 
 <br><br><br><br>Go 语言的注释主要分成两类，分别是单行注释和多行注释。<br>
<br>单行注释简称行注释，是最常见的注释形式，可以在任何地方使用以 // 开头的单行注释；
<br>多行注释简称块注释，以 /* 开头，并以 */ 结尾，且不可以嵌套使用，多行注释一般用于包的文档描述或注释成块的代码片段。
<br>单行注释的格式如下所示<br>//单行注释
复制<br>多行注释的格式如下所示<br>/*
第一行注释
第二行注释
...
*/
复制<br>每一个包都应该有相关注释，在使用 package 语句声明包名之前添加相应的注释，用来对包的功能及作用进行简要说明。<br>同时，在 package 语句之前的注释内容将被默认认为是这个包的文档说明。一个包可以分散在多个文件中，但是只需要对其中一个进行注释说明即可。<br><br><br>关键字即是被 Go 语言赋予了特殊含义的单词，也可以称为保留字。<br>
Go 中一共有 25 个关键字：<br><br>之所以刻意地将 Go 语言中的关键字保持的这么少，是为了简化在编译过程中的代码解析。<br>
和其它语言一样，关键字不能够作标识符使用。：<br><br><br>标识符是指 Go 语言对各种变量、方法、函数等命名时使用的字符序列，标识符由若干个字母、下划线 _、和数字组成，且第一个字符必须是字母。<br>下划线 `` 是一个特殊的标识符，称为空白标识符_<br>标识符的命名需要遵守以下规则：<br>
<br>由 26 个英文字母、0~9、_ 组成；
<br>不能以数字开头，例如 var 1num int 是错误的；
<br>Go 语言中严格区分大小写；
<br>标识符不能包含空格；
<br>不能以系统保留关键字作为标识符，比如 break，if 等等。
<br>命名标识符时还需要注意以下几点：<br>
<br>标识符的命名要尽量采取简短且有意义；
<br>不能和标准库中的包名重复；
<br>为变量、函数、常量命名时采用驼峰命名法，例如 stuName、getVal；
<br>在 Go 语言中还存在着一些特殊的标识符，叫做预定义标识符，如下表所示：<br><br><br>以下 3 个不确定是否是：<br><br><br><br>
Go 语言是静态类型语言，因此变量（variable）是有明确类型的，编译器也会检查变量类型的正确性。
<br>从计算机系统的角度来讲，变量就是一段或者多段内存，用于存储数据。<br><br>var 变量名 变量类型

//变量声明以关键字 var 开头，变量类型后置，行尾无须分号。
//例子：声明了一个名为age的变量，类型为int
//变量的命名规则遵循驼峰命名法，即首个单词小写，每个新单词的首字母大写，例如： startDate
var age int
var startDate string

复制<br>
如果你学过 C 语言，就会体会到这样声明的好处，比如 C 语言这样声明：int a, b ，那么只有 a 是指针，b 不是，这样会使人迷惑，如果想要两个变量都为指针，需要这样定义：`int a,*b`。
在 go 语言中，我们使用这样的声明方式：var a,b *int，就可以轻松的将 a，b 都声明为指针。
<br><br>每行都用 var 声明变量比较烦琐？Go 语言提供了批量声明的方式<br>var (
    a int
    b string
    c []float32
)

//%d 整数占位符，%s 字符串占位符， %f 浮点数占位符(默认精度为6)
fmt.Printf("%d,%s,%f",a,b,c)//0,,[]
复制<br><br><br>这种声明变量的方式，并没有指明类型，Go 语言中，在编译时会自动推导类型<br>//设置游戏中角色的初始等级为1，但是需要赋值
var level = 1;
//不能写成下面，因为自动加;所以认为你第一个变量没有赋值，没办法类型推导
//var level  
//level= 1

//我们可以使用 %T 进行类型输出。
fmt.Printf("类型为：%T", level)  //类型为：int
复制<br><br>可以省略 var 关键字，这样写起来更加便捷。<br>
简短变量声明被广泛用于大部分的局部变量的声明和初始化，var 形式的声明语句往往用于需要显式指定变量类型的地方。<br>但是有以下要求：<br>
<br>定义变量，同时显式初始化
<br>不能提供数据类型
<br>只能用在函数内部
<br>package main  
import "fmt"  
  
// 不在局部方法内，不能使用简短格式  
// aa :=1  
func main() {  
    // i是变量名 1 是值（或者表达式）不指明类型，直接赋值，Go会自动推导类型  
    aa := 1  
    fmt.Println(aa)          //1  
    fmt.Printf("类型为：%T", aa) //类型为：int  
}
复制<br><br>//创建了一个游戏角色 初始等级为1，标准声明
var level int = 1

//短变量声明 
// level := 1
// level := 1再次声明并赋值,会报错
// no new variables on left side of := （左边的变量已经被声明了，不能重复声明)
level2 := 1  

fmt.Printf("类型为：%T", level) //类型为：int  
fmt.Printf("类型为：%T", level2) //类型为：int
复制<br>以上对同一变量重复声明报错，但是有特例：<br>❶  特例 1：获取到新的变量<br>比如：net.Dial 提供按指定协议和地址发起网络连接，这个函数有两个返回值，一个是 连接对象（conn），一个是 `错误对象（err）<br>正常的写法：<br>package main  
  
import (  
    "fmt"  
    "net")  
  
func main() {  
    var conn net.Conn  
    var err error  
    //net.Dial 是 Go 语言标准库中的一个函数，位于 net 包中。它用于建立与指定网络地址的连接。  
    //TCP 连接，"127.0.0.1:8080" 是远程主机的 IP 地址和端口号。  
    conn, err = net.Dial("tcp", "127.0.0.1:8080")  
    fmt.Println(conn) //无连接，&lt;nil&gt;  
    fmt.Println(err)  //链接失败，dial tcp 127.0.0.1:8080: connectex: No connection could be made because the target machine actively refused it.  
}
复制<br>短变量的写法：<br>package main

import (
	"fmt"
	"net"
)

func main() {  
    conn, err := net.Dial("tcp", "127.0.0.1:8080")  
    conn1, err := net.Dial("tcp", "127.0.0.1:8080")  //相当于一个新链接
    fmt.Println(conn) //&lt;nil&gt;  
    fmt.Println(conn1) //&lt;nil&gt;  
    fmt.Println(err) //dial tcp 127.0.0.1:8080: connectex: No connection could be made because the target machine actively refused it.  
}
复制<br>在多个短变量声明和赋值中，至少有一个新声明的变量出现在左值中，即便其他变量名可能是重复声明的，编译器也不会报错<br>❷ 特例 2：重写全局<br><br><br><br>
变量交换，比如 a=100，b=200，交换之后 a=200，b=100
<br>常用第三变量赋值，或者位运算，但是 Go 里面可以这样：<br>package main

import "fmt"

func main() {
	a := 100
	b := 200
	b,a = a,b
	fmt.Printf("a=%d,b=%d",a,b)
}
复制<br><br>使用 多重赋值 时，如果 不需要在左值中接受变量，可以使用匿名变量<br>    //conn, err := net.Dial("tcp", "127.0.0.1:8080")
    //如果不想接收err的值，那么可以使用_表示，这就是匿名变量
	conn, _ := net.Dial("tcp", "127.0.0.1:8080")
	
	//匿名变量可以重复声明
	conn1, _ := net.Dial("tcp", "127.0.0.1:8080")
	
	// 匿名变量不可以直接开头
	// _ :=1
	
	fmt.Println(conn)
	fmt.Println(conn1)
复制<br>
匿名变量以 _ 下划线表示
匿名变量不占用命名空间，也不会分配内存。匿名变量可以重复声明使用
_ 本身就是一个特殊的标识符，被称为空白标识符。它可以像其他标识符那样用于变量的声明或赋值（任何类型都可以赋值给它），但任何赋给这个标识符的值都将被抛弃，因此这些值不能在后续的代码中使用，也不可以使用这个标识符作为变量对其它变量进行赋值或运算。
<br><br>
一个变量（常量、类型或函数）在程序中都有一定的作用范围，称之为 作用域。
<br>了解变量的作用域对我们学习 Go 语言来说是比较重要的，因为 Go语言(静态语言)会在编译时检查每个变量是否使用过，一旦出现未使用的变量，就会报编译错误。<br>如果不能理解变量的作用域，就有可能会带来一些不明所以的编译错误。<br>根据变量定义位置的不同，可以分为以下三个类型：<br>
<br>函数内定义的变量称为局部变量
<br>函数外定义的变量称为全局变量
<br>函数定义中的变量称为形式参数
<br><br>在函数体外声明的变量称之为 全局变量，全局变量只需要在 一个源文件中定义，就可以在所有源文件中使用，当然，不包含这个全局变量的源文件需要使用“import”关键字引入全局变量所在的源文件之后才能使用这个全局变量。<br>全局变量声明 必须以 var 关键字开头，如果想要在外部包中使用全局变量的 首字母必须大写。<br>package main
import "fmt"
//声明全局变量
var c int
func main() {
    //声明局部变量
    var a, b int
    //初始化参数
    a = 3
    b = 4
    c = a + b
    fmt.Printf("a = %d, b = %d, c = %d\n", a, b, c)
}
复制<br>Go 语言程序中全局变量与局部变量名称可以相同，但是函数体内的局部变量会被优先考虑。<br>package main
import "fmt"
//声明全局变量
var bb float32 = 3.14
func main() {
	bb := 3
	fmt.Println(bb)
}
//执行结果 3
复制<br><br>在函数体内声明的变量称之为 局部变量，它们的作用域 只在函数体内，函数的参数和返回值变量都属于局部变量。<br>局部变量不是一直存在的，它只在定义它的函数被调用后存在，函数调用结束后这个局部变量就会被销毁。<br>package main
import (
    "fmt"
)
func main() {
    //声明局部变量 a 和 b 并赋值
    var a int = 3
    var b int = 4
    //声明局部变量 c 并计算 a 和 b 的和
    c := a + b
    fmt.Printf("a = %d, b = %d, c = %d\n", a, b, c)
}
复制<br><br>在定义函数时函数名后面括号中的变量叫做 形式参数（简称形参）。形式参数只在函数调用时才会生效，函数调用结束后就会被销毁，在函数未被调用时，函数的形参 并不占用实际的存储单元，也没有实际值。<br>形式参数会作为 函数的局部变量来使用。<br>package main
import (
    "fmt"
)
//全局变量 a
var a int = 13
func main() {
    //局部变量 a 和 b
    var a int = 3
    var b int = 4
    fmt.Printf("main() 函数中 a = %d\n", a)
    fmt.Printf("main() 函数中 b = %d\n", b)
    c := sum(a, b)
    fmt.Printf("main() 函数中 c = %d\n", c)
}
func sum(a, b int) int {
    fmt.Printf("sum() 函数中 a = %d\n", a)
    fmt.Printf("sum() 函数中 b = %d\n", b)
    num := a + b
    return num
}
复制<br><br>
变量的生命周期指的是在程序运行期间变量有效存在的时间间隔。
<br>变量的生命周期与变量的作用域有不可分割的联系：<br>
<br>全局变量：它的生命周期和整个程序的运行周期是一致的；
<br>局部变量：它的生命周期则是动态的，从创建这个变量的声明语句开始，到这个变量不再被引用为止；
<br>形式参数和函数返回值：它们都属于局部变量，在函数被调用的时候创建，函数调用结束后被销毁。
<br>Go 的内存中应用了两种数据结构用于存放变量：<br>
<br>堆（heap）：堆是用于存放进程执行中被动态分配的内存段。它的大小并不固定，可动态扩张或缩减。当进程调用 malloc 等函数分配内存时，新分配的内存就被动态加入到堆上（堆被扩张）。当利用 free 等函数释放内存时，被释放的内存从堆中被剔除（堆被缩减）；
<br>栈 (stack)：栈又称堆栈，用来存放程序暂时创建的局部变量，也就是我们函数的大括号 { } 中定义的局部变量。
<br>栈是先进后出，往栈中放元素的过程，称为入栈，取元素的过程称为出栈。<br>栈可用于内存分配，栈的分配和回收速度非常快<br>在程序的编译阶段，编译器会根据实际情况 自动选择 在 栈 或者 堆 上分配局部变量的存储空间，不论使用 var 还是 new 关键字声明变量都不会影响编译器的选择。<br>var global *int
func f() {
    var x int
    x = 1
    global = &amp;x
}
func g() {
    y := new(int)
    *y = 1
}
复制<br>上述代码中，函数 f 里的变量 x 必须在堆上分配，因为它在函数退出后依然可以通过包一级的 global 变量找到，虽然它是在函数内部定义的。<br>用Go语言的术语说，这个局部变量 x 从函数 f 中逃逸了。<br>相反，当函数 g 返回时，变量 y 不再被使用，也就是说可以马上被回收的。因此，y 并没有从函数 g 中逃逸，编译器可以选择在栈上分配 *y 的存储空间，也可以选择在堆上分配，然后由 Go 语言的 GC（垃圾回收机制）回收这个变量的内存空间。<br><br>Go 语言中的常量使用关键字 const 定义，用于存储不会改变的数据，常量是在编译时被创建的，即使定义在函数内部也是如此，并且只能是 布尔型、数字型（整数型、浮点型和复数）和 字符串型。<br>由于编译时的限制，定义常量的表达式必须为能被编译器求值的常量表达式。<br>声明格式：<br>const name [type] = value
复制<br>例如：<br>const pi = 3.14159
复制<br>type 可以省略<br>和变量声明一样，可以批量声明多个常量：<br>const (
    e  = 2.7182818
    pi = 3.1415926
)
复制<br>
所有常量的运算都可以在编译期完成，这样不仅可以减少运行时的工作，也方便其他代码的编译优化，当操作数是常量时，一些运行时的错误也可以在编译时被发现，例如整数除零、字符串索引越界、任何导致无效浮点数的操作等。
<br>常量间的所有算术运算、逻辑运算和比较运算的结果也是常量，对常量的类型转换操作或以下函数调用都是返回常量结果：len、cap、real、imag、complex 和 unsafe. Sizeof。<br>因为它们的值是在编译期就确定的，因此常量可以是构成类型的一部分<br>如果是批量声明的常量，除了第一个外其它的常量右边的初始化表达式都可以省略，如果省略初始化表达式则表示使用前面常量的初始化表达式，对应的常量类型也是一样的。例如：<br>const (
    a = 1
    b
    c = 2
    d
)
fmt.Println(a, b, c, d) // "1 1 2 2"
复制<br><br>
常量声明可以使用 iota 常量生成器初始化，它用于生成一组以相似规则初始化的常量，但是不用每行都写一遍初始化表达式。
<br>在一个 const 声明语句中，在第一个声明的常量所在的行，iota 将会被置为 0，然后在每一个有常量声明的行加 1<br>比如，定义星期日到星期六，从 0-6<br>const (
    Sunday  = iota //0
    Monday
    Tuesday
    Wednesday
    Thursday
    Friday
    Saturday  //6
)
复制<br><br><br>
计算机中数据存储的最小单位为 bit（位），0 或者 1。<br>
字节 byte：计算机中数据的基本单元，1 字节=8 bit，数据在计算机中存储或者计算，至少为 1 个字节
<br>整型<br>
<br>int（随系统，一般是占用 4 个字节）、int 8 (占一个字节)、int 16 (占两个字节)、int 32 (占 4 个字节)、int 64（占 8 个字节）
<br>uint（无符号整数）、uint 8、uint 16、uint 32、uint 64、uintptr<br>
字符
<br>byte // uint8 的别名
<br>rune // int32 的别名 代表一个 Unicode 码<br>
浮点型
<br>float 32、float 64
<br>complex 64、complex 128<br>
布尔型
<br>bool<br>
字符串
<br>string
<br>
有符号和无符号的区别：int 8 范围 -128-127，uint 8 范围：0-255
<br>当一个变量被声明之后，系统自动赋予它该类型的零值：<br>
int 为 0，float 为 0.0，bool 为 false，string 为空字符串，指针为 nil<br><br>Go 语言同时提供了有符号和无符号的整数类型：<br><img alt="assets/101、Go语言基础2/img-20240112_214047.png" src="\02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240112_214047.png" style="width: 500px; max-width: 100%;"><br>
<img alt="assets/101、Go语言基础2/img-20240112_214101.png" src="\02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240112_214101.png" style="width: 500px; max-width: 100%;"><br>
<br>有符号整型：int、int 8、int 64、int 32、int 64
<br>无符号整型：uint、uint 8、uint 64、uint 32、uint 64、uintptr
<br>
有符号整型范围：-2^(n-1) 到 2^(n-1)-1<br>
无符号整型范围: 0 到 2^n-1
<br>实际开发中由于编译器和计算机硬件的不同，int 和 uint 所能表示的整数大小会在 32 bit 或 64 bit 之间变化。<br>其他整数类型：<br>
<img alt="assets/101、Go语言基础2/img-20240112_214319.png" src="\02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240112_214319.png" style="width: 400px; max-width: 100%;"><br>用来表示 Unicode 字符的 rune 类型 和 int32 类型 是等价的，通常用于表示一个 Unicode 码点。<br>
这两个名称可以互换使用。同样，byte 和 uint8 也是等价类型，byte 类型一般用于强调数值是一个 原始的数据 而不是一个小的整数。<br>
无符号的整数类型 uintptr，它没有指定具体的 bit 大小但是足以容纳指针。Uintptr 类型只有在 底层编程 时才需要，特别是 Go 语言和 C 语言函数库或操作系统接口相交互的地方。
<br>在二进制传输、读写文件的结构描述时，为了保持文件的结构不会受到不同编译目标平台字节长度的影响，不要使用 int 和 uint<br><br>Go 语言支持两种浮点型数：<br>
算术规范由 IEEE 754 浮点数国际标准定义，该浮点数规范被所有现代的 CPU 支持
<br>
<br>float32 ： 范围约 1.4e-45 到约 3.4e-38
<br>float64 ：范围约 4.9e-324 到约 1.8e-308
<br>floatStr1 := 3.2
//保留小数点位数
fmt.Printf("%.2f\n", floatStr1) //结果：3.20
复制<br>通常应该优先使用 float 64 类型，因为 float 32 类型的累计计算误差很容易扩散，并且 float 32 能精确表示的正整数并不是很大。<br>    var f float32 = 1 &lt;&lt; 24  
    fmt.Println(f)        // 1.6777216e+07  
    fmt.Println(f + 1)    // 1.6777216e+07  
    fmt.Println(f == f+1) // 结果确为true  
复制<br><img alt="assets/101、Go语言基础2/img-20240113_093823.png" src="\02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240113_093823.png" style="width: 750px; max-width: 100%;"><br>浮点数在声明的时候可以只写整数部分或者小数部分<br>
<br>var e = .71828 // 0.71828
var f = 1.     // 1
fmt.Printf("%.5f,%.1f",e,f)
复制<br>很小或很大的数最好用科学计数法书写，通过 e 或 E 来指定指数部分<br>var avogadro = 6.02214129e23  // 阿伏伽德罗常数
var planck   = 6.62606957e-34 // 普朗克常数
fmt.Printf("%f,%.35f",avogadro,planck)
复制<br><br>在 Go 语言中，以 bool 类型进行声明：<br>var 变量名 bool
复制<br>==, &gt;, &lt;，&lt;=, &gt;=, &amp;&amp;(AND), ||(OR) 等都会产生 bool 值Dataview (inline field '='): Error: 
-- PARSING FAILED --------------------------------------------------

&gt; 1 | =
    | ^

Expected one of the following: 

'(', 'null', boolean, date, duration, file link, list ('[1, 2, 3]'), negated field, number, object ('{ a: 1, b: 2 }'), string, variable
<br>var aVar = 10
aVar == 5  // false
aVar == 10 // true
aVar != 5  // true
aVar != 10 // false
复制<br>
Go 语言对于值之间的比较有非常严格的限制，只有两个相同类型的值才可以进行比较，如果值的类型是接口（interface），那么它们也必须都实现了相同的接口。
如果其中一个值是 常量，那么另外一个值可以不是常量，但是类型必须和该常量类型相同。
如果以上条件都不满足，则必须将其中一个值的类型转换为和另外一个值的类型相同之后才可以进行比较。
<br>&amp;&amp;(AND), ||(OR) 是具有短路行为的，如果运算符左边的值已经可以确定整个布尔表达式的值，那么运算符右边的值将不再被求值。(&amp;&amp;优先级高于||)<br>var a = 10
	//因为a&gt;11已经不满足了，所以a &lt; 30不会走，整个表达式为false
	if(a &gt; 11 &amp;&amp; a &lt; 30){
		fmt.Println("正确")
	}else{
		fmt.Println("错误")
	}

	//因为a &gt; 5已经满足了，所以a &lt; 30不会走，整个表达式为true
	if(a &gt; 5 || a &lt; 30){
		fmt.Println("正确")
	}else{
		fmt.Println("错误")
	}
复制<br>布尔型数据只有 true 和 false，且不能参与任何计算以及类型转换<br><br>Go 语言的字符有以下两种：<br>
<br>一种是 uint 8 类型，或者叫 byte 型，代表了 ASCII 码的一个字符。
<br>另一种是 rune 类型，代表一个 UTF-8 字符，当需要处理中文、日文或者其他复合字符时，则需要用到 rune 类型。Rune 类型等价于 int 32 类型。
<br>byte 类型是 uint 8 的别名，rune 类型是 int 32 的别名<br>
<img alt="assets/101、Go语言基础2/img-20240113_095314.png" src="\02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240113_095314.png" style="width: 425px; max-width: 100%;"><br>ASCII 码的一个字符占一个字节<br>ASCII 定义 128 个字符，由码位 0 – 127 标识。它涵盖英文字母，拉丁数字和其他一些字符。<br>字符的定义：<br>//使用单引号 表示一个字符  
var chA1 byte = 'A'  
fmt.Printf("%c", chA1)  
  
//在 ASCII 码表中，A 的值是 65,也可以这么定义  
var chA2 byte = 65  
fmt.Printf("%c", chA2)  
  
//65使用十六进制表示是41，所以也可以这么定义 \x 总是紧跟着长度为 2 的 16 进制数  
var chA3 byte = '\x41'  
fmt.Printf("%c", chA3)  
  
//65的八进制表示是101，所以使用八进制定义 \后面紧跟着长度为 3 的八进制数  
var chA4 byte = '\101'  
fmt.Printf("%c", chA4)
复制<br>Unicode 是 ASCII 的超集，它定义了 1,114,112 个代码点的代码空间。 Unicode 版本 10.0 涵盖 139 个现代和历史文本集（包括符文字母，但不包括 Klingon ）以及多个符号集。<br>Go 语言同样支持 Unicode（UTF-8）, 用rune来表示, 在内存中使用 int 来表示。<br>在书写 Unicode 字符时，需要在 16 进制数之前加上前缀 \u 或者 \U。<br>
如果需要使用到 4 字节，则使用 \u 前缀，如果需要使用到 8 个字节，则使用 \U 前缀。<br>var ch rune = '\u0041'  
var ch1 int64 = '\U00000041'  
//格式化说明符%c用于表示字符，%v或%d会输出用于表示该字符的整数，%U输出格式为 U+hhhh 的字符串。  
fmt.Printf("%c,%c,%U\n", ch, ch1, ch) //A,A,U+0041  
fmt.Printf("%v,%d\n", ch, ch1)        //65,65
复制<br>Unicode 包中内置了一些用于测试字符的函数，这些函数的返回值都是一个布尔值，如下所示（其中 ch 代表字符）：<br>
<br>判断是否为字母：unicode. IsLetter (ch)
<br>判断是否为数字：unicode. IsDigit (ch)
<br>判断是否为空白符号：unicode. IsSpace (ch)
<br>var chA rune = '\u0041'  
var ch2 rune = '\u0032'  
var space rune = '\u0020'  
  
fmt.Printf("%c,%v\n", chA, unicode.IsLetter(chA))    //A,true  
fmt.Printf("%c,%v\n", ch2, unicode.IsDigit(ch2))     //2,true  
fmt.Printf("%c,%v\n", space, unicode.IsSpace(space)) // ,true
复制<br><br>一个字符串是一个不可改变的字节序列，字符串可以包含任意的数据，但是通常是用来包含可读的文本，字符串是 UTF-8 字符的一个序列。<br>字符串的定义：<br>var mystr string = "hello"
复制<br>go 语言从底层就支持 UTF-8 编码。<br>
UTF-8 是一种被广泛使用的编码格式，是文本文件的标准编码。
由于该编码对占用字节长度的不定性，在 Go 语言中字符串也可能根据需要占用 1 至 4 个字节，这与其它编程语言不同。
Go 语言这样做不仅减少了内存和硬盘空间占用，同时也不用像其它语言那样需要对使用 UTF-8 字符集的文本进行编码和解码。
<br><br>字符串是一种值类型，且值不可变，即创建某个文本后将无法再次修改这个文本的内容。<br>当字符为 ASCII 码表上的字符时则占用 1 个字节<br>字符串中可以使用转义字符来实现换行、缩进等效果，常用的转义字符包括:<br>
<br>\n 换行符
<br>\r 回车符
<br>\t tab 键
<br>\u 或 \U Unicode 字符
<br>\ 反斜杠自身
<br>var str = "码神之路\nGo大法好"
fmt.Print(str)
复制<br>
如果使用``反引号，会被原样进行赋值和输出
<br> fmt.Println(`\t 码神之路Go大法好`)  // \t 码神之路Go大法好
 fmt.Println(`\t 码神之路
 Go大法好`) //使用反引号 可以进行字符串换行
//反引号一般用在 需要将内容进行原样输出的时候 使用
复制<br>字符串是字节的定长数组，byte 和 rune 都是字符类型，若多个字符放在一起，就组成了字符串<br>比如 hello ，对照 ascii 编码表，每个字母对应的编号是：104,101,108,108,111<br>var myStr01 string = "hello"  
var myStr02 [5]byte = [5]byte{104, 101, 108, 108, 111}  
fmt.Printf("myStr01: %s\n", myStr01) //myStr01: hello  
fmt.Printf("myStr02: %s", myStr02)   //myStr02: hello
复制<br><br>字符串的内容（纯字节）可以通过标准索引法来获取，在方括号 [ ] 内写入索引，索引从 0 开始计数，获取的是索引的字节：<br>
<br>字符串 str 的第 1 个字节：str[0]
<br>第 i 个字节：str[i - 1]
<br>最后 1 个字节：str[len (str)-1]
<br>这种转换方案只对纯 ASCII 码的字符串有效。<br>
对于有 Unicode 字符的，字符串中的字符可能由多个字节组成，使用下标就会出错。<br>
注意：获取字符串中某个字节的地址属于非法行为，例如 &amp;str[i]。
<br>一般的比较运算符（==、!=、&lt;、&lt;=、&gt;=、&gt;）是通过在内存中按字节比较，来实现字符串比较的，因此比较的结果是字符串自然编码的顺序。<br>从字符串 Hello, 世界 中获取 界 该如何方便获取呢？<br>直接索引对 rune 类型无效，可以使用 string 方法转换<br>//
fmt.Println(string([]rune(myStr)[10])) 
复制<br>str := "Hello, 我的世界"  
char := str[7]           // 想获取指定索引位置的字符  
fmt.Println(char)        //228  
fmt.Printf("%c\n", char) //发现不是想要的，结果：æ  
  
//  fmt.Println(&amp;str[7]) //非法行为，编译报错  
//  fmt.Println(&amp;char)   //不非法  
  
//获取指定字节范围的字符串 或 子串 或 字符  
slice := str[7:10]  
fmt.Println(slice)        //我  
fmt.Printf("%v\n", slice) //我  
  
//想要获取指定字符  
fmt.Println(string([]rune(str)[9])) //世
复制<br><br>两个字符串 s 1 和 s 2 可以通过 s := s 1 + s 2 拼接在一起。将 s 2 追加到 s 1 尾部并生成一个新的字符串 s。<br>//最好放在一行，如果分行“+”必须放在第一行末尾。
//因为编译器会在行尾自动补全分号
str = "第一部分 " + "第二部分"
str = "第一部分 " +  
    "第二部分"  
复制<br><img alt="assets/101、Go语言基础2/img-20240113_104300.png" src="\02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240113_104300.png" style="width: 475px; max-width: 100%;"><br>也可以使用“+=”来对字符串进行拼接：<br>s := "hel" + "lo,"
s += "world!"
fmt.Println(s) //输出 “hello, world!”
复制<br>除了使用 + 进行拼接，我们也可以使用 WriteString()<br>str1 := "你好,"  
str2 := "码神之路"  
var stringBuilder bytes.Buffer  
//节省内存分配，提高处理效率  
stringBuilder.WriteString(str1)  
stringBuilder.WriteString(str2)  
fmt.Println(stringBuilder.String())
复制<br><br>
<br>print ： 结果写到标准输出
<br>Sprint： 结果会以字符串形式返回
<br>str1 := "你好,"  
str2 := "码神之路"  
var stringBuilder bytes.Buffer  
stringBuilder.WriteString(str1)  
stringBuilder.WriteString(str2)  
// Sprint 以字符串形式返回  
result := fmt.Sprintf(stringBuilder.String())   //你好,码神之路
fmt.Println(result)   //
复制<br>%c  单一字符
%T  动态类型
%v  本来值的输出
%+v 字段名+值打印
%d  十进制打印数字
%p  指针，十六进制
%f  浮点数
%b 二进制
%s string
复制<br><br><br>指针（pointer）在 Go 语言中可以被拆分为两个核心概念：<br>
<br>类型指针，允许对这个指针类型的数据进行修改，传递数据可以直接使用指针，而无须拷贝数据，类型指针不能进行偏移和运算。
<br>切片，由指向起始元素的原始指针、元素数量和容量组成。
<br>受益于这样的约束和拆分，Go 语言的指针类型变量即拥有指针高效访问的特点，又不会发生指针偏移，从而避免了非法修改关键性数据的问题。<br>同时，垃圾回收 也比较容易对不会发生偏移的指针进行检索和回收。<br>切片比原始指针具备更强大的特性，而且更为安全。<br>切片在发生越界时，运行时会报出宕机，并打出堆栈，而原始指针只会崩溃。<br><br>
Var a int = 10
解释：<br>
在内存中开辟了一片空间，空间内存放着数值 10，这片空间在整个内存当中，有一个唯一的地址，用来进行标识，指向这个地址的变量就称为指针。
如果用类比的说明：<br>
内存比作酒店，每个房间就是一块内存，上述代码表示为：定了一间房间 a，让 10 住进了房间，房间有一个门牌号 px，这个 px 就是房间的地址，房卡可以理解为就是指针，指向这个地址。
<br>每个变量在运行时都拥有一个地址，这个地址代表变量在内存中的位置。<br>
变量、指针和地址三者的关系是，每个变量都拥有地址，指针的值就是地址<br>
一个指针变量可以指向任何一个值的内存地址，它所指向的值的内存地址在 32 和 64 位机器上分别占用 4 或 8 个字节，占用字节的大小与所指向的值的大小无关。
<br><br>最重要的就是两个符号：<br>
&amp; 取内存地址<br>
* 根据地址取值<br>
取地址操作符 &amp; 和取值操作符 * 是一对互补操作符<br>样例如下：<br>//其中 v 代表被取地址的变量，变量 v 的地址使用变量 ptr 进行接收，ptr 的类型为*T，称做 T 的指针类型，*代表指针。
var ptr *T = &amp;v

//简短格式
ptr := &amp;v    // v 的类型为 T
复制<br>package main

import (
	"fmt"
)

func main() {
	// 指针与变量
	var room int = 10 // room房间 里面放的 变量10  
	var ptr = &amp;room   // 门牌号px  指针  0xc00000a0b8  
	fmt.Printf("变量的内存地址:%p\n", &amp;room) // 变量的内存地址: 0xc00000a0b8  
	fmt.Printf("%T, %p\n", ptr, ptr)  // *int, 0xc00000a0b8  
	  
	fmt.Println("指针地址:", ptr)     // 指针地址:0xc00000a0a8  
	fmt.Println("指针地址代表的值", *ptr) // 10
}
复制<br>变量、指针地址、指针变量、取地址、取值的相互关系和特性如下：<br>
<br>对变量进行取地址操作使用 &amp; 操作符，可以获得这个变量的指针变量。
<br>指针变量的值是指针地址。
<br>对指针变量进行取值操作使用 * 操作符，可以获得指针变量指向的原变量的值。
<br><br>通过指针不仅可以取值，也可以修改值。<br>package main

import "fmt"

func main() {
	// 利用指针修改值
	var num = 10
	modifyFromPoint(num)
	fmt.Println("未使用指针，方法外", num) //未使用指针，方法外 10

	var num2 = 22
	newModifyFromPoint(&amp;num2)     // 传入指针
	fmt.Println("使用指针 方法外", num2) //使用指针 方法外 1000
}

func modifyFromPoint(num int) {
	// 未使用指针
	num = 10000
	fmt.Println("未使用指针，方法内:", num) //未使用指针，方法内: 10000
}

func newModifyFromPoint(ptr *int) {
	// 使用指针
	*ptr = 1000                    // 修改指针地址指向的值
	fmt.Println("使用指针，方法内:", *ptr) //使用指针，方法内: 1000

}
复制<br><br>Go 语言还提供了另外一种方法来创建指针变量，格式如下：<br>new(类型)
复制<br>str := new(string)
*str = "码神之路Go语言教程"
fmt.Println(*str)
复制<br>new () 函数可以创建一个对应类型的指针，创建过程会分配内存，被创建的指针指向默认值。<br><br>获取命令行的输入信息<br>Go 语言内置的 flag 包实现了对命令行参数的解析，flag 包使得开发命令行工具更为简单。<br>package main
// 导入系统包
import (
    "flag"
    "fmt"
)

// flag 包用于处理命令行参数
// 定义命令行参数 mode，在命令行中不指定 `-mode` 参数，那么 `mode` 变量将使用默认值（空字符串）
// "fast模式能让程序运行的更快"这个是说明字符串，主要用于在用户使用 `-h` 或 `--help` 参数时显示帮助信息。
var mode = flag.String("mode", "", "fast模式能让程序运行的更快")

func main() {
	// 解析命令行参数
	flag.Parse()
	fmt.Println(*mode)
}

复制<br>帮助提示如下：<br>
<img src="\02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240114_104359.png"><br>执行结果如下：<br>
<img src="\02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240114_104008.png"><br><br>A）当一个指针被定义后 没有分配到任何变量 时，它的默认值为 nil。<br>
B）指针变量接收的一定是地址值<br>package main  
  
import "fmt"  
  
func main() {  
    var room int = 10 // room房间 里面放的 变量10  
    fmt.Println(room)  
  
    //var ptr *int = room 编译报错  
    var ptr *int  
    ptr = &amp;room  
    // println(ptr)  //由于 fmt.Println() 和 println() 是两个独立的函数调用，它们的执行顺序是不确定的，可能受到编译器优化、操作系统调度等因素的影响。  
  
    fmt.Println(ptr)  
}
复制<br>C）基本数据类型（又叫值类型），都有对应的指针类型, 形式为 *数据类型 ，比如 int 的对应的指针就是 *int , float 32 对应的指针类型就是 *float 32。指针变量的地址不可以不匹配。<br>var room int32 = 10  
var ptr *int = &amp;room //编译错误  
fmt.Println(ptr)
复制<br><br>在必要以及可行的情况下，一个类型的值可以被转换成另一种类型的值。由于 Go 语言不存在隐式类型转换，因此所有的类型转换都必须显式的声明：<br>//类型 B 的值 = 类型 B(类型 A 的值)
valueOfTypeB = type B(valueOfTypeA)
复制<br>示例：<br>a := 5.0
b := int(a)
复制<br><br>❶ 类型转换只能在定义正确的情况下转换成功<br>
例如从一个取值范围较小的类型转换到一个取值范围较大的类型（将 int 16 转换为 int 32）。<br>❷ 当从一个取值范围较大的类型转换到取值范围较小的类型时<br>
将 int 32 转换为 int 16 或将 float 32 转换为 int，会发生 精度丢失 的情况。<br>❸ 只有相同底层类型的变量之间可以进行相互转换<br>
如将 int 16 类型转换成 int 32 类型，不同底层类型的变量相互转换时会引发编译错误（如将 bool 类型转换为 int 类型）<br>package main

import (
	"fmt"
	"math"
)

func main() {
	// 输出各数值范围
	fmt.Println("int8 range:", math.MinInt8, math.MaxInt8)    //int8 range: -128 127
	fmt.Println("int16 range:", math.MinInt16, math.MaxInt16) //int16 range: -32768 32767
	fmt.Println("int32 range:", math.MinInt32, math.MaxInt32) //int32 range: -2147483648 2147483647
	fmt.Println("int64 range:", math.MinInt64, math.MaxInt64) //int64 range: -9223372036854775808 9223372036854775807
	// 初始化一个32位整型值
	var a int32 = 1047483647  //变量 a 的值 1047483647 不在int16范围内
	// 输出变量的十六进制形式和十进制值
	fmt.Printf("int32: 0x%x %d\n", a, a) //int32: 0x3e6f54ff 1047483647
	// 将a变量数值转换为十六进制, 发生数值截断
	b := int16(a)
	// 输出变量的十六进制形式和十进制值
	fmt.Printf("int16: 0x%x %d\n", b, b) //int16: 0x54ff 21759
	// 将常量保存为float32类型
	var c float32 = math.Pi
	// 转换为int类型, 浮点发生精度丢失
	fmt.Println(int(c)) //3
}

复制<br><br>❶ 整数与字符串<br>package main  
  
import (  
    "fmt"  
    "strconv" //string conversion  
)  
  
func main() {  
    // 字符串与其他类型的转换  
    // str 转 int    newStr1 := "1"  
    intValue, _ := strconv.Atoi(newStr1)      //Atoi 的全称是 "ASCII to integer"    fmt.Printf("%T,%d\n", intValue, intValue) // int,1  
  
    // int 转 str    intValue2 := 1  
    strValue := strconv.Itoa(intValue2)        //Itoa 的全称是 "integer to ASCII"    fmt.Printf("%T, %s\n", strValue, strValue) //string, 1  
}
复制<br>❷ 浮点数与字符串<br>// str 转  floatstring3 := "3.1415926"  
f, _ := strconv.ParseFloat(string3, 32)  
fmt.Printf("%T, %f\n", f, f) // float64, 3.141593  
//float 转 stringfloatValue := 3.1415926  
//4个参数，  
//1：要转换的浮点数  
//2. 格式标记（b、e、E、f、g、G）  
//3. 精度  
//4. 指定浮点类型（32:float32、64:float64）  
// 格式标记：  
// ‘b’ (-ddddp±ddd，二进制指数)  
// ‘e’ (-d.dddde±dd，十进制指数)  
// ‘E’ (-d.ddddE±dd，十进制指数)  
// ‘f’ (-ddd.dddd，没有指数)  
// ‘g’ (‘e’:大指数，‘f’:其它情况)  
// ‘G’ (‘E’:大指数，‘f’:其它情况)  
//  
// 如果格式标记为 ‘e’，‘E’和’f’，则 prec 表示小数点后的数字位数  
// 如果格式标记为 ‘g’，‘G’，则 prec 表示总的数字位数（整数部分+小数部分）  
formatFloat := strconv.FormatFloat(floatValue, 'f', 2, 64)  
fmt.Printf("%T,%s", formatFloat, formatFloat)
复制<br><br>运算符是—种特殊的符号，用以表示数据的运算、赋值和比较等。<br><img src="\02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240113_141917.png"><br>运算符优先级<br>
所谓优先级，就是当多个运算符出现在同一个表达式中时，先执行哪个运算符。
<br>Go 语言有几十种运算符，被分成十几个级别，有的运算符优先级不同，有的运算符优先级相同，请看下表。<br>
注意：优先级值越大，表示优先级越高。<br><br>一下子记住所有运算符的优先级并不容易，还好 Go 语言中大部分运算符的优先级和数学中是一样的，大家在以后的编程过程中也会逐渐熟悉起来。如果实在搞不清，可以加括号，就像下面这样：<br>d := a + (b * c)
复制<br>括号的优先级是最高的，括号中的表达式会优先执行，这样各个运算符的执行顺序就一目了然了。<br><br>【1】算术运算符：+ ，-，*，/，%，++，--<br>
【2】介绍：算术运算符是对数值类型的变量进行运算的，比如，加减乘除<br><br>【1】赋值运算符： =,+=，-=，*=，/=,%=<br>
【2】赋值运算符就是将某个运算后的值，赋给指定的变量。Dataview (inline field ',+=，-=，*=，/=,%='): Error: 
-- PARSING FAILED --------------------------------------------------

&gt; 1 | ,+=，-=，*=，/=,%=
    | ^

Expected one of the following: 

'(', 'null', boolean, date, duration, file link, list ('[1, 2, 3]'), negated field, number, object ('{ a: 1, b: 2 }'), string, variable
<br><br>【1】关系运算符：==,!=,&gt;,&lt;,&gt; =，&lt;=<br>
关系运算符的结果都是 bool 型，也就是要么是 true，要么是 falseDataview (inline field '=,!=,&gt;,&lt;,&gt; =，&lt;='): Error: 
-- PARSING FAILED --------------------------------------------------

&gt; 1 | =,!=,&gt;,&lt;,&gt; =，&lt;=
    | ^

Expected one of the following: 

'(', 'null', boolean, date, duration, file link, list ('[1, 2, 3]'), negated field, number, object ('{ a: 1, b: 2 }'), string, variable
<br>【2】关系表达式经常用在流程控制中<br><br>【1】逻辑运算符：&amp;&amp;(逻辑与/短路与)，||（逻辑或/短路或），!（逻辑非）<br>
【2】用来进行逻辑运算的<br><br>下面是常见的位运算符及其功能：<br>
<br>按位与（AND）：a &amp; b&nbsp;执行按位与操作，返回一个新的值，其中每个对应的位都是在&nbsp;a&nbsp;和&nbsp;b&nbsp;中对应位都为 1 时为 1，否则为 0。
<br>按位或（OR）：a | b&nbsp;执行按位或操作，返回一个新的值，其中每个对应的位都是在&nbsp;a&nbsp;和&nbsp;b&nbsp;中至少有一个对应位为 1 时为 1，否则为 0。
<br>按位异或（XOR）：a ^ b&nbsp;执行按位异或操作，返回一个新的值，其中每个对应的位都是在&nbsp;a&nbsp;和&nbsp;b&nbsp;中只有一个对应位为 1 时为 1，否则为 0。
<br>按位取反（NOT）：^a&nbsp;执行按位取反操作，返回一个新的值，其中每个对应的位都是&nbsp;a&nbsp;中对应位的补码（0 变为 1，1 变为 0）。
<br>左移（Left Shift）：a &lt;&lt; b&nbsp;执行左移操作，将&nbsp;a&nbsp;的二进制表示向左移动&nbsp;b&nbsp;位，并在右侧填充零。这相当于将&nbsp;a&nbsp;的值乘以 2 的&nbsp;b&nbsp;次幂。
<br>右移（Right Shift）：a &gt;&gt; b&nbsp;执行右移操作，将&nbsp;a&nbsp;的二进制表示向右移动&nbsp;b&nbsp;位。对于无符号整数，左侧插入 0；对于有符号整数，左侧插入符号位的副本。
<br><br>【1】其它运算符：&amp; *<br>
&amp; ：返回变量的存储地址<br>
* ：取指针变量对应的数值<br><br><br><br>在 Go 语言中，关键字 if 是用于测试某个条件（布尔型或逻辑型）的语句，如果该条件成立，则会执行 if 后由大括号 {} 括起来的代码块，否则就忽略该代码块继续执行后续的代码。<br>❶ 单分支<br>if condition {
    // 条件为真执行
}
复制<br>//样例
x := 0
if x &lt;= 0 {
	fmt.Println("为真进入这里")
}
复制<br>❷ 双分支<br>如果存在第二个分支，则可以在上面代码的基础上添加 else 关键字以及另一代码块，这个代码块中的代码只有在条件不满足时才会执行，if 和 else 后的两个代码块是相互独立的分支，只能执行其中一个。<br>if condition {
    // 条件为真 执行
} else {
    // 条件不满足 执行
}
复制<br>var count int = 70
if count &lt; 30 { //这个条件表达式返回的是true的话，后面{}执行了
  fmt.Println("库存不足")
} else {//count &gt;= 30
  fmt.Println("库存充足")
}
复制<br>❸多分支<br>基本语法
if 条件表达式1 {
    逻辑代码1
} else if 条件表达式2 {
    逻辑代码2
}
.......
else {
                逻辑代码n
}
复制<br>package main
import "fmt"
func main(){
        //实现功能：根据给出的学生分数，判断学生的等级：
        // &gt;=90  -----A
        // &gt;=80  -----B
        // &gt;=70  -----C
        // &gt;=60  -----D
        // &lt;60   -----E

        //多分支：优点：如果已经走了一个分支了，那么下面的分支就不会再去判断执行了
        if score &gt;= 90 {
        	fmt.Println("您的成绩为A级别")
        } else if score &gt;= 80 {//else隐藏：score &lt; 90
        	fmt.Println("您的成绩为B级别")
        } else if score &gt;= 70 {//score &lt; 80
        	fmt.Println("您的成绩为C级别")
        } else if score &gt;= 60 {//score &lt; 70
        	fmt.Println("您的成绩为D级别")
        } else {//score &lt; 60
        	fmt.Println("您的成绩为E级别")
        } //建议你保证else的存在，只有有了else才会真正 起到多选一 的效果

}
复制<br>❹ If 嵌套<br>if 语句可以嵌套：<br>/* 定义局部变量 */
   var a int = 100
   var b int = 200
   /* 判断条件 */
   if a == 100 {
       /* if 条件语句为 true 执行 */
       if b == 200 {
          /* if 条件语句为 true 执行 */
          fmt.Printf("a 的值为 100 ， b 的值为 200\n" )
       }
   }
复制<br>❺ 特殊写法<br>If 还有一种特殊的写法，可以在 if 表达式之前添加一个执行语句，再根据变量值进行判断，代码如下：<br>if a := 10; a &gt;5 {
    fmt.Println(a)
    return
}
复制<br>这种写法可以将返回值与判断放在一行进行处理，而且返回值的作用范围被限制在 if、else 语句组合中。<br>
在编程中，变量的作用范围越小，所造成的问题可能性越小，每一个变量代表一个状态，有状态的地方，状态就会被修改，函数的局部变量只会影响一个函数的执行，但全局变量可能会影响所有代码的执行状态，因此限制变量的作用范围对代码的稳定性有很大的帮助。
<br><br>
Switch 语句用于基于不同条件执行不同动作，每一个 case 分支都是唯一的，从上至下逐一测试，直到匹配为止。
Switch 分支表达式可以是任意类型，不限于常量。可省略 break，默认自动终止。
<br>Switch 语句的语法如下：<br>switch 表达式var1 {
	case val1,val2,.….:
	  语句块1
	case 值3,值4,...:
	  语句块2
	....
	default:
	 语句块
}
复制<br>变量 var1 可以是任何类型，而 val1 和 val2 则可以是 同类型的任意值。<br>类型不被局限于常量或整数，但必须是相同的类型；或者最终结果为相同类型的表达式。<br>/* 定义局部变量 */
	var grade string = "B"
	var score int = 90

	switch score {
		case 90: grade = "A"
		case 80: grade = "B"
		case 50,60,70 : grade = "C"
		default: grade = "D"
	}
	//swtich后面如果没有条件表达式，则会对true进行匹配
	//swtich后面如果没有条件表达式，则会对true进行匹配
	switch {
		case grade == "A" :
			fmt.Printf("优秀!\n" )
		case grade == "B", grade == "C" :
			fmt.Printf("良好\n" )
		case grade == "D" :
			fmt.Printf("及格\n" )
		case grade == "F":
			fmt.Printf("不及格\n" )
		default:
			fmt.Printf("差\n" )
	}
	fmt.Printf("你的等级是 %s\n", grade )
复制<br>
Go 里面 switch 默认相当于每个 case 最后带有 break，匹配成功后不会自动向下执行其他 case，而是跳出整个 switch<br>
如果想要进入下一个 case，使用 fallthrough 关键字。
<br>注意事项：<br>加了 fallthrough 后，会直接运行【紧跟的后一个】case 或 default 语句，不论条件是否满足都会执行<br>var s = "hello"  
switch {  
case s == "hello":  
    fmt.Println("hello")  
    fallthrough  
case s == "world":  
    fmt.Println("world")  
}
// 结果：
// hello
// world
复制<br><br>
Go 语言中的循环语句只支持 for 关键字，这个其他语言是不同的。
<br><br>❶ 标准方式<br>//这是最常见的`for`循环形式。
//`initialization`是循环变量的初始表达式，
//`condition`是循环条件
//`post`是每次循环迭代完成后执行的语句(迭代因子)。

for initialization; condition; post {
    // 循环体
}
// 初始表达式 不能用var定义变量的形式，要用:=
复制<br>样例：<br>sum := 0
//i := 0; 赋初值，i&lt;10 循环条件 如果为真就继续执行 ；i++ 后置执行 执行后继续循环
for i := 0; i &lt; 10; i++ {
    sum += i
}
复制<br>❷ for 省略 <br>(A) 省略初始表达式<br>
for ; condition; post {
    // 循环体
}
复制<br>(B) 省略初始化、后置语句的形式<br>for condition {
    // 循环体
}
复制<br>(C) 无限循环形式<br>for {
    // 循环体
}

//或者
for ;; {
	// 循环体
 }
复制<br>❸  For range <br>
For range 结构是 Go 语言特有的一种的迭代结构，for range 可以遍历数组、切片、字符串、map 及管道（channel）<br>
语法上类似于其它语言中的 foreach 语句。
<br>一般形式为：<br>for key, val := range coll {
    ...
}
复制<br>var str string = "hello golang你好"
for i , value := range str {
	fmt.Printf("索引为：%d,具体的值为：%c \n",i,value)
}
复制<br>val 始终为集合中对应索引的 值拷贝，因此它一般只具有只读性质，对它所做的任何修改都不会影响到集合中原有的值<br>字符串也可以使用 for range:<br>	str := "码神之路"
	//因为一个字符串是 Unicode 编码的字符（或称之为 rune ）集合
	//char 实际类型是 rune 类型
	for pos, char := range str {
		fmt.Println(pos,char)
	}
复制<br>每个 rune 字符和索引在 for range 循环中是一一对应的，它能够自动根据 UTF-8 规则识别 Unicode 编码的字符。<br>通过 for range 遍历的返回值有一定的规律：<br>
<br>数组、切片、字符串返回索引和值。
<br>Map 返回键和值。
<br>Channel 只返回管道内的值。
<br><br>  ❶ continue<br>step := 100  
for step &gt; 0 {  
    step--  
    fmt.Println(step)  
    //结束本次循环，继续下一次循环  
    if step%6 != 0 {  
       continue  
    }  
    //i % 6 == 0下面这句才执行  
    fmt.Println("after continue" + strconv.Itoa(step))  
}  
//会执行  
fmt.Println("结束之后的语句....")

//结果：
//99
//98
//97
//96
//after continue96
//.......

复制<br>Continue 的作用是结束离它近的那个循环，继续离它近的那个循环:<br>//双重循环：
for i := 0; i &lt;= 3; i++ {  
    for j := 10; j &lt;= 13; j++ {  
       if i == 2 || j == 12 {  
          continue  
       }  
       fmt.Printf("i: %v, j: %v \n", i, j)  
    }  
}  
fmt.Println("-----ok")

//结果：
//i: 0, j: 10 
//i: 0, j: 11 
//i: 0, j: 13 
//i: 1, j: 10 
//i: 1, j: 11 
//i: 1, j: 13 
//i: 3, j: 10 
//i: 3, j: 11 
//i: 3, j: 13 
//-----ok

复制<br>
continue 语句后添加 标签 时，表示开始 标签对应的循环
<br>//双重循环：
outerLoop:  
    for i := 0; i &lt;= 3; i++ {  
       for j := 10; j &lt;= 13; j++ {  
          if i == 2 || j == 12 {  
             continue outerLoop  
          }  
          fmt.Printf("i: %v, j: %v \n", i, j)  
       }  
    }  
    fmt.Println("-----ok")

//结果：
//i: 0, j: 10 
//i: 0, j: 11 
//i: 1, j: 10 
//i: 1, j: 11 
//i: 3, j: 10 
//i: 3, j: 11 
//-----ok

复制<br> ❷ break<br>step := 100 
for step &gt; 0 {  
    step--  
    fmt.Println(step)  
    //跳出循环,还会继续执行循环外的语句  
    break  
}  
//会执行  
fmt.Println("结束之后的语句....")

//结果：
//99
//结束之后的语句....
复制<br>outerLoop&nbsp;是一个&nbsp;label，它被应用在外部的&nbsp;for&nbsp;循环上。当内部的&nbsp;if&nbsp;条件满足时，会执行&nbsp;break outerLoop&nbsp;语句，跳出外部的循环。这样可以实现在多层嵌套循环中直接跳出指定的循环。<br>package main
import "fmt"
func main() {
OuterLoop:
    for i := 0; i &lt; 2; i++ {
        for j := 0; j &lt; 5; j++ {
            switch j {
            case 2:
                fmt.Println(i, j)
                break OuterLoop
            case 3:
                fmt.Println(i, j)
                break OuterLoop
            }
        }
    }
}
复制<br>label 需和 continue 和 break 一起使用，不能单独使用。<br>
需要注意的是，label&nbsp;的使用是可选的，大多数情况下，我们可以通过适当的控制流程和条件语句来避免使用&nbsp;label。在实际编程中，过多或滥用&nbsp;label&nbsp;可能会导致代码变得难以理解和维护，因此需要慎重使用。<br>❸ Return<br>step := 100
for step &gt; 0 {  
   step--  
   fmt.Println(step)  
   //执行一次就结束了  
   return  
}  
//不会执行  
fmt.Println("结束之后的语句....")

//结果：
//99
复制<br>❹ Painc<br>step := 2  
for step &gt; 0 {  
   step--  
   fmt.Println(step)  
   //报错了，直接结束  
   panic("出错了")  
}  
//不会执行  
fmt.Println("结束之后的语句....")	
复制<br>❺ Goto<br>
【1】Golang 的 goto 语句可以无条件地转移到程序中指定的行。<br>
【2】goto 语句通常与条件语句配合使用。可用来实现条件转移.<br>
【3】在 Go 程序设计中一般不建议使用 goto 语句，以免造成程序流程的混乱。
在 Java 编程语言中是没有&nbsp;goto&nbsp;关键字的。这也是因为&nbsp;goto&nbsp;语句会导致代码的控制流变得不清晰和难以理解，容易引发编程错误。
<br>package main
import "fmt"
func main() {
    for x := 0; x &lt; 10; x++ {
        for y := 0; y &lt; 10; y++ {
            if y == 2 {
                // 跳转到标签
                goto breakHere
            }
        }
    }
    // 手动返回, 避免执行进入标签
    return
    // 标签
breakHere:
    fmt.Println("done")
}
复制<br><br>package main

func length(s string) int {
	println("call length.")
	return len(s)
}

func main() {
	s := "abcd"
    // 这样写会多次调佣length函数
	for i:= 0; i &lt; length(s); i++ {     
		println(i, s[i])
	}
}
复制<br>优化：<br>package main

func length(s string) int {
	println("call length.")
	return len(s)
}

func main() {
	s := "abcd"
    // 值调用一次
	for i,n:= 0,length(s); i &lt;n; i++ {     
		println(i, s[i])
	}
}
复制<br><br>函数是组织好的、可重复使用的、用来实现单一或相关联功能的代码段，其可以提高应用的模块性和代码的重复利用率。<br>Go 语言支持普通函数、匿名函数和闭包，从设计上对函数进行了优化和改进，让函数使用起来更加方便。<br>Go 语言的函数属于“一等公民”（first-class），也就是说：<br>
<br>函数本身可以作为值进行传递。
<br>支持匿名函数和闭包（closure）
<br>函数可以满足接口
<br>
【2】Golang 中函数不支持重载<br>
【3】Golang 中支持可变参数 (如果你希望函数带有可变数量的参数)<br>
【4】基本数据类型和数组默认都是值传递的，即进行值拷贝。在函数内修改，不会影响到原来的值<br>
以值传递方式的数据类型，如果希望在函数内的变量能修改函数外的变量，可以传入变量的地址&amp;，函数内以指针的方式操作变量。从效果来看类似引用传递。
<br><br>函数定义:<br>func function_name( [parameter list] ) [return_types] {
   函数体
}
复制<br>
<br>func：函数由 func 开始声明
<br>function_name：函数名称，函数名和参数列表一起构成了函数签名。<br>
首字母不能是数字<br>
首字母大写该函数可以被本包文件和其它包文件使用 (类似 public)<br>
首学母小写只能被本包文件使用，其它包文件不能使用 (类似 private)
<br>parameter list：参数列表，参数就像一个占位符，当函数被调用时，你可以将值传递给参数，这个值被称为 实际参数。<br>
参数列表指定的是参数类型、顺序、及参数个数。<br>
参数是可选的，函数可以不包含参数。
<br>return_types：返回类型，函数返回一列值。<br>
return_types 是该函数的返回类型。<br>
返回值是可选的，函数可以不包含返回值。
<br>函数体：函数定义的代码集合。
<br>示例：<br>package main

import "fmt"

func main() {
	fmt.Println(max(1, 10))
	fmt.Println(max(-1, -2))
}
//类型相同的相邻参数，参数类型可合并。
func max(n1, n2 int) int {
	if n1 &gt; n2 {
		return n1
	}
	return n2
}
复制<br><br><br>函数和函数是并列的关系，所以我们定义的函数不能写到 main 函数中，且函数编写的顺序是无关紧要的。<br>鉴于可读性的需求，最好把 main () 函数写在文件的前面，其他函数按照一定逻辑顺序进行编写（例如函数被调用的顺序）。<br><br>package main  
  
import "fmt"  
  
func printMessage(message string) {  
    fmt.Println("Printing message:", message)  
}  
  
func printMessage(message int) {   //Goland这里会标红
    fmt.Println("Printing message:", message)  
}  
  
func main() {  
    printMessage("Hello") // 编译错误：duplicate function printMessage  
}
复制<br><br>函数也是一种数据类型，可以赋值给一个变量，则该变量就是一个函数类型的变量了。通过该变量可以对函数调用。<br>package main

import "fmt"

// 定义一个函数：
func test(num int) {
	fmt.Println(num)
}
func main() {
	//函数也是一种数据类型，可以赋值给一个变量
	a := test                                        //变量就是一个函数类型的变量
	fmt.Printf("a的类型是：%T,test函数的类型是：%T \n", a, test) //a的类型是：func(int),test函数的类型是：func(int)
	//通过该变量可以对函数调用
	a(10) //等价于  test(10)
}
复制<br><br>
函数定义时指出，函数定义时有参数，该变量可称为函数的形参。<br>
形参就像定义在函数体内的局部变量。
<br><br>但当 调用函数，传递过来的变量就是函数的 实参，函数可以通过两种方式来传递参数，值传递和引用传递。<br><br>指在调用函数时将实际参数复制一份传递到函数中，这样在函数中如果对参数进行修改，将不会影响到实际参数。<br>package main

import "fmt"

func modifyValue(x int, arr [3]int) {
	x = 100
	arr[0] = 999
}

func main() {
	value := 5
	array := [3]int{1, 2, 3}

	fmt.Println("Before function call:")
	fmt.Println("Value:", value) // 输出：Value: 5
	fmt.Println("Array:", array) // 输出：Array: [1 2 3]

	modifyValue(value, array)

	fmt.Println("After function call:")
	fmt.Println("Value:", value) // 输出：Value: 5
	fmt.Println("Array:", array) // 输出：Array: [1 2 3]
}
复制<br><br>是指在调用函数时将实际参数的地址传递到函数中，那么在函数中对参数所进行的修改，将影响到实际参数。<br>package main

import (
	"fmt"
)

/* 定义相互交换值的函数 */
func swap(x, y *int) {
	*x,*y = *y,*x
}

func main() {
	var a, b int = 1, 2
	/*
	   调用 swap() 函数
	   &amp;a 指向 a 指针，a 变量的地址
	   &amp;b 指向 b 指针，b 变量的地址
	*/
	swap(&amp;a, &amp;b)

	fmt.Println(a, b)
}
复制<br>
注意1： 无论是值传递，还是引用传递，传递给函数的都是变量的副本，不过，值传递是值的拷贝。引用传递是地址的拷贝，一般来说，地址拷贝更为高效。而值拷贝取决于拷贝的对象大小，对象越大，则性能越低。<br>
基本数据类型和数组默认都是值传递的，即进行值拷贝。在函数内修改，不会影响到原来的值。
注意2： map、slice、chan、指针、interface 默认以引用的方式传递。
<br><br>函数的参数不是固定的，后面的类型是固定的。（可变参数）<br>Golang 可变参数本质上就是 slice。<br>
只能有一个，且必须是最后一个。<br>在参数赋值时可以不用用一个一个的赋值，可以直接传递一个数组或者切片。<br>格式:<br>func myfunc(args ...int) {    //0个或多个参数  
}  
  
func add(a int, args ...int) int {    //1个或多个参数  
}  
  
func add2(a int, b int, args ...int) int {    //2个或多个参数  
}
复制<br>注意：其中 args 是一个 slice，我们可以通过 arg[index]依次访问所有参数, 通过 len (arg)来判断传递参数的个数.<br>package main  
  
import (  
    "fmt"  
)  
  
func test(s string, n ...int) string {  
    var x int  
    for _, i := range n {  
       x += i  
    }  
  
    return fmt.Sprintf(s, x)  
}  
  
func main() {  
    s := []int{1, 2, 3}  
    res := test("sum: %d", s...) // slice... 展开slice  
    println(res)  
}
复制<br><br>
函数做为一等公民，可以做为参数传递。
<br>//传入函数参数fn，返回类型要int
func test(fn func() int) int {
    return fn()
}

//定义一个函数 fn
func fn()  int{
	return 200
}

func main() {
    //这是直接使用匿名函数
    s1 := test(func() int { return 100 }) 
    //这是传入一个函数
    s1 := test(fn)
	fmt.Println(s1)
}
复制<br>在将函数做为参数的时候，我们可以使用类型定义，将函数定义为类型，这样便于阅读<br>package main

import (
	"fmt"
)

// FormatFunc 定义函数类型。
type FormatFunc func(s string, x, y int) string

// format方法，参数为type是：FormatFunc的func
func format(fn FormatFunc, s string, x, y int) string {
	return fn(s, x, y)
}

// 定义一个满足type是：FormatFunc的func
func formatFun(s string, x, y int) string {
	return fmt.Sprintf(s, x, y)
}

func main() {
	s2 := format(formatFun, "%d, %d", 10, 20)
	fmt.Println(s2)
}

复制<br>有返回值的函数，必须有明确的终止语句，否则会引发编译错误。<br><br><br>func greet(name string) {
	fmt.Println("Hello, " + name + "!")
}

func main() {
	greet("Alice")
	greet("Bob")
}
复制<br><br>函数返回值可以有多个，同时 Go 支持对返回值命名<br>//多个返回值 用括号扩起来
func sumSub(a, b int) (int, int) {  
    sum := a + b  
    sub := a - b  
    return sum, sub  
}  
  
func main() {  
    sum, sub := sumSub(2, 3)  
    fmt.Println(sum, sub)  
}
复制<br>对函数返回值命名，里面顺序就无所谓了，顺序不用对应<br>// 对函数返回值命名，里面顺序就无所谓了，顺序不用对应  
func multiplyDivide(a, b float64) (multiply, divide float64) {  
    divide = a / b  
    multiply = a * b  
    return  
}  
  
func main() {  
    q, r := multiplyDivide(10, 3)  
    fmt.Println("multiply:", q)  
    fmt.Println("divide:", r)  
}
复制<br><br>package main

import "fmt"

//默认值为类型零值,
//命名返回参数可看做与形参类似的局部变量
//由return隐式返回
func f1() (names []string, m map[string]int, num int) {
   m = make(map[string]int)
   m["k1"] = 2
   return
}

func main() {
   a, b, c := f1()
   fmt.Println(a, b, c)
}
复制<br><br>通过使用&nbsp;_，我们告诉编译器我们不打算使用该位置的值，从而避免编译时产生未使用变量的警告。<br>
在这个例子中，我们只打印出&nbsp;c，而忽略了其他两个返回值。<br>func main() {
	_, _, c := f1()
	fmt.Println(c)
}
复制<br><br>初始化函数，可以用来进行一些初始化的操作。<br>
每一个源文件都可以包含一个 init 函数，该函数会在 main 函数执行前，被 Go 运行框架调用。<br><br>init&nbsp;函数的执行流程如下：<br>
<br>Go 程序首先会初始化包级别的常量和变量。<br>
包级别的变量和常量声明通常在包的顶层，位于函数之外。
<br>如果包级别存在全局变量的初始化表达式，则会按照顺序执行这些初始化表达式。<br>
例如其他函数方法
<br>每个包可以有多个&nbsp;init&nbsp;函数<br>
会按照它们在源代码中的顺序依次执行。
<br>init&nbsp;函数在程序运行时只执行一次，<br>
在包被第一次导入时调用。多次导入同一个包，init&nbsp;函数只会执行一次。
<br>如果引入其他包，优先加载依赖包的常量、变量、init&nbsp;函数<br>
依赖包按照上面 1-4 的顺序。<br>
依赖多个包，按照包的顺序
<br>Go 语言中禁止循环依赖的存在<br>
但包的依赖关系可以是多层嵌套的<br>
如果包存在依赖，不同包的 init 函数按照包导入的依赖关系决定执行顺序。调用顺序为最后被依赖的最先被初始化，如导入顺序 main &gt; a &gt; b &gt; c，则初始化顺序为 c &gt; b &gt; a &gt; main，依次执行对应的 init 方法。
<br> 引入包（多层嵌套按初始化顺序，非多层按包引入顺序） -&gt; 全局变量&nbsp;-&gt;&nbsp;init() -&gt; main()<br>如图：<br>
<img src="\02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240113_213810.png"><br>单文件：<br>package main  
  
import (  
    "fmt"  
)  
  
var preference string = test()  
var message string  
  
// 被成员变量调用了，所以先执行  
func test() string {  
    fmt.Println("--------Test method--------")  
    //fmt.Println("Preference:", preference) //被循环初始化了 initialization cycle for preference    fmt.Println("Message:", message)  
    return "testString"  
}  
  
// 在调用init，preference已经被赋值  
func init() {  
    fmt.Println("--------First init--------")  
    fmt.Println("Preference:", preference)  
    fmt.Println("Message:", message)  
    message = "Hello, world!"  
}  
  
func init() {  
    fmt.Println("--------Second init--------")  
    fmt.Println("Preference:", preference)  
    fmt.Println("Message:", message)  
}  
  
// main 是最后调用的  
func main() {  
    fmt.Println("--------Main function--------")  
    fmt.Println("Preference:", preference)  
    fmt.Println("Message:", message)  
}


//结果：
//--------Test method--------
//Message: 
//--------First init--------
//Preference: testString
//Message: 
//--------Second init--------
//Preference: testString
//Message: Hello, world!
//--------Main function--------
//Preference: testString
//Message: Hello, world!

复制<br>多文件 init 方法顺序：<br><img src="\02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240113_213221.png"><br>package main  
  
import (  
    "awesomeProject/mypackage"  
    "fmt")  
  
var preference string = test()  
var message string  
  
// 被成员变量调用了，所以先执行  
func test() string {  
    fmt.Println("--------Test method--------")  
    //fmt.Println("Preference:", preference) //被循环初始化了 initialization cycle for preference    fmt.Println("Message:", message)  
    fmt.Println("File1 gol value:", mypackage.File1)  
    mypackage.File1 = "test()"  
    return "testString"  
}  
  
// 在调用init，preference已经被赋值  
func init() {  
    fmt.Println("--------First init--------")  
    fmt.Println("Preference:", preference)  
    fmt.Println("Message:", message)  
    message = "Hello, world!"  
}  
  
func init() {  
    fmt.Println("--------Second init--------")  
    fmt.Println("Preference:", preference)  
    fmt.Println("Message:", message)  
}  
  
// main 是最后调用的  
func main() {  
    fmt.Println("--------Main function--------")  
    fmt.Println("File1 gol value:", mypackage.File1)  
    fmt.Println("Preference:", preference)  
    fmt.Println("Message:", message)  
}

//Init in file1.go
//Init in file2.go
//--------Test method--------
//Message: 
//File1 gol value: 
//--------First init--------
//Preference: testString
//Message: 
//--------Second init--------
//Preference: testString
//Message: Hello, world!
//--------Main function--------
//File1 gol value: test()
//Preference: testString
//Message: Hello, world!

复制<br><br>匿名函数是指不需要定义函数名的函数，由一个不带函数名的函数声明和函数体组成。<br>
可以直接使用函数内的变量，不必声明。<br>在 Go 里面，函数可以像普通变量一样被传递或使用，支持随时在代码里定义匿名函数。<br>匿名函数的定义格式如下：<br>func(参数列表)(返回参数列表){
    函数体
}
复制<br><br>package main

import (
    "fmt"
    "math"
)

func main() {
    //这里将一个函数当做一个变量一样的操作。
    getSqrt := func(a float64) float64 {
        return math.Sqrt(a)
    }
    fmt.Println(getSqrt(4)) //2
}
复制<br>全局变量：<br>package main  
  
import "fmt"  
  
// FunMul 全局函数  
var FunMul = func(num1 int, num2 int) int {  
    return num1 * num2  
}  
  
func main() {  
    //定义匿名函数：定义的同时调用  
    result := func(num1 int, num2 int) int {  
       return num1 + num2  
    }(10, 20) //返回的直接是调用结果  
    fmt.Printf("类型：%T ,值：%v \n", result, result) //类型：int ,值：30  
  
    //将匿名函数赋给一个变量，这个变量实际就是函数类型的变量  
    //sub等价于匿名函数  
    sub := func(num1 int, num2 int) int {  
       return num1 - num2  
    }  
    //直接调用sub就是调用这个匿名函数了  
    result01 := sub(70, 30)  
    fmt.Println(result01) //40  
  
    result02 := FunMul(3, 4)  
    fmt.Println(result02) //12  
}
复制<br><br>匿名函数可以在声明后调用，例如：<br>func(data int) {
    fmt.Println("hello", data)
}(100) //(100)，表示对匿名函数进行调用，传递参数为 100。
复制<br><br>匿名函数作为回调函数的设计在 Go 语言也比较常见<br>package main  
import (  
    "fmt"  
)  
  

func visit(list []int, f func(int)) {
	// 遍历切片的每个元素, 通过给定函数进行元素访问  
    for _, v := range list {
       f(v)      // 使用匿名函数打印切片内容  
    }  
}  
  
func main() {  
	//传入一个数组和匿名的函数func
    visit([]int{1, 2, 3, 4}, func(v int) {  
       fmt.Println(v)  
    })  
}
复制<br><br>package main

import "fmt"

func FGen(x, y int) (func() int, func(int) int) {

	//求和的匿名函数
	sum := func() int {
		return x + y
	}

	// (x+y) *z 的匿名函数
	avg := func(z int) int {
		return (x + y) * z
	}
	return sum, avg
}

func main() {
	f1, f2 := FGen(1, 2)
	fmt.Println(f1())  //3
	fmt.Println(f2(3)) //9
}

复制<br><br>
闭包是指：一个函数可以访问并操作其绑定的外部作用域中的变量，即使在函数被调用之后，这些变量的生命周期仍然存在。<br>
闭包 = 函数 + 引用环境
<br>示例：<br>package main

import (
	"fmt"
)

// 创建一个玩家生成器, 输入名称, 输出生成器
func playerGen(name string) func() (string, int) {
	// 血量一直为150
	hp := 150
	// 返回创建的闭包
	return func() (string, int) {
		// 将变量引用到闭包中
		return name, hp
	}
}

func main() {
	// 创建一个玩家生成器
	generator := playerGen("码神")
	// 返回玩家的名字和血量
	name, hp := generator()
	// 打印值
	fmt.Println(name, hp)

	generator2 := playerGen("大佬")
	name2, hp2 := generator2()
	// 打印值
	fmt.Println(name2, hp2)
}
复制<br>被调用后，引用环境依旧存在：<br>package main  
  
import (  
    "fmt"  
)  
  
func adder() func(int) int {  
    sum := 0  
    // 返回一个内部函数，该函数捕获了外部函数的 `sum` 变量  
    return func(x int) int {  
       sum += x  
       return sum  
    }  
}  
  
func main() {  
    // 创建一个 `add` 函数，它是一个闭包  
    add := adder()  
  
    // 使用闭包 `add` 进行累加操作  
    fmt.Println(add(10)) // 输出: 10  
    fmt.Println(add(5))  // 输出: 15  
    fmt.Println(add(3))  // 输出: 18  
}
复制<br><br>❶ 返回的是一个匿名函数，但是这个匿名函数引用到函数外的变量/参数 ,因此这个匿名函数就和变量/参数形成一个整体，构成闭包。<br>❷ 闭包中使用的变量/参数会一直保存在内存中，所以会一直使用。意味着闭包不可滥用（对内存消耗大）<br>package main

import "fmt"

// 函数功能：求和  
// 函数的名字：getSum 参数为空  
// getSum函数返回值为一个函数，这个函数的参数是一个int类型的参数，返回值也是int类型  
func getSum() func(int) int {
	var sum int = 0
	return func(num int) int {
		sum = sum + num
		return sum
	}
}

func getSum01(sum int, num int) int {
	sum = sum + num
	return sum
}

// 闭包：返回的匿名函数+匿名函数以外的变量num  
func main() {
	f := getSum()
	fmt.Println(f(1)) //1  
	fmt.Println(f(2)) //3  
	fmt.Println(f(3)) //6  
	fmt.Println(f(4)) //10  
	fmt.Println("----------------------")

	//不使用闭包的时候：我想保留的值，不可以反复使用  
	//闭包应用场景：闭包可以保留上次引用的某个值，我们传入一次就可以反复使用了
	fmt.Println(getSum01(0, 1)) //1  
	fmt.Println(getSum01(1, 2)) //3  
	fmt.Println(getSum01(3, 3)) //6  
	fmt.Println(getSum01(6, 4)) //10  
}  
复制<br><br>
Go 语言的 defer 语句会将其后面跟随的语句进行延迟处理
<br>关键字 defer 用于注册延迟调用。<br>
所以产用于：<br>
<br>关闭文件句柄
<br>锁资源释放
<br>数据库连接释放
<br>defer 特性:<br>
<br>
多个 defer 语句，按先进后出的方式执行。

<br>
所有函数在执行 RET 返回指令之前，都会先检查是否存在 defer 语句，若存在则先逆序调用 defer 语句进行收尾工作再退出返回；

<br>
匿名返回值是在 return 执行时被声明，有名返回值则是在函数声明的同时被声明，因此在 defer 语句中只能访问有名返回值，而不能直接访问匿名返回值；<br>
Return 其实应该包含前后两个步骤：<br>
第一步是给返回值赋值（若为有名返回值则直接赋值，若为匿名返回值则先声明再赋值）；<br>
第二步是调用 RET 返回指令并传入返回值，而 RET 则会检查 defer 是否存在，若存在就先逆序插播 defer 语句，最后 RET 携带返回值退出函数；
defer、return、返回值三者的执行顺序应该是：return最先给返回值赋值；接着defer开始执行一些收尾工作；最后RET指令携带返回值退出函数。

<br>
Defer 语句中的变量，在 defer 声明时就决定了。

<br>package main  
  
import "fmt"  
  
func sum(n1 int, n2 int) int {  
    //当执行到defer时，暂时不执行，会将其压入一个独立的栈中  
    //和sum栈和main栈不在一个地方的栈  
    //当函数执行完毕后，再从defer栈中按照先入后出原则出栈  
    defer fmt.Println("ok1,n1=", n1)              //5.再执行这句  
    defer fmt.Println("ok2,n2=", n2)              //4.再执行这句  
    res := n1 + n2                                //1.先执行了这句  
    fmt.Println("ok3=", res, "n1=", n1, "n2", n2) //2.再执行这句  
    return res                                    //3.再执行这句  6.最后RET
}  
  
func main() {  
    res := sum(20, 30)  
    fmt.Println("res=", res) //7.再执行这句  
}
复制<br><br>go 语言的 defer 功能强大，对于资源管理非常方便，但是如果没用好，也会有陷阱。<br><br>package main

import "fmt"

func main() {  
    var whatever = [5]int{1, 2, 3, 4, 5}  
  
    for _, a := range whatever {  
       defer fmt.Print(a)  
    }  
}
//结果：
//54321
复制<br>关于内存泄漏的警告是由于&nbsp;defer&nbsp;语句在循环中被使用，导致在每次迭代时都会推迟执行操作，这些推迟的操作会在函数返回时才执行。这可能导致在函数执行期间积累大量的推迟操作，占用额外的内存。<br><br>❶ 基本类型入栈<br>func sum(n1 int, n2 int) int {  
    defer fmt.Println("ok1,n1=", n1)  
    defer fmt.Println("ok2,n2=", n2)  
    n1++  
    n2++  
    res := n1 + n2  
    fmt.Println("ok3=", res, "n1=", n1, "n2", n2)  
    return res  
}  
  
func main() {  
    res := sum(20, 30)  
    fmt.Println("res=", res)  
}

//ok3= 52 ,n1= 21 ,n2= 31
//ok2,n2= 30
//ok1,n1= 20
//res= 52
复制<br>❷ 引用类型入栈<br>func sum(n1 *int, n2 *int) int {  
    defer fmt.Println("ok1,n1=", *n1)  
    defer fmt.Println("ok2,n2=", *n2)  
    *n1++  
    *n2++  
    res := *n1 + *n2  
    fmt.Println("ok3=", res, "n1=", *n1, "n2", *n2)  
    return res  
}  
  
func main() {  
    n1 := 20  
    n2 := 30  
    var p1 *int = &amp;n1  
    var p2 *int = &amp;n2  
    res := sum(p1, p2)  
    fmt.Println("res=", res)  
}

//结果和上面一样！
//ok3= 52 n1= 21 n2 31
//ok2,n2= 30
//ok1,n1= 20
//res= 52
复制<br>❸ 例子三：<br>package main

import (
	"log"
	"time"
)

func main() {
	start := time.Now()
	log.Printf("开始时间为：%v", start)
  defer log.Printf("时间差：%v", time.Since(start))  // Now()此时已经copy进去了
    //不受这3秒睡眠的影响
	time.Sleep(3 * time.Second)
	log.Printf("函数结束")
}

//2024/01/14 15:01:56 开始时间为：2024-01-14 15:01:56.2283069 +0800 CST m=+0.005217101
//2024/01/14 15:01:59 函数结束
//2024/01/14 15:01:59 时间差：31.8719ms

复制<br>
<br>Go 语言中所有的 函数调用都是传值的
<br>调用 defer 关键字会 立刻拷贝函数中引用的外部参数 ，包括 start 和 time. Since 中的 Now
<br>defer 的函数在 压栈的时候也会保存参数的值，并非在执行时取值。
<br>如何解决上述问题：使用 defer fun ()，拷贝的是 函数指针<br>package main

import (
	"log"
	"time"
)

func main() {
	start := time.Now()
	log.Printf("开始时间为：%v", start)
	defer func() {
		log.Printf("开始调用defer")
		log.Printf("时间差：%v", time.Since(start))
		log.Printf("结束调用defer")
	}()
	time.Sleep(3 * time.Second)

	log.Printf("函数结束")
}

//2024/01/14 15:01:18 开始时间为：2024-01-14 15:01:18.3644022 +0800 CST m=+0.005763401
//2024/01/14 15:01:21 函数结束
//2024/01/14 15:01:21 开始调用defer
//2024/01/14 15:01:21 时间差：3.0330456s
//2024/01/14 15:01:21 结束调用defer
复制<br><br>package main

import "fmt"

func main() {  
    var whatever = [5]int{1, 2, 3, 4, 5}  
    for _, a := range whatever {  
       //函数正常执行,由于闭包用到的变量 a 在执行的时候已经变成5,所以输出全都是5.  
       defer func() { fmt.Print(a) }()  
    }  
}
//结果：
//55555
复制<br>怎么解决：<br>package main

import "fmt"

func main() {  
    var whatever = [5]int{1, 2, 3, 4, 5}  
    for _, a := range whatever {  
       a := a // 赋值  
       defer func() { fmt.Print(a) }()  
    }  
}
//结果：
//54321
复制<br><br>
和 java 中的 finally 有点像
<br>Java 中的 finally:<br>public class Main {
    public static void main(String[] args) {
        try {
            System.out.println("Hello");
            throw new Exception("Exception occurred");
        } catch (Exception e) {
            System.out.println("Exception caught");
        } finally {
            System.out.println("Finally block");
        }
    }
}

//Hello
//Exception caught
//Finally block

复制<br>Go 中的 Defer:<br>func main() {  
    defer fmt.Println("Defer(Like Finally block)")  
    defer func() {  
       if r := recover(); r != nil {  
          fmt.Println("Exception caught")  
       }  
    }()  
  
    fmt.Println("Hello")  
    panic("Exception occurred")  
}

//Hello
//Exception caught
//Defer(Like Finally block)
复制<br><br><br>Golang 设计者为了编程方便，提供了一些不用导包可以直接使用的函数，称为 Go 的内置函数/内建函数。<br>
存放位置：在 builtin 包下`
<br>func main() {  
	//使用 len 获取字节长度
	str := "hello"
	length := len(str)
    fmt.Println(length) // 输出: 5  

    // 使用 new 创建指针  
    p := new(int)  
    fmt.Println(*p) // 输出: 0  


    // 使用 append 向切片追加元素  
    slice := []int{1, 2, 3}  
    slice = append(slice, 4, 5)  
    fmt.Println(slice) // 输出: [1 2 3 4 5]  
  
    // 使用 copy 复制切片  
    source := []int{1, 2, 3}  
    destination := make([]int, len(source))  
    copy(destination, source)  
    fmt.Println(destination) // 输出: [1 2 3]  
  
    // 使用 make 创建切片和映射  
    s := make([]int, 0, 5)  
    m := make(map[string]int)  
    fmt.Println(s, m) // 输出: [] map[]  
  

  
    // 使用 print 和 println 打印输出  
    print("Hello")  
    println(", Go!")  
  
    // 使用 close 关闭通道  
    ch := make(chan int)  
    close(ch)  
  
    // 使用 cap 返回切片的容量  
    slice = make([]int, 0, 10)  
    fmt.Println(cap(slice)) // 输出: 10  
  
    // 使用 delete 从映射中删除键值对  
    m = map[string]int{"apple": 5, "banana": 3, "cherry": 8}  
    delete(m, "banana")  
    fmt.Println(m) // 输出: map[apple:5 cherry:8]  
  
    // 使用 panic 和 recover 处理运行时恐慌  
    defer func() {  
       if err := recover(); err != nil {  
          fmt.Println("恐慌已恢复:", err)  
       }  
    }()  
  
    panic("发生错误！")  
  
}
复制<br><br><br>// 字符串是否为空  
isEmpty := strings.TrimSpace("") == ""  
fmt.Println("字符串是否为空:", isEmpty)  
  
// 字符串连接  
concatenated := strings.Join([]string{"hello", "world"}, " ")  
fmt.Println("字符串连接:", concatenated)  
  
// 字符串重复  
repeated := strings.Repeat("abc", 3)  
fmt.Println("字符串重复:", repeated)  
  
// 查找子串是否在指定的字符串中  
isCont := strings.Contains("javaandgolang", "go")  
fmt.Println("查找子串是否在指定的字符串中:", isCont)  
  
// 统计一个字符串中指定子串出现的次数  
count := strings.Count("javaandgolang", "a")  
fmt.Println("统计一个字符串有几个指定的子串:", count)  
  
// 不区分大小写的字符串比较  
equalFold := strings.EqualFold("go", "Go")  
fmt.Println("不区分大小写的字符串比较:", equalFold)  
  
// 返回子串在字符串中第一次出现的索引值，如果没有则返回-1  
index := strings.Index("javaandgolang", "a")  
fmt.Println("子串在字符串中第一次出现的索引值:", index)  
  
// 替换字符串中的子串，n可以指定替换的次数，-1表示全部替换  
replaced := strings.Replace("goandjavagogo", "go", "golang", 2)  
fmt.Println("替换后的字符串:", replaced)  
  
// 将字符串按指定字符为分割标识拆分成字符串数组  
split := strings.Split("go-python-java", "-")  
fmt.Printf("拆分后的字符串数组: %v\n", split)  
  
// 将字符串转换为小写和大写形式  
lower := strings.ToLower("Go")  
upper := strings.ToUpper("go")  
fmt.Println("将字符串转换为小写形式:", lower)  
fmt.Println("将字符串转换为大写形式:", upper)  
  
// 去除字符串左右两边的空格  
trimmedSpace := strings.TrimSpace("     go and java    ")  
fmt.Println("去除左右两边空格后的字符串:", trimmedSpace)  
  
// 去除字符串左右两边指定的字符  
trimmedChars := strings.Trim("~golang~ ", " ~")  
fmt.Println("去除左右两边指定字符后的字符串:", trimmedChars)  
  
// 去除字符串左边指定的字符  
trimmedLeft := strings.TrimLeft("~golang~", "~")  
fmt.Println("去除左边指定字符后的字符串:", trimmedLeft)  
  
// 去除字符串右边指定的字符  
trimmedRight := strings.TrimRight("~golang~", "~")  
fmt.Println("去除右边指定字符后的字符串:", trimmedRight)  
  
// 判断字符串是否以指定前缀开头  
hasPrefix := strings.HasPrefix("http://java.sun.com/jsp/jstl/fmt", "http")  
fmt.Println("判断字符串是否以指定前缀开头:", hasPrefix)  
  
// 判断字符串是否以指定后缀结尾  
hasSuffix := strings.HasSuffix("http://java.sun.com/jsp/jstl/fmt", "fmt")  
fmt.Println("判断字符串是否以指定后缀结尾:", hasSuffix)
复制<br><br>字符串所占的字节长度获取根据编码来定：<br>ASCII 字符使用 len() 函数<br>
Unicode 字符串长度使用 utf8.RuneCountInString() 函数<br>//中文三字节，字母一个字节  
var myStrHello string = "hello"  
var myStrSpl string = ","  
var myStrZw string = "码神之路"  
var myStrAll = myStrHello + myStrSpl + myStrZw  
  
fmt.Printf("myStrHello: %d\n", len(myStrHello)) //myStrHello:5  
fmt.Printf("myStrSpl: %d\n", len(myStrSpl))     //myStrSpl:1  
fmt.Printf("myStrZw: %d\n", len(myStrZw))       //myStrZw:12  
fmt.Printf("myStrAll: %d\n", len(myStrAll))     //myStrAll:18

//计算字符串的长度  
fmt.Println(utf8.RuneCountInString(myStrZw)) // 4
复制<br><br>ascii 字符集可以使用 for range 或者 for 循环遍历<br>var str1 string = "hello"  

// 遍历  
for i := 0; i &lt; len(str1); i++ {  
    fmt.Printf("ascii: %c %d\n", str1[i], str1[i])  
}  
for _, s := range str1 {  
    fmt.Printf("unicode: %c %d\n ", s, s)  
}  

复制<br>unicode 字符集使用 for range 进行遍历<br>var str2 string = "hello,码神之路"  
// 中文只能用 for range

for _, s := range str2 {  
    fmt.Printf("unicode: %c %d\n ", s, s)  
}
复制<br>转换 R:=[]rune(str)，也可以使用两种方式遍历<br>var str2 string = "hello,码神之路"  
  
r := []rune(str2)  
  
for i := 0; i &lt; len(r); i++ {  
    fmt.Printf("unicode: %c %d\n", r[i], r[i])  
}  
  
fmt.Println("-------------")  
  
for _, s := range r {  
    fmt.Printf("unicode: %c %d\n", s, s)  
}
复制<br><br>如何获取字符串中的某一段字符?<br>
<br>Strings. Index ()： 正向搜索子字符串
<br>Strings. LastIndex ()：反向搜索子字符串
<br>package main

import (
	"fmt"
	"strings"
)

func main() {
	// 查找  
	tracer := "码神来了,码神bye bye"  
	  
	// 正向搜索字符串  
	comma := strings.Index(tracer, ",")  
	fmt.Println(",所在的位置:", comma) //,所在的位置: 12  
	fmt.Println(tracer[comma+1:]) // 码神bye bye  
	  
	add := strings.Index(tracer, "+")  
	fmt.Println("+所在的位置:", add) // +所在的位置: -1  
	  
	pos := strings.Index(tracer[comma:], "码神")  
	fmt.Println("码神，所在的位置", pos) // 码神，所在的位置 1  
	fmt.Println(comma, pos, tracer[5+pos:]) // 12 1 码神bye bye
}
复制<br>返回的是单字节字符的位，如果想要的 unicode 字符的位置，需要封装<br>package main

import (
	"fmt"
	"strings"
	"unicode/utf8"
)

// Utf8Index strings.Index 的 UTF-8 版本
// 即 Utf8Index("Go语言中文网", "中文") 返回 4，而不是 strings.Index 的 8

func Utf8Index(str, substr string) int {
	index := strings.Index(str, substr)
	if index &lt; 0 {
		return -1
	}
	return utf8.RuneCountInString(str[:index])
}

func Utf8Substring(str string, start int) string {
	//_, startBytes := utf8.DecodeRuneInString(str[start:])
	//return str[start+startBytes:]

	runes := []rune(str)
	if start &gt;= len(runes) {
		return ""
	}
	return string(runes[start:])
}

func main() {
	// 查找
	tracer := "码神来了,码神bye bye"

	comma := Utf8Index(tracer, ",")
	fmt.Println(",所在的位置:", comma) //,所在的位置: 4

	fmt.Println(Utf8Substring(tracer, comma+1)) // 码神bye bye
}

复制<br><br>Golang 语言的字符串是 不可变的<br>修改字符串时，可以将字符串 转换为[]byte 进行修改<br>
[]byte 和 string 可以通过强制类型转换
<br>package main

import (
	"fmt"
)

func main() {
	str := "Hello, World!"
	strBytes := []byte(str)

	// 修改第一个字符
	strBytes[0] = 'M'

	// 将字节切片转换回字符串
	newStr := string(strBytes)

	fmt.Println(newStr) // Mello, World!
}
复制<br>
中文
<br>package main

import (
	"fmt"
)

func main() {
	str := "你好，世界！"
	runes := []rune(str)

	// 修改第一个中文字符
	runes[0] = '好'

	// 将 rune 切片转换回字符串
	newStr := string(runes)

	fmt.Println(newStr) // 好好，世界！
}
复制<br>
字符串替换
<br>package main

import (
	"fmt"
	"strings"
)

func main() {
	// 查找
	str := "Hello, World!"
	newStr := strings.Replace(str, "Hello", "Hi", 1)
	fmt.Println(newStr) // Hi, World!
}
复制<br><br><br><br><br>数组是一个由固定长度的特定类型元素组成的序列，一个数组可以由零个或多个元素组成。<br>因为数组的长度是固定的，所以在 Go 语言中很少直接使用数组。<br><br>var 数组变量名 [元素数量]Type

//- 数组变量名：数组声明及使用时的变量名。
//- 元素数量：数组的元素数量，可以是一个表达式，但最终通过编译期计算的结果必须是整型数值，元素数量不能含有到运行时才能确认大小的数值。
//- Type：可以是任意基本类型，包括数组本身，类型为数组本身时，可以实现多维数组。

//默认数组中的值是类型的默认值
var arr [3]int

//××arr := [3]int
复制<br>
一定要注意，数组是定长的，不可更改，在编译阶段就决定了
<br><br>❶ 初始化赋值<br>//第一种：
var arr [3]int = [3]int{1,2,3}

//如果第三个不赋值，就是默认值0
var arr [3]int = [3]int{1,2}

//可以使用简短声明
arr := [3]int{1,2,3}

//如果不写数据数量，而使用...，表示数组的长度是根据初始化值的个数来计算
arr := [...]int{1,2,3}
复制<br>❷  通过索引下标赋值<br>  var arr [3]int
  arr[0] = 5
  arr[1] = 6
  arr[2] = 7
复制<br>❸ 只初始化第三个值怎么写？<br>//2 给索引为2的赋值 ，所以结果是 0,0,3
arr := [3]int{2:3}
for index,value := range arr{
	fmt.Printf("索引:%d,值：%d \n",index,value)
}
复制<br><br>
<br>通过索引下标取值，索引从 0 开始
```go
复制
fmt.Println(arr[0])<br>
fmt.Println(arr[1])<br>
fmt.Println(arr[2])<br>
```<br>

<br>For range 获取
```go
复制
var arr [3]int<br>
for index, value := range arr {<br>
fmt.Printf("索引:%d,值：%d \n", index, value)<br>
}<br>
```<br>

<br><br>小技巧： 如果觉的每次写 [3]int 有点麻烦，你可以为 [3]int 定义一个新的类型。<br>	type arr3 [3]int
	//这样每次用arr3 代替[3]int，注意前面学过 定义一个类型后 arr3就是一个新的类型
	var arr arr3
	arr[0] = 2
	for index,value := range arr{
		fmt.Printf("索引:%d,值：%d \n",index,value)
	}
复制<br><br>如果两个数组类型相同（包括数组的长度，数组中元素的类型）的情况下，我们可以直接通过较运算符（ == 和 !=）来判断两个数组是否相等，只有当两个数组的所有元素都是相等的时候数组才是相等的，不能比较两个类型不同的数组，否则程序将无法完成编译。Dataview (inline field '='): Error: 
-- PARSING FAILED --------------------------------------------------

&gt; 1 | =
    | ^

Expected one of the following: 

'(', 'null', boolean, date, duration, file link, list ('[1, 2, 3]'), negated field, number, object ('{ a: 1, b: 2 }'), string, variable
<br>a := [2]int{1, 2}  
//`...`来表示数组的长度，我们可以让编译器根据初始化值的数量自动确定数组的长度。  
b := [...]int{1, 2}  
c := [2]int{1, 3}  
fmt.Println(a == b, a == c, b == c) // "true false false"  

//d := [3]int{1, 2}  
//fmt.Println(a == d) // 编译错误：无法比较 [2]int == [3]int
复制<br><br>Go 语言中允许使用多维数组，因为数组属于值类型，所以多维数组的所有维度都会在创建时自动初始化零值，多维数组尤其适合管理具有父子关系或者与坐标系相关联的数据。<br>声明多维数组的语法如下所示：<br>//array_name 为数组的名字，array_type 为数组的类型，size1、size2 等等为数组每一维度的长度。
var array_name [size1][size2]...[sizen] array_type
复制<br>二维数组是最简单的多维数组，二维数组本质上是由多个一维数组组成的。<br>// 声明一个二维整型数组，两个维度的长度分别是 4 和 2
var array [4][2]int
// 使用数组字面量来声明并初始化一个二维整型数组
array = [4][2]int{{10, 11}, {20, 21}, {30, 31}, {40, 41}}
// 声明并初始化数组中索引为 1 和 3 的元素
array = [4][2]int{1: {20, 21}, 3: {40, 41}}
// 声明并初始化数组中指定的元素
array = [4][2]int{1: {0: 20}, 3: {1: 41}}
复制<br>取值：<br>
<br>通过索引下标取值
fmt.Println(array[1][0])
复制

<br>循环取值
```go
复制
array := [4][2]int{{10, 11}, {20, 21}, {30, 31}, {40, 41}}<br>
for index, value := range array {<br>
fmt.Printf("索引:%d,值：%d \n", index, value)<br>
}<br>
```<br>

<br>赋值：<br>// 声明一个 2×2 的二维整型数组
var array [2][2]int
// 设置每个元素的整型值
array[0][0] = 10
array[0][1] = 20
array[1][0] = 30
array[1][1] = 40
复制<br>只要类型一致，就可以将多维数组互相赋值，如下所示，多维数组的类型包括每一维度的长度以及存储在元素中数据的类型：<br>// 声明两个二维整型数组 [2]int [2]int
var array1 [2][2]int  
var array2 [2][2]int
// 为array2的每个元素赋值
array2[0][0] = 10
array2[0][1] = 20
array2[1][0] = 30
array2[1][1] = 40
// 将 array2 的值复制给 array1
array1 = array2
复制<br>因为数组中每个元素都是一个值，所以可以独立复制某个维度，如下所示：<br>array1 := [4][2]int{{10, 11}, {20, 21}, {30, 31}, {40, 41}}
// 将 array1 的索引为 1 的维度复制到一个同类型的新数组里  {20, 21} -&gt; array3
var array3 [2]int = array1[1]
// 将数组中指定的整型值复制到新的整型变量里
var value int = array1[1][0]
for i, v := range array3 {
	fmt.Printf("index:%d,value:%v", i, v)
	fmt.Println()
}
fmt.Println("array1 索引1的二维数组，第0个值:", value)
复制<br><br>切片（Slice） 与数组一样，也是可以容纳若干类型相同的元素的容器。每个切片值都会将数组作为其底层数据结构。<br>
我们也把这样的数组称为 切片的底层数组。与数组不同的是，无法通过切片类型来确定其值的长度。<br>切片（slice） 是对数组的一个连续片段的引用，所以切片是一个引用类型。<br>这个片段可以是 整个数组，也可以是由起始和终止索引标识的一些 项的子集，需要注意的是，终止索引标识的项 不包括在切片内 (左闭右开的区间)。<br>Go 语言中切片的内部结构包含 地址、大小 和 容量，切片一般用于快速地操作一块数据集合。<br><br>从连续内存区域生成切片是常见的操作，格式如下：<br>slice [开始位置 : 结束位置]
//- Slice：表示目标切片对象；
//- 开始位置：对应目标切片对象的索引；
//- 结束位置：对应目标切片的结束索引。
复制<br>从数组生成切片，代码如下：<br>var a  = [3]int{1, 2, 3}
//a[1:2] 生成了一个新的切片
fmt.Println(a, a[1:2])
复制<br>注意：超界会报运行时错误，比如数组长度为 3，则结束位置最大只能为 3<br>
切片在指针的基础上增加了大小，约束了切片对应的内存区域，切片使用中无法对切片内部的地址和大小进行手动调整，因此切片比指针更安全、强大。
<br>
切片和数组密不可分，如果将数组理解为一栋办公楼，那么切片就是把不同的连续楼层出租给使用者，出租的过程需要选择开始楼层和结束楼层，这个过程就会生成切片
<br>var highRiseBuilding [30]int  
for i := 0; i &lt; 30; i++ {  
    highRiseBuilding[i] = i + 1  
}  
//原切片  
fmt.Println(highRiseBuilding[:])  
// 区间  索引位置：10 - 15的元素，不包含索引15  
fmt.Println(highRiseBuilding[10:15])  
// 中间到尾部的所有元素  
fmt.Println(highRiseBuilding[20:])  
// 开头到中间指定位置的所有元素   索引位置为：0,1  
fmt.Println(highRiseBuilding[:2])

//[1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30]
//[11 12 13 14 15]
//[21 22 23 24 25 26 27 28 29 30]
//[1 2]
复制<br><br>除了可以从原有的数组或者切片中生成切片外，也可以 声明一个新的切片，每一种类型都可以拥有其切片类型，表示多个相同类型元素的连续集合。<br>切片类型声明格式如下：<br>var name []Type
//name 表示切片的变量名，Type 表示切片对应的元素类型。
复制<br>// 声明字符串切片
var strList []string
// 声明整型切片
var numList []int
// 声明一个空切片
var numListEmpty = []int{}
// 输出3个切片
fmt.Println(strList, numList, numListEmpty)
// 输出3个切片大小
fmt.Println(len(strList), len(numList), len(numListEmpty))
// 切片判定空的结果
fmt.Println(strList == nil)
fmt.Println(numList == nil)
fmt.Println(numListEmpty == nil)

//[] [] []
//0 0 0
//true
//true
//false  空切片和nil还是不一样的
复制<br>切片是动态结构，只能与 nil 判定相等，不能互相判定相等。声明新的切片后，可以使用 append () 函数向切片中添加元素。<br>var strList []string  
// 追加一个元素  
strList = append(strList, "码神之路")  
fmt.Println(strList)
复制<br><br>如果需要动态地创建一个切片，可以使用 make () 内建函数，格式如下：<br>make( []Type, size, cap )
//`Type` 是指切片的元素类型
//`size` 指的是为这个类型分配多少个元素
//`cap` 为预分配的元素数量
// 这个值设定后不影响 size，只是能提前分配空间，降低多次分配空间造成的性能问题。


a := make([]int, 2)
b := make([]int, 2, 10)
fmt.Println(a, b)
//容量不会影响当前的元素个数，因此 a 和 b 取 len 都是 2
//但如果我们给a 追加一个 a的长度就会变为3
fmt.Println(len(a), len(b))
复制<br>
使用 make () 函数生成的切片一定发生了内存分配操作，但给定开始与结束位置（包括切片复位）的切片只是将新的切片结构指向已经分配好的内存区域，设定开始与结束位置，不会发生内存分配操作。
<br>var numbers4 = [...]int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}
myslice := numbers4[4:6]
//打印出来长度为2=6-4
fmt.Printf("myslice为 %d, 其长度为: %d\n", myslice, len(myslice))
//打印出来cap是6=10-4，cap=`底层数组的长度`-`起始位置`。
fmt.Printf("cap: %d\n", cap(myslice))

//fmt.Printf("直接获取第四个元素异常，为: %d", myslice[3])

// 重新切片，获取第四个元素
myslice = myslice[:cap(myslice)]
fmt.Printf("myslice为 %d, 其长度为: %d\n", myslice, len(myslice))

fmt.Printf("myslice的第四个元素为: %d", myslice[3])
复制<br><br>从数组或切片生成新的切片拥有如下特性：<br>
<br>取出的元素数量为：结束位置 - 开始位置；
<br>取出元素不包含结束位置对应的索引，切片最后一个元素使用 slice[len (slice)] 获取；
<br>当缺省开始位置时，表示从连续区域开头到结束位置 (a[:2])；
<br>当缺省结束位置时，表示从开始位置到整个连续区域末尾 (a[0:])；
<br>两者同时缺省时，与切片本身等效 (a[:])；
<br>两者同时为 0 时，等效于空切片，一般用于切片复位 (a[0:0])。
<br>去除的容量 cap = 底层数组的长度 - 起始位置。
<br>数组切片区别：<br>
<br>片的长度是可变的，它是对数组的一个引用。数组的长度是固定的。
<br>切片的声明使用方括号&nbsp;[]&nbsp;表示切片类型，不指定长度。数组要指定。
<br>切片的长度可以通过内置函数&nbsp;len()&nbsp;来获取，数组直接能看到长度。
<br><br>Go 语言的内置函数 copy () 可以将一个数组切片复制到另一个数组切片中，如果加入的两个数组切片不一样大，就会按照其中较小的那个数组切片的元素个数进行复制。<br>Copy () 函数的使用格式如下：<br>copy( destSlice, srcSlice []T) int
复制<br>其中 srcSlice 为数据来源切片，destSlice 为复制的目标（也就是将 srcSlice 复制到 destSlice），目标切片必须分配过空间且足够承载复制的元素个数，并且来源和目标的 类型必须一致，copy () 函数的返回值表示实际发生复制的元素个数。<br>下面的代码展示了使用 copy () 函数将一个切片复制到另一个切片的过程：<br>slice1 := []int{1, 2, 3, 4, 5}  
slice2 := []int{5, 4, 3}  
//copy(slice2, slice1) // 只会复制slice1的前3个元素到slice2中  
copy(slice1, slice2) // 只会复制slice2的3个元素到slice1的前3个位置  
fmt.Println(slice1)  
fmt.Println(slice2)
复制<br>切片的引用和复制操作对切片元素的影响:<br>package main

import "fmt"

func main() {
	// 设置元素数量为1000
	const elementCount = 1000
	// 预分配足够多的元素切片
	srcData := make([]int, elementCount)
	// 将切片赋值
	for i := 0; i &lt; elementCount; i++ {
		srcData[i] = i
	}
	// 引用切片数据 切片不会因为等号操作进行元素的复制
	refData := srcData
	// 预分配足够多的元素切片
	copyData := make([]int, elementCount)
	// 将数据复制到新的切片空间中
	copy(copyData, srcData)
	// 修改原始数据的第一个元素
	srcData[0] = 999
	// 打印引用切片的第一个元素 引用数据的第一个元素将会发生变化
	fmt.Println("引用的发生变化了：", refData[0])
	// 打印复制切片的第一个和最后一个元素 由于数据是复制的，因此不会发生变化。
	fmt.Println("复制的未发生变化：", copyData[0], copyData[elementCount-1])
	// 复制原始数据从4到6(不包含6)，4，5替换0，1
	copy(copyData, srcData[4:6])
	for i := 0; i &lt; 5; i++ {
		fmt.Printf("%d ", copyData[i])
	}
}

复制<br><br>map 是一种无序的 键值对 的集合。<br>Map 最重要的一点是通过 key 来快速检索数据，key 类似于索引，指向数据的值。<br>Map 是一种集合，所以我们可以像迭代数组和切片那样迭代它。不过，map 是无序的，我们无法决定它的返回顺序，这是因为 map 是使用 hash 表来实现的。<br><br>Map 是引用类型，可以使用如下方式声明：<br>var mapname map[keytype]valuetype
//[keytype] 和 valuetype 之间允许有空格。
//Mapname 为 map 的变量名。
//Keytype 为键类型。
//Valuetype 是键对应的值类型。
复制<br>
声明不需要知道 map 的长度，Map 可以根据新增的 key-value 动态的伸缩，未初始化的 map 的值是 nil，使用函数 len () 可以获取 map 中键值对的数目。
<br>package main

import "fmt"

func main() {
	var mapLit map[string]int
	var mapAssigned map[string]int
	mapLit = map[string]int{"one": 1, "two": 2}
	mapAssigned = mapLit
	//mapAssigned 是 mapList 的引用，对 mapAssigned 的修改也会影响到 mapList 的值。
	mapAssigned["two"] = 3
	fmt.Printf("Map literal at \"one\" is: %d\n", mapLit["one"])
	fmt.Printf("Map assigned at \"two\" is: %d\n", mapLit["two"])
	fmt.Printf("Map literal at \"ten\" is: %d\n", mapLit["ten"])
	//没有会返回这个类型的初始值，所以要判断是否存在需要加exists
	value, exists := mapLit["ten"]
	if exists {
		fmt.Printf("Map literal at \"ten\" is: %d\n", value)
	} else {
		fmt.Println("Key 'ten' does not exist in the map.")
	}
}

//Map literal at "one" is: 1
//Map assigned at "two" is: 3
//Map literal at "ten" is: 0
//Key 'ten' does not exist in the map.
复制<br><br>map 使用 make创建方式：<br>make(map[keytype]valuetype)

//不存在固定长度或者最大限制，但是也可以选择标明 map 的初始容量 capacity
make(map[keytype]valuetype, cap)

//例子：
map2 := make(map[string]int, 100)
复制<br>切记不要使用 new 创建 map，否则会得到一个空引用的指针<br>当 map 增长到容量上限的时候，如果再增加新的 key-value，map 的大小会自动加 1，所以出于性能的考虑，对于大的 map 或者会快速扩张的 map，即使只是大概知道容量，也最好先标明。<br>3、Map 和切片结合<br>例：当我们要处理 unix 机器上的所有进程，以父进程（pid 为整形）作为 key，所有的子进程（以所有子进程的 pid 组成的切片）作为 value。<br>
通过将 value 定义为 []int 类型或者其他类型的切片，类似于 java 中的 Map&lt;Interger,List&lt;Interger&gt;。<br>示例代码如下所示：<br>//键的类型是 `int`，值的类型是 `[]int`，即整数切片。
//直接通过键来访问和修改整数切片的内容
mp1 := make(map[int][]int)

//键的类型是 `int`，值的类型是 `*[]int`，即指向整数切片的指针。
//先通过键获取指向整数切片的指针，然后再访问和修改切片的内容
mp2 := make(map[int]*[]int)
复制<br>使用：<br>// mp1 示例  
mp1 := make(map[int][]int)  
slice1 := []int{1, 2, 3}  
mp1[1] = slice1  
  
// 修改 mp1 中键为 1 的切片  
mp1[1][0] = 10  
fmt.Println(mp1[1]) // 输出: [10 2 3]  
  
// mp2 示例  
mp2 := make(map[int]*[]int)  
slice2 := []int{1, 2, 3}  
mp2[1] = &amp;slice2  
  
// 修改 mp2 中键为 1 的切片  
(*mp2[1])[0] = 10  
fmt.Println(*mp2[1]) // 输出: [10 2 3]
复制<br><br><br>Map 的遍历过程使用 for range 循环完成，代码如下：<br>scene := make(map[string]int)
scene["cat"] = 66
scene["dog"] = 4
scene["pig"] = 960
for k, v := range scene {
    fmt.Println(k, v)
}
复制<br>注意：map 是无序的，不要期望 map 在遍历时返回某种期望顺序的结果<br><br>使用 delete () 内建函数从 map 中删除一组键值对，delete () 函数的格式如下：<br>delete(map, 键)
复制<br>Map 为要删除的 map 实例，键为要删除的 map 中键值对的键。<br>scene := make(map[string]int)  
// 准备map数据  
scene["cat"] = 66  
scene["dog"] = 4  
scene["pig"] = 960  
delete(scene, "dog")  
for k, v := range scene {  
    fmt.Println(k, v)  
    delete(scene, k)  
}  
fmt.Println(scene)
复制<br>Go 语言中并没有为 map 提供任何清空所有元素的函数、方法，清空 map 的唯一办法就是重新 make 一个新的 map，不用担心垃圾回收的效率，Go 语言中的并行垃圾回收效率比写一个清空函数要高效的多。<br><br>注意 map 在并发情况下，只读是线程安全的，同时读写是线程不安全的。<br>并发情况下读写 map 时会出现问题，代码如下：<br>// 创建一个int到int的映射
m := make(map[int]int)
// 开启一段并发代码
go func() {
    // 不停地对map进行写入
    for {
        m[1] = 1
    }
}()
// 开启一段并发代码
go func() {
    // 不停地对map进行读取
    for {
        _ = m[1]
    }
}()
// 无限循环, 让并发程序在后台执行
for {
}

//编译不报错，但运行报错，报错输出：
//fatal error: concurrent map read and map write
//使用了两个并发函数不断地对 map 进行读和写而发生了竞态问题，map 内部会对这种并发操作进行检查并提前发现。

复制<br>需要并发读写时，一般的做法是加锁，但这样性能并不高，Go 语言在 1.9 版本中提供了一种效率较高的并发安全的 sync.Map，sync. Map 和 map 不同，不是以语言原生形态提供，而是在 sync 包下的特殊结构。<br>Sync. Map 有以下特性：<br>
<br>无须初始化，直接声明即可。
<br>Sync. Map 不能使用 map 的方式进行取值和设置等操作，而是使用 sync. Map 的方法进行调用，Store 表示存储，Load 表示获取，Delete 表示删除。
<br>使用 Range 配合一个回调函数进行遍历操作，通过回调函数返回内部遍历出来的值，Range 参数中回调函数的返回值在需要继续迭代遍历时，返回 true，终止迭代遍历时，返回 false。
<br>package main
import (
      "fmt"
      "sync"
)
func main() {
    //sync.Map 不能使用 make 创建
    var scene sync.Map
    // 将键值对保存到sync.Map
    //sync.Map 将键和值以 interface{} 类型进行保存。
    scene.Store("greece", 97)
    scene.Store("london", 100)
    scene.Store("egypt", 200)
    // 从sync.Map中根据键取值
    fmt.Println(scene.Load("london"))
    // 根据键删除对应的键值对
    scene.Delete("london")
    // 遍历所有sync.Map中的键值对
    //遍历需要提供一个匿名函数，参数为 k、v，类型为 interface{}，每次 Range() 在遍历一个元素时，都会调用这个匿名函数把结果返回。
    scene.Range(func(k, v interface{}) bool {
        fmt.Println("iterate:", k, v)
        return true
    })
}
复制<br>sync. Map 为了保证并发安全有一些性能损失，因此在非并发情况下，使用 map 相比使用 sync. Map 会有更好的性能。<br><br>零值是 Go 语言中变量在声明之后但是未初始化被赋予的该类型的一个默认值。<br>在 Go 语言中，布尔类型的零值（初始值）为 false，数值类型的零值为 0，字符串类型的零值为空字符串 ""。<br>
指针、切片、映射、通道、函数和接口的零值则是 nil 标识符。<br>Nil 和其他语言的 null 是不同的。<br>1、谨慎比较<br>nil&nbsp;只能与指针类型进行比较，而不能与其他类型的值进行直接比较（**包括 nil 本身）。<br>var sp []int  
fmt.Println(sp == nil) //true  
fmt.Println(nil == sp) //true  
  
//var ot int  
//fmt.Println(ot == nil)  
//编译时候就报错  
  
//fmt.Println(nil == nil)  
//运行直接报错 invalid operation: nil == nil (operator == not defined on untyped nil)
复制<br>2、不是关键字或保留字<br>Nil 并不是 Go 语言的关键字或者保留字，也就是说我们可以定义一个名称为 nil 的变量，比如下面这样：<br>//但不提倡这样做
var nil = errors.New("my god")
复制<br>3、没有默认类型<br>package main
import (
    "fmt"
)
func main() {
    //error :use of untyped nil
    fmt.Printf("%T", nil)
    print(nil)
}
复制<br>4、不同类型的 nil，指针的地址相同。<br>package main
import (
    "fmt"
)
func main() {
    var arr []int
    var num *int
    fmt.Printf("%p\n", arr)
    fmt.Printf("%p", num)
}

//0x0
//0x0
复制<br>5、nil 是 map、slice、pointer、channel、func、interface 的零值<br>package main
import (
    "fmt"
)
func main() {
    var m map[int]string
    var ptr *int
    var c chan int
    var sl []int
    var f func()
    var i interface{}
    fmt.Printf("%#v\n", m)
    fmt.Printf("%#v\n", ptr)
    fmt.Printf("%#v\n", c)
    fmt.Printf("%#v\n", sl)
    fmt.Printf("%#v\n", f)
    fmt.Printf("%#v\n", i)
}
复制<br> 6、不同类型的 nil 值占用的内存大小可能是不一样的<br>
具体的大小取决于编译器和架构<br>package main
import (
    "fmt"
    "unsafe"
)
func main() {
    var p *struct{}
    fmt.Println( unsafe.Sizeof( p ) ) // 8
    var s []int
    fmt.Println( unsafe.Sizeof( s ) ) // 24
    var m map[int]bool
    fmt.Println( unsafe.Sizeof( m ) ) // 8
    var c chan string
    fmt.Println( unsafe.Sizeof( c ) ) // 8
    var f func()
    fmt.Println( unsafe.Sizeof( f ) ) // 8
    var i interface{}
    fmt.Println( unsafe.Sizeof( i ) ) // 16
}
复制<br><br>Make 关键字的主要作用是创建 slice、map 和 Channel 等内置的数据结构，而 new 的主要作用是为类型申请一片内存空间，并返回指向这片内存的指针。<br>
<br>Make 分配空间后，会进行初始化，new 分配的空间被清零
<br>New 分配返回的是指针，即类型 *Type。Make 返回引用，即 Type；
<br>New 可以分配任意类型的数据；
<br><br><br>
Go 语言可以通过自定义的方式形成新的类型，结构体就是这些类型中的一种复合类型，结构体是由零个或多个任意类型的值聚合成的实体，每个值都可以称为结构体的成员。
<br>结构体成员也可以称为“字段”，这些字段有以下特性：<br>
<br>字段拥有自己的类型和值；
<br>字段名必须唯一；
<br>字段的类型也可以是结构体，甚至是字段所在结构体的类型。
<br>使用关键字 type 可以将各种基本类型定义为自定义类型，基本类型包括整型、字符串、布尔等。结构体是一种复合的基本类型，通过 type 定义为自定义类型后，使结构体更便于使用。<br>结构体的定义格式如下：<br>type 类型名 struct {
    字段1 字段1类型
    字段2 字段2类型
    …
}
复制<br>
<br>类型名：标识自定义结构体的名称，在同一个包内不能重复。
<br>struct{}：表示结构体类型，type 类型名 struct{} 可以理解为将 struct{} 结构体定义为类型名的类型。
<br>字段 1、字段 2……：表示结构体字段名，结构体中的字段名必须唯一。
<br>字段 1 类型、字段 2 类型……：表示结构体各个字段的类型。
<br>示例：<br>type Point struct {
    X int
    Y int
}
复制<br>颜色的红、绿、蓝 3 个分量可以使用 byte 类型:<br>type Color struct {
    R, G, B byte
}
复制<br>结构体的定义只是一种内存布局的描述，只有当结构体实例化时，才会真正地分配内存<br><br>实例化就是根据结构体定义的格式创建一份与格式一致的内存区域，结构体实例与实例间的内存是完全独立的。<br>基本的实例化形式:<br>结构体本身是一种类型，可以像整型、字符串等类型一样，以 var 的方式声明结构体即可完成实例化。<br>var ins T
复制<br>T 为结构体类型，ins 为结构体的实例。<br>package main

import "fmt"

type Point struct {
	X int
	Y int
}
func main() {
    //使用.来访问结构体的成员变量,结构体成员变量的赋值方法与普通变量一致。
	var p Point
	p.X = 1
	p.Y = 2
	fmt.Printf("%v,x=%d,y=%d",p,p.X,p.Y )
}

复制<br>package main

import "fmt"

type Point struct {
	X int
	Y int
}
func main() {

	var p Point
	//p.X = 1
	//p.Y = 2
    //如果不赋值 结构体中的变量会使用零值初始化
	fmt.Printf("%v,x=%d,y=%d",p,p.X,p.Y )
}

复制<br>package main

import "fmt"

type Point struct {
	X int
	Y int
}
func main() {
	//可以使用
	var p = Point{
		X: 1,
		Y: 2,
	}
    var p = Point{
		1,
		2,
	}
	fmt.Printf("%v,x=%d,y=%d",p,p.X,p.Y )
}

复制<br>创建指针类型的结构体：<br>Go 语言中，还可以使用 new 关键字对类型（包括结构体、整型、浮点数、字符串等）进行实例化，结构体在实例化后会形成指针类型的结构体。<br>ins := new(T)
复制<br>
<br>T 为类型，可以是结构体、整型、字符串等。
<br>Ins：T 类型被实例化后保存到 ins 变量中，ins 的类型为 *T，属于指针。
<br>下面的例子定义了一个玩家（Player）的结构，玩家拥有名字、生命值和魔法值：<br>type Player struct{
    Name string
    HealthPoint int
    MagicPoint int
}
tank := new(Player)
tank.Name = "码神"
tank.HealthPoint = 300
复制<br>new 实例化的结构体实例在成员赋值上与基本实例化的写法一致。<br>取结构体的地址实例化:<br>在 Go 语言中，对结构体进行 &amp; 取地址操作时，视为对该类型进行一次 new 的实例化操作，取地址格式如下：<br>ins := &amp;T{}
复制<br>其中：<br>
<br>T 表示结构体类型。
<br>Ins 为结构体的实例，类型为 *T，是指针类型。
<br>示例：<br>package main

import "fmt"

type Command struct {
	Name    string    // 指令名称
	Var     *int      // 指令绑定的变量
	Comment string    // 指令的注释
}

func newCommand(name string, varRef *int, comment string) *Command {
	return &amp;Command{
		Name:    name,
		Var:     varRef,
		Comment: comment,
	}
}

var version = 1
func main() {
	cmd := newCommand(
		"version",
		&amp;version,
		"show version",
	)
	fmt.Println(cmd)
}

复制<br><br>匿名结构体没有类型名称，无须通过 type 关键字定义就可以直接使用。<br>ins := struct {
    // 匿名结构体字段定义
    字段1 字段类型1
    字段2 字段类型2
    …
}{
    // 字段值初始化
    初始化字段1: 字段1的值,
    初始化字段2: 字段2的值,
    …
}
复制<br>
<br>字段 1、字段 2……：结构体定义的字段名。
<br>初始化字段 1、初始化字段 2……：结构体初始化时的字段名，可选择性地对字段初始化。
<br>字段类型 1、字段类型 2……：结构体定义字段的类型。
<br>字段 1 的值、字段 2 的值……：结构体初始化字段的初始值。
<br>package main
import (
	"fmt"
)
// 打印消息类型, 传入匿名结构体
func printMsgType(msg *struct {
	id   int
	data string
}) {
	// 使用动词%T打印msg的类型
	fmt.Printf("%T\n, msg:%v", msg,msg)
}
func main() {
	// 实例化一个匿名结构体
	msg := &amp;struct {  // 定义部分
		id   int
		data string
	}{  // 值初始化部分
		1024,
		"hello",
	}
	printMsgType(msg)
}
复制<br><br>在 Go 语言中，结构体就像是类的一种 简化形式，那么类的方法在哪里呢？<br>在 Go 语言中有一个概念，它和方法有着同样的名字，并且大体上意思相同，Go 方法是作用在接收器（receiver）上的一个函数，接收器是某种类型的变量，因此方法是一种特殊类型的函数。<br>接收器类型可以是（几乎）任何类型，不仅仅是结构体类型，任何类型都可以有方法，甚至可以是函数类型，可以是 int、bool、string 或数组的别名类型，但是接收器不能是一个接口类型，因为接口是一个抽象定义，而方法却是具体实现，如果这样做了就会引发一个编译错误 invalid receiver type…<br>接收器也不能是一个指针类型，但是它可以是任何其他允许类型的指针。<br>一个类型加上它的方法等价于面向对象中的一个类<br>在 Go 语言中，类型的 代码 和绑定在它上面的 方法 的代码可以 不放置在一起，它们可以存在不同的源文件中，唯一的要求是它们必须是 同一个包的。<br>
类型 T（或 T）上的所有方法的集合叫做类型 T（或 T）的方法集。
<br>在面向对象的语言中，类拥有的方法一般被理解为类可以做的事情。在 Go 语言中“方法”的概念与其他语言一致，只是 Go 语言建立的“接收器”强调方法的作用对象是接收器，也就是类实例，而函数没有作用对象。<br>为结构体添加方法：<br>
需求：将物品放入背包
<br>面向对象的写法：<br>​ 将背包做为一个对象，将物品放入背包的过程作为“方法”<br>package main

import "fmt"

type Bag struct {
	items []int
}
func (b *Bag) Insert(itemid int) {
	b.items = append(b.items, itemid)
}
func main() {
	b := new(Bag)
	b.Insert(1001)
	fmt.Println(b.items)
}
复制<br>(b *Bag)  表示接收器，即 Insert 作用的对象实例。每个方法只能有一个接收器。<br><br>接收器的格式如下：<br>func (接收器变量 接收器类型) 方法名(参数列表) (返回参数) {
    函数体
}
复制<br>
<br>接收器变量：接收器中的参数变量名在命名时，官方建议使用接收器类型名的第一个小写字母，而不是 self、this 之类的命名。例如，Socket 类型的接收器变量应该命名为 s，Connector 类型的接收器变量应该命名为 c 等。
<br>接收器类型：接收器类型和参数类似，可以是指针类型和非指针类型。
<br>方法名、参数列表、返回参数：格式与函数定义一致。
<br>接收器根据接收器的类型可以分为 指针接收器、非指针接收器，两种接收器在使用时会产生不同的效果，根据效果的不同，两种接收器会被用于不同性能和功能要求的代码中。<br>指针类型的接收器:<br>指针类型的接收器由一个结构体的指针组成，更接近于面向对象中的 this 或者 self。<br>由于指针的特性，调用方法时，修改接收器指针的任意成员变量，在方法结束后，修改都是有效的。<br>示例：<br>使用结构体定义一个属性（Property），为属性添加 SetValue () 方法以封装设置属性的过程，通过属性的 Value () 方法可以重新获得属性的数值，使用属性时，通过 SetValue () 方法的调用，可以达成修改属性值的效果：<br>package main
import "fmt"
// 定义属性结构
type Property struct {
    value int  // 属性值
}
// 设置属性值
func (p *Property) SetValue(v int) {
    // 修改p的成员变量
    p.value = v
}
// 取属性值
func (p *Property) Value() int {
    return p.value
}
func main() {
    // 实例化属性
    p := new(Property)
    // 设置值
    p.SetValue(100)
    // 打印值
    fmt.Println(p.Value())
}
复制<br>非指针类型的接收器:<br>当方法作用于非指针接收器时，Go 语言会在代码运行时将接收器的值复制一份，在非指针接收器的方法中可以获取接收器的成员值，但 修改后无效。<br>点（Point）使用结构体描述时，为点添加 Add () 方法，这个方法不能修改 Point 的成员 X、Y 变量，而是在计算后返回新的 Point 对象，Point 属于小内存对象，在函数返回值的复制过程中可以极大地提高代码运行效率:<br>package main
import (
    "fmt"
)
// 定义点结构
type Point struct {
    X int
    Y int
}
// 非指针接收器的加方法
func (p Point) Add(other Point) Point {
    // 成员值与参数相加后返回新的结构
    return Point{p.X + other.X, p.Y + other.Y}
}
func main() {
    // 初始化点
    p1 := Point{1, 1}
    p2 := Point{2, 2}
    // 与另外一个点相加
    result := p1.Add(p2)
    // 输出结果
    fmt.Println(result)
}
复制<br>在计算机中，小对象由于值复制时的速度较快，所以适合使用非指针接收器，大对象因为复制性能较低，适合使用指针接收器，在接收器和参数间传递时不进行复制，只是传递指针。<br><br>在游戏中，一般使用二维矢量保存玩家的位置，使用矢量运算可以计算出玩家移动的位置，本例子中，首先实现二维矢量对象，接着构造玩家对象，最后使用矢量对象和玩家对象共同模拟玩家移动的过程。<br>实现二维矢量结构:<br>矢量是数学中的概念，二维矢量拥有两个方向的信息，同时可以进行加、减、乘（缩放）、距离、单位化等计算，在计算机中，使用拥有 X 和 Y 两个分量的 Vec 2 结构体实现数学中二维向量的概念。<br>package main
import "math"
type Vec2 struct {
    X, Y float32
}
// 加
func (v Vec2) Add(other Vec2) Vec2 {
    return Vec2{
        v.X + other.X,
        v.Y + other.Y,
    }
}
// 减
func (v Vec2) Sub(other Vec2) Vec2 {
    return Vec2{
        v.X - other.X,
        v.Y - other.Y,
    }
}
// 乘 缩放或者叫矢量乘法，是对矢量的每个分量乘上缩放比，Scale() 方法传入一个参数同时乘两个分量，表示这个缩放是一个等比缩放
func (v Vec2) Scale(s float32) Vec2 {
    return Vec2{v.X * s, v.Y * s}
}
// 距离 计算两个矢量的距离，math.Sqrt() 是开方函数，参数是 float64，在使用时需要转换，返回值也是 float64，需要转换回 float32
func (v Vec2) DistanceTo(other Vec2) float32 {
    dx := v.X - other.X
    dy := v.Y - other.Y
    return float32(math.Sqrt(float64(dx*dx + dy*dy)))
}
// 矢量单位化
func (v Vec2) Normalize() Vec2 {
    mag := v.X*v.X + v.Y*v.Y
    if mag &gt; 0 {
        oneOverMag := 1 / float32(math.Sqrt(float64(mag)))
        return Vec2{v.X * oneOverMag, v.Y * oneOverMag}
    }
    return Vec2{0, 0}
}
复制<br>实现玩家对象：<br>玩家对象负责存储玩家的当前位置、目标位置和速度，使用 MoveTo () 方法为玩家设定移动的目标，使用 Update () 方法更新玩家位置，在 Update () 方法中，通过一系列的矢量计算获得玩家移动后的新位置。<br>
<br>使用矢量减法，将目标位置（targetPos）减去当前位置（currPos）即可计算出位于两个位置之间的新矢量
<br>使用 Normalize () 方法将方向矢量变为模为 1 的单位化矢量，这里需要将矢量单位化后才能进行后续计算
<br>获得方向后，将单位化方向矢量根据速度进行等比缩放，速度越快，速度数值越大，乘上方向后生成的矢量就越长（模很大）
<br>将缩放后的方向添加到当前位置后形成新的位置
<br>package main
type Player struct {
    currPos   Vec2    // 当前位置
    targetPos Vec2    // 目标位置
    speed     float32 // 移动速度
}
// 移动到某个点就是设置目标位置
//逻辑层通过这个函数告知玩家要去的目标位置，随后的移动过程由 Update() 方法负责
func (p *Player) MoveTo(v Vec2) {
    p.targetPos = v
}
// 获取当前的位置
func (p *Player) Pos() Vec2 {
    return p.currPos
}

//判断玩家是否到达目标点，玩家每次移动的半径就是速度（speed），因此，如果与目标点的距离小于速度，表示已经非常靠近目标，可以视为到达目标。
func (p *Player) IsArrived() bool {
    // 通过计算当前玩家位置与目标位置的距离不超过移动的步长，判断已经到达目标点
    return p.currPos.DistanceTo(p.targetPos) &lt; p.speed
}
// 逻辑更新
func (p *Player) Update() {
    if !p.IsArrived() {
        // 计算出当前位置指向目标的朝向
        //数学中，两矢量相减将获得指向被减矢量的新矢量
        dir := p.targetPos.Sub(p.currPos).Normalize()
        // 添加速度矢量生成新的位置
        newPos := p.currPos.Add(dir.Scale(p.speed))
        // 移动完成后，更新当前位置
        p.currPos = newPos
    }
}
// 创建新玩家
func NewPlayer(speed float32) *Player {
    return &amp;Player{
        speed: speed,
    }
}
复制<br>处理移动逻辑：<br>将 Player 实例化后，设定玩家移动的最终目标点，之后开始进行移动的过程，这是一个不断更新位置的循环过程，每次检测玩家是否靠近目标点附近，如果还没有到达，则不断地更新位置，让玩家朝着目标点不停的修改当前位置，如下代码所示：<br>package main
import "fmt"

func main() {
	// 实例化玩家对象，并设速度为0.5
	p := NewPlayer(0.5)
	// 让玩家移动到3,1点
	p.MoveTo(Vec2{3, 1})
	// 如果没有到达就一直循环
	for !p.IsArrived() {
		// 更新玩家位置
		p.Update()
		// 打印每次移动后的玩家位置
		fmt.Println(p.Pos())
	}
	fmt.Printf("到达了：%v",p.Pos())
}
复制<br>给任意类型添加方法<br>Go 语言可以对任何类型添加方法，给一种类型添加方法就像给结构体添加方法一样，因为结构体也是一种类型。<br>为基本类型添加方法：<br>在 Go 语言中，使用 type 关键字可以定义出新的自定义类型，之后就可以为自定义类型添加各种方法了。我们习惯于使用面向过程的方式判断一个值是否为 0，例如：<br>if  v == 0 {
    // v等于0
}
复制<br>如果将 v 当做整型对象，那么判断 v 值就可以增加一个 IsZero () 方法，通过这个方法就可以判断 v 值是否为 0，例如：<br>if  v.IsZero() {
    // v等于0
}
复制<br>为基本类型添加方法的详细实现流程如下：<br>package main
import (
    "fmt"
)
// 将int定义为MyInt类型
type MyInt int
// 为MyInt添加IsZero()方法
func (m MyInt) IsZero() bool {
    return m == 0
}
// 为MyInt添加Add()方法
func (m MyInt) Add(other int) int {
    return other + int(m)
}
func main() {
    var b MyInt
    fmt.Println(b.IsZero())
    b = 1
    fmt.Println(b.Add(2))
}
复制<br><br>结构体可以包含匿名字段。匿名字段是指在结构体中声明的字段没有具体的字段名，只有字段的类型。<br>通过使用匿名字段，可以将其他类型的字段嵌入到结构体中，从而实现代码复用和组合的效果。这种方式有时也被称为"嵌入字段"或"嵌入结构体"。<br>Go 语言中的继承通常是通过内嵌或组合来实现的。<br>package main

import "fmt"

type User struct {
    id   int
    name string
}

type Manager struct {
    User
}

func (self *User) ToString() string { // receiver = &amp;(Manager.User)
    return fmt.Sprintf("User: %p, %v", self, self)
}

func main() {
    m := Manager{User{1, "Tom"}}
    fmt.Printf("Manager: %p\n", &amp;m)
    fmt.Println(m.ToString())
}
复制<br>类似于重写的功能：<br>package main

import "fmt"

type User struct {
    id   int
    name string
}

type Manager struct {
    User
    title string
}

func (self *User) ToString() string {
    return fmt.Sprintf("User: %p, %v", self, self)
}

func (self *Manager) ToString() string {
    return fmt.Sprintf("Manager: %p, %v", self, self)
}

func main() {
    m := Manager{User{1, "Tom"}, "Administrator"}

    fmt.Println(m.ToString())

    fmt.Println(m.User.ToString())
}
复制<br><br>在 Go 语言中接口（interface）是一种类型，一种抽象的类型。<br>Interface 是一组 method 的集合，接口做的事情就像是定义一个协议（规则），只要一台机器有洗衣服和甩干的功能，我就称它为洗衣机。不关心属性（数据），只关心行为（方法）。<br>接口（interface）是一种类型<br>接口类型是对其它类型行为的抽象和概括；因为接口类型不会和特定的实现细节绑定在一起，通过这种抽象的方式我们可以让我们的函数更加灵活和更具有适应能力。<br>接口是双方约定的一种合作协议。接口实现者不需要关心接口会被怎样使用，调用者也不需要关心接口的实现细节。接口是一种类型，也是一种抽象结构，不会暴露所含数据的格式、类型及结构。<br><br>
Go 语言提倡面向接口编程。
<br>每个接口类型由数个方法组成。接口的形式代码如下：<br>type 接口类型名 interface{
    方法名1( 参数列表1 ) 返回值列表1
    方法名2( 参数列表2 ) 返回值列表2
    …
}

//接口类型名：使用 type 将接口定义为自定义的类型名。Go 语言的接口在命名时，一般会在单词后面添加 er，如有写操作的接口叫 Writer，有字符串功能的接口叫 Stringer，有关闭功能的接口叫 Closer 等。
//方法名：当方法名首字母是大写时，且这个接口类型名首字母也是大写时，这个方法可以被接口所在的包（package）之外的代码访问。
//参数列表、返回值列表：参数列表和返回值列表中的参数变量名可以被忽略

复制<br>type Writer interface{
    //大写字母开头 意味着别的包 也可以访问
    Write([]byte) error
}
复制<br><br>在Go语言中，要实现一个接口，需要满足以下条件：<br>
<br>方法集匹配：类型必须实现接口中的所有方法。

<br>方法集是指类型中可以被直接调用的方法集合。如果一个任意类型 T 的方法集为一个接口类型的方法集的超集，则我们说类型 T 实现了此接口类型。
<br>T 可以是一个非接口类型，也可以是一个接口类型。


<br>隐式实现：Go 语言中没有类似于 implements 的关键字，接口的实现是隐式的，无需显式声明。只要类型的方法集匹配接口的方法集，就视为实现了该接口。
<br>示例：<br>package main
import (
    "fmt"
)
// 定义一个数据写入器
type DataWriter interface {
    WriteData(data interface{}) error
}
// 定义文件结构，用于实现DataWriter
type file struct {
}
// 实现DataWriter接口的WriteData方法
func (d *file) WriteData(data interface{}) error {
    // 模拟写入数据
    fmt.Println("WriteData:", data)
    return nil
}
func main() {
    // 实例化file
    f := new(file)
    // 声明一个DataWriter的接口
    var writer DataWriter
    // 将接口赋值f，也就是*file类型
    writer = f
    // 使用DataWriter接口进行数据写入
    writer.WriteData("data")
}
复制<br>接口定义后，需要实现接口，才能正确编译通过并使用接口。<br>❶ 实现方法必须和接口方法格式完全一致<br>
在类型中添加与接口签名一致的方法就可以实现该方法。签名包括方法中的名称、参数列表、返回参数列表。<br>
只要实现接口类型中的方法的名称、参数列表、返回参数列表中的任意一项与接口要实现的方法不一致，那么接口的这个方法就不会被实现。<br>示例：<br>package main  
  
import "fmt"  
  
type Printer interface {  
    Print(message string)  
}  
  
type MyPrinter struct{}  
  
// 错误的实现方法，参数列表不匹配  
func (mp MyPrinter) Print() {  
    fmt.Println("Printing...")  
}  
  
func main() {  
    var p Printer  
    p = MyPrinter{} // 编译错误：MyPrinter.Print method has different signature than Printer.Print  
    p.Print("Hello")  
}
复制<br>❷ 必须实现接口所有方法<br>
当一个接口中有多个方法时，只有这些方法都被实现了，接口才能被正确编译并使用。<br>type DataWriter interface {  
    WriteData(data interface{}) error  
}  
  
type FileWriter struct {  
    FilePath string  
}  

//func (f FileWriter) WriteData(data interface{}) error {  
//  //TODO implement me  
//  panic("implement me")  
//}
  
func main() {  
    var writer DataWriter  
    writer = FileWriter{FilePath: "data.txt"} // 编译错误：FileWriter does not implement DataWriter (missing WriteData method)  
    err := writer.WriteData("Hello")  
    if err != nil {  
       return  
    }  
}
复制<br>但是如果 main 方法根本没有使用到接口，那不会编译报错。 <br>package main  
  
import "fmt"  

//此接口根本没有人用
type DataWriter interface {  
    WriteData(data interface{}) error  
}  
  
type FileWriter struct {  
    FilePath string  
}  
  
func main() {  
    var writer FileWriter  
    writer = FileWriter{FilePath: "data.txt"} // 编译错误：FileWriter does not implement DataWriter (missing WriteData method)  
    fmt.Print(writer)  
}
复制<br><br>
在 Go 语言中类型和接口之间有一对多和多对一的关系
<br>❶ 一个类型可以实现多个接口<br>一个类型可以同时实现多个接口，而接口间彼此独立，不知道对方的实现。<br>例如，狗可以叫，也可以动。<br>我们就分别定义 Sayer 接口和 Mover 接口，如下：<br>// Sayer 接口
type Sayer interface {
    say()
}

// Mover 接口
type Mover interface {
    move()
}
复制<br>Dog 既可以实现 Sayer 接口，也可以实现 Mover 接口。<br>type dog struct {
    name string
}

// 实现Sayer接口
func (d dog) say() {
    fmt.Printf("%s会叫汪汪汪\n", d.name)
}

// 实现Mover接口
func (d dog) move() {
    fmt.Printf("%s会动\n", d.name)
}

func main() {
    var x Sayer
    var y Mover

    var a = dog{name: "旺财"}
    x = a
    y = a
    x.say()
    y.move()
}
复制<br>❷ 多个类型实现同一接口<br>Go 语言中不同的类型还可以实现同一接口首先我们定义一个 Mover 接口，它要求必须有一个 move 方法。<br>// Mover 接口
type Mover interface {
    move()
}
复制<br>例如狗可以动，汽车也可以动，可以使用如下代码实现这个关系：<br>type dog struct {
    name string
}

type car struct {
    brand string
}

// dog类型实现Mover接口
func (d dog) move() {
    fmt.Printf("%s会跑\n", d.name)
}

// car类型实现Mover接口
func (c car) move() {
    fmt.Printf("%s速度70迈\n", c.brand)
}
复制<br>这个时候我们在代码中就可以把狗和汽车当成一个会动的物体来处理了，不再需要关注它们具体是什么，只需要调用它们的 move 方法就可以了。<br>func main() {
    var x Mover
    var a = dog{name: "旺财"}
    var b = car{brand: "保时捷"}
    x = a
    x.move()
    x = b
    x.move()
}
复制<br>并且一个接口的方法，不一定需要由一个类型完全实现，接口的方法可以通过在类型中嵌入其他类型或者结构体来实现。<br>// WashingMachine 洗衣机
type WashingMachine interface {
    wash()
    dry()
}

// 甩干器
type dryer struct{}

// 实现WashingMachine接口的dry()方法
func (d dryer) dry() {
    fmt.Println("甩一甩")
}

// 海尔洗衣机
type haier struct {
    dryer //嵌入甩干器
}

// 实现WashingMachine接口的wash()方法
func (h haier) wash() {
    fmt.Println("洗刷刷")
}
复制<br>❸ 接口嵌套<br>接口与接口间可以通过嵌套创造出新的接口<br>// Sayer 接口
type Sayer interface {
    say()
}

// Mover 接口
type Mover interface {
    move()
}

// 接口嵌套
type animal interface {
    Sayer
    Mover
}
复制<br>嵌套得到的接口的使用与普通接口一样，这里我们让 cat 实现 animal 接口：<br>type cat struct {
    name string
}

func (c cat) say() {
    fmt.Println("喵喵喵")
}

func (c cat) move() {
    fmt.Println("猫会动")
}

func main() {
    var x animal
    x = cat{name: "花花"}
    x.move()
    x.say()
}
复制<br><br>空接口是指没有定义任何方法的接口，因此任何类型都实现了空接口。<br>
可以接收任意类型的值作为参数，可以存储任意类型的变量。<br>
类似于其他编程语言中的泛型概念。
<br>func main() {
    // 定义一个空接口x
    var x interface{}
    s := "码神之路"
    x = s
    fmt.Printf("type:%T value:%v\n", x, x)
    i := 100
    x = i
    fmt.Printf("type:%T value:%v\n", x, x)
    b := true
    x = b
    fmt.Printf("type:%T value:%v\n", x, x)
}
复制<br><br>空接口作为函数的参数<br>使用空接口实现可以接收任意类型的函数参数。<br>// 空接口作为函数参数
func show(a interface{}) {
    fmt.Printf("type:%T value:%v\n", a, a)
}
复制<br>空接口作为 map 的值<br>使用空接口实现可以保存任意值的字典。<br>// 空接口作为map值
    var studentInfo = make(map[string]interface{})
    studentInfo["name"] = "李白"
    studentInfo["age"] = 18
    studentInfo["married"] = false
    fmt.Println(studentInfo)
复制<br><br>空接口可以存储任意类型的值，那我们如何获取其存储的具体数据呢？<br>接口值<br>一个接口的值（简称接口值）是由一个具体类型和具体类型的值两部分组成的。<br>这两部分分别称为 接口的动态类型 和 动态值。<br>想要判断空接口中的值这个时候就可以使用类型断言，其语法格式：<br>x.(T)
复制<br>其中：<br>
<br>X：表示类型为 interface{}的变量
<br>T：表示断言 x 可能是的类型。
<br>该语法返回两个参数，第一个参数是 x 转化为 T 类型后的变量，第二个值是一个布尔值，若为 true 则表示断言成功，为 false 则表示断言失败。<br>func main() {
 var x interface{}
 x = "码神之路"
 v, ok := x.(string)
 if ok {
     fmt.Println(v)
 } else {
     fmt.Println("类型断言失败")
 }
}
复制<br>上面的示例中如果要断言多次就需要写多个 if 判断，这个时候我们可以使用 switch 语句来实现：<br>func justifyType(x interface{}) {
    switch v := x.(type) {
    case string:
        fmt.Printf("x is a string，value is %v\n", v)
    case int:
        fmt.Printf("x is a int is %v\n", v)
    case bool:
        fmt.Printf("x is a bool is %v\n", v)
    default:
        fmt.Println("unsupport type！")
    }
}
复制<br>因为空接口可以存储任意类型值的特点，所以空接口在 Go 语言中的使用十分广泛。<br>
关于接口需要注意的是，只有当有两个或两个以上的具体类型必须以相同的方式进行处理时才需要定义接口。不要为了接口而写接口，那样只会增加不必要的抽象，导致不必要的运行时损耗。
<br><br>
Go 语言中使用 panic 抛出错误，recover 捕获错误。
<br>异常的使用场景简单描述：Go 中可以抛出一个 panic 的异常，然后在 defer 中通过 recover 捕获这个异常，然后正常处理。<br>panic：<br>
<br>内置函数
<br>假如函数 F 中书写了 panic 语句，会终止其后要执行的代码，在 panic 所在函数 F 内如果存在要执行的 defer 函数列表，按照 defer 的逆序执行
<br>返回函数 F 的调用者 G，在 G 中，调用函数 F 语句之后的代码不会执行，假如函数 G 中存在要执行的 defer 函数列表，按照 defer 的逆序执行
<br>直到 goroutine 整个退出，并报告错误
<br>recover：<br>
<br>内置函数
<br>用来捕获 panic，从而影响应用的行为
<br>
Golang 的错误处理流程：当一个函数在执行过程中出现了异常或遇到 panic ()，正常语句就会立即终止，然后执行 defer 语句，再报告异常信息，最后退出 goroutine。如果在 defer 中使用了 recover () 函数, 则会捕获错误信息，使该错误信息终止报告。
<br>注意:<br>
<br>利用 recover 处理 panic 指令，defer 必须放在 panic 之前定义，另外 recover 只有在 defer 调用的函数中才有效。否则当 panic 时，recover 无法捕获到 panic，无法防止 panic 扩散。
<br>Recover 处理异常后，逻辑并不会恢复到 panic 那个点去，函数跑到 defer 之后的那个点。
<br>多个 defer 会形成 defer 栈，后定义的 defer 语句会被最先调用。
<br>package main

func main() {
    test()
}

func test() {
    defer func() {
        if err := recover(); err != nil {
            println(err.(string)) // 将 interface{} 转型为具体类型。
        }
    }()

    panic("panic error!")
}
复制<br>由于 panic、recover 参数类型为 interface{}，因此可抛出任何类型对象。<br> func panic(v interface{})
 func recover() interface{}
复制<br>延迟调用中引发的错误，可被后续延迟调用捕获，但仅最后一个错误可被捕获:<br>package main

import "fmt"

func test() {
    defer func() {
        // defer panic 会打印
        fmt.Println(recover())
    }()

    defer func() {
        panic("defer panic")
    }()

    panic("test panic")
}

func main() {
    test()
}
复制<br>如果需要保护代码段，可将代码块重构成匿名函数，如此可确保后续代码被执 ：<br>package main

import "fmt"

func test(x, y int) {
    var z int

    func() {
        defer func() {
            if recover() != nil {
                z = 0
            }
        }()
        panic("test panic")
        z = x / y
        return
    }()

    fmt.Printf("x / y = %d\n", z)
}

func main() {
    test(2, 1)
}
复制<br>除用 panic 引发中断性错误外，还可返回 error 类型错误对象来表示函数调用状态:<br>type error interface {
    Error() string
}
复制<br>标准库 errors.New 和 fmt.Errorf 函数用于创建实现 error 接口的错误对象。通过判断错误对象实例来确定具体错误类型。<br>package main

import (
    "errors"
    "fmt"
)

var ErrDivByZero = errors.New("division by zero")

func div(x, y int) (int, error) {
    if y == 0 {
        return 0, ErrDivByZero
    }
    return x / y, nil
}

func main() {
    defer func() {
        fmt.Println(recover())
    }()
    switch z, err := div(10, 0); err {
    case nil:
        println(z)
    case ErrDivByZero:
        panic(err)
    }
}
复制<br>Go 实现类似 try catch 的异常处理:<br>package main

import "fmt"

func Try(fun func(), handler func(interface{})) {
    defer func() {
        if err := recover(); err != nil {
            handler(err)
        }
    }()
    fun()
}

func main() {
    Try(func() {
        panic("test panic")
    }, func(err interface{}) {
        fmt.Println(err)
    })
}
复制<br>如何区别使用 panic 和 error 两种方式?<br>惯例是: 导致关键流程出现不可修复性错误的使用 panic，其他使用 error。<br><br><br><br><br><br>
首先，需要引入 mysql 驱动
<br>_ "github. Com/go-sql-driver/mysql"
&gt; ```

表准备

```sql
CREATE TABLE `user` (
    `user_id` int(11) NOT NULL AUTO_INCREMENT,
    `username` varchar(255) DEFAULT NULL,
    `sex` varchar(255) DEFAULT NULL,
    `email` varchar(255) DEFAULT NULL,
    PRIMARY KEY (`user_id`)
  ) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8;
复制<br><br>package main

import (
	"database/sql"
	"fmt"
	_ "github.com/go-sql-driver/mysql"
	"log"
	"time"
)
var DB *sql.DB
func init()  {
	db,err := sql.Open("mysql","root:root@tcp(localhost:3306)/go_learn")
	if err != nil {
		panic(err)
	}
	//最大空闲连接数，默认不配置，是2个最大空闲连接
	db.SetMaxIdleConns(5)
	//最大连接数，默认不配置，是不限制最大连接数
	db.SetMaxOpenConns(100)
	// 连接最大存活时间
	db.SetConnMaxLifetime(time.Minute * 3)
	//空闲连接最大存活时间
	db.SetConnMaxIdleTime(time.Minute * 1)
	err = db.Ping()
	if err != nil {
		log.Println("数据库连接失败")
		db.Close()
		panic(err)
	}
	DB = db

}

func save()  {
	r,err := DB.Exec("insert into user (username,sex,email) values(?,?,?)","mszlu001","man","001@mszlu.com")
	if err != nil {
		log.Println("执行sql语句出错")
		panic(err)
	}
	id, err := r.LastInsertId()
	if err != nil {
		panic(err)
	}
	fmt.Println("插入成功:",id)
}
func main()  {
	defer DB.Close()
	save()
}

复制<br><br>type User struct {
	UserId   int    `db:"user_id"`
	Username string `db:"username"`
	Sex      string `db:"sex"`
	Email    string `db:"email"`
}

func query(id int)  (*User,error) {
	rows, err := DB.Query("select * from user where user_id=? limit 1", id)
	if err != nil{
		log.Println("查询出现错误:",err)
		return nil,errors.New(err.Error())
	}
	user := new(User)
	for rows.Next() {
		if err := rows.Scan(&amp;user.UserId,&amp;user.Username,&amp;user.Sex,&amp;user.Email); err != nil{
			log.Println("scan error:",err)
			return nil,errors.New(err.Error())
		}
	}
	return user,nil
}
复制<br><br>func update(username string, id int)  {
	ret, err := DB.Exec("update user set username=? where user_id=?", username, id)
	if err != nil {
		log.Println("更新出现问题:",err)
		return
	}
	affected, _ := ret.RowsAffected()
	fmt.Println("更新成功的行数:",affected)
}

复制<br><br>func delete(id int)  {
	ret, err := DB.Exec("delete from user where user_id=?", id)
	if err != nil {
		log.Println("删除出现问题:",err)
		return
	}
	affected, _ := ret.RowsAffected()
	fmt.Println("删除成功的行数:",affected)
}
复制<br><br>mysql事务特性：<br>
<br>原子性
<br>一致性
<br>隔离性
<br>持久性
<br>func insertTx(username string)  {
	tx, err := DB.Begin()
	if err != nil {
		log.Println("开启事务错误:",err)
		return
	}
	ret, err := tx.Exec("insert into user (username,sex,email) values (?,?,?)", username, "man", "test@mszlu.com")
	if err != nil {
		log.Println("事务sql执行出错:",err)
		return
	}
	id, _ := ret.LastInsertId()
	fmt.Println("插入成功:",id)
	if username == "lisi" {
		fmt.Println("回滚...")
		_ = tx.Rollback()
	}else {
		_ = tx.Commit()
	}

}
```&gt;)


### ▶　Redis

安装：go get github. Com/go-redis/redis/v 8

```go
package main

import (
	"context"
	"fmt"
	"github.com/go-redis/redis/v8"
)

func main()  {
	ctx := context.Background()

	rdb := redis.NewClient(&amp;redis.Options{
		Addr:	  "localhost:6379",
		Password: "", // no password set
		DB:		  0,  // use default DB
	})

	err := rdb.Set(ctx, "key", "value", 0).Err()
	if err != nil {
		panic(err)
	}

	val, err := rdb.Get(ctx, "key").Result()
	if err != nil {
		panic(err)
	}
	fmt.Println("key", val)

	val2, err := rdb.Get(ctx, "key2").Result()
	if err == redis.Nil {
		fmt.Println("key2 does not exist")
	} else if err != nil {
		panic(err)
	} else {
		fmt.Println("key2", val2)
	}
}

复制<br><br><br><br>同一个文件中定义了两个同名的函数分别在不同操作系统下实现，Go语言会根据当前编译的操作系统自动选择相应的函数实现，不需要开发者手动指定。<br>此外，还可以使用// +build标记来指定不同平台编译的文件，这种方式更加灵活，但需要手动编写标记，具体可查看Go语言官方文档的相关说明。<br><br><a data-tooltip-position="top" aria-label="https://www.baidu.com/link?url=Wb3BbPlZndKfQHAPSOSdebvled1c5jjF1wdwB9EbRw-hq1gk--Qz0L7GlBXh3W9WI3BJjLCzouluCGGLK-P74_&amp;wd=&amp;eqid=c155631e000330a20000000665aba15d" rel="noopener" class="external-link" href="https://www.baidu.com/link?url=Wb3BbPlZndKfQHAPSOSdebvled1c5jjF1wdwB9EbRw-hq1gk--Qz0L7GlBXh3W9WI3BJjLCzouluCGGLK-P74_&amp;wd=&amp;eqid=c155631e000330a20000000665aba15d" target="_blank">笔记来源</a>]]></description><link>02、多编程语言\03、go语言\01、go语言基础\101、go语言基础2.html</link><guid isPermaLink="false">02、多编程语言/03、Go语言/01、Go语言基础/101、Go语言基础2.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:44 GMT</pubDate><enclosure url="02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240112_214047.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;02、多编程语言\03、go语言\01、go语言基础\assets\101、go语言基础2\img-20240112_214047.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[04、Unix IO 模型]]></title><description><![CDATA[ 
 <br><br><br>服务器大多都采用 Linux 系统，这里我们以 Linux 为例来讲解:<br>Ubuntu 和 Centos 都是 Linux 的发行版，发行版可以看成对 linux 包了一层壳，任何 Linux 发行版，其系统内核都是 Linux 。我们的应用都需要通过 Linux 内核与硬件交互。<br>用户的应用，比如 redis ，mysql 等其实是没有办法去执行访问我们操作系统的硬件的，所以我们可以通过发行版的系统去访问内核，再通过内核去访问计算机硬件。<br>​ 计算机硬件包括，如 cpu，内存，网卡等等，内核（通过寻址空间）可以操作硬件的，但是内核需要不同设备的驱动，有了这些驱动之后，内核就可以去对计算机硬件去进行内存管理，文件系统的管理，进程的管理等。<br><img src="\03、java核心\03、java-io相关\assets\04、unix-io-模型\img-20240316_211906.png"><br>​ 我们想要用户的应用来访问，计算机就必须要通过对外暴露的一些接口，才能访问到，从而简介的实现对内核的操控，但是内核本身上来说也是一个应用，所以他本身也需要一些内存，cpu 等设备资源，用户应用本身也在消耗这些资源，如果不加任何限制，用户去操作随意的去操作我们的资源，就有可能导致一些冲突，甚至有可能导致我们的系统出现无法运行的问题，因此我们需要把用户和内核隔离开。<br><br><img src="\03、java核心\03、java-io相关\assets\04、unix-io-模型\img-20240319_211256.png"><br><br><br>应用进程被阻塞，直到数据复制到应用进程缓冲区中才返回。<br>应该注意到，在阻塞的过程中，其它程序还可以执行，因此阻塞不意味着整个操作系统都被阻塞。因为其他程序还可以执行，因此不消耗 CPU 时间，这种模型的执行效率会比较高。<br>下图中，recvfrom 用于接收 Socket 传来的数据，并复制到应用进程的缓冲区 buf 中。这里把 recvfrom () 当成系统调用。<br><img alt="assets/04、Unix IO 模型/img-20240319_211434.png" src="\03、java核心\03、java-io相关\assets\04、unix-io-模型\img-20240319_211434.png" style="width: 675px; max-width: 100%;"><br><img alt="assets/04、Unix IO 模型/img-20240319_211412.png" src="\03、java核心\03、java-io相关\assets\04、unix-io-模型\img-20240319_211412.png" style="width: 775px; max-width: 100%;"><br>阶段一：<br>
<br>用户进程尝试读取数据（比如网卡数据）
<br>此时数据尚未到达，内核需要等待数据
<br>此时用户进程也处于阻塞状态
<br>阶段二：<br>
<br>数据到达并拷贝到内核缓冲区，代表已就绪
<br>将内核数据拷贝到用户缓冲区
<br>拷贝过程中，用户进程依然阻塞等待
<br>拷贝完成，用户进程解除阻塞，处理数据
<br>可以看到，阻塞 IO 模型中，用户进程在两个阶段都是阻塞状态。<br><br>应用进程执行系统调用之后，内核返回一个错误码。应用进程可以继续执行，但是需要不断的执行系统调用来获知 I/O 是否完成，这种方式称为轮询(polling)。<br><img alt="assets/04、Unix IO 模型/img-20240319_211539.png" src="\03、java核心\03、java-io相关\assets\04、unix-io-模型\img-20240319_211539.png" style="width: 775px; max-width: 100%;"><br>阶段一：<br>
<br>用户进程尝试读取数据（比如网卡数据）
<br>此时数据尚未到达，内核需要等待数据
<br>返回异常给用户进程
<br>用户进程拿到error后，再次尝试读取
<br>循环往复，直到数据就绪
<br>阶段二：<br>
<br>将内核数据拷贝到用户缓冲区
<br>拷贝过程中，用户进程依然阻塞等待
<br>拷贝完成，用户进程解除阻塞，处理数据
<br>可以看到，非阻塞IO模型中，用户进程在第一个阶段是非阻塞，第二个阶段是阻塞状态。虽然是非阻塞，但性能并没有得到提高。而且忙等机制会导致CPU空转，CPU使用率暴增。
<br>由于 CPU 要处理更多的系统调用，因此这种模型是比较低效的。<br><br>如果没有 I/O 复用，那么每一个 Socket 连接都需要创建一个线程去处理。如果同时有几万个连接，那么就需要创建相同数量的线程。并且相比于多进程和多线程技术，I/O 复用不需要进程线程创建和切换的开销，系统开销更小。<br>它可以让单个进程具有处理多个 I/O 事件的能力。又被称为 Event Driven I/O，即事件驱动 I/O。<br>文件描述符（File Descriptor）：简称 FD，是一个从 0 开始的无符号整数，用来关联 Linux 中的一个文件。在 Linux 中，一切皆文件，例如常规文件、视频、硬件设备等，当然也包括网络套接字（Socket）。<br>通过 FD，我们的网络模型可以利用一个线程监听多个 FD，并在某个 FD 可读、可写时得到通知，从而避免无效的等待，充分利用 CPU 资源。 <br><img alt="assets/04、Unix IO 模型/img-20240319_212511.png" src="\03、java核心\03、java-io相关\assets\04、unix-io-模型\img-20240319_212511.png" style="width: 850px; max-width: 100%;"><br>阶段一：<br>
<br>用户进程调用select，指定要监听的FD集合
<br>核监听FD对应的多个socket
<br>任意一个或多个socket数据就绪则返回readable
<br>此过程中用户进程阻塞
<br>阶段二：<br>
<br>用户进程找到就绪的socket
<br>依次调用recvfrom读取数据
<br>内核将数据拷贝到用户空间
<br>用户进程处理数据
<br>IO多路复用是利用单个线程来同时监听多个FD，并在某个FD可读、可写时得到通知，从而避免无效的等待，充分利用CPU资源。不过监听FD的方式、通知的方式又有多种实现，常见的有：<br>
<br>select
<br>poll
<br>epoll
<br>其中select和pool相当于是当被监听的数据准备好之后，他会把你监听的FD整个数据都发给你，你需要到整个FD中去找，哪些是处理好了的，需要通过遍历的方式，所以性能也并不是那么好<br>而epoll，则相当于内核准备好了之后，他会把准备好的数据，直接发给你，咱们就省去了遍历的动作<br><br><img alt="assets/04、Unix IO 模型/img-20240319_212804.png" src="\03、java核心\03、java-io相关\assets\04、unix-io-模型\img-20240319_212804.png" style="width: 500px; max-width: 100%;"><br>应用场景<br>select 的 timeout 参数精度为 1ns，而 poll 和 epoll 为 1ms，因此 select 更加适用于实时要求更高的场景，比如核反应堆的控制。<br>select 可移植性更好，几乎被所有主流平台所支持。<br><br>应用场景<br>poll 没有最大描述符数量的限制，如果平台支持并且对实时性要求不高，应该使用 poll 而不是 select。<br>需要同时监控小于 1000 个描述符，就没有必要使用 epoll，因为这个应用场景下并不能体现 epoll 的优势。<br>需要监控的描述符状态变化多，而且都是非常短暂的，也没有必要使用 epoll。因为 epoll 中的所有描述符都存储在内核中，造成每次需要对描述符的状态改变都需要通过 epoll_ctl() 进行系统调用，频繁系统调用降低效率。并且epoll 的描述符存储在内核，不容易调试。<br><br><a rel="noopener" class="external-link" href="http://www.cnblogs.com/Airgity/p/16742319.html" target="_blank">http://www.cnblogs.com/Airgity/p/16742319.html</a><br><a rel="noopener" class="external-link" href="https://blog.csdn.net/TiankkTT/article/details/131149697" target="_blank">https://blog.csdn.net/TiankkTT/article/details/131149697</a><br><a rel="noopener" class="external-link" href="http://blog.czk.pub/post/8e58a56a.html#%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8-IO-%E7%9A%84%E5%AE%9E%E7%8E%B0" target="_blank">http://blog.czk.pub/post/8e58a56a.html#%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8-IO-%E7%9A%84%E5%AE%9E%E7%8E%B0</a><br><img alt="assets/04、Unix IO 模型/img-20240319_212945.png" src="\03、java核心\03、java-io相关\assets\04、unix-io-模型\img-20240319_212945.png" style="width: 525px; max-width: 100%;"><br>epoll 的描述符事件有两种触发模式: LT(level trigger)和 ET(edge trigger)。<br><br>当 epoll_wait() 检测到描述符事件到达时，将此事件通知进程，进程可以不立即处理该事件，下次调用 epoll_wait() 会再次通知进程。是默认的一种模式，并且同时支持 Blocking 和 No-Blocking。<br><br>和 LT 模式不同的是，通知之后进程必须立即处理事件，下次再调用 epoll_wait() 时不会再得到事件到达的通知。<br>很大程度上减少了 epoll 事件被重复触发的次数，因此效率要比 LT 模式高。只支持 No-Blocking，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死<br>应用场景<br>只需要运行在 Linux 平台上，并且有非常大量的描述符需要同时轮询，而且这些连接最好是长连接。<br><br>信号驱动IO是与内核建立SIGIO的信号关联并设置回调，当内核有FD就绪时，会发出SIGIO信号通知用户，期间用户应用可以执行其它业务，无需阻塞等待。<br><img alt="assets/04、Unix IO 模型/img-20240319_213413.png" src="\03、java核心\03、java-io相关\assets\04、unix-io-模型\img-20240319_213413.png" style="width: 750px; max-width: 100%;"><br>阶段一：<br>
<br>用户进程调用 sigaction，注册信号处理函数
<br>内核返回成功，开始监听 FD
<br>用户进程不阻塞等待，可以执行其它业务
<br>当内核数据就绪后，回调用户进程的 SIGIO 处理函数
<br>阶段二：<br>
<br>收到 SIGIO 回调信号
<br>调用 recvfrom，读取
<br>内核将数据拷贝到用户空间
<br>用户进程处理数据
<br><br>不仅是用户态在试图读取数据后，不阻塞，而且当内核的数据准备完成后，也不会阻塞。<br>信号驱动 I/O 与异步 I/O  的区别在于：<br>
信号驱动 I/O 的信号是通知应用进程可以开始 I/O<br>
而异步 I/O 的信号直接通知应用进程 I/O 完成！<br><img alt="assets/04、Unix IO 模型/img-20240319_213433.png" src="\03、java核心\03、java-io相关\assets\04、unix-io-模型\img-20240319_213433.png" style="width: 850px; max-width: 100%;"><br><br><br>
<br>同步 I/O: 应用进程在调用 recvfrom 操作时会阻塞。
<br>异步 I/O: 不会阻塞。
<br>阻塞式 I/O、非阻塞式 I/O、I/O 复用和信号驱动 I/O 都是同步 I/O，虽然非阻塞式 I/O 和信号驱动 I/O 在等待数据阶段不会阻塞，但是在之后的将数据从内核复制到应用进程这个操作会阻塞。<br><br><img src="\03、java核心\03、java-io相关\assets\04、unix-io-模型\img-20240316_212152.png">]]></description><link>03、java核心\03、java-io相关\04、unix-io-模型.html</link><guid isPermaLink="false">03、Java核心/03、Java IO相关/04、Unix IO 模型.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Tue, 19 Mar 2024 13:58:54 GMT</pubDate><enclosure url="03、java核心\03、java-io相关\assets\04、unix-io-模型\img-20240316_211906.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;03、java核心\03、java-io相关\assets\04、unix-io-模型\img-20240316_211906.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[JVM-内存结构]]></title><description><![CDATA[ 
 <br><br>下图是 JVM 整体架构，中间部分就是 Java 虚拟机定义的各种运行时数据区（内存机构）。<br><img style="zoom:50%;" alt="jvm-framework" src="\.pic-JVM-内存结构\0082zybply1gc6fz21n8kj30u00wpn5v.jpg" referrerpolicy="no-referrer"><br><br>程序计数寄存器（Program Counter Register），Register 的命名源于 CPU 的寄存器，寄存器存储指令相关的线程信息，CPU 只有把数据装载到寄存器才能够运行。<br>JVM 中的 PC 寄存器是对物理 PC 寄存器的一种抽象模拟。<br>程序计数器是一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。<br><br>PC 寄存器用来存储指向下一条指令的地址，即将要执行的指令代码。由执行引擎读取下一条指令。<br>“./.pic-JVM-内存结构/0082zybply1gc5kmznm1sj31m50u0wph.jpg” could not be found.<br>（分析：进入class文件所在目录，执行 javap -v xx.class 反解析（或者通过 IDEA 插件 Jclasslib 直接查看，上图），可以看到当前类对应的Code区（汇编指令）、本地变量表、异常表和代码行偏移量映射表、常量池等信息。）<br><br>记录当前线程的执行地址<br>CPU需要不停的切换各个线程，切换回来以后，必然会导致经常中断或恢复原位继续执行。JVM的字节码解释器就需要通过改变PC寄存器的值来明确下一条应该执行什么样的字节码指令。<br>线程私有<br>每个线程都分配了一个PC寄存器，每个线程都独立计算，不会互相影响。<br>
相关总结如下：
<br>
<br>它是一块很小的内存空间（可忽略）、是运行速度最快的存储区域
<br>线程私有的，与线程的生命周期一致
<br>任何时间一个线程都只有一个方法在执行，也就是所谓的当前方法。如果当前线程正在执行的是 Java 方法，程序计数器记录的是 JVM 字节码指令地址，如果是执行 native 方法，则是未指定值（undefined）
<br>它是程序控制流的指示器，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成
<br>字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令
<br>它是唯一一个在 JVM 规范中没有规定任何 OutOfMemoryError 情况的区域
<br><br><br>
Java 虚拟机栈(Java Virtual Machine Stacks)，早期也叫 Java 栈。每个线程在创建的时候都会创建一个虚拟机栈，其内部保存一个个的栈帧(Stack Frame），对应着一次次 Java 方法调用，是线程私有的，生命周期和线程一致。
<br>作用：主管 Java 程序的运行，它保存方法的局部变量、部分结果，并参与方法的调用和返回。<br>特点：<br>
<br>栈是一种快速有效的分配存储方式，访问速度仅次于程序计数器
<br>JVM 直接对虚拟机栈的操作只有两个：每个方法执行，伴随着入栈（进栈/压栈），方法执行结束出栈
<br>栈不存在垃圾回收问题
<br>栈中可能出现的异常：<br>Java 虚拟机规范允许 Java虚拟机栈的大小是动态的或者是固定不变的<br>
<br>如果采用固定大小的 Java 虚拟机栈，那每个线程的 Java 虚拟机栈容量可以在线程创建的时候独立选定。如果线程请求分配的栈容量超过 Java 虚拟机栈允许的最大容量，Java 虚拟机将会抛出一个 StackOverflowError 异常
<br>如果 Java 虚拟机栈可以动态扩展，并且在尝试扩展的时候无法申请到足够的内存，或者在创建新的线程时没有足够的内存去创建对应的虚拟机栈，那 Java 虚拟机将会抛出一个OutOfMemoryError异常
<br>可以通过参数-Xss来设置线程的最大栈空间，栈的大小直接决定了函数调用的最大可达深度。<br><br>
<br>每个线程都有自己的栈，栈中的数据都是以栈帧（Stack Frame）的格式存在
<br>在这个线程上正在执行的每个方法都各自有对应的一个栈帧
<br>栈帧是一个内存区块，是一个数据集，维系着方法执行过程中的各种数据信息
<br><br>
<br>JVM 直接对 Java 栈的操作只有两个，对栈帧的压栈和出栈，遵循“先进后出/后进先出”原则
<br>在一条活动线程中，一个时间点上，只会有一个活动的栈帧。即只有当前正在执行的方法的栈帧（栈顶栈帧）是有效的，这个栈帧被称为当前栈帧（Current Frame），与当前栈帧对应的方法就是当前方法（Current Method），定义这个方法的类就是当前类（Current Class）
<br>执行引擎运行的所有字节码指令只针对当前栈帧进行操作
<br>如果在该方法中调用了其他方法，对应的新的栈帧会被创建出来，放在栈的顶端，称为新的当前栈帧
<br>不同线程中所包含的栈帧是不允许相互引用的，即不可能在一个栈帧中引用另外一个线程的栈帧
<br>如果当前方法调用了其他方法，方法返回之际，当前栈帧会传回此方法的执行结果给前一个栈帧，接着，虚拟机会丢弃当前栈帧，使得前一个栈帧重新成为当前栈帧
<br>Java 方法有两种返回函数的方式，一种是正常的函数返回，使用 return 指令，另一种是抛出异常，不管用哪种方式，都会导致栈帧被弹出
<br>IDEA 在 debug 时候，可以在 debug 窗口看到 Frames 中各种方法的压栈和出栈情况<br><img style="zoom:50%;" alt="img" src="\.pic-JVM-内存结构\0082zybply1gc9lezaxrbj319v0u0k4w.jpg" referrerpolicy="no-referrer"><br><br>每个栈帧（Stack Frame）中存储着：<br>
<br>局部变量表（Local Variables）
<br>操作数栈（Operand Stack）(或称为表达式栈)
<br>动态链接（Dynamic Linking）：指向运行时常量池的方法引用
<br>方法返回地址（Return Address）：方法正常退出或异常退出的地址
<br>一些附加信息
<br><img style="zoom:50%;" alt="jvm-stack-frame" src="\.pic-JVM-内存结构\0082zybply1gc8tjehg8bj318m0lbtbu.jpg" referrerpolicy="no-referrer"><br><br>
<br>局部变量表也被称为局部变量数组或者本地变量表
<br>是一组变量值存储空间，主要用于存储方法参数和定义在方法体内的局部变量，包括编译器可知的各种 Java 虚拟机基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，它并不等同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此相关的位置）和 returnAddress 类型（指向了一条字节码指令的地址，已被异常表取代）
<br>由于局部变量表是建立在线程的栈上，是线程的私有数据，因此不存在数据安全问题
<br>局部变量表所需要的容量大小是编译期确定下来的，并保存在方法的 Code 属性的 maximum local variables 数据项中。在方法运行期间是不会改变局部变量表的大小的
<br>方法嵌套调用的次数由栈的大小决定。一般来说，栈越大，方法嵌套调用次数越多。对一个函数而言，它的参数和局部变量越多，使得局部变量表膨胀，它的栈帧就越大，以满足方法调用所需传递的信息增大的需求。进而函数调用就会占用更多的栈空间，导致其嵌套调用次数就会减少。
<br>局部变量表中的变量只在当前方法调用中有效。在方法执行时，虚拟机通过使用局部变量表完成参数值到参数变量列表的传递过程。当方法调用结束后，随着方法栈帧的销毁，局部变量表也会随之销毁。
<br>参数值的存放总是在局部变量数组的 index0 开始，到数组长度 -1 的索引结束
<br><br>
<br>
局部变量表最基本的存储单元是 Slot（变量槽）

<br>
在局部变量表中，32 位以内的类型只占用一个 Slot(包括returnAddress类型)，64 位的类型（long和double）占用两个连续的 Slot

<br>byte、short、char 在存储前被转换为int，boolean也被转换为int，0 表示 false，非 0 表示 true
<br>long 和 double 则占据两个 Slot


<br>
JVM 会为局部变量表中的每一个 Slot 都分配一个访问索引，通过这个索引即可成功访问到局部变量表中指定的局部变量值，索引值的范围从 0 开始到局部变量表最大的 Slot 数量

<br>
当一个实例方法被调用的时候，它的方法参数和方法体内部定义的局部变量将会按照顺序被复制到局部变量表中的每一个 Slot 上

<br>
如果需要访问局部变量表中一个 64bit 的局部变量值时，只需要使用前一个索引即可。（比如：访问 long 或 double 类型变量，不允许采用任何方式单独访问其中的某一个 Slot）

<br>
如果当前帧是由构造方法或实例方法创建的，那么该对象引用 this 将会存放在 index 为 0 的 Slot 处，其余的参数按照参数表顺序继续排列（这里就引出一个问题：静态方法中为什么不可以引用 this，就是因为this 变量不存在于当前方法的局部变量表中）

<br>
栈帧中的局部变量表中的槽位是可以重用的，如果一个局部变量过了其作用域，那么在其作用域之后申明的新的局部变量就很有可能会复用过期局部变量的槽位，从而达到节省资源的目的。（下图中，this、a、b、c 理论上应该有 4 个变量，c 复用了 b 的槽）

<br>
在栈帧中，与性能调优关系最为密切的就是局部变量表。在方法执行时，虚拟机使用局部变量表完成方法的传递

<br>
局部变量表中的变量也是重要的垃圾回收根节点，只要被局部变量表中直接或间接引用的对象都不会被回收

<br><br>
<br>每个独立的栈帧中除了包含局部变量表之外，还包含一个后进先出（Last-In-First-Out）的操作数栈，也可以称为表达式栈（Expression Stack）
<br>操作数栈，在方法执行过程中，根据字节码指令，往操作数栈中写入数据或提取数据，即入栈（push）、出栈（pop）
<br>某些字节码指令将值压入操作数栈，其余的字节码指令将操作数取出栈。使用它们后再把结果压入栈。比如，执行复制、交换、求和等操作
<br><br>
<br>操作数栈，主要用于保存计算过程的中间结果，同时作为计算过程中变量临时的存储空间
<br>操作数栈就是 JVM 执行引擎的一个工作区，当一个方法刚开始执行的时候，一个新的栈帧也会随之被创建出来，此时这个方法的操作数栈是空的
<br>每一个操作数栈都会拥有一个明确的栈深度用于存储数值，其所需的最大深度在编译期就定义好了，保存在方法的 Code 属性的 max_stack 数据项中
<br>栈中的任何一个元素都可以是任意的 Java 数据类型 

<br>32bit 的类型占用一个栈单位深度
<br>64bit 的类型占用两个栈单位深度


<br>操作数栈并非采用访问索引的方式来进行数据访问的，而是只能通过标准的入栈和出栈操作来完成一次数据访问
<br>如果被调用的方法带有返回值的话，其返回值将会被压入当前栈帧的操作数栈中，并更新 PC 寄存器中下一条需要执行的字节码指令
<br>操作数栈中元素的数据类型必须与字节码指令的序列严格匹配，这由编译器在编译期间进行验证，同时在类加载过程中的类检验阶段的数据流分析阶段要再次验证
<br>另外，我们说Java虚拟机的解释引擎是基于栈的执行引擎，其中的栈指的就是操作数栈
<br><br>Top-of-stack-Cashing<br>HotSpot 的执行引擎采用的并非是基于寄存器的架构，但这并不代表 HotSpot VM 的实现并没有间接利用到寄存器资源。寄存器是物理 CPU 中的组成部分之一，它同时也是 CPU 中非常重要的高速存储资源。一般来说，寄存器的读/写速度非常迅速，甚至可以比内存的读/写速度快上几十倍不止，不过寄存器资源却非常有限，不同平台下的CPU 寄存器数量是不同和不规律的。寄存器主要用于缓存本地机器指令、数值和下一条需要被执行的指令地址等数据。<br>基于栈式架构的虚拟机所使用的零地址指令更加紧凑，但完成一项操作的时候必然需要使用更多的入栈和出栈指令，这同时也就意味着将需要更多的指令分派（instruction dispatch）次数和内存读/写次数。由于操作数是存储在内存中的，因此频繁的执行内存读/写操作必然会影响执行速度。为了解决这个问题，HotSpot JVM 设计者们提出了栈顶缓存技术，将栈顶元素全部缓存在物理 CPU 的寄存器中，以此降低对内存的读/写次数，提升执行引擎的执行效率<br><br>指向运行时常量池的方法引用。<br>
<br>每一个栈帧内部都包含一个指向运行时常量池中该栈帧所属方法的引用。包含这个引用的目的就是为了支持当前方法的代码能够实现动态链接(Dynamic Linking)。
<br>在 Java 源文件被编译到字节码文件中时，所有的变量和方法引用都作为符号引用（Symbolic Reference）保存在 Class 文件的常量池中。比如：描述一个方法调用了另外的其他方法时，就是通过常量池中指向方法的符号引用来表示的，那么动态链接的作用就是为了将这些符号引用转换为调用方法的直接引用
<br><img style="zoom:50%;" alt="jvm-dynamic-linking" src="\.pic-JVM-内存结构\0082zybply1gca4k4gndgj31d20o2td0.jpg" referrerpolicy="no-referrer"><br><br>方法调用不同于方法执行，方法调用阶段的唯一任务就是确定被调用方法的版本（即调用哪一个方法），暂时还不涉及方法内部的具体运行过程。Class 文件的编译过程中不包括传统编译器中的连接步骤，一切方法调用在 Class文件里面存储的都是符号引用，而不是方法在实际运行时内存布局中的入口地址（直接引用）。也就是需要在类加载阶段，甚至到运行期才能确定目标方法的直接引用。<br>
【这一块内容，除了方法调用，还包括解析、分派（静态分派、动态分派、单分派与多分派），这里先不介绍，后续再挖】
<br>在 JVM 中，将符号引用转换为调用方法的直接引用与方法的绑定机制有关<br>
<br>静态链接：当一个字节码文件被装载进 JVM 内部时，如果被调用的目标方法在编译期可知，且运行期保持不变时。这种情况下将调用方法的符号引用转换为直接引用的过程称之为静态链接
<br>动态链接：如果被调用的方法在编译期无法被确定下来，也就是说，只能在程序运行期将调用方法的符号引用转换为直接引用，由于这种引用转换过程具备动态性，因此也就被称之为动态链接
<br>对应的方法的绑定机制为：早期绑定（Early Binding）和晚期绑定（Late Binding）。绑定是一个字段、方法或者类在符号引用被替换为直接引用的过程，这仅仅发生一次。<br>
<br>早期绑定：早期绑定就是指被调用的目标方法如果在编译期可知，且运行期保持不变时，即可将这个方法与所属的类型进行绑定，这样一来，由于明确了被调用的目标方法究竟是哪一个，因此也就可以使用静态链接的方式将符号引用转换为直接引用。
<br>晚期绑定：如果被调用的方法在编译器无法被确定下来，只能够在程序运行期根据实际的类型绑定相关的方法，这种绑定方式就被称为晚期绑定。
<br><br>
<br>如果方法在编译器就确定了具体的调用版本，这个版本在运行时是不可变的。这样的方法称为非虚方法，比如静态方法、私有方法、final 方法、实例构造器、父类方法都是非虚方法
<br>其他方法称为虚方法
<br><br>在面向对象编程中，会频繁的使用到动态分派，如果每次动态分派都要重新在类的方法元数据中搜索合适的目标有可能会影响到执行效率。为了提高性能，JVM 采用在类的方法区建立一个虚方法表（virtual method table），使用索引表来代替查找。非虚方法不会出现在表中。<br>每个类中都有一个虚方法表，表中存放着各个方法的实际入口。<br>虚方法表会在类加载的连接阶段被创建并开始初始化，类的变量初始值准备完成之后，JVM 会把该类的方法表也初始化完毕。<br><br>用来存放调用该方法的 PC 寄存器的值。<br>一个方法的结束，有两种方式<br>
<br>正常执行完成
<br>出现未处理的异常，非正常退出
<br>无论通过哪种方式退出，在方法退出后都返回到该方法被调用的位置。方法正常退出时，调用者的 PC 计数器的值作为返回地址，即调用该方法的指令的下一条指令的地址。而通过异常退出的，返回地址是要通过异常表来确定的，栈帧中一般不会保存这部分信息。<br>当一个方法开始执行后，只有两种方式可以退出这个方法：<br>
<br>
执行引擎遇到任意一个方法返回的字节码指令，会有返回值传递给上层的方法调用者，简称正常完成出口
一个方法的正常调用完成之后究竟需要使用哪一个返回指令还需要根据方法返回值的实际数据类型而定
在字节码指令中，返回指令包含 ireturn(当返回值是 boolean、byte、char、short 和 int 类型时使用)、lreturn、freturn、dreturn 以及 areturn，另外还有一个 return 指令供声明为 void 的方法、实例初始化方法、类和接口的初始化方法使用。

<br>
在方法执行的过程中遇到了异常，并且这个异常没有在方法内进行处理，也就是只要在本方法的异常表中没有搜索到匹配的异常处理器，就会导致方法退出。简称异常完成出口
方法执行过程中抛出异常时的异常处理，存储在一个异常处理表，方便在发生异常的时候找到处理异常的代码。

<br>本质上，方法的退出就是当前栈帧出栈的过程。此时，需要恢复上层方法的局部变量表、操作数栈、将返回值压入调用者栈帧的操作数栈、设置PC寄存器值等，让调用者方法继续执行下去。<br>正常完成出口和异常完成出口的区别在于：通过异常完成出口退出的不会给他的上层调用者产生任何的返回值<br><br>栈帧中还允许携带与 Java 虚拟机实现相关的一些附加信息。例如，对程序调试提供支持的信息，但这些信息取决于具体的虚拟机实现。<br><br><br><br>有些任务用 Java 实现不容易，且对程序的效率影响大，需要用到其他代码实现。<br>本地方法（Native Method）就是 Java 调用非 Java 代码的接口。<br>如： Unsafe 类就有很多本地方法。<br>
<br>与 Java 环境外交互：有时 Java 应用需要与 Java 外面的环境交互，这就是本地方法存在的原因。
<br>与操作系统交互：JVM 支持 Java 语言本身和运行时库，但是有时仍需要依赖一些底层系统的支持。通过本地方法，我们可以实现用 Java 与实现了 jre 的底层系统交互， JVM 的一些部分就是 C 语言写的。
<br>Sun's Java：Sun的解释器就是C实现的，这使得它能像一些普通的C一样与外部交互。jre大部分都是用 Java 实现的，它也通过一些本地方法与外界交互。比如，类 java.lang.Thread 的 setPriority() 的方法是用Java 实现的，但它实现调用的是该类的本地方法 setPrioruty()，该方法是C实现的，并被植入 JVM 内部。
<br><br>
<br>Java 虚拟机栈用于管理 Java 方法的调用，而本地方法栈用于管理本地方法的调用
<br>本地方法栈也是线程私有的
<br>允许线程固定或者可动态扩展的内存大小

<br>如果线程请求分配的栈容量超过本地方法栈允许的最大容量，Java 虚拟机将会抛出一个 StackOverflowError 异常
<br>如果本地方法栈可以动态扩展，并且在尝试扩展的时候无法申请到足够的内存，或者在创建新的线程时没有足够的内存去创建对应的本地方法栈，那么 Java虚拟机将会抛出一个OutofMemoryError异常


<br>本地方法是使用 C 语言实现的
<br>它的具体做法是 Native Method Stack 中登记 native 方法，在 Execution Engine 执行时加载本地方法库当某个线程调用一个本地方法时，它就进入了一个全新的并且不再受虚拟机限制的世界。它和虚拟机拥有同样的权限。
<br>本地方法可以通过本地方法接口来访问虚拟机内部的运行时数据区，它甚至可以直接使用本地处理器中的寄存器，直接从本地内存的堆中分配任意数量的内存
<br>并不是所有 JVM 都支持本地方法。因为 Java 虚拟机规范并没有明确要求本地方法栈的使用语言、具体实现方式、数据结构等。如果 JVM 产品不打算支持 native 方法，也可以无需实现本地方法栈
<br>在 Hotspot JVM 中，直接将本地方法栈和虚拟机栈合二为一
<br><br><br>
栈是运行时的单位，而堆是存储的单位。
栈解决程序的运行问题，即程序如何执行，或者说如何处理数据。堆解决的是数据存储的问题，即数据怎么放、放在哪。
<br><br>对于大多数应用，Java 堆是 Java 虚拟机管理的内存中最大的一块，被所有线程共享。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数据都在这里分配内存。<br>为了进行高效的垃圾回收，虚拟机把堆内存逻辑上划分成三块区域（分代的唯一理由就是优化 GC 性能）：<br>
<br>新生带（年轻代）：新对象和没达到一定年龄的对象都在新生代
<br>老年代（养老区）：被长时间使用的对象，老年代的内存空间应该要比年轻代更大
<br>元空间（JDK1.8 之前叫永久代）：像一些方法中的操作临时对象等，JDK1.8 之前是占用 JVM 内存，JDK1.8 之后直接使用物理内存
<br>“./.pic-JVM-内存结构/00831rSTly1gdbr7ek6pfj30ci0560t4-1683946891374-7.jpg” could not be found.<br>Java 虚拟机规范规定，Java 堆可以是处于物理上不连续的内存空间中，只要逻辑上是连续的即可，像磁盘空间一样。实现时，既可以是固定大小，也可以是可扩展的，主流虚拟机都是可扩展的（通过 -Xmx 和 -Xms 控制），如果堆中没有完成实例分配，并且堆无法再扩展时，就会抛出 OutOfMemoryError 异常。<br><br>年轻代是所有新对象创建的地方。当填充年轻代时，执行垃圾收集。这种垃圾收集称为 Minor GC。年轻一代被分为三个部分——伊甸园（Eden Memory）和两个幸存区（Survivor Memory，被称为from/to或s0/s1），默认比例是8:1:1<br>
<br>大多数新创建的对象都位于 Eden 内存空间中
<br>当 Eden 空间被对象填充时，执行Minor GC，并将所有幸存者对象移动到一个幸存者空间中
<br>Minor GC 检查幸存者对象，并将它们移动到另一个幸存者空间。所以每次，一个幸存者空间总是空的
<br>经过多次 GC 循环后存活下来的对象被移动到老年代。通常，这是通过设置年轻一代对象的年龄阈值来实现的，然后他们才有资格提升到老一代
<br><br>旧的一代内存包含那些经过许多轮小型 GC 后仍然存活的对象。通常，垃圾收集是在老年代内存满时执行的。老年代垃圾收集称为 主GC（Major GC），通常需要更长的时间。<br>大对象直接进入老年代（大对象是指需要大量连续内存空间的对象）。这样做的目的是避免在 Eden 区和两个Survivor 区之间发生大量的内存拷贝<br><img style="zoom:50%;" alt="img" src="\.pic-JVM-内存结构\007S8ZIlly1gg06065oa9j31kw0u0q69-1683946924214-10.jpg" referrerpolicy="no-referrer"><br><br>不管是 JDK8 之前的永久代，还是 JDK8 及以后的元空间，都可以看作是 Java 虚拟机规范中方法区的实现。<br>虽然 Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫 Non-Heap（非堆），目的应该是与 Java 堆区分开。<br>所以元空间放在后边的方法区再说。<br><br>Java 堆用于存储 Java 对象实例，那么堆的大小在 JVM 启动的时候就确定了，我们可以通过 -Xmx 和 -Xms 来设定<br>
<br>-Xms 用来表示堆的起始内存，等价于 -XX:InitialHeapSize
<br>-Xmx 用来表示堆的最大内存，等价于 -XX:MaxHeapSize
<br>如果堆的内存大小超过 -Xmx 设定的最大内存， 就会抛出 OutOfMemoryError 异常。<br>我们通常会将 -Xmx 和 -Xms 两个参数配置为相同的值，其目的是为了能够在垃圾回收机制清理完堆区后不再需要重新分隔计算堆的大小，从而提高性能<br>
<br>默认情况下，初始堆内存大小为：电脑内存大小/64
<br>默认情况下，最大堆内存大小为：电脑内存大小/4
<br>可以通过代码获取到我们的设置值，当然也可以模拟 OOM：<br>public static void main(String[] args) {

  //返回 JVM 堆大小
  long initalMemory = Runtime.getRuntime().totalMemory() / 1024 /1024;
  //返回 JVM 堆的最大内存
  long maxMemory = Runtime.getRuntime().maxMemory() / 1024 /1024;

  System.out.println("-Xms : "+initalMemory + "M");
  System.out.println("-Xmx : "+maxMemory + "M");

  System.out.println("系统内存大小：" + initalMemory * 64 / 1024 + "G");
  System.out.println("系统内存大小：" + maxMemory * 4 / 1024 + "G");
}
复制<br><br>
<br>
在默认不配置 JVM 堆内存大小的情况下，JVM 根据默认值来配置当前内存大小

<br>
默认情况下新生代和老年代的比例是 1:2，可以通过 –XX:NewRatio 来配置

<br>新生代中的 Eden:From Survivor:To Survivor 的比例是 8:1:1，可以通过 -XX:SurvivorRatio 来配置


<br>
若在 JDK 7 中开启了 -XX:+UseAdaptiveSizePolicy，JVM 会动态调整 JVM 堆中各个区域的大小以及进入老年代的年龄
此时 –XX:NewRatio 和 -XX:SurvivorRatio 将会失效，而 JDK 8 是默认开启-XX:+UseAdaptiveSizePolicy
在 JDK 8中，不要随意关闭-XX:+UseAdaptiveSizePolicy，除非对堆内存的划分有明确的规划

<br>每次 GC 后都会重新计算 Eden、From Survivor、To Survivor 的大小<br>计算依据是GC过程中统计的GC时间、吞吐量、内存占用量<br>java -XX:+PrintFlagsFinal -version | grep HeapSize
    uintx ErgoHeapSizeLimit                         = 0                                   {product}
    uintx HeapSizePerGCThread                       = 87241520                            {product}
    uintx InitialHeapSize                          := 134217728                           {product}
    uintx LargePageHeapSizeThreshold                = 134217728                           {product}
    uintx MaxHeapSize                              := 2147483648                          {product}
java version "1.8.0_211"
Java(TM) SE Runtime Environment (build 1.8.0_211-b12)
Java HotSpot(TM) 64-Bit Server VM (build 25.211-b12, mixed mode)
$ jmap -heap 进程号
复制<br><br>
<br>在 JVM 内存模型的堆中，堆被划分为新生代和老年代 

<br>新生代又被进一步划分为 Eden区 和 Survivor区，Survivor 区由 From Survivor 和 To Survivor 组成


<br>当创建一个对象时，对象会被优先分配到新生代的 Eden 区 

<br>此时 JVM 会给对象定义一个对象年轻计数器（-XX:MaxTenuringThreshold）


<br>当 Eden 空间不足时，JVM 将执行新生代的垃圾回收（Minor GC） 

<br>JVM 会把存活的对象转移到 Survivor 中，并且对象年龄 +1
<br>对象在 Survivor 中同样也会经历 Minor GC，每经历一次 Minor GC，对象年龄都会+1


<br>如果分配的对象超过了-XX:PetenureSizeThreshold，对象会直接被分配到老年代
<br><br>为对象分配内存是一件非常严谨和复杂的任务，JVM 的设计者们不仅需要考虑内存如何分配、在哪里分配等问题，并且由于内存分配算法和内存回收算法密切相关，所以还需要考虑 GC 执行完内存回收后是否会在内存空间中产生内存碎片。<br>
<br>new 的对象先放在伊甸园区，此区有大小限制
<br>当伊甸园的空间填满时，程序又需要创建对象，JVM 的垃圾回收器将对伊甸园区进行垃圾回收（Minor GC），将伊甸园区中的不再被其他对象所引用的对象进行销毁。再加载新的对象放到伊甸园区
<br>然后将伊甸园中的剩余对象移动到幸存者 0 区
<br>如果再次触发垃圾回收，此时上次幸存下来的放到幸存者 0 区，如果没有回收，就会放到幸存者 1 区
<br>如果再次经历垃圾回收，此时会重新放回幸存者 0 区，接着再去幸存者 1 区
<br>什么时候才会去养老区呢？ 默认是 15 次回收标记
<br>在养老区，相对悠闲。当养老区内存不足时，再次触发 Major GC，进行养老区的内存清理
<br>若养老区执行了 Major GC 之后发现依然无法进行对象的保存，就会产生 OOM 异常
<br><br><br>JVM 在进行 GC 时，并非每次都对堆内存（新生代、老年代；方法区）区域一起回收的，大部分时候回收的都是指新生代。<br>针对 HotSpot VM 的实现，它里面的 GC 按照回收区域又分为两大类：部分收集（Partial GC），整堆收集（Full GC）<br>
<br>部分收集：不是完整收集整个 Java 堆的垃圾收集。其中又分为： 

<br>新生代收集（Minor GC/Young GC）：只是新生代的垃圾收集
<br>老年代收集（Major GC/Old GC）：只是老年代的垃圾收集 

<br>目前，只有 CMS GC 会有单独收集老年代的行为
<br>很多时候 Major GC 会和 Full GC 混合使用，需要具体分辨是老年代回收还是整堆回收


<br>混合收集（Mixed GC）：收集整个新生代以及部分老年代的垃圾收集 

<br>目前只有 G1 GC 会有这种行为




<br>整堆收集（Full GC）：收集整个 Java 堆和方法区的垃圾
<br><br><br>
<br>从内存模型而不是垃圾回收的角度，对 Eden 区域继续进行划分，JVM 为每个线程分配了一个私有缓存区域，它包含在 Eden 空间内
<br>多线程同时分配内存时，使用 TLAB 可以避免一系列的非线程安全问题，同时还能提升内存分配的吞吐量，因此我们可以将这种内存分配方式称为快速分配策略
<br>OpenJDK 衍生出来的 JVM 大都提供了 TLAB 设计
<br><br>
<br>堆区是线程共享的，任何线程都可以访问到堆区中的共享数据
<br>由于对象实例的创建在 JVM 中非常频繁，因此在并发环境下从堆区中划分内存空间是线程不安全的
<br>为避免多个线程操作同一地址，需要使用加锁等机制，进而影响分配速度
<br>尽管不是所有的对象实例都能够在 TLAB 中成功分配内存，但 JVM 确实是将 TLAB 作为内存分配的首选。<br>在程序中，可以通过 -XX:UseTLAB 设置是否开启 TLAB 空间。<br>默认情况下，TLAB 空间的内存非常小，仅占有整个 Eden 空间的 1%，我们可以通过 -XX:TLABWasteTargetPercent 设置 TLAB 空间所占用 Eden 空间的百分比大小。<br>一旦对象在 TLAB 空间分配内存失败时，JVM 就会尝试着通过使用加锁机制确保数据操作的原子性，从而直接在 Eden 空间中分配内存。<br><br>
随着 JIT 编译期的发展和逃逸分析技术的逐渐成熟，栈上分配、标量替换优化技术将会导致一些微妙的变化，所有的对象都分配到堆上也渐渐变得不那么“绝对”了。 ——《深入理解 Java 虚拟机》
<br><br>逃逸分析(Escape Analysis)**是目前 Java 虚拟机中比较前沿的优化技术**。这是一种可以有效减少 Java 程序中同步负载和内存堆分配压力的跨函数全局数据流分析算法。通过逃逸分析，Java Hotspot 编译器能够分析出一个新的对象的引用的使用范围从而决定是否要将这个对象分配到堆上。<br>逃逸分析的基本行为就是分析对象动态作用域：<br>
<br>当一个对象在方法中被定义后，对象只在方法内部使用，则认为没有发生逃逸。
<br>当一个对象在方法中被定义后，它被外部方法所引用，则认为发生逃逸。例如作为调用参数传递到其他地方中，称为方法逃逸。
<br>例如：<br>public static StringBuffer craeteStringBuffer(String s1, String s2) {
   StringBuffer sb = new StringBuffer();
   sb.append(s1);
   sb.append(s2);
   return sb;
}
复制<br>StringBuffer sb是一个方法内部变量，上述代码中直接将sb返回，这样这个 StringBuffer 有可能被其他方法所改变，这样它的作用域就不只是在方法内部，虽然它是一个局部变量，但是其逃逸到了方法外部。甚至还有可能被外部线程访问到，譬如赋值给类变量或可以在其他线程中访问的实例变量，称为线程逃逸。<br>上述代码如果想要 StringBuffer sb不逃出方法，可以这样写：<br>public static String createStringBuffer(String s1, String s2) {
   StringBuffer sb = new StringBuffer();
   sb.append(s1);
   sb.append(s2);
   return sb.toString();
}
复制<br>不直接返回 StringBuffer，那么 StringBuffer 将不会逃逸出方法。<br>参数设置：<br>
<br>在 JDK 6u23 版本之后，HotSpot 中默认就已经开启了逃逸分析
<br>如果使用较早版本，可以通过-XX"+DoEscapeAnalysis显式开启
<br>开发中使用局部变量，就不要在方法外定义。<br>使用逃逸分析，编译器可以对代码做优化：<br>
<br>栈上分配：将堆分配转化为栈分配。如果一个对象在子程序中被分配，要使指向该对象的指针永远不会逃逸，对象可能是栈分配的候选，而不是堆分配
<br>同步省略：如果一个对象被发现只能从一个线程被访问到，那么对于这个对象的操作可以不考虑同步
<br>分离对象或标量替换：有的对象可能不需要作为一个连续的内存结构存在也可以被访问到，那么对象的部分（或全部）可以不存储在内存，而存储在 CPU 寄存器
<br>JIT 编译器在编译期间根据逃逸分析的结果，发现如果一个对象并没有逃逸出方法的话，就可能被优化成栈上分配。分配完成后，继续在调用栈内执行，最后线程结束，栈空间被回收，局部变量对象也被回收。这样就无需进行垃圾回收了。<br>常见栈上分配的场景：成员变量赋值、方法返回值、实例引用传递<br><br>
<br>线程同步的代价是相当高的，同步的后果是降低并发性和性能
<br>在动态编译同步块的时候，JIT 编译器可以借助逃逸分析来判断同步块所使用的锁对象是否能够被一个线程访问而没有被发布到其他线程。如果没有，那么 JIT 编译器在编译这个同步块的时候就会取消对这个代码的同步。这样就能大大提高并发性和性能。这个取消同步的过程就叫做同步省略，也叫锁消除。
<br>public void keep() {
  Object keeper = new Object();
  synchronized(keeper) {
    System.out.println(keeper);
  }
}
复制<br>如上代码，代码中对 keeper 这个对象进行加锁，但是 keeper 对象的生命周期只在 keep()方法中，并不会被其他线程所访问到，所以在 JIT编译阶段就会被优化掉。优化成：<br>public void keep() {
  Object keeper = new Object();
  System.out.println(keeper);
}
复制<br><br>标量（Scalar）是指一个无法再分解成更小的数据的数据。Java 中的原始数据类型就是标量。<br>相对的，那些的还可以分解的数据叫做聚合量（Aggregate），Java 中的对象就是聚合量，因为其还可以分解成其他聚合量和标量。<br>在 JIT 阶段，通过逃逸分析确定该对象不会被外部访问，并且对象可以被进一步分解时，JVM 不会创建该对象，而会将该对象成员变量分解若干个被这个方法使用的成员变量所代替。这些代替的成员变量在栈帧或寄存器上分配空间。这个过程就是标量替换。<br>通过 -XX:+EliminateAllocations 可以开启标量替换，-XX:+PrintEliminateAllocations 查看标量替换情况。<br>public static void main(String[] args) {
   alloc();
}

private static void alloc() {
   Point point = new Point（1,2）;
   System.out.println("point.x="+point.x+"; point.y="+point.y);
}
class Point{
    private int x;
    private int y;
}
复制<br>以上代码中，point 对象并没有逃逸出 alloc() 方法，并且 point 对象是可以拆解成标量的。那么，JIT 就不会直接创建 Point 对象，而是直接使用两个标量 int x ，int y 来替代 Point 对象。<br>private static void alloc() {
   int x = 1;
   int y = 2;
   System.out.println("point.x="+x+"; point.y="+y);
}
复制<br><br>我们通过 JVM 内存分配可以知道 JAVA 中的对象都是在堆上进行分配，当对象没有被引用的时候，需要依靠 GC 进行回收内存，如果对象数量较多的时候，会给 GC 带来较大压力，也间接影响了应用的性能。为了减少临时对象在堆内分配的数量，JVM 通过逃逸分析确定该对象不会被外部访问。那就通过标量替换将该对象分解在栈上分配内存，这样该对象所占用的内存空间就可以随栈帧出栈而销毁，就减轻了垃圾回收的压力。<br>总结：<br>关于逃逸分析的论文在1999年就已经发表了，但直到JDK 1.6才有实现，而且这项技术到如今也并不是十分成熟的。<br>其根本原因就是无法保证逃逸分析的性能消耗一定能高于他的消耗。虽然经过逃逸分析可以做标量替换、栈上分配、和锁消除。但是逃逸分析自身也是需要进行一系列复杂的分析的，这其实也是一个相对耗时的过程。<br>一个极端的例子，就是经过逃逸分析之后，发现没有一个对象是不逃逸的。那这个逃逸分析的过程就白白浪费掉了。<br>虽然这项技术并不十分成熟，但是他也是即时编译器优化技术中一个十分重要的手段。<br><br>方法区（method area）只是 JVM 规范 中定义的一个概念，规范把方法区描述为堆的一个逻辑部分。<br>方法区（Method Area）与 Java 堆一样，是所有线程共享的内存区域。JVM 关闭后方法区即被释放。<br>HotSpotJVM实现：<br>实现上特殊，将堆和方法区分开，认为是两个不同的结构，方法区还有一个别名是Non-Heap(非堆)，目的就是要和堆分开。<br>永久代和元空间都可以理解为方法区的落地实现。<br>永久代（PermGen）是 Hotspot 虚拟机特有的概念，Java8 的时候被元空间取代。<br><br>所以对于方法区，Java8 之后的变化：<br>
<br>移除了永久代（PermGen），替换为元空间（Metaspace）；
<br>永久代中的 class metadata 转移到了 native memory（本地内存，而不是虚拟机）；
<br>永久代中的 interned Strings 和 class static variables 转移到了 Java heap；（从7开始）
<br>永久代参数 （PermSize MaxPermSize） -&gt; 元空间参数（MetaspaceSize MaxMetaspaceSize）
<br>总结：<br>
<br>
JAVA7：永久代在物理是堆的一部分，和新生代，老年代地址是连续的（受垃圾回收器管理）<br>
JAVA8：元空间存在于本地内存（我们常说的堆外内存，不受垃圾回收器管理），这样就不受 JVM 限制了，也比较难发生OOM（都会有溢出异常）

<br>
Java7：通过-XX:PermSize 和 -xx:MaxPermSize 来设置永久代参数<br>
JAVA8：改为通过-XX:MetaspaceSize 和 -XX:MaxMetaspaceSize 用来设置元空间参数

<br>
Java6：永久代中保存所有数据<br>
Java7：永久代的数据部分被分到了堆中<br>
Java8：元空间存储类的元信息，静态变量和常量池等并入堆。永久代的数据被分到了堆和元空间中。

<br><br>8以后方法区的实现，即元空间设置：<br>-XX:MetaspaceSize 为初始的元空间大小，默认是 21M（20.75MB）。<br>初始的高水位线，一旦触及这个水位线，Full GC 将会被触发并卸载没用的类（即这些类对应的类加载器不再存活），然后这个高水位线将会重置，新的高水位线的值取决于 GC 后释放了多少元空间。如果释放的空间不足，那么在不超过 MaxMetaspaceSize时，适当提高该值。如果释放空间过多，则适当降低该值。<br>如果初始化的高水位线设置过低，上述高水位线调整情况会发生很多次，通过垃圾回收的日志可观察到 Full GC 多次调用。为了避免频繁 GC，建议将 -XX:MetaspaceSize 设置为一个相对较高的值。<br>-XX:MaxMetaspacaSize 设置元空间最大值，默认的值是 -1（没有限制）。<br>即使没有限制，虚拟机会耗尽所有的可用系统内存元数据发生溢出，虚拟机一样会抛出异常 OutOfMemoryError:Metaspace。<br><br>“./.pic-JVM-内存结构/79dfe8a4647e443299aa667df53d1d63.png” could not be found.<br><br>对每个加载的类型（类 class、接口 interface、枚举 enum、注解 annotation），JVM 必须在方法区中存储以下类型信息<br>
<br>这个类型的完整有效名称（全名=包名.类名）
<br>这个类型直接父类的完整有效名（对于 interface或是 java.lang.Object，都没有父类）
<br>这个类型的修饰符（public，abstract，final 的某个子集）
<br>这个类型直接接口的一个有序列表
<br><br>
<br>JVM 必须在方法区中保存类型的所有域的相关信息以及域的声明顺序
<br>域的相关信息包括：域名称、域类型、域修饰符（public、private、protected、static、final、volatile、transient 的某个子集）
<br><br>JVM 必须保存所有方法的<br>
<br>方法名称
<br>方法的返回类型
<br>方法参数的数量和类型
<br>方法的修饰符（public，private，protected，static，final，synchronized，native，abstract 的一个子集）
<br>方法的字符码（bytecodes）、操作数栈、局部变量表及大小（abstract 和 native 方法除外）
<br>异常表（abstract 和 native 方法除外） 

<br>每个异常处理的开始位置、结束位置、代码处理在程序计数器中的偏移地址、被捕获的异常类的常量池索引


<br>栈、堆、方法区的交互关系<br><br>运行时常量池（Runtime Constant Pool）是方法区的一部分。串池也属于运行时常量池的一部分。<br>运行期间也可能将新的常量放入池中，被开发人员利用得比较多的是 String.intern()方法。受方法区内存的限制，当常量池无法再申请到内存时会抛出 OutOfMemoryError 异常。<br><br>常量池（常量池表） 是 字节码文件（Class 文件）中的一部分。<br>一个 Java 源文件中的类、接口，编译后产生一个字节码文件。Java 中的字节码需要数据支持，通常这种数据会很大以至于不能直接存到字节码里，换另一种方式，可以存到常量池，这个字节码包含了指向常量池的引用。在动态链接的时候用到的就是运行时常量池。如果不使用常量池，就需要将用到的类信息、方法信息等记录在当前的字节码文件中，造成文件臃肿。<br>一个有效的字节码文件中除了包含类的版本信息、字段、方法以及接口等描述信息外，还包含一项信息那就是常量池表（Constant Pool Table），包含各种字面量和对类型、域和方法的符号引用。<br>如下，我们通过 jclasslib 查看一个只有 Main 方法的简单类，字节码中的 #2 指向的就是 Constant Pool<br><img style="zoom:50%;" alt="img" src="\.pic-JVM-内存结构\007S8ZIlly1gg9i91ze2gj320i0riahe-1681916255690-3.jpg" referrerpolicy="no-referrer"><br>常量池可以看作是一张表，虚拟机指令根据这张常量表找到要执行的类名、方法名、参数类型、字面量等类型。<br><br>在加载类和结构到虚拟机后，就会创建对应的运行时常量池<br>常量池表（Constant Pool Table）是 Class 文件的一部分，用于存储编译期生成的各种字面量和符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中<br>JVM 为每个已加载的类型（类或接口）都维护一个常量池。池中的数据项像数组项一样，是通过索引访问的<br>运行时常量池中包含各种不同的常量，包括编译器就已经明确的数值字面量，也包括到运行期解析后才能够获得的方法或字段引用。此时不再是常量池中的符号地址了，这里换为真实地址 <br>
<br>运行时常量池，相对于 Class 文件常量池的另一个重要特征是：动态性，Java 语言并不要求常量一定只有编译期间才能产生，运行期间也可以将新的常量放入池中，String 类的 intern() 方法就是这样的
<br>当创建类或接口的运行时常量池时，如果构造运行时常量池所需的内存空间超过了方法区所能提供的最大值，则 JVM 会抛出 OutOfMemoryError 异常。<br><br>只有 HotSpot 才有永久代的概念<br>JDK6<br>方法区由永久代实现，使用 JVM 虚拟机内存<br><img style="zoom: 67%;" alt="img" src="\.pic-JVM-内存结构\a9c7e4f45fdd44b7a7fc2f7bf3adb57b.png" referrerpolicy="no-referrer"><br>JDK7<br>方法区由永久代实现，使用 JVM 虚拟机内存<br><img style="zoom:67%;" alt="img" src="\.pic-JVM-内存结构\0b08e94120134ffc90d84be8e3cb6bbd.png" referrerpolicy="no-referrer"><br>DK8<br>方法区由元空间实现，使用物理机本地内存<br><img style="zoom:67%;" alt="img" src="\.pic-JVM-内存结构\bae9b875bdc142ae85da54300fe0478b.png" referrerpolicy="no-referrer"><br>总结：<br><br><br>1、永久代设置空间大小是很难确定的<br>在某些场景下，如果动态加载类过多，容易产生 Perm 区的 OOM。如果某个实际 Web 工程中，因为功能点比较多，在运行过程中，要不断动态加载很多类，经常出现 OOM。而元空间和永久代最大的区别在于，元空间不在虚拟机中，而是使用本地内存，所以默认情况下，元空间的大小仅受本地内存限制<br>2、对永久代进行调优较困难<br><br>方法区的垃圾收集主要回收两部分内容：常量池中废弃的常量和不再使用的类型。<br><br>方法区内常量池之中主要存放的两大类常量：字面量和符号引用。<br>字面量比较接近 Java 语言层次的常量概念，如文本字符串、被声明为 final 的常量值等。<br>符号引用则属于编译原理方面的概念，包括下面三类常量：<br>
<br>类和接口的全限定名
<br>字段的名称和描述符
<br>方法的名称和描述符
<br>HotSpot 虚拟机对常量池的回收策略是很明确的，只要常量池中的常量没有被任何地方引用，就可以被回收<br><br>判定一个类型是否属于“不再被使用的类”，需要同时满足三个条件：<br>
<br>该类所有的实例都已经被回收，也就是 Java 堆中不存在该类及其任何派生子类的实例
<br>加载该类的类加载器已经被回收，这个条件除非是经过精心设计的可替换类加载器的场景，如 OSGi、JSP 的重加载等，否则通常很难达成
<br>该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法
<br>Java 虚拟机被允许堆满足上述三个条件的无用类进行回收，这里说的仅仅是“被允许”，而并不是和对象一样，不使用了就必然会回收。是否对类进行回收，HotSpot 虚拟机提供了 -Xnoclassgc 参数进行控制，还可以使用 -verbose:class 以及 -XX:+TraceClassLoading 、-XX:+TraceClassUnLoading 查看类加载和卸载信息。<br>在大量使用反射、动态代理、CGLib 等 ByteCode 框架、动态生成 JSP 以及 OSGi 这类频繁自定义 ClassLoader 的场景都需要虚拟机具备类卸载的功能，以保证永久代不会溢出。<br><br>1、如何设置为动态大小的栈呢？参数是什么？]]></description><link>03、java核心\04、jvm-相关\jvm-内存结构.html</link><guid isPermaLink="false">03、Java核心/04、Jvm 相关/JVM-内存结构.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:45 GMT</pubDate><enclosure url=".pic-JVM-内存结构\0082zybply1gc6fz21n8kj30u00wpn5v.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;.pic-JVM-内存结构\0082zybply1gc6fz21n8kj30u00wpn5v.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[01、函数编程]]></title><description><![CDATA[ 
 <br><br>面向对象编程是对数据进行抽象；函数式编程是对行为进行抽象。<br>函数式编程提升 Java 语言的表达能力和简化代码。<br>
程序员在写回调函数、事件处理器、惰性代码时，不必再纠缠于匿名内部类的冗繁和可读性。<br>对核心类库的改进主要包括集合类的 API 和新引入的流 Stream。流使程序员可以站在更高的抽象层次上对集合进行操作。<br><br><br>lambda表达式仅能放入如下代码:<br>1、预定义使用了 @FunctionalInterface  注释的函数式接口。<br>
2、自带一个抽象函数的方法， SAM (Single Abstract Method 单个抽象方法)类型。（注解并不是必需的，但它有助于提高代码的可读性和可维护性。）<br><br>1、函数接口<br>
Lambda 表达式主要用于实现函数接口。函数接口是指仅包含一个抽象方法的接口，例如 Runnable、Callable、Comparator 等。<br>// Lambda 表达式实现 Runnable 接口
Runnable r = () -&gt; System.out.println("Hello, Lambda!");

复制<br>2、集合操作<br>
在使用 Java 8 引入的 Stream API 进行集合操作时，可以使用 Lambda 表达式来传递操作。<br>List&lt;String&gt; names = Arrays.asList("Alice", "Bob", "Charlie");
names.stream().forEach(name -&gt; System.out.println(name));
复制<br>3、事件处理<br>
在事件处理中，比如使用 Swing 或 JavaFX 进行图形用户界面编程时，可以使用 Lambda 表达式来简化事件处理代码。<br>button.addActionListener(event -&gt; System.out.println("Button clicked!"));
复制<br>4、线程并发<br>
在创建线程或进行并发编程时，Lambda 表达式可以用于简化代码。<br>new Thread(() -&gt; System.out.println("Hello from a thread!")).start();
复制<br><br><br>在 Java 8 之前，并没有像 Java 8 中的 Stream API 这样显式的支持惰性求值的机制。<br>
Java 8引入的 Stream API 为惰性求值提供了更加方便和强大的工具，使得处理集合数据的代码更为简洁和可读。<br><br>
这行代码并未做什么实际性的工作，filter 和 map 只是描述定义了 Stream，没有产生新的集合。
<br>List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 3, 4, 5);
//这行代码并未做什么实际性的工作，filter和map只是描述定义了Stream，没有产生新的集合。
Stream&lt;Integer&gt; stream = numbers.stream().filter(x -&gt; x &gt; 2).map(x -&gt; x * x);
复制<br><br>
collect 方法最终会从 Stream 产生新值，拥有终止操作。
<br>List&lt;Integer&gt; result =  stream.collect(Collectors.toList());
复制<br><br><br>
<br>单线程进行处理。
<br>保持元素的顺序。
<br>适用于处理小规模数据集，或者在处理时不涉及大量计算的场景。
<br>List &lt;Person&gt; people = list.getStream.collect(Collectors.toList());
复制<br><br>
<br>多线程进行处理（将数据集分成多个部分并在不同线程上并行处理）。
<br>不保证元素的顺序。
<br>适用于大规模数据集或者需要大量计算的场景。
<br>原理类似于：<br>//伪代码
List originalList = someData;
split1 = originalList(0, mid);//将数据分小部分
split2 = originalList(mid,end);
new Runnable(split1.process());//小部分执行操作
new Runnable(split2.process());
List revisedList = split1 + split2;//将结果合并
复制<br>具体代码实现：<br>class ParallelProcessingTask implements Callable&lt;Integer&gt; {
    private List&lt;Integer&gt; data;

    public ParallelProcessingTask(List&lt;Integer&gt; data) {
        this.data = data;
    }

    @Override
    public Integer call() {
        return data.stream().filter(number -&gt; number % 2 == 0).mapToInt(Integer::intValue).sum();
    }
}

public class ParallelProcessingExample {
    public static void main(String[] args) throws InterruptedException, ExecutionException {
        //初始一个大的运算集合
        List&lt;Integer&gt; originalList = new ArrayList&lt;&gt;();
        for (int i = 0; i &lt; 1000000; i++) {
            originalList.add(i);
        }

        //拆分
        int mid = originalList.size() / 2;
        List&lt;Integer&gt; split1 = originalList.subList(0, mid);
        List&lt;Integer&gt; split2 = originalList.subList(mid, originalList.size());

        // 使用线程池并行处理数据
        ExecutorService executorService = Executors.newFixedThreadPool(2);
        Callable&lt;Integer&gt; task1 = new ParallelProcessingTask(split1);
        Callable&lt;Integer&gt; task2 = new ParallelProcessingTask(split2);

        Future&lt;Integer&gt; result1 = executorService.submit(task1);
        Future&lt;Integer&gt; result2 = executorService.submit(task2);

        // 等待任务完成并合并结果
        int sum = result1.get() + result2.get();

        // 关闭线程池
        executorService.shutdown();

        System.out.println("Sum of even numbers: " + sum);
    }
}

复制<br><br>import java.util.ArrayList;
import java.util.List;
import java.util.stream.IntStream;

public class StreamVsParallelStreamExample {
    public static void main(String[] args) {
        List&lt;Integer&gt; data = new ArrayList&lt;&gt;();
        for (int i = 0; i &lt; 1000000; i++) {
            data.add(i);
        }

        // 使用Stream处理
        long streamStartTime = System.currentTimeMillis();
        long streamResult = data.stream()
                                .filter(StreamVsParallelStreamExample::isEven)
                                .count();
        long streamEndTime = System.currentTimeMillis();

        System.out.println("Stream Result: " + streamResult);
        System.out.println("Stream Time: " + (streamEndTime - streamStartTime) + " ms");

        // 使用ParallelStream处理
        long parallelStreamStartTime = System.currentTimeMillis();
        long parallelStreamResult = data.parallelStream()
                                        .filter(StreamVsParallelStreamExample::isEven)
                                        .count();
        long parallelStreamEndTime = System.currentTimeMillis();

        System.out.println("ParallelStream Result: " + parallelStreamResult);
        System.out.println("ParallelStream Time: " + (parallelStreamEndTime - parallelStreamStartTime) + " ms");
    }

    private static boolean isEven(int number) {
        return number % 2 == 0;
    }
}
复制<br>
数据规模较小，而并行化的开销可能会影响性能。<br>
当数据规模较大时，并行化的优势才能更明显地体现出来。
<br>在 100 W 的处理时：<br>Stream Result: 500000
Stream Time: 49 ms
ParallelStream Result: 500000
ParallelStream Time: 54 ms
复制<br>在 1 亿（100 W 的 100 倍 ）的处理时：<br>Stream Result: 50000000
Stream Time: 339 ms
ParallelStream Result: 50000000
ParallelStream Time: 125 ms
复制<br><br><img src="\03、java核心\05、java-版本和特性\java8\assets\01、函数编程\img-20240128_114739.png"><br>一般分为两大类：<br>中间操作不会立即执行，而是返回一个新的 Stream，可以链式调用多个中间操作。<br>
终端操作会触发流的处理，产生最终的结果。<br><br>
创建一个流、过滤元素、规约操作、截断、映射、排序都属于中间操作。
<br>创建流：<br>
<br>stream(), parallelStream()： 这两个方法用于创建一个流。<br>
**过滤、去重、截断：
<br>filter(Predicate&lt;T&gt; predicate) ：过滤符合条件的元素。
<br>distinct()：去除重复元素。
<br>limit(long maxSize)： 截断流，使其元素不超过给定数量。
<br>peek(Consumer&lt;T&gt; action)： 对每个元素执行操作，并返回一个新的 Stream。
<br>skip(long n)： 跳过流中的前 n 个元素。<br>
映射操作：
<br>map(Function&lt;T, R&gt; mapper)：对每个元素进行映射操作。
<br>flatMap(Function&lt;T, Stream&lt;R&gt;&gt; mapper)：将每个元素映射为一个 Stream，然后将各个 Stream 扁平化为一个 Stream。<br>
排序操作：
<br>sorted()：对元素进行排序。
<br><br>元素执行操作、转化、收集、统计、获取等都属于终端操作。<br>遍历迭代：<br>
<br>forEach(Consumer&lt;T&gt; action) ：对每个元素执行操作。
<br>iterator()：该方法用于获取流中元素的迭代器。
<br>spliterator()：返回一个拆分迭代器，用于并行流的划分。<br>
转换为数组：
<br>toArray() ：将流元素转换为数组。<br>
规约收集：
<br>reduce(BinaryOperator&lt;T&gt; accumulator)：将流元素按照指定的二元操作符进行规约。
<br>collect(Collector&lt;T, A, R&gt; collector)：将流元素收集为一个集合。<br>
聚合和统计操作：
<br>min(Comparator&lt;T&gt; comparator)：找出流中的最小元素。
<br>max(Comparator&lt;T&gt; comparator)： 找出流中的最大元素。
<br>summaryStatistics()：该对象包含流中元素的统计信息，例如总数、平均值、最大值、最小值等。
<br>count(): 计算流中元素的数量。<br>
匹配操作：
<br>anyMatch(Predicate&lt;T&gt; predicate)：检查流中是否有任一元素满足给定条件。
<br>allMatch(Predicate&lt;T&gt; predicate)：检查流中的所有元素是否都满足给定条件。
<br>noneMatch(Predicate&lt;T&gt; predicate): 检查流中是否没有元素满足给定条件。<br>
查找操作：
<br>findFirst()：返回流中的第一个元素。
<br>findAny()：返回流中的任意一个元素。`
<br><br><br>
匿名类可以使用 Lambda 表达式进行简化，Lambda 表达式自身也可以简化。
<br>public class LambdaSimplifyExample {  
  
    public static void main(String[] args) {  
        //匿名类  
        new Thread(new Runnable() {  
            @Override  
            public void run() {  
                System.out.println("In Java8, Lambda expression rocks !!")  
            }  
        }).start();  
  
        // 完整的Lambda表达式  
        Consumer&lt;String&gt; consumer = (String s) -&gt; System.out.println(s);  
        Function&lt;Integer, Integer&gt; function = (Integer x) -&gt; x * x;  
        BiFunction&lt;Integer, Integer, Integer&gt; biFunction = (Integer a, Integer b) -&gt; {  
            int sum = a + b;  
            return sum;  
        };  
        Supplier&lt;LambdaSimplifyExample&gt; supplier = () -&gt; new LambdaSimplifyExample();  
  
        //一、匿名类简写  
        new Thread(() -&gt; System.out.println("In Java8, Lambda expression rocks !!")).start();  
  
        //二、lambda简写  
        // 1、参数类型可以被省略  
        //  当Lambda表达式的参数类型可以从上下文中推断出时，可以省略参数类型。  
        consumer = s -&gt; System.out.println(s);  
  
        //2、单个参数的括号  
        //  单个参数的括号可以被省略  
        function = x -&gt; x * x;  
  
        //3、大括号中的单个语句  
        //  当Lambda表达式的方法体只有一条语句时，可以省略大括号和return语句。  
        biFunction = (a, b) -&gt; a + b;  
  
        //4、方法引用简写（普通方法、构造方法、静态方法）  
        consumer = System.out::println;  
        //构造方法引用  
        supplier = LambdaSimplifyExample::new;  
  
    }  
}
复制<br><br>public class ForEachConsumerExample {

    public static void main(String[] args) {
        List&lt;String&gt; fruits = Arrays.asList("Apple", "Banana", "Orange", "Grape");

        // 使用 Consumer 来定义操作
        Consumer&lt;String&gt; print = System.out::print;
        Consumer&lt;String&gt; printUpperCase = s -&gt; System.out.println(":"+s.toUpperCase());
        Consumer&lt;String&gt; printLength = s -&gt; System.out.println("Length: " + s.length());

        // 使用 forEach 和 Consumer 组合操作
        fruits.forEach(print.andThen(printUpperCase.andThen(printLength)));
    }
}
复制<br><br>public class FilterPredicateExample {  

    public static void main(String[] args) {  
        List&lt;String&gt; fruits = Arrays.asList("Apple", "Banana", "Orange", "Grape");  
  
        // 定义 Predicate 来筛选条件  
        Predicate&lt;String&gt; startsWithA = s -&gt; s.startsWith("A");  
        Predicate&lt;String&gt; lengthGreaterThan5 = s -&gt; s.length() &gt;= 5;  
  
        // 使用 filter 和 Predicate 组合操作  
        List&lt;String&gt; filteredFruits = fruits.stream()  
                .filter(startsWithA.and(lengthGreaterThan5))  
                .collect(Collectors.toList());  
                //.toList()  Java 16+ 中的新方法，用于将 Stream 转换为 List  
        // 打印筛选结果  
        filteredFruits.forEach(System.out::println);  
    }  
}
复制<br><br>public class MapReduceExample {  
  
    public static void main(String[] args) {  
        // 创建一个包含商品费用的列表  
        List&lt;Double&gt; costBeforeTax = Arrays.asList(100.0, 200.0, 300.0, 400.0, 500.0);  
  
        // 使用 Stream API 对费用进行操作  
        double bill = costBeforeTax.stream()  
                // 使用 map 将每个费用增加 12%                .map(cost -&gt; cost + 0.12 * cost)  
                // 使用 reduce 将所有费用相加 
                // 参数`BinaryOperator`是BiFunction&lt;T,​U,​R&gt;接口实现，理解是个Function 
                .reduce((sum, cost) -&gt; sum + cost)  
                // 获取计算结果，如果存在的话  
                .orElse(0.0);  
  
        // 打印总费用  
        System.out.println("Total : " + bill);  
    }  
}
复制<br><br><br>
<br>toList：将流中的元素收集到一个 List 中。
<br>toSet：将流中的元素收集到一个 Set 中。
<br>toMap：将流中的元素按照指定的键值映射规则收集到一个 Map 中。
<br>toCollection：将流中的元素收集到指定类型的集合中。
<br>toConcurrentMap：将流中的元素按照指定的键值映射规则收集到一个并发的 Map 中。
<br>public class CollectorsExample {  
  
    public static void main(String[] args) {  
        // 示例数据  
        List&lt;String&gt; strings = Arrays.asList("apple", "banana", "orange", "grape");  
  
        // toMap：将流中的元素按照指定的键值映射规则收集到一个 Map 中  
//        Map&lt;Integer, String&gt; map = strings.stream()  
//                .collect(Collectors.toMap(String::length, s -&gt; s));  
        // 使用 toMap 时提供合并函数，解决重复键的冲突  
        Map&lt;Integer, String&gt; map = strings.stream()  
                .collect(Collectors.toMap(String::length, s -&gt; s, (existing, replacement) -&gt; existing + ", " + replacement));  
        System.out.println("toMap: " + map);  
  
        // toCollection：将流中的元素收集到指定类型的集合中（例如 ArrayList）  
        ArrayList&lt;String&gt; arrayList = strings.stream()  
                .collect(Collectors.toCollection(ArrayList::new));//(HashSet::new) 指定类型的集合中（例如 HashSet）  
        System.out.println("toCollection (ArrayList): " + arrayList);  
  
        // toConcurrentMap：将流中的元素按照指定的键值映射规则收集到一个并发的 Map 中  
        ConcurrentMap&lt;Integer, String&gt; concurrentMap = strings.stream()  
                .collect(Collectors.toConcurrentMap(String::length, s -&gt; s, (existing, replacement) -&gt; existing + ", " + replacement));  
        System.out.println("toConcurrentMap: " + concurrentMap);  
    }  
}
复制<br><br>
<br>joining：将流中的元素连接成一个字符串，可指定分隔符、前缀和后缀。
<br>List&lt;String&gt; G7 = Arrays.asList("USA", "Japan", "France", "Germany", "Italy", "U.K.","Canada");  
String G7Countries = G7.stream().map(x -&gt; x.toUpperCase()).collect(Collectors.joining(", "));  
System.out.println(G7Countries);
复制<br><br>
<br>counting：计算流中的元素数量。
<br>summarizingInt/Double/Long：对流中的元素进行统计，包括总和、平均值、最大值、最小值等。
<br>List&lt;String&gt; strings = Arrays.asList("apple", "banana", "orange", "grape");  
  
// 使用 counting 统计流中的元素数量  
long count = strings.stream()  
        .collect(Collectors.counting());  
  
System.out.println("count: " + count);  
  
// 使用 summarizingInt 统计流中的元素长度的统计信息  
IntSummaryStatistics statistics = strings.stream()  
        .collect(Collectors.summarizingInt(String::length));  
  
System.out.println("Statistics: " + statistics);  
System.out.println("Sum: " + statistics.getSum());  
System.out.println("Average: " + statistics.getAverage());  
System.out.println("Max: " + statistics.getMax());  
System.out.println("Min: " + statistics.getMin());  
System.out.println("Count: " + statistics.getCount());
复制<br><br>
<br>groupingBy：根据某个分类函数将流中的元素分组。
<br>partitioningBy：根据给定的条件将流中的元素分成两个部分。
<br>List&lt;String&gt; strings = Arrays.asList("apple", "banana", "orange", "grape", "cola");  
  
// 分多个组  
// 使用 groupingBy 根据字符串长度分组  
Map&lt;Integer, List&lt;String&gt;&gt; groupedByLength = strings.stream()  
        .collect(Collectors.groupingBy(String::length));  
// 输出分组结果  
groupedByLength.forEach((length, group) -&gt;  
        System.out.println("Group with length " + length + ": " + group));  
  
  
// 分两个区  
// 使用 partitioningBy 根据字符串长度是否大于 5 进行分区  
Map&lt;Boolean, List&lt;String&gt;&gt; partitioned = strings.stream()  
        .collect(Collectors.partitioningBy(s -&gt; s.length() &gt; 5));  
// 输出分区结果  
partitioned.forEach((isLong, group) -&gt;  
        System.out.println("Partition " + (isLong ? "Long" : "Short") + ": " + group));
复制<br><br>
<br>reducing：使用提供的归约函数对流中的元素进行归约操作。
<br>List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 3, 4, 5);  
  
// 使用 reducing 对流中的元素进行求和  
Optional&lt;Integer&gt; sum = numbers.stream().collect(Collectors.reducing((a, b) -&gt; a + b));  
// 使用 reducing 计算阶乘  
Integer factorial = numbers.stream().collect(Collectors.reducing(1, (a, b) -&gt; a * b));  
  
// 输出阶乘结果  
sum.ifPresent(result -&gt; System.out.println("Sum: " + sum.get()));  
System.out.println("Factorial: " + factorial);
复制<br><br>
<br>mapping：对流中的元素进行映射后再进行其他收集操作。
<br>collectingAndThen：对收集结果应用转换函数。
<br>List&lt;String&gt; fruits = Arrays.asList("apple", "banana", "orange", "grape");  
  
// 使用 mapping 对流中的元素进行映射后再进行收集操作  
List&lt;Integer&gt; lengths = fruits.stream()  
        .collect(Collectors.mapping(String::length, Collectors.toList()));  
System.out.println("Lengths of fruits: " + lengths);  
  
// 使用 collectingAndThen 对收集结果应用转换函数  
String concatenated = fruits.stream()  
        .collect(Collectors.collectingAndThen(Collectors.joining(", "), result -&gt; "[" + result + "]"));  
System.out.println("Concatenated fruits: " + concatenated);
复制<br><br>
<br>averagingInt/Double/Long：计算流中元素的平均值。
<br>List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 3, 4, 5);  
  
// 使用 averagingInt 计算整数列表的平均值  
double average = numbers.stream()  
        .collect(Collectors.averagingInt(Integer::intValue));  
System.out.println("Average: " + average);
复制<br><br>
将多个Stream连接成一个Stream
<br>List&lt;List&lt;String&gt;&gt; nestedLists = Arrays.asList(  
        Arrays.asList("apple", "banana"),  
        Arrays.asList("orange", "grape"),  
        Arrays.asList("watermelon", "pineapple")  
);  
  
// 使用 flatMap 展开嵌套的集合  
List&lt;String&gt; flattenedList = nestedLists.stream()  
        .flatMap(List::stream)  
        .collect(Collectors.toList());  
  
// 输出展开后的列表  
System.out.println("Flattened List: " + flattenedList);
复制<br><br>
判断流中的元素是否满足某些条件
<br>List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 3, 4, 5);

// 使用 allMatch 检查所有元素是否都大于 0
boolean allGreaterThanZero = numbers.stream().allMatch(n -&gt; n &gt; 0);
System.out.println("All elements greater than 0: " + allGreaterThanZero);

// 使用 anyMatch 检查是否存在至少一个元素等于 3
boolean anyEqualToThree = numbers.stream().anyMatch(n -&gt; n == 3);
System.out.println("Any element equal to 3: " + anyEqualToThree);

// 使用 noneMatch 检查是否没有元素大于 10
boolean noneGreaterThanTen = numbers.stream().noneMatch(n -&gt; n &gt; 10);
System.out.println("No element greater than 10: " + noneGreaterThanTen);
复制<br><br>
查找流中元素的统计信息
<br>List&lt;Integer&gt; numbers = Arrays.asList(3, 1, 4, 1, 5, 9, 2, 6, 5);

// 使用 min 查找最小值
Optional&lt;Integer&gt; min = numbers.stream()
        .min(Integer::compareTo);
min.ifPresent(value -&gt; System.out.println("Min value: " + value));

// 使用 max 查找最大值
Optional&lt;Integer&gt; max = numbers.stream()
        .max(Integer::compareTo);
max.ifPresent(value -&gt; System.out.println("Max value: " + value));

// 使用 summaryStatistics 获取统计信息
IntSummaryStatistics statistics = numbers.stream()
        .mapToInt(Integer::intValue)
        .summaryStatistics();
System.out.println("Count: " + statistics.getCount());
System.out.println("Sum: " + statistics.getSum());
System.out.println("Min: " + statistics.getMin());
System.out.println("Max: " + statistics.getMax());
System.out.println("Average: " + statistics.getAverage());
复制<br><br>
foreach 属于终止方法，而 peek 属于中间方法。<br>
peek 一般用于调试。
<br>List&lt;Person&gt; lists = new ArrayList&lt;Person&gt;();
lists.add(new Person(1L, "p1"));
lists.add(new Person(2L, "p2"));
lists.add(new Person(3L, "p3"));
lists.add(new Person(4L, "p4"));
System.out.println(lists);

List&lt;Person&gt; list2 = lists.stream()
				 .filter(f -&gt; f.getName().startsWith("p"))
                .peek(t -&gt; {
                    System.out.println(t.getName());
                })
                .collect(Collectors.toList());
System.out.println(list2);
复制<br><br><br>List&lt;ImageModel&gt; imageModelList = null;
Map&lt;Long, String&gt; imagesMap = null;
imagesMap = imageModelList.stream().collect(Collectors.toMap(ImageModel::getAid, o -&gt; IMAGE_ADDRESS_PREFIX + o.getUrl()));
复制<br><br>List&lt;AdDO&gt; adDOList;
adDOList.stream().map(adDo -&gt; convertAdModel(adDo))
                .collect(Collectors.toList());
复制<br><br>List&lt;String&gt; phones=new ArrayList&lt;String&gt;();
        phones.add("a");
        phones.add("b");
        phones.add("a");
        phones.add("a");
        phones.add("c");
        phones.add("b");
        Map&lt;String, List&lt;String&gt;&gt; phoneClassify = phones.stream().collect(Collectors.groupingBy(item -&gt; item));
        System.out.println(phoneClassify);

返回结果: 
{a=[a, a, a], b=[b, b], c=[c]}
复制<br>static class Employee {
    private String name;
    private String deptName;
    private double salary;
    //....构造，getset，toString
}


public static void main(String[] args) throws IOException {
    List&lt;Employee&gt; list = new ArrayList&lt;&gt;();
    list.add(new Employee("可哈哈", "开发部", 16500));
    list.add(new Employee("张晓曦", "开发部", 5000));
    list.add(new Employee("是前锋", "财务部", 10000));
    list.add(new Employee("彭十六", "主播部", 150000));

    Map&lt;String, List&lt;Employee&gt;&gt; collect = list.stream().collect(Collectors.groupingBy(Employee::getDeptName));
    collect.forEach((s, employees) -&gt; {
        System.out.println(s + "--" + Arrays.toString(employees.toArray()));
    });

    Map&lt;String, Double&gt; collect2 = list.stream().collect(Collectors.groupingBy(Employee::getDeptName, Collectors.summingDouble(Employee::getSalary)));
    collect2.forEach((s, sum) -&gt; {
        System.out.println(s + "--" + sum);
    });
}

结果：
    主播部--[Employee{name='彭十六', deptName='主播部', salary=150000.0}]
    财务部--[Employee{name='是前锋', deptName='财务部', salary=10000.0}]
    开发部--[Employee{name='可哈哈', deptName='开发部', salary=16500.0}, Employee{name='张晓曦', deptName='开发部', salary=5000.0}]
    主播部--150000.0
    财务部--10000.0
    开发部--21500.0
复制<br><br>先按名字不分大小写排，再按 GID 倒序排，最后按年龄正序排<br>public static void main(String[] args) {
	List&lt;Person&gt; personList = getTestList();
	personList.sort(Comparator.comparing(Person::getName, String.CASE_INSENSITIVE_ORDER)
			.thenComparing(Person::getGid, (a, b) -&gt; b.compareTo(a))
			.thenComparingInt(Person::getAge));
	personList.stream().forEach(System.out::println);
}

public static List&lt;Person&gt; getTestList() {
	return Lists.newArrayList(new Person("dai", "301", 10), new Person("dai", "303", 10),
			new Person("dai", "303", 8), new Person("dai", "303", 6), new Person("dai", "303", 11),
			new Person("dai", "302", 9), new Person("zhang", "302", 9), new Person("zhang", "301", 9),
			new Person("Li", "301", 8));
}

// 输出结果
// Person [name=dai, gid=303, age=6]
// Person [name=dai, gid=303, age=8]
// Person [name=dai, gid=303, age=10]
// Person [name=dai, gid=303, age=11]
// Person [name=dai, gid=302, age=9]
// Person [name=dai, gid=301, age=10]
// Person [name=Li, gid=301, age=8]
// Person [name=zhang, gid=302, age=9]
// Person [name=zhang, gid=301, age=9]
复制<br><br>两个新的方法可在字符串类上使用: join 和 chars。第一个方法使用指定的分隔符，将任何数量的字符串连接为一个字符串。<br>String.join(":", "foobar", "foo", "bar");
// =&gt; foobar:foo:bar
复制<br>第二个方法 chars 从字符串所有字符创建数据流，所以你可以在这些字符上使用流式操作。<br>"foobar:foo:bar"
    .chars()
    .distinct()
    .mapToObj(c -&gt; String.valueOf((char)c))
    .sorted()
    .collect(Collectors.joining());
// =&gt; :abfor
复制<br><br>模式串也能受益于数据流。我们可以分割任何模式串，并创建数据流来处理它们，而不是将字符串分割为单个字符的数据流，像下面这样:<br>Pattern.compile(":")
    .splitAsStream("foobar:foo:bar")
    .filter(s -&gt; s.contains("bar"))
    .sorted()
    .collect(Collectors.joining(":"));
// =&gt; bar:foobar
复制<br>此外，正则模式串可以转换为谓词。这些谓词可以像下面那样用于过滤字符串流:<br>Pattern pattern = Pattern.compile(".*@gmail\\.com");
Stream.of("bob@gmail.com", "alice@hotmail.com")
    .filter(pattern.asPredicate())
    .count();
// =&gt; 1
复制<br>上面的模式串接受任何以@gmail. Com 结尾的字符串，并且之后用作 Java 8 的 Predicate 来过滤电子邮件地址流。<br><br>public class TestLocalCache {

	private static ConcurrentHashMap&lt;Integer, Long&gt; cache = new ConcurrentHashMap&lt;&gt;();

	static long fibonacci(int i) {
		if (i == 0)
			return i;

		if (i == 1)
			return 1;

		return cache.computeIfAbsent(i, (key) -&gt; {
			System.out.println("Slow calculation of " + key);

			return fibonacci(i - 2) + fibonacci(i - 1);
		});
	}
	
	public static void main(String[] args) {
		// warm up
		for (int i = 0; i &lt; 101; i++)
	        System.out.println(
	            "f(" + i + ") = " + fibonacci(i));
		
		// read -&gt; cal
		long current = System.currentTimeMillis();
		System.out.println(fibonacci(100));
		System.out.println(System.currentTimeMillis()-current);
	}
}
复制<br><br><br>@FunctionInterface<br>
如果一个类型被该注解修饰，编译器必须满足：<br>
1、类型必须是一个 interface<br>
2、符合函数接口的条件，最多包含一个抽象方法。
<br>编译器会自动把满足 function interface 要求的接口自动识别为 function interface，按照编码规范建议加上。<br>对于条件 2，只能有一个抽象方法，存在两种特殊例外（可以参照 Comparator 类的源码）<br>
1、接口允许有实现的方法，这种实现的方法是用default 关键字来标记的。<br>
2、第二如果声明的方法和 java. Lang. Object 中的某个方法一样，它可以不当做未实现的方法。<br>
认为不违背这个原则: 一个被它注解的接口只能有一个抽象方法。
<br>如下：<br>
<img src="\03、java核心\05、java-版本和特性\java8\assets\01、函数编程\img-20240128_103832.png"><br><br>如上要求：<br>
<br>建议接口标记 @FunctionalInterface 注解。
<br>接口中只能有一个抽象方法。
<br>@FunctionalInterface
interface MathOperation {
    int operate(int a, int b);

    default MathOperation andThen(MathOperation after) {
        // 默认方法，返回一个新的 MathOperation，表示两个操作的串联
        return (int x, int y) -&gt; after.operate(this.operate(x, y), y);
    }

    static MathOperation compose(MathOperation before, MathOperation after) {
        // 静态方法，返回一个新的 MathOperation，表示两个操作的组合
        return (int x, int y) -&gt; after.operate(before.operate(x, y), y);
    }
}

public class TestIMyInterface {
    public static void main(String[] args) {
        // 使用 lambda 表达式创建 MathOperation 实例
        MathOperation add = (a, b) -&gt; a + b;
        MathOperation subtract = (a, b) -&gt; a - b;
        MathOperation multiply = (a, b) -&gt; a * b;

        // 调用自定义接口的抽象方法
        System.out.println("Addition: " + add.operate(5, 3));         // 输出 8
        System.out.println("Subtraction: " + subtract.operate(5, 3));  // 输出 2
        System.out.println("Multiplication: " + multiply.operate(5, 3));// 输出 15

        // 使用默认方法 andThen 进行操作串联
        MathOperation addAndMultiply = add.andThen(multiply);
        System.out.println("Add and Multiply: " + addAndMultiply.operate(5, 3));  // 输出 24

        // 使用静态方法 compose 进行操作组合
        MathOperation composedOperation = MathOperation.compose(subtract, multiply);
        System.out.println("Subtract and Multiply: " + composedOperation.operate(5, 3));  // 输出 6
    }
}
复制<br><br>○ 消费型接口: Consumer &lt;T&gt; void accept(T t) 有参数，无返回值的抽象方法；<br>○ 供给型接口: Supplier &lt;T&gt; T get() 无参有返回值的抽象方法；<br>○ 函数型接口: Function&lt;T,R&gt; R apply(T t) 有参有返回值的抽象方法；<br>○ 断定型接口: Predicate&lt;T&gt; boolean test(T t) 有参，但是返回值类型是固定的 boolean<br><br><br>Consumer 消费型接口：接受单一的参数进行处理，处理完成后不返回任何结果。<br>
源码如下：
<br>@FunctionalInterface  
public interface Consumer&lt;T&gt; {  

	//抽象方法 ，用于接受一个输入参数并在其上执行操作。
	//其中`T` 是输入参数的类型。
	void accept(T t);  

	//`default` 方法是在接口中提供一个默认的实现
	//此方法将多个 `Consumer` 组合成一个，然后从左到右的顺序执行。
	default Consumer&lt;T&gt; andThen(Consumer&lt;? super T&gt; after) {  
        Objects.requireNonNull(after);  
        return (T t) -&gt; { accept(t); after.accept(t); };  
    }
    
}
复制<br><br>
四种定义方式：<br>
1）使用匿名类<br>
2）使用 Lambda<br>
3）方法引用<br>
4）调用 andThen
<br>public class ConsumerTest {  
  
    public static void main(String[] args) {  
  
        //1、使用匿名类  
        Consumer&lt;String&gt; consumer = new Consumer&lt;String&gt;() {  
            @Override  
            public void accept(String s) {  
                //方法实现  
                System.out.println("Consumer1: " + s);  
            }  
        };  
        consumer.accept("匿名类");  
  
        //2、使用 Lambda 表达式  
        Consumer&lt;String&gt; consumer2 = s -&gt; System.out.println("Consumer2-1: " + s);  
        consumer2 = (ob) -&gt; {  
            System.out.println("Consumer2: " + ob);  
        };  
        consumer2.accept("Lambda 表达式");  
  
        //3、方法引用  
        Consumer&lt;String&gt; consumer3 = System.out::println;  
        consumer3 = ConsumerTest::printInfo;  
        consumer3.accept("Consumer3: 方法引用");  
  
        //4、使用andTen  
        Consumer&lt;String&gt; consumer4_1 = s -&gt; System.out.print("Consumer4: " + s);  
        Consumer&lt;String&gt; consumer4_2 = s -&gt; System.out.println(",获取长度:" + s.length());  
  
        Consumer&lt;String&gt; combinedConsumer = consumer4_1.andThen(consumer4_2);  
        combinedConsumer.accept("使用andThen");  
    }  
  
  
    // 定义一个普通的函数  
    private static void printInfo(String str) {  
        System.out.println(str);  
    }
  
}
复制<br>
使用对象当做入参：
<br>Consumer&lt;Person&gt; greeter = (p) -&gt; System.out.println("Hello, " + p.firstName);
greeter.accept(new Person("Luke", "Skywalker"));
复制<br><br>Java 中的 java.util.function 包提供了各种类型的 Consumer 接口的变体：<br><img alt="assets/01、函数编程/img-20240127_103306.png" src="\03、java核心\05、java-版本和特性\java8\assets\01、函数编程\img-20240127_103306.png" style="width: 288px; max-width: 100%;"><br>
<br>BiConsumer&lt;T, U&gt;：处理接受和处理 两个输入参数 的情况。
<br>DoubleConsumer： 处理接受和处理 double 类型参数的情况。
<br>IntConsumer：处理接受和处理 int 类型参数的情况。
<br>LongConsumer：处理接受和处理 long 类型参数的情况。
<br>下面的接受一个对象，但是没有 andThen 方法了<br>
<br>ObjDoubleConsumer&lt;T&gt;： 处理接受对象和 double 类型参数的情况。
<br>ObjIntConsumerr&lt;T&gt;：处理接受对象和 int 类型参数的情况。
<br>ObjLongConsumerr&lt;T&gt;：处理接受对象和 long 类型参数的情况。
<br>
 比如: map. ForEach (BiConsumer&lt;A, T&gt;) 方法：
<br>Map&lt;String, String&gt; map = new HashMap&lt;&gt;();
map.forEach((key, value) -&gt; {
	System.out.println(key + value);
});
复制<br><br>Supplier 供给型接口：代表了一个供应者，不接受任何参数，但会返回一个结果。<br><br>@FunctionalInterface  
public interface Supplier&lt;T&gt; {  
	//返回一个类型为T的结果
    T get();  
}
复制<br><br>
四种定义方式：<br>
1）匿名类<br>
2）Lambda<br>
3）方法引用<br>
4）构造器
<br>public class SupplierTest {  
    public static void main(String[] args) {  
        //1、使用匿名类  
        Supplier&lt;String&gt; supplier1 = new Supplier&lt;String&gt;() {  
            @Override  
            public String get() {  
                return "匿名类获取";  
            }  
        };  
        System.out.println("结果：" + supplier1.get());  
  
        //2、Lambda  
        Supplier&lt;String&gt; supplier2 = () -&gt; "Lambda获取";  
        System.out.println("结果：" + supplier2.get());  
  
        //3、方法引用  
        Supplier&lt;Double&gt; supplier3 = Math::random;  
        System.out.println("结果：方法引用获取" + supplier3.get());  
  
        //4、构造器
        Supplier&lt;StringUtils&gt; supplier4 = StringUtils::new;  
        System.out.println("结果：构造器" + supplier4.get().trimWhitespace("  创建StringUtils对象后使用trim  "));  
    }  
}
复制<br>
使用对象当构造：
<br>Supplier&lt;Person&gt; personSupplier = Person::new;
personSupplier.get();   // new Person
复制<br><br><img alt="assets/01、函数编程/img-20240127_110053.png" src="\03、java核心\05、java-版本和特性\java8\assets\01、函数编程\img-20240127_110053.png" style="width: 225px; max-width: 100%;"><br>
<br>BooleanSupplier：适用于需要提供 布尔值 的场景。
<br>DoubleSupplier： 适用于需要提供 double 值的场景。
<br>IntSupplier：适用于需要提供 int 值的场景。
<br>LongSupplier：适用于需要提供 long 值的场景。
<br><br>Function 函数型接口：代表一个接受一个参数并产生结果的函数。<br><br>@FunctionalInterface  
public interface Function&lt;T, R&gt; {  

	//接受一个参数并返回结果。
	R apply(T t);  

	//default方法，返回一个组合函数
	//首先将参数应用于 before 函数，然后将 before 函数的结果应用于当前函数。
	default &lt;V&gt; Function&lt;V, R&gt; compose(Function&lt;? super V, ? extends T&gt; before) {  
        Objects.requireNonNull(before);  
        return (V v) -&gt; apply(before.apply(v));  
    }  

	//default方法，返回一个组合函数
	//首先将当前函数的结果应用于当前函数，然后将结果应用于 after 函数。
	default &lt;V&gt; Function&lt;T, V&gt; andThen(Function&lt;? super R, ? extends V&gt; after) {  
        Objects.requireNonNull(after);  
        return (T t) -&gt; after.apply(apply(t));  
    }  
  
	//静态方法，返回一个执行恒等转换的函数，即返回输入参数本身。
	static &lt;T&gt; Function&lt;T, T&gt; identity() {  
        return t -&gt; t;  
    }  
}
复制<br><br>
四种定义方式：<br>
1）匿名函数<br>
2）Lambda<br>
3）方法引用<br>
4）组合函数
<br>public class FunctionTest {  
    public static void main(String[] args) {  
  
        //1、匿名函数  
        Function&lt;Integer, String&gt; function1 = new Function&lt;Integer, String&gt;() {  
            @Override  
            public String apply(Integer i) {  
                return String.valueOf(i);  
            }  
        };  
        System.out.println("匿名函数:" + function1.apply(01));  
  
        //2、Lambda 表达式  
        Function&lt;Integer, String&gt; function2_1 = (Integer i) -&gt; String.valueOf(i);  
        Function&lt;Integer, String&gt; function2_2 = (i) -&gt; String.valueOf(i);  
        Function&lt;Integer, String&gt; function2_3 = i -&gt; String.valueOf(i);  
  
        System.out.println("Lambda:" + function2_1.apply(02));  
        System.out.println("Lambda:" + function2_2.apply(02));  
        System.out.println("Lambda:" + function2_3.apply(02));  
  
        //3、方法引用  
        Function&lt;Integer, String&gt; function3_1 = String::valueOf;  
        //使用已有的方法进行转换  
        Function&lt;Integer, String&gt; function3_2 = Object::toString;  
        //自定义函数  
        Function&lt;Integer, String&gt; function3_3 = FunctionTest::customConvert;  
  
        System.out.println("方法引用:" + function3_1.apply(03));  
        System.out.println("方法引用:" + function3_2.apply(03));  
        System.out.println("方法引用:" + function3_3.apply(03));  
  
  
        //4、组合函数  
        Function&lt;Integer, String&gt; intToString = String::valueOf;  
        Function&lt;String, Integer&gt; stringToInt = Integer::parseInt;  
  
        Function&lt;Integer, Integer&gt; function5_1 = intToString.andThen(stringToInt);  
        Function&lt;String, String&gt; function5_2 =  intToString.compose(stringToInt);  
  
        System.out.println("组合函数:" + function5_1.apply(04));  
        System.out.println("组合函数:" + function5_2.apply("04"));  
    }  
  
    //定义一个函数  
    public static String customConvert(Integer i) {  
        // 自定义转换逻辑  
        return "Custom: " + String.valueOf(i);  
    }  
  
}
复制<br><br>
<br>BiFunction&lt;T, U&gt;: 接受 T, U ，返回 R 泛型的场景。
<br>IntFunction&lt;R&gt;: 提供 int 值,，返回 R 泛型的场景。
<br>LongFunction&lt;R&gt;：提供 long 值,，返回 R 泛型的场景。
<br>DoubleFunction&lt;R&gt;： 提供 double 值,，返回 R 泛型的场景。
<br>6 种方式<br>
类型之间转化，注意都是基本类型，不是包装类型：<br>
<br>DoubleToIntFunction：接受 double，返回 int。
<br>IntToDoubleFunction：接受 int，返回 double。
<br>DoubleToLongFunction：接受 double，返回 long。
<br>LongToDoubleFunction：接受 long，返回 double。
<br>IntToLongFunction：接受 int，返回 long。
<br>LongToIntFunction：接受 long，返回 `int。
<br>返回 double、int、long 的 6 种方式，参数 1-2 个。<br>
apply 方法名变化了，而且没有其他多余方法：<br>
<br>ToDoubleBiFunction&lt;T, U&gt; ：接受 T, U 返回 double，方法 applyAsDouble。
<br>ToDoubleFunction&lt;T&gt;：接受 T 返回 double，方法 applyAsDouble。
<br>ToIntBiFunction&lt;T, U&gt; ：接受 T, U 返回 int，方法 applyAsInt。
<br>ToIntFunction&lt;T&gt;：接受 T 返回 int，方法 applyAsInt。
<br>ToLongBiFunction&lt;T, U&gt;：接受 T, U 返回 long，方法 applyAsLong。
<br>ToLongFunction&lt;T&gt;：接受 T 返回 long，方法 applyAsLong。
<br><br>Predicate 断定型接口：表示一个断定型操作，接受一个输入参数，返回一个布尔值。通常用于测试某个条件是否满足。<br><br>@FunctionalInterface  
public interface Predicate&lt;T&gt; {  

	//核心方法，用于定义断言逻辑。它接受一个输入参数，并返回一个布尔值。
	boolean test(T t);  

	//default方法，返回一个组合函数
	//表示两个条件的逻辑与。
	default Predicate&lt;T&gt; and(Predicate&lt;? super T&gt; other) {  
        Objects.requireNonNull(other);  
        return (t) -&gt; test(t) &amp;&amp; other.test(t);  
    }  
  
    //default方法，返回函数
    //用于对 `Predicate` 的结果取反，返回一个新的 `Predicate`。
    default Predicate&lt;T&gt; negate() {  
        return (t) -&gt; !test(t);  
    }  
  
    //default方法，返回一个组合函数
    //表示两个条件的逻辑或。
    default Predicate&lt;T&gt; or(Predicate&lt;? super T&gt; other) {  
        Objects.requireNonNull(other);  
        return (t) -&gt; test(t) || other.test(t);  
    }  
  
    //静态方法用于创建一个判断相等的 `Predicate`。
    static &lt;T&gt; Predicate&lt;T&gt; isEqual(Object targetRef) {  
        return (null == targetRef)  
                ? Objects::isNull  
                : object -&gt; targetRef.equals(object);  
    }  
}
复制<br><br>
四种定义方式：<br>
1）匿名函数<br>
2）Lambda<br>
3）方法引用<br>
4）组合函数
<br>public class PredicateTest {  
  
    public static void main(String[] args) {  
  
        //1、匿名函数  
        Predicate&lt;Integer&gt; predicate1 = new Predicate&lt;Integer&gt;() {  
            @Override  
            public boolean test(Integer num) {  
                return num % 2 == 0;  
            }  
        };  
        System.out.println("测试匿名函数：" + predicate1.test(10));  
  
        //2、Lambda 表达式  
        Predicate&lt;Integer&gt; predicate2 = num -&gt; num % 2 == 0;  
        System.out.println("测试Lambda 表达式：" + predicate2.test(10));  
  
        //3、方法引用  
        Predicate&lt;String&gt; predicate3_1 = String::isEmpty;  
        Predicate&lt;Integer&gt; predicate3_2 = PredicateTest::isPositive;  
        System.out.println("测试方法引用1：" + predicate3_1.test(""));  
        System.out.println("测试方法引用2：" + predicate3_2.test(-5));  
  
        //4、组合函数  
        BiPredicate&lt;String, String&gt; predicate4_1 = String::startsWith;  
        BiPredicate&lt;String, String&gt; predicate4_2 = String::equals;  
  
        System.out.println("测试or结果：" + predicate4_1.or(predicate4_2).test("testPre", "test"));  
        System.out.println("测试and结果：" + predicate4_1.and(predicate4_2).test("testPre", "test"));  
        System.out.println("测试negate结果：" + predicate4_2.negate().test("testPre", "test"));  
    }  
  
    //定义函数  
    public static boolean isPositive(int num) {  
        return num &gt; 0;  
    }  
  
}
复制<br>
比如: steam (). Filter ()中参数就是 Predicate
<br>Predicate&lt;String&gt; predicate = (s) -&gt; s.length() &gt; 0;

predicate.test("foo");              // true
predicate.negate().test("foo");     // false negate取！

Predicate&lt;Boolean&gt; nonNull = Objects::nonNull;
Predicate&lt;Boolean&gt; isNull = Objects::isNull;

Predicate&lt;String&gt; isEmpty = String::isEmpty;
Predicate&lt;String&gt; isNotEmpty = isEmpty.negate();
复制<br><br>BiPredicate&lt;T, U&gt;：传入 T, U 两个泛型参数，结果输出 boolean。<br>
DoublePredicate：传入 double 参数，结果输出 boolean。<br>
IntPredicate：传入 int 参数，结果输出 boolean。<br>
LongPredicate：传入 long 参数，结果输出 boolean。<br><br>
比如：stream().collect(Collector&lt;? super T, A, R&gt; collector)<br>
Collectors.toSet 中传入了 Supplier  完成了对 CollectorImpl 的实现
<br><img src="\03、java核心\05、java-版本和特性\java8\assets\01、函数编程\img-20240127_110820.png">]]></description><link>03、java核心\05、java-版本和特性\java8\01、函数编程.html</link><guid isPermaLink="false">03、Java核心/05、Java 版本和特性/Java8/01、函数编程.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:44 GMT</pubDate><enclosure url="03、java核心\05、java-版本和特性\java8\assets\01、函数编程\img-20240128_114739.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;03、java核心\05、java-版本和特性\java8\assets\01、函数编程\img-20240128_114739.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[02、默认方法]]></title><description><![CDATA[ 
 <br><br>之前的接口是个双刃剑。好处是面向抽象而不是面向具体编程，缺陷是当需要修改接口时候，需要修改全部实现该接口的类。<br>Java 8之前的集合框架没有 foreach 方法，通常能想到的解决办法是在 JDK 里给相关的接口添加新的方法及实现。然而，对于已经发布的版本，是没法在给接口添加新方法的同时不影响已有的实现。所以引进的默认方法。他们的目的是为了解决接口的修改与现有的实现不兼容的问题。<br><br><br>
<br>定义： 抽象类是一种不能被实例化的类，通常包含抽象方法（没有实现的方法）和具体方法（有实现的方法）。
<br>构造函数： 抽象类可以有构造函数，用于初始化对象状态。
<br>字段： 抽象类可以有实例字段，也可以有静态字段。
<br>访问修饰符： 抽象类的方法可以有不同的访问修饰符。
<br>单继承： 一个类只能继承一个抽象类。
<br>public abstract class AbstractClass {  
  
    // 实例字段  
    private int instanceField;  
  
    // 静态字段  
    private static int staticField;  
  
    // 构造函数  
    public AbstractClass(int instanceFieldValue) {  
        this.instanceField = instanceFieldValue;  
        // 其他初始化逻辑  
    }  
  
    // 抽象方法  
    public abstract void abstractMethod();  
  
    // 具体方法  
    public void concreteMethod() {  
        // 具体方法的实现  
        System.out.println("Concrete method implementation");  
    }  
  
    // 静态方法  
    public static void staticMethod() {  
        // 静态方法的实现  
        System.out.println("Static method implementation");  
    }  
  
    // 具有不同访问修饰符的方法  
    private void privateMethod() {  
        // 私有方法的实现  
    }  
  
    protected void protectedMethod() {  
        // 受保护方法的实现  
    }  
  
    void packagePrivateMethod() {  
        // 包内可见方法的实现  
    }  
  
    public final void finalMethod() {  
        // 最终方法的实现  
    }  
}
复制<br><br>
<br>定义： 接口是一种完全抽象的类型，它可以包含抽象方法和默认方法（有实现的方法），以及静态方法。
<br>构造函数： 接口不能有构造函数。
<br>字段： 接口中只能包含常量字段（public static final），不能包含实例字段。
<br>访问修饰符： 接口中的方法默认是public，且只能是public。
<br>多继承： 一个类可以实现多个接口。
<br>public interface MyInterface {
    // 抽象方法
    /**abstract**/ void abstractMethod();

    // 默认方法
    default void defaultMethod() {
        // 默认方法的实现
        System.out.println("Default method implementation");
    }

    // 静态方法
    static void staticMethod() {
        // 静态方法的实现
        System.out.println("Static method implementation");
    }

    // 常量字段
    public static final int CONSTANT_FIELD = 42;

    // 只能是public修饰符
    public void publicMethod();

    // 接口中的方法默认是public，不能使用其他访问修饰符
    // private void privateMethod(); // 错误，不能是private
    // protected void protectedMethod(); // 错误，不能是protected
    // void packagePrivateMethod(); // 错误，不能是包内可见

    // 一个类可以实现多个接口
    // 如果有冲突，实现类需要提供具体的实现
}
复制<br><br><br><br>由于同一个方法可以从不同接口引入，自然而然的会有冲突的现象，默认方法判断冲突的规则如下:<br>
1、<br>
2、否则，则
<br><br>一个声明在类里面的方法优先于任何默认方法 ()。<br>D -&gt; C -&gt; B &amp; A<br>
D 重写，使用 C 的方法。<br>interface A {
    default void aa() {
        System.out.println("A's aa");
    }
}

interface B {
    default void aa() {
        System.out.println("B's aa");
    }
}

interface C extends A, B {
    default void aa() {
        System.out.println("C's aa");
    }
}

public class D implements A, B, C {

    public void aa() {
        System.out.println("D's aa");
    }

    public static void main(String[] args) {
        new D().aa();  //D's aa
        //如果D中没有aa（）方法，结果为C's aa
    }
}
复制<br><br>会优先选取路径最短的。<br>D -&gt; C -&gt; B -&gt; A<br>
D 没有重写，使用 C 的方法。<br>interface A {  
    default void aa() {  
        System.out.println("A's aa");  
    }  
}  
  
interface B extends A {  
    default void aa() {  
        System.out.println("B's aa");  
    }  
}  
  
interface C extends B {  
    default void aa() {  
        System.out.println("C's aa");  
    }  
}  
  
public class D implements C {  
    public static void main(String[] args) {  
        new D().aa();  //C's aa
    }  
}
复制<br><br>
同等路径，需要指定实现哪一个
<br>interface A {  
    default void aa() {  
        System.out.println("A's aa");  
    }  
}  
  
interface B {  
    default void aa() {  
        System.out.println("B's aa");  
    }  
}  
  
public class D implements A, B {  
  
    public static void main(String[] args) {  
        new D().aa();  
    }  
}
复制<br>编译报错 Duplicate default methods named aa with the parameters () and () are inherited from the types DocApplication.B and DocApplication.A<br>如果一定要这么写呢，D 必须重写方法，或者制定实现两者之一。<br>public class D implements A, B {  
    @Override  
    public void aa() {  
        //重写或者选择两者之一  
        //写法 类.super.方法(…)
        //A.super.aa();  
    }  
  
    //正确执行  
    public static void main(String[] args) {  
        new D().aa();  
    }  
}
复制<br><br>
接口多级集成，super 也只能访问最近的一层。
<br>interface A {  
    default void aa() {  
        System.out.println("A's aa");  
    }  
}  
  
interface B {  
    default void aa() {  
        System.out.println("B's aa");  
    }  
}  
  
interface C extends A, B {  
    default void aa() {  
        System.out.println("C's aa");  
    }  
}  
  
public class D implements C {  
    @Override  
    public void aa() {  
        C.super.aa(); // 编译通过  
        A.super.aa(); //编译不通过  
    }  
}
复制]]></description><link>03、java核心\05、java-版本和特性\java8\02、默认方法.html</link><guid isPermaLink="false">03、Java核心/05、Java 版本和特性/Java8/02、默认方法.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:44 GMT</pubDate></item><item><title><![CDATA[03、Optional类深度解析]]></title><description><![CDATA[ 
 <br>Optional 类是为了解决 Java 中可能出现的空指针异常（NullPointerException）而引入的。在 Java 中，当我们调用一个对象的方法时，如果该对象为 null，就有可能触发空指针异常。<br>Optional 类的 Javadoc 描述如下:<br>
这是一个可以为null的容器对象。如果值存在则isPresent()方法会返回true，调用get()方法会返回该对象。
<br><br><br>
为非 null 的值创建一个 Optional。
<br>of方法通过工厂方法创建Optional类。需要注意的是，创建对象时传入的参数不能为null。如果传入参数为null，则抛出NullPointerException 。<br>//调用工厂方法创建Optional实例
Optional&lt;String&gt; name = Optional.of("Sanaulla");
//传入参数为null，抛出NullPointerException.
Optional&lt;String&gt; someNull = Optional.of(null);
复制<br><br>
为指定的值创建一个 Optional，包括 null。<br>
如果指定的值为 null，则返回一个空的 Optional。
<br>ofNullable与of方法相似，唯一的区别是可以接受参数为null的情况。示例如下:<br>//下面创建了一个不包含任何值的Optional实例
//例如，值为'null'
Optional empty = Optional.ofNullable(null);
复制<br><br>非常容易理解<br>
如果值存在返回true，否则返回false。
<br>类似下面的代码:<br>//isPresent方法用来检查Optional实例中是否包含值
if (name.isPresent()) {
  //在Optional实例内调用get()返回已存在的值
  System.out.println(name.get());//输出Sanaulla
}
复制<br><br>
如果Optional有值则将其返回，否则抛出NoSuchElementException。
<br>上面的示例中，get方法用来得到Optional实例中的值。下面我们看一个抛出NoSuchElementException的例子:<br>//执行下面的代码会输出: No value present 
try {
  //在空的Optional实例上调用get()，抛出NoSuchElementException
  System.out.println(empty.get());
} catch (NoSuchElementException ex) {
  System.out.println(ex.getMessage());
}
复制<br><br>
如果Optional实例有值则为其调用consumer，否则不做处理
<br>要理解ifPresent方法，首先需要了解Consumer类。简答地说，Consumer类包含一个抽象方法。该抽象方法对传入的值进行处理，但没有返回值。Java8支持不用接口直接通过lambda表达式传入参数。<br>如果Optional实例有值，调用ifPresent()可以接受接口段或lambda表达式。类似下面的代码:<br>//ifPresent方法接受lambda表达式作为参数。
//lambda表达式对Optional的值调用consumer进行处理。
name.ifPresent((value) -&gt; {
  System.out.println("The length of the value is: " + value.length());
});
复制<br><br>
如果有值则将其返回，否则返回指定的其它值。
<br>如果Optional实例有值则将其返回，否则返回orElse方法传入的参数。示例如下:<br>//如果值不为null，orElse方法返回Optional实例的值。
//如果为null，返回传入的消息。
//输出: There is no value present!
System.out.println(empty.orElse("There is no value present!"));
//输出: Sanaulla
System.out.println(name.orElse("There is some value!"));
复制<br><br>
OrElseGet 与 orElse 方法类似，区别在于得到的默认值。<br>
orElse方法将传入的字符串作为默认值，orElseGet方法可以接受Supplier接口的实现用来生成默认值。示例如下:
<br>//orElseGet与orElse方法类似，区别在于orElse传入的是默认值，
//orElseGet可以接受一个lambda表达式生成默认值。
//输出: Default Value
System.out.println(empty.orElseGet(() -&gt; "Default Value"));
//输出: Sanaulla
System.out.println(name.orElseGet(() -&gt; "Default Value"));
复制<br><br>
如果有值则将其返回，否则抛出supplier接口创建的异常。
<br>在orElseGet方法中，我们传入一个Supplier接口。然而，在orElseThrow中我们可以传入一个lambda表达式或方法，如果值不存在来抛出异常。示例如下:<br>try {
  //orElseThrow与orElse方法类似。与返回默认值不同，
  //orElseThrow会抛出lambda表达式或方法生成的异常 

  empty.orElseThrow(ValueAbsentException::new);
} catch (Throwable ex) {
  //输出: No value present in the Optional instance
  System.out.println(ex.getMessage());
}
复制<br>ValueAbsentException定义如下:<br>class ValueAbsentException extends Throwable {

  public ValueAbsentException() {
    super();
  }

  public ValueAbsentException(String msg) {
    super(msg);
  }

  @Override
  public String getMessage() {
    return "No value present in the Optional instance";
  }
}
复制<br><br>map方法文档说明如下:<br>
如果有值，则对其执行调用mapping函数得到返回值。如果返回值不为null，则创建包含mapping返回值的Optional作为map方法返回值，否则返回空Optional。
<br>map方法用来对Optional实例的值执行一系列操作。通过一组实现了Function接口的lambda表达式传入操作。如果你不熟悉Function接口，可以参考我的这篇博客。map方法示例如下:<br>//map方法执行传入的lambda表达式参数对Optional实例的值进行修改。
//为lambda表达式的返回值创建新的Optional实例作为map方法的返回值。
Optional&lt;String&gt; upperName = name.map((value) -&gt; value.toUpperCase());
System.out.println(upperName.orElse("No value found"));
复制<br><br>
如果有值，为其执行mapping函数返回Optional类型返回值，否则返回空Optional。flatMap与map(Funtion)方法类似，区别在于flatMap中的mapper返回值必须是Optional。调用结束时，flatMap不会对结果用Optional封装。
<br>flatMap方法与map方法类似，区别在于mapping函数的返回值不同。map方法的mapping函数返回值可以是任何类型T，而flatMap方法的mapping函数必须是Optional。<br>参照map函数，使用flatMap重写的示例如下:<br>//flatMap与map(Function)非常类似，区别在于传入方法的lambda表达式的返回类型。
//map方法中的lambda表达式返回值可以是任意类型，在map函数返回之前会包装为Optional。 
//但flatMap方法中的lambda表达式返回值必须是Optionl实例。 
upperName = name.flatMap((value) -&gt; Optional.of(value.toUpperCase()));
System.out.println(upperName.orElse("No value found"));//输出SANAULLA
复制<br><br>filter个方法通过传入限定条件对Optional实例的值进行过滤。文档描述如下:<br>
如果有值并且满足断言条件返回包含该值的Optional，否则返回空Optional。
<br>读到这里，可能你已经知道如何为filter方法传入一段代码。是的，这里可以传入一个lambda表达式。对于filter函数我们应该传入实现了Predicate接口的lambda表达式。如果你不熟悉Predicate接口，可以参考这篇文章。<br>现在我来看看filter的各种用法，下面的示例介绍了满足限定条件和不满足两种情况:<br>//filter方法检查给定的Option值是否满足某些条件。
//如果满足则返回同一个Option实例，否则返回空Optional。
Optional&lt;String&gt; longName = name.filter((value) -&gt; value.length() &gt; 6);
System.out.println(longName.orElse("The name is less than 6 characters"));//输出Sanaulla

//另一个例子是Optional值不满足filter指定的条件。
Optional&lt;String&gt; anotherName = Optional.of("Sana");
Optional&lt;String&gt; shortName = anotherName.filter((value) -&gt; value.length() &gt; 6);
//输出: name长度不足6字符
System.out.println(shortName.orElse("The name is less than 6 characters"));
复制<br><br>public class OptionalDemo {

  public static void main(String[] args) {
    //创建Optional实例，也可以通过方法返回值得到。
    Optional&lt;String&gt; name = Optional.of("Sanaulla");

    //创建没有值的Optional实例，例如值为'null'
    Optional empty = Optional.ofNullable(null);

    //isPresent方法用来检查Optional实例是否有值。
    if (name.isPresent()) {
      //调用get()返回Optional值。
      System.out.println(name.get());
    }

    try {
      //在Optional实例上调用get()抛出NoSuchElementException。
      System.out.println(empty.get());
    } catch (NoSuchElementException ex) {
      System.out.println(ex.getMessage());
    }

    //ifPresent方法接受lambda表达式参数。
    //如果Optional值不为空，lambda表达式会处理并在其上执行操作。
    name.ifPresent((value) -&gt; {
      System.out.println("The length of the value is: " + value.length());
    });

    //如果有值orElse方法会返回Optional实例，否则返回传入的错误信息。
    System.out.println(empty.orElse("There is no value present!"));
    System.out.println(name.orElse("There is some value!"));

    //orElseGet与orElse类似，区别在于传入的默认值。
    //orElseGet接受lambda表达式生成默认值。
    System.out.println(empty.orElseGet(() -&gt; "Default Value"));
    System.out.println(name.orElseGet(() -&gt; "Default Value"));

    try {
      //orElseThrow与orElse方法类似，区别在于返回值。
      //orElseThrow抛出由传入的lambda表达式/方法生成异常。
      empty.orElseThrow(ValueAbsentException::new);
    } catch (Throwable ex) {
      System.out.println(ex.getMessage());
    }

    //map方法通过传入的lambda表达式修改Optonal实例默认值。 
    //lambda表达式返回值会包装为Optional实例。
    Optional&lt;String&gt; upperName = name.map((value) -&gt; value.toUpperCase());
    System.out.println(upperName.orElse("No value found"));

    //flatMap与map(Funtion)非常相似，区别在于lambda表达式的返回值。
    //map方法的lambda表达式返回值可以是任何类型，但是返回值会包装成Optional实例。
    //但是flatMap方法的lambda返回值总是Optional类型。
    upperName = name.flatMap((value) -&gt; Optional.of(value.toUpperCase()));
    System.out.println(upperName.orElse("No value found"));

    //filter方法检查Optiona值是否满足给定条件。
    //如果满足返回Optional实例值，否则返回空Optional。
    Optional&lt;String&gt; longName = name.filter((value) -&gt; value.length() &gt; 6);
    System.out.println(longName.orElse("The name is less than 6 characters"));

    //另一个示例，Optional值不满足给定条件。
    Optional&lt;String&gt; anotherName = Optional.of("Sana");
    Optional&lt;String&gt; shortName = anotherName.filter((value) -&gt; value.length() &gt; 6);
    System.out.println(shortName.orElse("The name is less than 6 characters"));

  }
}
复制<br><br>假设我们有一个像这样的类层次结构:<br>class Outer {
    Nested nested;
    Nested getNested() {
        return nested;
    }
}
class Nested {
    Inner inner;
    Inner getInner() {
        return inner;
    }
}
class Inner {
    String foo;
    String getFoo() {
        return foo;
    }
}
复制<br>解决这种结构的深层嵌套路径是有点麻烦的。我们必须编写一堆 null 检查来确保不会导致一个 NullPointerException:<br>Outer outer = new Outer();
if (outer != null &amp;&amp; outer.nested != null &amp;&amp; outer.nested.inner != null) {
    System.out.println(outer.nested.inner.foo);
}
复制<br>我们可以通过利用 Java 8 的 Optional 类型来摆脱所有这些 null 检查。map 方法接收一个 Function 类型的 lambda 表达式，并自动将每个 function 的结果包装成一个 Optional 对象。这使我们能够在一行中进行多个 map 操作。Null 检查是在底层自动处理的。<br>Optional.of(new Outer())
    .map(Outer::getNested)
    .map(Nested::getInner)
    .map(Inner::getFoo)
    .ifPresent(System.out::println);
复制<br>还有一种实现相同作用的方式就是通过利用一个 supplier 函数来解决嵌套路径的问题:<br>Outer obj = new Outer();
resolve(() -&gt; obj.getNested().getInner().getFoo())
    .ifPresent(System.out::println);
复制<br>调用 obj.getNested().getInner().getFoo()) 可能会抛出一个 NullPointerException 异常。在这种情况下，该异常将会被捕获，而该方法会返回 Optional.empty()。<br>public static &lt;T&gt; Optional&lt;T&gt; resolve(Supplier&lt;T&gt; resolver) {
    try {
        T result = resolver.get();
        return Optional.ofNullable(result);
    }
    catch (NullPointerException e) {
        return Optional.empty();
    }
}
复制<br>请记住，这两个解决方案可能没有传统 null 检查那么高的性能。不过在大多数情况下不会有太大问题。]]></description><link>03、java核心\05、java-版本和特性\java8\03、optional类深度解析.html</link><guid isPermaLink="false">03、Java核心/05、Java 版本和特性/Java8/03、Optional类深度解析.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:43 GMT</pubDate></item><item><title><![CDATA[Java8新特性]]></title><description><![CDATA[ 
 <br><br><br>List&lt;ImageModel&gt; imageModelList = null;
Map&lt;Long, String&gt; imagesMap = null;
imagesMap = imageModelList.stream().collect(Collectors.toMap(ImageModel::getAid, o -&gt; IMAGE_ADDRESS_PREFIX + o.getUrl()));
复制<br><br>List&lt;AdDO&gt; adDOList;
adDOList.stream().map(adDo -&gt; convertAdModel(adDo))
                .collect(Collectors.toList());
复制<br><br>List&lt;String&gt; phones=new ArrayList&lt;String&gt;();
        phones.add("a");
        phones.add("b");
        phones.add("a");
        phones.add("a");
        phones.add("c");
        phones.add("b");
        Map&lt;String, List&lt;String&gt;&gt; phoneClassify = phones.stream().collect(Collectors.groupingBy(item -&gt; item));
        System.out.println(phoneClassify);

返回结果: 
{a=[a, a, a], b=[b, b], c=[c]}
复制<br>static class Employee {
    private String name;
    private String deptName;
    private double salary;
    //....构造，getset，toString
}


public static void main(String[] args) throws IOException {
    List&lt;Employee&gt; list = new ArrayList&lt;&gt;();
    list.add(new Employee("可哈哈", "开发部", 16500));
    list.add(new Employee("张晓曦", "开发部", 5000));
    list.add(new Employee("是前锋", "财务部", 10000));
    list.add(new Employee("彭十六", "主播部", 150000));

    Map&lt;String, List&lt;Employee&gt;&gt; collect = list.stream().collect(Collectors.groupingBy(Employee::getDeptName));
    collect.forEach((s, employees) -&gt; {
        System.out.println(s + "--" + Arrays.toString(employees.toArray()));
    });

    Map&lt;String, Double&gt; collect2 = list.stream().collect(Collectors.groupingBy(Employee::getDeptName, Collectors.summingDouble(Employee::getSalary)));
    collect2.forEach((s, sum) -&gt; {
        System.out.println(s + "--" + sum);
    });
}

结果：
    主播部--[Employee{name='彭十六', deptName='主播部', salary=150000.0}]
    财务部--[Employee{name='是前锋', deptName='财务部', salary=10000.0}]
    开发部--[Employee{name='可哈哈', deptName='开发部', salary=16500.0}, Employee{name='张晓曦', deptName='开发部', salary=5000.0}]
    主播部--150000.0
    财务部--10000.0
    开发部--21500.0
复制<br><br>先按名字不分大小写排，再按GID倒序排，最后按年龄正序排<br>public static void main(String[] args) {
	List&lt;Person&gt; personList = getTestList();
	personList.sort(Comparator.comparing(Person::getName, String.CASE_INSENSITIVE_ORDER)
			.thenComparing(Person::getGid, (a, b) -&gt; b.compareTo(a))
			.thenComparingInt(Person::getAge));
	personList.stream().forEach(System.out::println);
}

public static List&lt;Person&gt; getTestList() {
	return Lists.newArrayList(new Person("dai", "301", 10), new Person("dai", "303", 10),
			new Person("dai", "303", 8), new Person("dai", "303", 6), new Person("dai", "303", 11),
			new Person("dai", "302", 9), new Person("zhang", "302", 9), new Person("zhang", "301", 9),
			new Person("Li", "301", 8));
}

// 输出结果
// Person [name=dai, gid=303, age=6]
// Person [name=dai, gid=303, age=8]
// Person [name=dai, gid=303, age=10]
// Person [name=dai, gid=303, age=11]
// Person [name=dai, gid=302, age=9]
// Person [name=dai, gid=301, age=10]
// Person [name=Li, gid=301, age=8]
// Person [name=zhang, gid=302, age=9]
// Person [name=zhang, gid=301, age=9]
复制<br><br>两个新的方法可在字符串类上使用: join和chars。第一个方法使用指定的分隔符，将任何数量的字符串连接为一个字符串。<br>String.join(":", "foobar", "foo", "bar");
// =&gt; foobar:foo:bar
复制<br>第二个方法chars从字符串所有字符创建数据流，所以你可以在这些字符上使用流式操作。<br>"foobar:foo:bar"
    .chars()
    .distinct()
    .mapToObj(c -&gt; String.valueOf((char)c))
    .sorted()
    .collect(Collectors.joining());
// =&gt; :abfor
复制<br><br>模式串也能受益于数据流。我们可以分割任何模式串，并创建数据流来处理它们，而不是将字符串分割为单个字符的数据流，像下面这样:<br>Pattern.compile(":")
    .splitAsStream("foobar:foo:bar")
    .filter(s -&gt; s.contains("bar"))
    .sorted()
    .collect(Collectors.joining(":"));
// =&gt; bar:foobar
复制<br>此外，正则模式串可以转换为谓词。这些谓词可以像下面那样用于过滤字符串流:<br>Pattern pattern = Pattern.compile(".*@gmail\\.com");
Stream.of("bob@gmail.com", "alice@hotmail.com")
    .filter(pattern.asPredicate())
    .count();
// =&gt; 1
复制<br>上面的模式串接受任何以@gmail.com结尾的字符串，并且之后用作Java8的Predicate来过滤电子邮件地址流。<br><br>public class TestLocalCache {

	private static ConcurrentHashMap&lt;Integer, Long&gt; cache = new ConcurrentHashMap&lt;&gt;();

	static long fibonacci(int i) {
		if (i == 0)
			return i;

		if (i == 1)
			return 1;

		return cache.computeIfAbsent(i, (key) -&gt; {
			System.out.println("Slow calculation of " + key);

			return fibonacci(i - 2) + fibonacci(i - 1);
		});
	}
	
	public static void main(String[] args) {
		// warm up
		for (int i = 0; i &lt; 101; i++)
	        System.out.println(
	            "f(" + i + ") = " + fibonacci(i));
		
		// read -&gt; cal
		long current = System.currentTimeMillis();
		System.out.println(fibonacci(100));
		System.out.println(System.currentTimeMillis()-current);
	}
}
复制<br><br>解决问题：调用一个方法得到了返回值却不能直接将返回值作为参数去调用别的方法。我们首先要判断这个返回值是否为null，只有在非空的前提下才能将其作为其他方法的参数。<br>Optional类的Javadoc描述如下:<br>
这是一个可以为null的容器对象。如果值存在则isPresent()方法会返回true，调用get()方法会返回该对象。
<br><br><br><br>
为非null的值创建一个Optional。
<br>of方法通过工厂方法创建Optional类。需要注意的是，创建对象时传入的参数不能为null。如果传入参数为null，则抛出NullPointerException 。<br><br>著作权归@pdai所有 原文链接：<a rel="noopener" class="external-link" href="https://pdai.tech/md/java/java8/java8-optional.html" target="_blank">https://pdai.tech/md/java/java8/java8-optional.html</a><br>//调用工厂方法创建Optional实例
Optional&lt;String&gt; name = Optional.of("Sanaulla");

//传入参数为null，抛出NullPointerException.
Optional&lt;String&gt; someNull = Optional.of(null);
复制<br><br>
为指定的值创建一个Optional，如果指定的值为null，则返回一个空的Optional。
<br>ofNullable与of方法相似，唯一的区别是可以接受参数为null的情况。示例如下:<br>//下面创建了一个不包含任何值的Optional实例
//例如，值为'null'
Optional empty = Optional.ofNullable(null);
复制<br><br><br>非常容易理解<br>
如果值存在返回true，否则返回false。
<br>类似下面的代码:<br>//isPresent方法用来检查Optional实例中是否包含值
if (name.isPresent()) {
  //在Optional实例内调用get()返回已存在的值
  System.out.println(name.get());//输出Sanaulla
}
复制<br><br>
如果Optional有值则将其返回，否则抛出NoSuchElementException。
<br>上面的示例中，get方法用来得到Optional实例中的值。下面我们看一个抛出NoSuchElementException的例子:<br>//执行下面的代码会输出: No value present 
try {
  //在空的Optional实例上调用get()，抛出NoSuchElementException
  System.out.println(empty.get());
} catch (NoSuchElementException ex) {
  System.out.println(ex.getMessage());
}
复制<br><br>
如果Optional实例有值则为其调用consumer，否则不做处理
<br>要理解ifPresent方法，首先需要了解Consumer类。简答地说，Consumer类包含一个抽象方法。该抽象方法对传入的值进行处理，但没有返回值。Java8支持不用接口直接通过lambda表达式传入参数。<br>如果Optional实例有值，调用ifPresent()可以接受接口段或lambda表达式。类似下面的代码:<br>//ifPresent方法接受lambda表达式作为参数。
//lambda表达式对Optional的值调用consumer进行处理。
name.ifPresent((value) -&gt; {
  System.out.println("The length of the value is: " + value.length());
});
复制<br><br><br>
如果有值则将其返回，否则返回指定的其它值。
<br>如果Optional实例有值则将其返回，否则返回orElse方法传入的参数。示例如下:<br>//如果值不为null，orElse方法返回Optional实例的值。
//如果为null，返回传入的消息。
//输出: There is no value present!
System.out.println(empty.orElse("There is no value present!"));
//输出: Sanaulla
System.out.println(name.orElse("There is some value!"));
复制<br><br>
orElseGet与orElse方法类似，区别在于得到的默认值。orElse方法将传入的字符串作为默认值，orElseGet方法可以接受Supplier接口的实现用来生成默认值。示例如下:
<br>//orElseGet与orElse方法类似，区别在于orElse传入的是默认值，
//orElseGet可以接受一个lambda表达式生成默认值。
//输出: Default Value
System.out.println(empty.orElseGet(() -&gt; "Default Value"));
//输出: Sanaulla
System.out.println(name.orElseGet(() -&gt; "Default Value"));
复制<br><br>
如果有值则将其返回，否则抛出supplier接口创建的异常。
<br>在orElseGet方法中，我们传入一个Supplier接口。然而，在orElseThrow中我们可以传入一个lambda表达式或方法，如果值不存在来抛出异常。示例如下:<br>try {
  //orElseThrow与orElse方法类似。与返回默认值不同，
  //orElseThrow会抛出lambda表达式或方法生成的异常 

  empty.orElseThrow(ValueAbsentException::new);
} catch (Throwable ex) {
  //输出: No value present in the Optional instance
  System.out.println(ex.getMessage());
}
复制<br>ValueAbsentException定义如下:<br>class ValueAbsentException extends Throwable {

  public ValueAbsentException() {
    super();
  }

  public ValueAbsentException(String msg) {
    super(msg);
  }

  @Override
  public String getMessage() {
    return "No value present in the Optional instance";
  }
}
复制<br><br><br>map方法文档说明如下:<br>
如果有值，则对其执行调用mapping函数得到返回值。如果返回值不为null，则创建包含mapping返回值的Optional作为map方法返回值，否则返回空Optional。
<br>map方法用来对Optional实例的值执行一系列操作。通过一组实现了Function接口的lambda表达式传入操作。如果你不熟悉Function接口，可以参考我的这篇博客。map方法示例如下:<br>//map方法执行传入的lambda表达式参数对Optional实例的值进行修改。
//为lambda表达式的返回值创建新的Optional实例作为map方法的返回值。
Optional&lt;String&gt; upperName = name.map((value) -&gt; value.toUpperCase());
System.out.println(upperName.orElse("No value found"));
复制<br><br>
如果有值，为其执行mapping函数返回Optional类型返回值，否则返回空Optional。flatMap与map(Funtion)方法类似，区别在于flatMap中的mapper返回值必须是Optional。调用结束时，flatMap不会对结果用Optional封装。
<br>flatMap方法与map方法类似，区别在于mapping函数的返回值不同。map方法的mapping函数返回值可以是任何类型T，而flatMap方法的mapping函数必须是Optional。<br>参照map函数，使用flatMap重写的示例如下:<br>//flatMap与map(Function)非常类似，区别在于传入方法的lambda表达式的返回类型。
//map方法中的lambda表达式返回值可以是任意类型，在map函数返回之前会包装为Optional。 
//但flatMap方法中的lambda表达式返回值必须是Optionl实例。 
upperName = name.flatMap((value) -&gt; Optional.of(value.toUpperCase()));
System.out.println(upperName.orElse("No value found"));//输出SANAULLA
复制<br><br>filter个方法通过传入限定条件对Optional实例的值进行过滤。文档描述如下:<br>
如果有值并且满足断言条件返回包含该值的Optional，否则返回空Optional。
<br>读到这里，可能你已经知道如何为filter方法传入一段代码。是的，这里可以传入一个lambda表达式。对于filter函数我们应该传入实现了Predicate接口的lambda表达式。如果你不熟悉Predicate接口，可以参考这篇文章。<br>现在我来看看filter的各种用法，下面的示例介绍了满足限定条件和不满足两种情况:<br>//filter方法检查给定的Option值是否满足某些条件。
//如果满足则返回同一个Option实例，否则返回空Optional。
Optional&lt;String&gt; longName = name.filter((value) -&gt; value.length() &gt; 6);
System.out.println(longName.orElse("The name is less than 6 characters"));//输出Sanaulla

//另一个例子是Optional值不满足filter指定的条件。
Optional&lt;String&gt; anotherName = Optional.of("Sana");
Optional&lt;String&gt; shortName = anotherName.filter((value) -&gt; value.length() &gt; 6);
//输出: name长度不足6字符
System.out.println(shortName.orElse("The name is less than 6 characters"));
复制<br><br><br>假设我们有一个像这样的类层次结构:<br>class Outer {
    Nested nested;
    Nested getNested() {
        return nested;
    }
}
class Nested {
    Inner inner;
    Inner getInner() {
        return inner;
    }
}
class Inner {
    String foo;
    String getFoo() {
        return foo;
    }
}
复制<br>解决这种结构的深层嵌套路径是有点麻烦的。我们必须编写一堆 null 检查来确保不会导致一个 NullPointerException:<br>Outer outer = new Outer();
if (outer != null &amp;&amp; outer.nested != null &amp;&amp; outer.nested.inner != null) {
    System.out.println(outer.nested.inner.foo);
}
复制<br>解决方法：<br>1、Optional 类型来摆脱所有这些 null 检查<br>map 方法接收一个 Function 类型的 lambda 表达式，并自动将每个 function 的结果包装成一个 Optional 对象。这使我们能够在一行中进行多个 map 操作。Null 检查是在底层自动处理的。<br>Optional.of(new Outer())
    .map(Outer::getNested)
    .map(Nested::getInner)
    .map(Inner::getFoo)
    .ifPresent(System.out::println);
复制<br>2、利用一个 supplier 函数来解决嵌套路径的问题<br>Outer obj = new Outer();
resolve(() -&gt; obj.getNested().getInner().getFoo())
    .ifPresent(System.out::println);
复制<br>调用 obj.getNested().getInner().getFoo()) 可能会抛出一个 NullPointerException 异常。在这种情况下，该异常将会被捕获，而该方法会返回 Optional.empty()。<br>public static &lt;T&gt; Optional&lt;T&gt; resolve(Supplier&lt;T&gt; resolver) {
    try {
        T result = resolver.get();
        return Optional.ofNullable(result);
    }
    catch (NullPointerException e) {
        return Optional.empty();
    }
}
复制<br>这两个解决方案可能没有传统 null 检查那么高的性能。不过在大多数情况下不会有太大问题。<br><br><br><br>之前的接口是个双刃剑，好处是面向抽象而不是面向具体编程，缺陷是，当需要修改接口时候，需要修改全部实现该接口的类。<br>比如：目前的java 8之前的集合框架没有foreach方法，通常能想到的解决办法是在JDK里给相关的接口添加新的方法及实现。然而，对于已经发布的版本，是没法在给接口添加新方法的同时不影响已有的实现。所以引进的默认方法。他们的目的是为了解决接口的修改与现有的实现不兼容的问题。<br><br>接口可以有实现方法，而且不需要实现类去实现其方法。只需在方法名前面加个default关键字。<br>样例：一个接口A，Clazz类实现了接口A。<br>public interface A {
    default void foo(){
       System.out.println("Calling A.foo()");
    }
}

public class Clazz implements A {
    public static void main(String[] args){
       Clazz clazz = new Clazz();
       clazz.foo();//调用A.foo()
    }
}
复制<br>代码是可以编译的，即使Clazz类并没有实现foo()方法。在接口A中提供了foo()方法的默认实现。<br><br>java 8的接口都有实现方法了，跟抽象类还有什么区别? 其实还是有的，请看下表对比。<br><br><br>由于同一个方法可以从不同接口引入，自然而然的会有冲突的现象，默认方法判断冲突的规则如下:<br>1.一个声明在类里面的方法优先于任何默认方法<br>2.否则，则会优先选取路径最短的。<br><br>
<br>Case 1
<br>public interface A{
	default void aa() {
		System.out.println("A's aa");
	}
}
public interface B{
	default void aa() {
		System.out.println("B's aa");
	}
}
public static class D implements A,B{
	
}
复制<br>报错 Duplicate default methods named aa with the parameters () and () are inherited from the types DocApplication.B and DocApplication.A<br>如果一定要这么写呢，同时实现A,B并且使用A中aa? 可以这么写:<br>public static class D implements A,B{
    @Override
    public void aa(){
        A.super.aa();
    }
}
复制<br>
<br>Case 2
<br>public interface A{
	default void aa() {
		System.out.println("A's aa");
	}
}
public interface B{
	default void aa() {
		System.out.println("B's aa");
	}
}
public interface C extends A, B{
	default void aa() {
		System.out.println("C's aa");
	}
}
public static class D implements A,B,C{
	
}
复制<br>输出 C's aa<br>
<br>Case 3
<br>public interface A{
	default void aa() {
		System.out.println("A's aa");
	}
}
public interface C extends A{
	default void aa() {
		System.out.println("C's aa");
	}
}
public static class D implements C{
	
}
复制<br>输出 C's aa<br>
通过Case1-3可以知道它是找唯一的最短路径的default，如果是多个那么报错。
<br>
<br>Case 4 如果想调用A的默认函数，则用到新语法X.super.m(…),下面修改C类，实现A接口，重写一个hello方法，如下所示:
<br>public interface A{
	default void aa() {
		System.out.println("A's aa");
	}
}
public class X implements A{
    @Override
    public void aa(){
        A.super.aa();
    }
}
复制<br>输出: A's aa<br>
<br>Case 5
<br>public interface A{
	default void aa() {
		System.out.println("A's aa");
	}
}
public interface B{
	default void aa() {
		System.out.println("B's aa");
	}
}
public interface C extends A,B{
	default void aa() {
		System.out.println("C's aa");
	}
}
public static class D implements C{
	@Override
    public void aa(){
        C.super.aa();
    }
}
复制<br>输出 C's aa 可见C.super表示的是C接口，同时D无法访问A,B的aa<br>
通过Case 5也可以看出，C虽然有同一个两个最短路径的aa, 但是它自己有一个更高优先级的aa，所以不会报错; case 6 会报错
<br>
<br>Case 6
<br>public interface A{
	default void aa() {
		System.out.println("A's aa");
	}
}
public interface B{
	default void aa() {
		System.out.println("B's aa");
	}
}
public interface C extends A,B{
}
复制<br><br><br>之前，注解只能是在声明的地方所使用，比如类，方法，属性；<br>java 8里面，注解可以应用在任何地方，比如:<br>创建类实例<br>new @Interned MyObject();
复制<br>类型映射<br>myString = (@NonNull String) str;
复制<br>implements 语句中<br>class UnmodifiableList&lt;T&gt; implements @Readonly List&lt;@Readonly T&gt; { … }
复制<br>throw exception声明<br>void monitorTemperature() throws @Critical TemperatureException { … }
复制<br>需要注意的是，类型注解只是语法而不是语义，并不会影响java的编译时间，加载时间，以及运行时间，也就是说，编译成class文件的时候并不包含类型注解。<br><br>类型注解被用来支持在Java的程序中做强类型检查。配合插件式的check framework，可以在编译的时候检测出runtime error，以提高代码质量。<br>//下面的代码编译是通过的，但运行会报异常，runtime error
Collections.emptyList().add("One");//UnsupportedOperationException
int i=Integer.parseInt("hello");//NumberFormatException
System.console().readLine();//NullPointerException异常
复制<br>check framework是第三方工具，配合Java的类型注解效果就是1+1&gt;2。它可以嵌入到javac编译器里面，可以配合ant和maven使用, 地址是<a data-tooltip-position="top" aria-label="http://types.cs.washington.edu/checker-framework/%E3%80%82" rel="noopener" class="external-link" href="http://types.cs.washington.edu/checker-framework/%E3%80%82" target="_blank">http://types.cs.washington.edu/checker-framework/。</a> <br>check framework可以找到类型注解出现的地方并检查，举个简单的例子:<br>import checkers.nullness.quals.*;
public class GetStarted {
    void sample() {
        @NonNull Object ref = new Object();
    }
}
复制<br>使用javac编译上面的类<br>javac -processor checkers.nullness.NullnessChecker GetStarted.java
复制<br>编译是通过，但如果修改成<br>@NonNull Object ref = null;
复制<br>再次编译，则出现<br>GetStarted.java:5: incompatible types.
found   : @Nullable &lt;nulltype&gt;
required: @NonNull Object
        @NonNull Object ref = null;
                              ^
1 error
复制<br><br>如果你不想使用类型注解检测出来错误，则不需要processor，直接javac GetStarted.java是可以编译通过的，这是在java 8 with Type Annotation Support版本里面可以，但java 5,6,7版本都不行，因为javac编译器不知道@NonNull是什么东西，但check framework 有个向下兼容的解决方案，就是将类型注解nonnull用//注释起来**，比如上面例子修改为<br>import checkers.nullness.quals.*;
public class GetStarted {
    void sample() {
        /*@NonNull*/ Object ref = null;
    }
}
复制<br>这样javac编译器就会忽略掉注释块，但用check framework里面的javac编译器同样能够检测出nonnull错误。 通过类型注解+check framework我们可以看到，现在runtime error可以在编译时候就能找到。<br><br>JSR 308想要解决在Java 1.5注解中出现的两个问题:<br>
<br>在句法上对注解的限制: 只能把注解写在声明的地方
<br>类型系统在语义上的限制: 类型系统还做不到预防所有的bug
<br>JSR 308 通过如下方法解决上述两个问题:<br>
<br>对Java语言的句法进行扩充，允许注解出现在更多的位置上。包括: 方法接收器(method receivers，译注: 例public int size() @Readonly { … })，泛型参数，数组，类型转换，类型测试，对象创建，类型参数绑定，类继承和throws子句。其实就是类型注解，现在是java 8的一个特性
<br>通过引入可插拔的类型系统(pluggable type systems)能够创建功能更强大的注解处理器。类型检查器对带有类型限定注解的源码进行分析，一旦发现不匹配等错误之处就会产生警告信息。其实就是check framework
<br>对JSR308，有人反对，觉得更复杂更静态了，比如<br>@NotEmpty List&lt;@NonNull String&gt; strings = new ArrayList&lt;@NonNull String&gt;()&gt;
复制<br>换成动态语言为<br>var strings = ["one", "two"];
复制<br>有人赞成，说到底，代码才是“最根本”的文档。代码中包含的注解清楚表明了代码编写者的意图。当没有及时更新或者有遗漏的时候，恰恰是注解中包含的意图信息，最容易在其他文档中被丢失。而且将运行时的错误转到编译阶段，不但可以加速开发进程，还可以节省测试时检查bug的时间。<br>并不是人人都喜欢这个特性，特别是动态语言比较流行的今天，所幸，java 8并不强求大家使用这个特性，反对的人可以不使用这一特性，而对代码质量有些要求比较高的人或公司可以采用JSR 308，毕竟代码才是“最基本”的文档，这句话我是赞同的。虽然代码会增多，但可以使你的代码更具有表达意义。对这个特性有何看法，大家各抒己见。<br><br>允许在同一申明类型(类，属性，或方法)的多次使用同一个注解<br><br>之前也有重复使用注解的解决方案，但可读性不是很好，比如下面的代码:<br>public @interface Authority {
     String role();
}

public @interface Authorities {
    Authority[] value();
}

public class RepeatAnnotationUseOldVersion {

    @Authorities({@Authority(role="Admin"),@Authority(role="Manager")})
    public void doSomeThing(){
    }
}
复制<br>由另一个注解来存储重复注解，在使用时候，用存储注解Authorities来扩展重复注解。<br><br>我们再来看看java 8里面的做法:<br>@Repeatable(Authorities.class)
public @interface Authority {
     String role();
}

public @interface Authorities {
    Authority[] value();
}

public class RepeatAnnotationUseNewVersion {
    @Authority(role="Admin")
    @Authority(role="Manager")
    public void doSomeThing(){ }
}
复制<br>不同的地方是，创建重复注解Authority时，加上@Repeatable,指向存储注解Authorities，在使用时候，直接可以重复使用Authority注解。从上面例子看出，java 8里面做法更适合常规的思维，可读性强一点。<br>JEP120没有太多内容，是一个小特性，仅仅是为了提高代码可读性。这次java 8对注解做了2个方面的改进(JEP 104,JEP120)，相信注解会比以前使用得更加频繁了。<br><br>泛型是Java SE 1.5的新特性，泛型的本质是参数化类型，也就是说所操作的数据类型被指定为一个参数。通俗点将就是“类型的变量”。这种类型变量可以用在类、接口和方法的创建中。<br>理解Java泛型最简单的方法是把它看成一种便捷语法，能节省你某些Java类型转换(casting)上的操作:<br>List&lt;Apple&gt; box = new ArrayList&lt;Apple&gt;();
box.add(new Apple());
//box是一个装有Apple对象的List。get方法返回一个Apple对象实例，这个过程不需要进行类型转换。
Apple apple =box.get(0);

//没有泛型，上面的代码需要写成这样:
Apple apple = (Apple)box.get(0);
复制<br><br>泛型的最大优点是提供了程序的类型安全同时可以向后兼容，但也有尴尬的地方，就是每次定义时都要写明泛型的类型，这样显示指定不仅感觉有些冗长，最主要是很多程序员不熟悉泛型，因此很多时候不能够给出正确的类型参数，现在通过编译器自动推断泛型的参数类型，能够减少这样的情况，并提高代码可读性。<br><br>在以前的版本中使用泛型类型，需要在声明并赋值的时候，两侧都加上泛型类型。例如:<br>Map&lt;String, String&gt; myMap = new HashMap&lt;String, String&gt;();
复制<br>你可能觉得:老子在声明变量的的时候已经指明了参数类型，为毛还要在初始化对象时再指定? 幸好，在Java SE 7中，这种方式得以改进，现在你可以使用如下语句进行声明并赋值:<br>Map&lt;String, String&gt; myMap = new HashMap&lt;&gt;(); //注意后面的"&lt;&gt;"
复制<br>在这条语句中，编译器会根据变量声明时的泛型类型自动推断出实例化HashMap时的泛型类型。再次提醒一定要注意new HashMap后面的“&lt;&gt;”，只有加上这个“&lt;&gt;”才表示是自动类型推断，否则就是非泛型类型的HashMap，并且在使用编译器编译源代码时会给出一个警告提示。<br>但是: Java SE 7在创建泛型实例时的类型推断是有限制的: 只有构造器的参数化类型在上下文中被显著的声明了，才可以使用类型推断，否则不行。例如: 下面的例子在java 7无法正确编译(但现在在java8里面可以编译，因为根据方法参数来自动推断泛型的类型):<br>List&lt;String&gt; list = new ArrayList&lt;&gt;();
list.add("A");// 由于addAll期望获得Collection&lt;? extends String&gt;类型的参数，因此下面的语句无法通过
list.addAll(new ArrayList&lt;&gt;());
复制<br><br>java8里面泛型的目标类型推断主要2个:<br>1.支持通过方法上下文推断泛型目标类型<br>2.支持在方法调用链路当中，泛型类型推断传递到最后一个方法<br>让我们看看官网的例子<br>class List&lt;E&gt; {
   static &lt;Z&gt; List&lt;Z&gt; nil() { ... };
   static &lt;Z&gt; List&lt;Z&gt; cons(Z head, List&lt;Z&gt; tail) { ... };
   E head() { ... }
}
复制<br>根据JEP101的特性，我们在调用上面方法的时候可以这样写<br>//通过方法赋值的目标参数来自动推断泛型的类型
List&lt;String&gt; l = List.nil();
//而不是显示的指定类型
//List&lt;String&gt; l = List.&lt;String&gt;nil();
//通过前面方法参数类型推断泛型的类型
List.cons(42, List.nil());
//而不是显示的指定类型
//List.cons(42, List.&lt;Integer&gt;nil());
复制<br>以上是JEP101的特性内容了，Java作为静态语言的代表者，可以说类型系统相当丰富。导致类型间互相转换的问题困扰着每个java程序员，通过编译器自动推断类型的东西可以稍微缓解一下类型转换太复杂的问题。<br><br><br>
<br>更小的Java环境需要更少的计算资源。
<br>一个较小的运行时环境可以更好的优化性能和启动时间。
<br>消除未使用的代码从安全的角度总是好的。
<br>这些打包的应用程序可以下载速度更快。
<br><br>紧凑的JRE分3种，分别是compact1、compact2、compact3。<br>关系是compact1 &lt; compact2 &lt; compact3<br>占用的空间：<br><img style="zoom:50%;" alt="img" src="\.pic-Java8新特性\java8-jre-3.png" referrerpolicy="no-referrer"><br>使用javac根据profile编译应用程序<br>javac –bootclasspath, or javac –profile
复制<br>如果不符合compact的api，则报错。<br>$ javac -profile compact2 Test.java
Test.java:7: error: ThreadMXBean is not available in profile 'compact2'
 ThreadMXBean bean = ManagementFactory.getThreadMXBean();
 ^
Test.java:7: error: ManagementFactory is not available in profile 'compact2'
 ThreadMXBean bean = ManagementFactory.getThreadMXBean();
                     ^
2 errors
复制<br>三种的API如下：<br>“./.pic-Java8新特性/java8-jre-1.png” could not be found.<br><br><br>java8新增一个工具，用来分析应用程序所依赖的profile，有三个参数比较常用 -p，-v，-r<br>import java.util.Set;
import java.util.HashSet;

public class Deps {
  public static void main(String[] args) {
    System.out.println(Math.random());
    Set&lt;String&gt; set = new HashSet&lt;&gt;();
  }
}
************** PROFILE ********************
jdeps -P Deps.class 
Deps.class -&gt; /Library/Java/JavaVirtualMachines/jdk1.8.0.jdk/Contents/Home/jre/lib/rt.jar
   &lt;unnamed&gt; (Deps.class)
      -&gt; java.io                                            compact1
      -&gt; java.lang                                          compact1
      -&gt; java.util                                          compact1

************** VERBOSE ********************
jdeps -v Deps.class 
Deps.class -&gt; /Library/Java/JavaVirtualMachines/jdk1.8.0.jdk/Contents/Home/jre/lib/rt.jar
   Deps (Deps.class)
      -&gt; java.io.PrintStream                                
      -&gt; java.lang.Math                                     
      -&gt; java.lang.Object                                   
      -&gt; java.lang.String                                   
      -&gt; java.lang.System                                   
      -&gt; java.util.HashSet  

************** RECURSIVE ********************
jdeps -R Deps.class 
Deps.class -&gt; /Library/Java/JavaVirtualMachines/jdk1.8.0.jdk/Contents/Home/jre/lib/rt.jar
   &lt;unnamed&gt; (Deps.class)
      -&gt; java.io                                            
      -&gt; java.lang                                          
      -&gt; java.util                                          
/Library/Java/JavaVirtualMachines/jdk1.8.0.jdk/Contents/Home/jre/lib/jce.jar -&gt; /Library/Java/JavaVirtualMachines/jdk1.8.0.jdk/Contents/Home/jre/lib/rt.jar
   javax.crypto (jce.jar)
      -&gt; java.io                                            
      -&gt; java.lang                                          
      -&gt; java.lang.reflect                                  
      -&gt; java.net                                           
      -&gt; java.nio                                           
      -&gt; java.security                                      
      -&gt; java.security.cert                                 
      -&gt; java.security.spec                                 
      -&gt; java.util                                          
      -&gt; java.util.concurrent                               
      -&gt; java.util.jar                                      
      -&gt; java.util.regex                                    
      -&gt; java.util.zip                                      
      -&gt; javax.security.auth                                
      -&gt; sun.security.jca                                   JDK internal API (rt.jar)
      -&gt; sun.security.util                                  JDK internal API (rt.jar)
      -&gt; sun.security.validator                             JDK internal API (rt.jar)
   javax.crypto.interfaces (jce.jar)
      -&gt; java.lang                                          
      -&gt; java.math                                          
      -&gt; java.security                                      
   javax.crypto.spec (jce.jar)
      -&gt; java.lang                                          
      -&gt; java.math                                          
      -&gt; java.security.spec                                 
      -&gt; java.util                                          
/Library/Java/JavaVirtualMachines/jdk1.8.0.jdk/Contents/Home/jre/lib/rt.jar -&gt; /Library/Java/JavaVirtualMachines/jdk1.8.0.jdk/Contents/Home/jre/lib/jce.jar
   java.security (rt.jar)
      -&gt; javax.crypto                                       JDK internal API (jce.jar)
   sun.security.util (rt.jar)
      -&gt; javax.crypto                                       JDK internal API (jce.jar)
      -&gt; javax.crypto.interfaces                            JDK internal API (jce.jar)
      -&gt; javax.crypto.spec                                  JDK internal API (jce.jar)
复制<br><br>$ hg clone http://hg.openjdk.java.net/jdk8/jdk8/
$ cd jdk8
$ make images profiles : 
# Finished profiles (build time 00:00:27)
----- Build times -------
Start 2013-03-17 14:47:35
End 2013-03-17 14:58:26
00:00:25 corba
00:00:15 demos
00:01:50 hotspot
00:00:24 images
00:00:21 jaxp
00:00:31 jaxws
00:05:37 jdk
00:00:43 langtools
00:00:18 nashorn
00:00:27 profiles
00:10:51 TOTAL
-------------------------
Finished building Java(TM) for target 'images profiles'
$ cd images
$ ls -d *image
j2re-compact1-image j2re-compact2-image j2re-compact3-image j2re-image j2sdk-image
复制<br><br>“java.lang.OutOfMemoryError: PermGen space”这一问题。<br>这往往是由类加载器相关的内存泄漏以及新类加载器的创建导致的，通常出现于代码热部署时。<br>相对于正式产品，该问题在开发机上出现的频率更高，在产品中最常见的“问题”是默认值太低了。常用的解决方法是将其设置为256MB或更高。<br><br>PermGen space的全称是Permanent Generation space,是指内存的永久保存区域。如果你的APP会LOAD很多CLASS的话,就很可能出现PermGen space错误。这种错误常见在web服务器对JSP进行pre compile的时候。<br>JVM 种类有很多，比如 Oralce-Sun Hotspot, Oralce JRockit, IBM J9, Taobao JVM 等等。当然武林盟主是Hotspot了，这个毫无争议。<br>需要注意的是，PermGen space 是 Oracle-Sun Hotspot 才有，JRockit以及J9是没有这个区域。<br><br>元空间<br>虽然不会再有java.lang.OutOfMemoryError: PermGen问题，但仍然要关注类元数据内存的占用，这个新特性也不能消除类和类加载器导致的内存泄漏。<br>java8 中 Metaspace 总结如下:<br>○ PermGen 空间的状况<br>这部分内存空间将全部移除。JVM的参数: PermSize 和 MaxPermSize 会被忽略并给出警告(如果在启用时设置了这两个参数)。<br>○ Metaspace 内存分配模型<br>大部分类元数据都在本地内存中分配。用于描述类元数据的“klasses”已经被移除。<br>○ Metaspace 容量<br>默认情况下，类元数据只受可用的本地内存限制(容量取决于是32位或是64位操作系统的可用虚拟内存大小)。<br>新参数(MaxMetaspaceSize)用于限制本地内存分配给类元数据的大小。如果没有指定这个参数，元空间会在运行时根据需要动态调整。<br>○ Metaspace 垃圾回收<br>对于僵死的类及类加载器的垃圾回收将在元数据使用达到“MaxMetaspaceSize”参数的设定值时进行。<br>适时地监控和调整元空间对于减小垃圾回收频率和减少延时是很有必要的。持续的元空间垃圾回收说明，可能存在类、类加载器导致的内存泄漏或是大小设置不合适。<br>○ Java 堆内存的影响<br>一些杂项数据已经移到Java堆空间中。升级到JDK8之后，会发现Java堆 空间有所增长。<br>○ Metaspace 监控<br>元空间的使用情况可以从HotSpot1.8的详细GC日志输出中得到。<br>Jstat 和 JVisualVM两个工具，在使用b75版本进行测试时，已经更新了，但是还是能看到老的PermGen空间的出现。<br><br>为了更好地理解Metaspace内存空间的运行时行为，<br>将进行以下几种场景的测试:<br>
<br>使用JDK1.7运行Java程序，监控并耗尽默认设定的85MB大小的PermGen内存空间。
<br>使用JDK1.8运行Java程序，监控新Metaspace内存空间的动态增长和垃圾回收过程。
<br>使用JDK1.8运行Java程序，模拟耗尽通过“MaxMetaspaceSize”参数设定的128MB大小的Metaspace内存空间。
<br>首先建立了一个模拟PermGen OOM的代码<br>public class ClassA {
 public void method(String name) {
  // do nothing
 }
}
复制<br>上面是一个简单的ClassA，把他编译成class字节码放到D: /classes下面，测试代码中用URLClassLoader来加载此类型上面类编译成class<br>/**
 * 模拟PermGen OOM
 * @author benhail
 */
public class OOMTest {
    public static void main(String[] args) {
        try {
            //准备url
            URL url = new File("D:/classes").toURI().toURL();
            URL[] urls = {url};
            //获取有关类型加载的JMX接口
            ClassLoadingMXBean loadingBean = ManagementFactory.getClassLoadingMXBean();
            //用于缓存类加载器
            List&lt;ClassLoader&gt; classLoaders = new ArrayList&lt;ClassLoader&gt;();
            while (true) {
                //加载类型并缓存类加载器实例
                ClassLoader classLoader = new URLClassLoader(urls);
                classLoaders.add(classLoader);
                classLoader.loadClass("ClassA");
                //显示数量信息(共加载过的类型数目，当前还有效的类型数目，已经被卸载的类型数目)
                System.out.println("total: " + loadingBean.getTotalLoadedClassCount());
                System.out.println("active: " + loadingBean.getLoadedClassCount());
                System.out.println("unloaded: " + loadingBean.getUnloadedClassCount());
            }
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}
复制<br>虚拟机器参数设置如下: -verbose -verbose:gc<br>设置-verbose参数是为了获取类型加载和卸载的信息<br>设置-verbose:gc是为了获取垃圾收集的相关信息<br><br>Java1.7的PermGen默认空间为85 MB(或者可以通过-XX:MaxPermSize=XXXm指定)<br>“./.pic-Java8新特性/java8-jvm-2-1684584360118-12.jpg” could not be found.<br>可以从上面的JVisualVM的截图看出: 当加载超过6万个类之后，PermGen被耗尽。我们也能通过程序和GC的输出观察耗尽的过程。<br>程序输出(摘取了部分)<br>......
[Loaded ClassA from file:/D:/classes/]
total: 64887
active: 64887
unloaded: 0
[GC 245041K-&gt;213978K(536768K), 0.0597188 secs]
[Full GC 213978K-&gt;211425K(644992K), 0.6456638 secs]
[GC 211425K-&gt;211425K(656448K), 0.0086696 secs]
[Full GC 211425K-&gt;211411K(731008K), 0.6924754 secs]
[GC 211411K-&gt;211411K(726528K), 0.0088992 secs]
...............
java.lang.OutOfMemoryError: PermGen space
复制<br><br>Java的Metaspace空间: 不受限制 (默认)<br>“./.pic-Java8新特性/java8-jvm-3-1684584402197-18.png” could not be found.<br>从上面的截图可以看到，JVM Metaspace进行了动态扩展，本地内存的使用由20MB增长到646MB，以满足程序中不断增长的类数据内存占用需求。我们也能观察到JVM的垃圾回收事件—试图销毁僵死的类或类加载器对象。但是，由于我们程序的泄漏，JVM别无选择只能动态扩展Metaspace内存空间。程序加载超过10万个类，而没有出现OOM事件。<br><br>Java的Metaspace空间: 128MB(-XX:MaxMetaspaceSize=128m)<br>“./.pic-Java8新特性/java8-jvm-4-1684584413419-21.png” could not be found.<br>可以从上面的JVisualVM的截图看出: 当加载超过2万个类之后，Metaspace被耗尽；与JDK1.7运行时非常相似。我们也能通过程序和GC的输出观察耗尽的过程。另一个有趣的现象是，保留的原生内存占用量是设定的最大大小两倍之多。这可能表明，如果可能的话，可微调元空间容量大小策略，来避免本地内存的浪费。<br>从Java程序的输出中看到如下异常。<br>[Loaded ClassA from file:/D:/classes/]
total: 21393
active: 21393
unloaded: 0
[GC (Metadata GC Threshold) 64306K-&gt;57010K(111616K), 0.0145502 secs]
[Full GC (Metadata GC Threshold) 57010K-&gt;56810K(122368K), 0.1068084 secs]
java.lang.OutOfMemoryError: Metaspace
复制<br>在设置了MaxMetaspaceSize的情况下，该空间的内存仍然会耗尽，进而引发“java.lang.OutOfMemoryError: Metadata space”错误。因为类加载器的泄漏仍然存在，而通常Java又不希望无限制地消耗本机内存，因此设置一个类似于MaxPermSize的限制看起来也是合理的。<br><br>
<br>之前不管是不是需要，JVM都会吃掉那块空间……如果设置得太小，JVM会死掉；如果设置得太大，这块内存就被JVM浪费了。理论上说，现在你完全可以不关注这个，因为JVM会在运行时自动调校为“合适的大小”；
<br>提高Full GC的性能，在Full GC期间，Metadata到Metadata pointers之间不需要扫描了，别小看这几纳秒时间；
<br>隐患就是如果程序存在内存泄露，像OOMTest那样，不停的扩展metaspace的空间，会导致机器的内存不足，所以还是要有必要的调试和监控。
<br><br><br><br>java5 之前，实现同步主要是使用synchronized。是Java语言的关键字，当它用来修饰一个方法或者一个代码块的时候，能够保证在同一时刻最多只有一个线程执行该段代码。<br>在多线程并发编程中Synchronized一直是元老级角色，会称呼它为重量级锁，但是随着Java SE1.6对Synchronized进行了各种优化之后，性能上也有所提升。<br>synchronized(this)
// do operation
}
复制<br>主要分四种：<br>
<br>实例方法
<br>静态方法
<br>实例方法中的同步块
<br>静态方法中的同步块
<br><br>Java 5 在java.util.concurrent.locks新增的一个API。<br>//Lock是一个接口，核心方法是lock()，unlock()，tryLock()。

//实现类有ReentrantLock, ReentrantReadWriteLock.ReadLock, ReentrantReadWriteLock.WriteLock；

//因为lock是通过代码实现的，要保证锁定一定会被释放，就必须将unLock()放到finally{}中,如下：

rwlock.writeLock().lock();
try {
	// do operation
} finally {
	rwlock.writeLock().unlock();
}


复制<br>ReentrantReadWriteLock、ReentrantLock 和 synchronized 锁都有相同的内存语义。与synchronized不同的是，Lock完全用Java写成，在java这个层面是无关JVM实现的。<br>Lock提供更灵活的锁机制，很多synchronized 没有提供的许多特性，比如锁投票，定时锁等候和中断锁等候。<br>代码实例 todo<br>小结: 比synchronized更灵活、更具可伸缩性的锁定机制，但不管怎么说还是synchronized代码要更容易书写些<br><br>它是java8在java.util.concurrent.locks新增的一个API。<br>ReentrantReadWriteLock 在沒有任何读写锁时，才可以取得写入锁，这可用于实现了悲观读取(Pessimistic Reading)，即如果执行中进行读取时，经常可能有另一执行要写入的需求，为了保持同步，ReentrantReadWriteLock 的读取锁定就可派上用场。<br>然而，如果读取执行情况很多，写入很少的情况下，使用 ReentrantReadWriteLock 可能会使写入线程遭遇饥饿(Starvation)问题，也就是写入线程迟迟无法竞争到锁定而一直处于等待状态。<br>StampedLock控制锁有三种模式(写，读，乐观读)，一个StampedLock状态是由版本和模式两个部分组成，锁获取方法返回一个数字作为票据stamp，它用相应的锁状态表示并控制访问，数字0表示没有写锁被授权访问。在读锁上分为悲观锁和乐观锁。<br>所谓的乐观读模式，也就是若读的操作很多，写的操作很少的情况下，你可以乐观地认为，写入与读取同时发生几率很少，因此不悲观地使用完全的读取锁定，程序可以查看读取资料之后，是否遭到写入执行的变更，再采取后续的措施(重新读取变更信息，或者抛出异常) ，这一个小小改进，可大幅度提高程序的吞吐量！！<br>下面是java doc提供的StampedLock一个例子<br>class Point {
   private double x, y;
   private final StampedLock sl = new StampedLock();
   void move(double deltaX, double deltaY) { // an exclusively locked method
     long stamp = sl.writeLock();
     try {
       x += deltaX;
       y += deltaY;
     } finally {
       sl.unlockWrite(stamp);
     }
   }
  //下面看看乐观读锁案例
   double distanceFromOrigin() { // A read-only method
     long stamp = sl.tryOptimisticRead(); //获得一个乐观读锁
     double currentX = x, currentY = y; //将两个字段读入本地局部变量
     if (!sl.validate(stamp)) { //检查发出乐观读锁后同时是否有其他写锁发生? 
        stamp = sl.readLock(); //如果没有，我们再次获得一个读悲观锁
        try {
          currentX = x; // 将两个字段读入本地局部变量
          currentY = y; // 将两个字段读入本地局部变量
        } finally {
           sl.unlockRead(stamp);
        }
     }
     return Math.sqrt(currentX * currentX + currentY * currentY);
   }
	//下面是悲观读锁案例
   void moveIfAtOrigin(double newX, double newY) { // upgrade
     // Could instead start with optimistic, not read mode
     long stamp = sl.readLock();
     try {
       while (x == 0.0 &amp;&amp; y == 0.0) { //循环，检查当前状态是否符合
         long ws = sl.tryConvertToWriteLock(stamp); //将读锁转为写锁
         if (ws != 0L) { //这是确认转为写锁是否成功
           stamp = ws; //如果成功 替换票据
           x = newX; //进行状态改变
           y = newY; //进行状态改变
           break;
         }
         else { //如果不能成功转换为写锁
           sl.unlockRead(stamp); //我们显式释放读锁
           stamp = sl.writeLock(); //显式直接进行写锁 然后再通过循环再试
         }
       }
     } finally {
       sl.unlock(stamp); //释放读锁或写锁
     }
   }
 }
复制<br>小结:<br>StampedLock要比ReentrantReadWriteLock更加廉价，也就是消耗比较小。<br><br>是和ReadWritLock相比，在一个线程情况下，是读速度其4倍左右，写是1倍。<br>下图是六个线程情况下，读性能是其几十倍，写性能也是近10倍左右:<br>“./.pic-Java8新特性/java-stampedlock-1-1684566817469-5.png” could not be found.<br><br>
<br>synchronized是在JVM层面上实现的，不但可以通过一些监控工具监控synchronized的锁定，而且在代码执行时出现异常，JVM会自动释放锁定；
<br>ReentrantLock、ReentrantReadWriteLock,、StampedLock都是对象层面的锁定，要保证锁定一定会被释放，就必须将unLock()放到finally{}中；
<br>StampedLock 对吞吐量有巨大的改进，特别是在读线程越来越多的场景下；
<br>StampedLock有一个复杂的API，对于加锁操作，很容易误用其他方法;
<br>当只有少量竞争者的时候，synchronized是一个很好的通用的锁实现;
<br>当线程增长能够预估，ReentrantLock是一个很好的通用的锁实现;
<br>StampedLock 可以说是Lock的一个很好的补充，吞吐量以及性能上的提升足以打动很多人了，但并不是说要替代之前Lock的东西，毕竟他还是有些应用场景的，起码API比StampedLock容易入手。<br><br><br>
Tiago Fernandez做过一次投票，选举最烂的JAVA API，排第一的EJB2.X，第二的就是日期API。
<br><br>最开始的时候，Date既要承载日期信息，又要做日期之间的转换，还要做不同日期格式的显示，职责较繁杂(不懂单一职责，你妈妈知道吗? 纯属恶搞~哈哈)<br>后来从JDK 1.1 开始，这三项职责分开了:<br>使用Calendar类实现日期和时间字段之间转换；
使用DateFormat类来格式化和分析日期字符串；
而Date只用来承载日期和时间信息。
复制<br>原有Date中的相应方法已废弃。不过，无论是Date，还是Calendar，都用着太不方便了，这是API没有设计好的地方。<br><br>坑爹的year和month<br>Date date = new Date(2012,1,1);
System.out.println(date);
输出Thu Feb 01 00:00:00 CST 3912
复制<br>观察输出结果，year是2012+1900，而month，月份参数我不是给了1吗? 怎么输出二月(Feb)了?<br>应该曾有人告诉你，如果你要设置日期，应该使用 java.util.Calendar，像这样…<br>Calendar calendar = Calendar.getInstance();
calendar.set(2013, 8, 2);
复制<br>这样写又不对了，calendar的month也是从0开始的，表达8月份应该用7这个数字，要么就干脆用枚举<br>calendar.set(2013, Calendar.AUGUST, 2);
复制<br>注意上面的代码，Calendar年份的传值不需要减去1900(当然月份的定义和Date还是一样)，这种不一致真是让人抓狂！<br>有些人可能知道，Calendar相关的API是IBM捐出去的，所以才导致不一致。<br><br>java.util.Date与java.util.Calendar中的所有属性都是可变的<br>下面的代码，计算两个日期之间的天数….<br>public static void main(String[] args) {
    Calendar birth = Calendar.getInstance();
    birth.set(1975, Calendar.MAY, 26);
    Calendar now = Calendar.getInstance();
    System.out.println(daysBetween(birth, now));
    System.out.println(daysBetween(birth, now)); // 显示 0? 
 }  

public static long daysBetween(Calendar begin, Calendar end) {
    long daysBetween = 0;
    while(begin.before(end)) {
        begin.add(Calendar.DAY_OF_MONTH, 1);
        daysBetween++;
    }
    return daysBetween;
}
复制<br>daysBetween有点问题，如果连续计算两个Date实例的话，第二次会取得0，因为Calendar状态是可变的，考虑到重复计算的场合，最好复制一个新的Calendar<br>public static long daysBetween(Calendar begin, Calendar end) {
    Calendar calendar = (Calendar) begin.clone(); // 复制
    long daysBetween = 0;
    while(calendar.before(end)) {
        calendar.add(Calendar.DAY_OF_MONTH, 1);
        daysBetween++;
    }
    return daysBetween;
}
复制<br><br>SimpleDateTimeFormat是非线程安全的。<br><br>Date formats are not synchronized.
It is recommended to create separate format instances for each thread.
If multiple threads access a format concurrently, it must be synchronized
externally.

日期格式不同步。
建议为每个线程创建单独的格式实例。 
如果多个线程同时访问一种格式，则必须在外部同步该格式。
复制<br>使用单例的 SimpleDateFormat 类在多线程的环境中处理日期转换，极易出现转换异常（java.lang.NumberFormatException:multiple points）以及转换错误的情况。<br><img style="zoom:25%;" alt="img" src="\.pic-Java8新特性\fee169e775556d86ec395a496deb4b32.png" referrerpolicy="no-referrer"><br><br>重点在 calendar ，方法在执行过程中，会操作成员变量 calendar 来保存时间 calendar.setTime(date) 。<br>除了 format() 方法以外，SimpleDateFormat 的 parse 方法也有同样的问题。<br>假设线程 A 刚执行完 calendar.setTime(date) 语句，把时间设置为 2020-09-01，但线程还没执行完，线程 B 又执行了 calendar.setTime(date) 语句，把时间设置为 2020-09-02，这个时候就出现幻读了，线程 A 继续执行下去的时候，拿到的 calendar.getTime 得到的时间就是线程B改过之后的。<br>至此，我们发现了 SimpleDateFormat 的弊端，所以为了解决这个问题就是不要把 SimpleDateFormat 当做一个共享变量来使用。<br><br>1、每次使用就创建一个新的 SimpleDateFormat<br>2、synchronized 锁<br>3、ThreadLocal（阿里也推荐使用）<br><img style="zoom: 25%;" alt="img" src="\.pic-Java8新特性\98989aca94530afc6af9e31781c15fe4.png" referrerpolicy="no-referrer"><br>public class DateUtils {

    private static ThreadLocal&lt;DateFormat&gt; threadLocal = new ThreadLocal&lt;DateFormat&gt;(){
        @Override
        protected DateFormat initialValue() {
            return new SimpleDateFormat("yyyy-MM-dd");
        }
    };

    public static Date parse(String formatPattern, String dateString) throws ParseException {
        return threadLocal.get().parse(dateString);
    }

    public static String format(String formatPattern, Date date) {
        return threadLocal.get().format(date);
    }
}
复制<br>如果是 JDK8 的应用，可以使用 Instant 代替 Date，LocalDateTime 代替 Calendar，DateTimeFormatter 代替 SimpleDateFormat。<br><br><br>Java 8仍然延用了ISO的日历体系，并且与它的前辈们不同，java.time包中的类是不可变且线程安全的。新的时间及日期API位于java.time包中，下面是里面的一些关键的类:<br>
<br>Instant----它代表的是时间戳
<br>LocalDate----不包含具体时间的日期，比如2014-01-14。它可以用来存储生日，周年纪念日，入职日期等。
<br>LocalTime----它代表的是不含日期的时间
<br>LocalDateTime----它包含了日期及时间，不过还是没有偏移信息或者说时区。
<br>ZonedDateTime----这是一个包含时区的完整的日期时间，偏移量是以UTC/格林威治时间为基准的。
<br>DateTimeFormatter ----
<br>新的库还增加了ZoneOffset及Zoned，可以为时区提供更好的支持。<br><br>该包的API提供了大量相关的方法，这些方法一般有一致的方法前缀:<br>
<br>of: 静态工厂方法。
<br>parse: 静态工厂方法，关注于解析。
<br>get: 获取某些东西的值。
<br>is: 检查某些东西的是否是true。
<br>with: 不可变的setter等价物。
<br>plus: 加一些量到某个对象。
<br>minus: 从某个对象减去一些量。
<br>to: 转换到另一个类型。
<br>at: 把这个对象与另一个对象组合起来，例如: date.atTime(time)
<br><br>public class TimeIntroduction {
    public static void testClock() throws InterruptedException {
        //时钟提供给我们用于访问某个特定 时区的 瞬时时间、日期 和 时间的。  
        Clock c1 = Clock.systemUTC(); //系统默认UTC时钟(当前瞬时时间 System.currentTimeMillis())  
        System.out.println(c1.millis()); //每次调用将返回当前瞬时时间(UTC)  
        Clock c2 = Clock.systemDefaultZone(); //系统默认时区时钟(当前瞬时时间)  
        Clock c31 = Clock.system(ZoneId.of("Europe/Paris")); //巴黎时区  
        System.out.println(c31.millis()); //每次调用将返回当前瞬时时间(UTC)  
        Clock c32 = Clock.system(ZoneId.of("Asia/Shanghai"));//上海时区  
        System.out.println(c32.millis());//每次调用将返回当前瞬时时间(UTC)  
        Clock c4 = Clock.fixed(Instant.now(), ZoneId.of("Asia/Shanghai"));//固定上海时区时钟  
        System.out.println(c4.millis());
        Thread.sleep(1000);
        System.out.println(c4.millis()); //不变 即时钟时钟在那一个点不动  
        Clock c5 = Clock.offset(c1, Duration.ofSeconds(2)); //相对于系统默认时钟两秒的时钟  
        System.out.println(c1.millis());
        System.out.println(c5.millis());
    }
    public static void testInstant() {
        //瞬时时间 相当于以前的System.currentTimeMillis()  
        Instant instant1 = Instant.now();
        System.out.println(instant1.getEpochSecond());//精确到秒 得到相对于1970-01-01 00:00:00 UTC的一个时间  
        System.out.println(instant1.toEpochMilli()); //精确到毫秒  
        Clock clock1 = Clock.systemUTC(); //获取系统UTC默认时钟  
        Instant instant2 = Instant.now(clock1);//得到时钟的瞬时时间  
        System.out.println(instant2.toEpochMilli());
        Clock clock2 = Clock.fixed(instant1, ZoneId.systemDefault()); //固定瞬时时间时钟  
        Instant instant3 = Instant.now(clock2);//得到时钟的瞬时时间  
        System.out.println(instant3.toEpochMilli());//equals instant1  
    }
    public static void testLocalDateTime() {
        //使用默认时区时钟瞬时时间创建 Clock.systemDefaultZone() --&gt;即相对于 ZoneId.systemDefault()默认时区  
        LocalDateTime now = LocalDateTime.now();
        System.out.println(now);
		//自定义时区  
        LocalDateTime now2 = LocalDateTime.now(ZoneId.of("Europe/Paris"));
        System.out.println(now2);//会以相应的时区显示日期  
		//自定义时钟  
        Clock clock = Clock.system(ZoneId.of("Asia/Dhaka"));
        LocalDateTime now3 = LocalDateTime.now(clock);
        System.out.println(now3);//会以相应的时区显示日期  
		//不需要写什么相对时间 如java.util.Date 年是相对于1900 月是从0开始  
		//2013-12-31 23:59  
		
        LocalDateTime d1 = LocalDateTime.of(2013, 12, 31, 23, 59);
		//年月日 时分秒 纳秒  
        LocalDateTime d2 = LocalDateTime.of(2013, 12, 31, 23, 59, 59, 11);
		//使用瞬时时间 + 时区  
        Instant instant = Instant.now();
        LocalDateTime d3 = LocalDateTime.ofInstant(Instant.now(), ZoneId.systemDefault());
        System.out.println(d3);
        
		//解析String---&gt;LocalDateTime  
        LocalDateTime d4 = LocalDateTime.parse("2013-12-31T23:59");
        System.out.println(d4);
        LocalDateTime d5 = LocalDateTime.parse("2013-12-31T23:59:59.999");//999毫秒 等价于999000000纳秒  
        System.out.println(d5);
        
		//使用DateTimeFormatter API 解析 和 格式化  
        DateTimeFormatter formatter = DateTimeFormatter.ofPattern("yyyy/MM/dd HH:mm:ss");
        LocalDateTime d6 = LocalDateTime.parse("2013/12/31 23:59:59", formatter);
        System.out.println(formatter.format(d6));
        
		//时间获取  
        System.out.println(d6.getYear());
        System.out.println(d6.getMonth());
        System.out.println(d6.getDayOfYear());
        System.out.println(d6.getDayOfMonth());
        System.out.println(d6.getDayOfWeek());
        System.out.println(d6.getHour());
        System.out.println(d6.getMinute());
        System.out.println(d6.getSecond());
        System.out.println(d6.getNano());
        
		//时间增减  
        LocalDateTime d7 = d6.minusDays(1);
        LocalDateTime d8 = d7.plus(1, IsoFields.QUARTER_YEARS);
		//LocalDate 即年月日 无时分秒  
		//LocalTime即时分秒 无年月日  
		//API和LocalDateTime类似就不演示了  
		
		// 两个日期是否相等
		System.out.println(d1.equals(d2));
		
		// MonthDay - 用来检查生日
		LocalDate dateOfBirth = LocalDate.of(2010, 01, 14); 
		MonthDay birthday = MonthDay.of(dateOfBirth.getMonth(), dateOfBirth.getDayOfMonth()); 
		MonthDay currentMonthDay = MonthDay.from(today); 
		System.out.println(currentMonthDay.equals(birthday));
		
		// YearMonth - 用来检查信用卡过期
		YearMonth currentYearMonth = YearMonth.now(); System.out.printf("Days in month year %s: %d%n", currentYearMonth, currentYearMonth.lengthOfMonth()); 
		YearMonth creditCardExpiry = YearMonth.of(2018, Month.FEBRUARY); 
		System.out.printf("Your credit card expires on %s %n", creditCardExpiry); 
		
		// 判断闰年 - LocalDate类有一个isLeapYear()的方法
		System.out.println(dateOfBirth.isLeapYear());
    }
    public static void testZonedDateTime() {
        //即带有时区的date-time 存储纳秒、时区和时差(避免与本地date-time歧义)。  
		//API和LocalDateTime类似，只是多了时差(如2013-12-20T10:35:50.711+08:00[Asia/Shanghai])  
        ZonedDateTime now = ZonedDateTime.now();
        System.out.println(now);
        ZonedDateTime now2 = ZonedDateTime.now(ZoneId.of("Europe/Paris"));
        System.out.println(now2);
		//其他的用法也是类似的 就不介绍了  
        ZonedDateTime z1 = ZonedDateTime.parse("2013-12-31T23:59:59Z[Europe/Paris]");
        System.out.println(z1);
    }
    public static void testDuration() {
        //表示两个瞬时时间的时间段  
        Duration d1 = Duration.between(Instant.ofEpochMilli(System.currentTimeMillis() - 12323123), Instant.now());
		//得到相应的时差  
        System.out.println(d1.toDays());
        System.out.println(d1.toHours());
        System.out.println(d1.toMinutes());
        System.out.println(d1.toMillis());
        System.out.println(d1.toNanos());
		//1天时差 类似的还有如ofHours()  
        Duration d2 = Duration.ofDays(1);
        System.out.println(d2.toDays());
    }
    public static void testChronology() {
        //提供对java.util.Calendar的替换，提供对年历系统的支持  
        Chronology c = HijrahChronology.INSTANCE;
        ChronoLocalDateTime d = c.localDateTime(LocalDateTime.now());
        System.out.println(d);
    }
    /**
     * 新旧日期转换
     */
    public static void testNewOldDateConversion(){
        Instant instant=new Date().toInstant();
        Date date=Date.from(instant);
        System.out.println(instant);
        System.out.println(date);
    }
    public static void main(String[] args) throws InterruptedException {
        testClock();
        testInstant();
        testLocalDateTime();
        testZonedDateTime();
        testDuration();
        testChronology();
        testNewOldDateConversion();
    }
}
复制<br><br>▶ 时区<br>时区指的是地球上共享同一标准时间的地区。每个时区都有一个唯一标识符，同时还有一个地区/城市(Asia/Tokyo)的格式以及从格林威治时间开始的一个偏移时间。<br>比如说，东京的偏移时间就是+09:00。 OffsetDateTime类实际上包含了LocalDateTime与ZoneOffset。它用来表示一个包含格林威治时间偏移量(+/-小时: 分，比如+06:00或者 -08: 00)的完整的日期(年月日)及时间(时分秒，纳秒)。 <br>▶ 格式化<br>DateTimeFormatter类用于在Java中进行日期的格式化与解析。不可变且线程安全的，可赋值于静态变量。<br>DateTimeFormatter类提供了许多预定义的格式器，也可以自定义自己想要的格式。<br>format()格式化方法，出错抛出DateTimeException异常。<br>parse()解析方法，出错抛出DateTimeParseException异常。<br>“MMM d yyyy”与“MMm dd yyyy”这两个日期格式不同，前者能识别出”Jan 2 2014″与”Jan 14 2014″这两个串，而后者如果传进来的是”Jan 2 2014″则会报错，因为它期望月份处传进来的是两个字符。为了解决这个问题，在天为个位数的情况下，你得在前面补0，比如”Jan 2 2014″应该改为”Jan 02 2014″。<br><br>
<br>
提供了javax.time.ZoneId用来处理时区。提供了LocalDate与LocalTime类，且线程安全。

<br>
新的时间与日期API中很重要的一点是它定义清楚了基本的时间与日期的概念，比方说，瞬时时间，持续时间，日期，时间，时区以及时间段。它们都是基于ISO日历体系的。

<br>
这个库的主包是java.time，里面包含了代表日期，时间，瞬时以及持续时间的类。它有两个子package，java.time.foramt，java.time.temporal。

<br><br>日期与时间处理API，在各种语言中，可能都只是个不起眼的API，如果你没有较复杂的时间处理需求，可能只是利用日期与时间处理API取得系统时间，简单做些显示罢了，然而如果认真看待日期与时间，其复杂程度可能会远超过你的想象，天文、地理、历史、政治、文化等因素，都会影响到你对时间的处理。所以在处理时间上，最好选用JSR310(如果你用java8的话就实现310了)，或者Joda-Time。<br>不止是java面临时间处理的尴尬，其他语言同样也遇到过类似的问题，比如<br>Arrow: Python 中更好的日期与时间处理库<br>Moment.js: JavaScript 中的日期库<br>Noda-Time: .NET 阵营的 Joda-Time 的复制<br><br><br>Java8添加了对无符号数的额外支持。int 有4字节，本可以表示最多 232&nbsp;个数。Java中的数值默认为有符号的，所以最后一个二进制数字表示符号(0为正数，1为负数)。所以从十进制的0开始，最大的有符号正整数为 231 -1。<br><br>可以通过Integer.MAX_VALUE来访问它:<br>System.out.println(Integer.MAX_VALUE);      // 2147483647
System.out.println(Integer.MAX_VALUE + 1);  // -2147483648
复制<br>Java8添加了解析无符号整数的支持，让我们看看它如何工作:<br>long maxUnsignedInt = (1l &lt;&lt; 32) - 1;  //long类型
String string = String.valueOf(maxUnsignedInt); // 等于Long.toString(maxUnsignedInt)
System.out.println(string);     //4294967295
int unsignedInt = Integer.parseUnsignedInt(string, 10); //变成整数
System.out.println(unsignedInt); //int值为-1
String string2 = Integer.toUnsignedString(unsignedInt, 10);//再将-1转化为无符号字符串
System.out.println(string2);     //4294967295
复制<br>就像你看到的那样，现在可以将最大的无符号数 232 -1 解析为整数。而且你也可以将这个数值转换回无符号数的字符串表示。<br>这在之前不可能使用parseInt完成，就像这个例子展示的那样:<br>try {
    Integer.parseInt(string, 10);
}catch (NumberFormatException e) {
    System.err.println("could not parse signed int of " + maxUnsignedInt);
}
复制<br>这个数值不可解析为有符号整数，因为它超出了最大范围 232 -1。 <br><br>Math工具类新增了一些方法来处理数值溢出。如：【 Integer.MAX_VALUE + 1 】发生了整数溢出，这通常是我们不愿意看到的。<br>Java8添加了严格数学运算的支持来解决这个问题。Math扩展了一些方法，它们全部以exact结尾，例如addExact。当运算结果不能被数值类型装下时，这些方法通过抛出ArithmeticException异常来合理地处理溢出。<br>try {
    Math.addExact(Integer.MAX_VALUE, 1);
}
catch (ArithmeticException e) {
    System.err.println(e.getMessage());
    // =&gt; integer overflow
}
复制<br>当尝试通过toIntExact将长整数转换为整数时，可能会抛出同样的异常:<br>try {
    Math.toIntExact(Long.MAX_VALUE);
}
catch (ArithmeticException e) {
    System.err.println(e.getMessage());
    // =&gt; integer overflow
}
复制<br><br>Files工具类首次在Java7中引入，作为NIO的一部分。JDK8 API添加了一些额外的方法，它们可以将文件用于函数式数据流。<br>列出文件 Files.list（） 方法将指定目录的所有路径转换为数据流，便于我们在文件系统的内容上使用类似filter和sorted的流操作。<br>try (Stream&lt;Path&gt; stream = Files.list(Paths.get(""))) {
    String joined = stream
        .map(String::valueOf) //  valueOf = path对象的toString() = getPath() 方法
        .filter(path -&gt; !path.startsWith("."))
        .sorted()
        .collect(Collectors.joining("; "));
    System.out.println("List: " + joined);
}
复制<br>上面的例子列出了当前工作目录的所有文件，之后将每个路径都映射为它的字符串表示。之后结果被过滤、排序，最后连接为一个字符串。<br>你可能已经注意到，数据流的创建包装在try-with语句中。数据流实现了AutoCloseable，并且这里我们需要显式关闭数据流，因为它基于IO操作。<br>
返回的数据流是DirectoryStream的封装。如果需要及时处理文件资源，就应该使用try-with结构来确保在流式操作完成后，数据流的close方法被调用。
<br><br>面的例子演示了如何查找在目录及其子目录下的文件:<br>Path start = Paths.get("");
int maxDepth = 5;
try (Stream&lt;Path&gt; stream = Files.find(start, maxDepth, (path, attr) -&gt;
        String.valueOf(path).endsWith(".js"))) {
    String joined = stream
        .sorted()
        .map(String::valueOf)
        .collect(Collectors.joining("; "));
    System.out.println("Found: " + joined);
}
复制<br>find方法接受三个参数: 目录路径start是起始点，maxDepth定义了最大搜索深度。第三个参数是一个匹配谓词，定义了搜索的逻辑。上面的例子中，我们搜索了所有JavaScirpt文件(以.js结尾的文件名)。<br>我们可以使用Files.walk方法来完成相同的行为。这个方法会遍历每个文件，而不需要传递搜索谓词。<br>Path start = Paths.get("");
int maxDepth = 5;
try (Stream&lt;Path&gt; stream = Files.walk(start, maxDepth)) {
    String joined = stream
        .map(String::valueOf)
        .filter(path -&gt; path.endsWith(".js"))
        .sorted()
        .collect(Collectors.joining("; "));
    System.out.println("walk(): " + joined);
}
复制<br><br>将文本文件读到内存，以及向文本文件写入字符串在Java 8 中是简单的任务。不需要再去摆弄读写器了。Files.readAllLines从指定的文件把所有行读进字符串列表中。你可以简单地修改这个列表，并且将它通过Files.write写到另一个文件中:<br>List&lt;String&gt; lines = Files.readAllLines(Paths.get("res/nashorn1.js"));
lines.add("print('foobar');");
Files.write(Paths.get("res/nashorn1-modified.js"), lines);
复制<br>要注意这些方法对内存并不十分高效，因为整个文件都会读进内存。文件越大，所用的堆区也就越大。<br>你可以使用Files.lines方法来作为内存高效的替代。这个方法读取每一行，并使用函数式数据流来对其流式处理，而不是一次性把所有行都读进内存。<br>try (Stream&lt;String&gt; stream = Files.lines(Paths.get("res/nashorn1.js"))) {
    stream
        .filter(line -&gt; line.contains("print"))
        .map(String::trim)
        .forEach(System.out::println);
}
复制<br>如果你需要更多的精细控制，你需要构造一个新的BufferedReader来代替:<br>Path path = Paths.get("res/nashorn1.js");
try (BufferedReader reader = Files.newBufferedReader(path)) {
    System.out.println(reader.readLine());
}
复制<br>或者，你需要写入文件时，简单地构造一个BufferedWriter来代替:<br>Path path = Paths.get("res/output.js");
try (BufferedWriter writer = Files.newBufferedWriter(path)) {
    writer.write("print('Hello World');");
}
复制<br>BufferedReader也可以访问函数式数据流。lines方法在它所有行上面构建数据流:<br>Path path = Paths.get("res/nashorn1.js");
try (BufferedReader reader = Files.newBufferedReader(path)) {
    long countPrints = reader
        .lines()
        .filter(line -&gt; line.contains("print"))
        .count();
    System.out.println(countPrints);
}
复制<br>目前为止你可以看到Java8提供了三个简单的方法来读取文本文件的每一行，使文件处理更加便捷。<br>不幸的是你需要显式使用try-with语句来关闭文件流，这会使示例代码有些凌乱。我期待函数式数据流可以在调用类似count和collect时可以自动关闭，因为你不能在相同数据流上调用终止操作两次.<br><br>java.util.Random<br>在Java8中java.util.Random类的一个非常明显的变化就是新增了返回随机数流(random Stream of numbers)的一些方法。<br>下面的代码是创建一个无穷尽的double类型的数字流，这些数字在0(包括0)和1(不包含1)之间。<br>Random random = new Random();
DoubleStream doubleStream = random.doubles();
复制<br>下面的代码是创建一个无穷尽的int类型的数字流，这些数字在0(包括0)和100(不包括100)之间。<br>Random random = new Random();
IntStream intStream = random.ints(0, 100);
复制<br>那么这些无穷尽的数字流用来做什么呢? 接下来，我通过一些案例来分析。记住，这些无穷大的数字流只能通过某种方式被截断(limited)。<br>示例1: 创建10个随机的整数流并打印出来:<br>intStream.limit(10).forEach(System.out::println);
复制<br>示例2: 创建100个随机整数:<br>    List&lt;Integer&gt; randomBetween0And99 = intStream
                                       .limit(100)
                                       .boxed()
                                       .collect(Collectors.toList());
复制<br>对于高斯伪随机数(gaussian pseudo-random values)来说，random.doubles()方法所创建的流不能等价于高斯伪随机数，然而，如果用java8所提供的功能是非常容易实现的。<br>Random random = new Random();
DoubleStream gaussianStream = Stream.generate(random::nextGaussian).mapToDouble(e -&gt; e);
复制<br>这里，我使用了Stream.generate api，并传入Supplier 类的对象作为参数，这个对象是通过调用Random类中的方法 nextGaussian()创建另一个高斯伪随机数。<br>接下来，我们来对double类型的伪随机数流和double类型的高斯伪随机数流做一个更加有意思的事情，那就是获得两个流的随机数的分配情况。预期的结果是: double类型的伪随机数是均匀的分配的，而double类型的高斯伪随机数应该是正态分布的。<br>通过下面的代码，我生成了一百万个伪随机数，这是通过java8提供的api实现的:<br>Random random = new Random();
DoubleStream doubleStream = random.doubles(-1.0, 1.0);
LinkedHashMap&lt;Range, Integer&gt; rangeCountMap = doubleStream.limit(1000000)
    .boxed()
    .map(Ranges::of)
    .collect(Ranges::emptyRangeCountMap, (m, e) -&gt; m.put(e, m.get(e) + 1), Ranges::mergeRangeCountMaps);

rangeCountMap.forEach((k, v) -&gt; System.out.println(k.from() + "\t" + v));
复制<br>代码的运行结果如下:<br>    -1      49730
    -0.9    49931
    -0.8    50057
    -0.7    50060
    -0.6    49963
    -0.5    50159
    -0.4    49921
    -0.3    49962
    -0.2    50231
    -0.1    49658
    0       50177
    0.1     49861
    0.2     49947
    0.3     50157
    0.4     50414
    0.5     50006
    0.6     50038
    0.7     49962
    0.8     50071
    0.9     49695
复制<br>为了类比，我们再生成一百万个高斯伪随机数:<br>Random random = new Random();
DoubleStream gaussianStream = Stream.generate(random::nextGaussian).mapToDouble(e -&gt; e);
LinkedHashMap&lt;Range, Integer&gt; gaussianRangeCountMap =
    gaussianStream
            .filter(e -&gt; (e &gt;= -1.0 &amp;&amp; e &lt; 1.0))
            .limit(1000000)
            .boxed()
            .map(Ranges::of)
            .collect(Ranges::emptyRangeCountMap, (m, e) -&gt; m.put(e, m.get(e) + 1), Ranges::mergeRangeCountMaps);

gaussianRangeCountMap.forEach((k, v) -&gt; System.out.println(k.from() + "\t" + v));
复制<br>上面代码输出的结果恰恰与我们预期结果相吻合，即: double类型的伪随机数是均匀的分配的，而double类型的高斯伪随机数应该是正态分布的<br><br>
Java8中java.util.Base64性能比较高，推荐使用。请参考:
性能对比: <a rel="noopener" class="external-link" href="https://wizardforcel.gitbooks.io/java8-new-features/content/11.html" target="_blank">https://wizardforcel.gitbooks.io/java8-new-features/content/11.html</a>
源代码: <a rel="noopener" class="external-link" href="http://git.oschina.net/benhail/javase8-sample" target="_blank">http://git.oschina.net/benhail/javase8-sample</a>
<br>该类提供了一套静态方法获取下面三种BASE64编解码器:<br>1)Basic编码: 是标准的BASE64编码，用于处理常规的需求<br>// 编码
String asB64 = Base64.getEncoder().encodeToString("some string".getBytes("utf-8"));
System.out.println(asB64); // 输出为: c29tZSBzdHJpbmc=
// 解码
byte[] asBytes = Base64.getDecoder().decode("c29tZSBzdHJpbmc=");
System.out.println(new String(asBytes, "utf-8")); // 输出为: some string
复制<br>2)URL编码: 使用下划线替换URL里面的反斜线“/”<br>String urlEncoded = Base64.getUrlEncoder().encodeToString("subjects?abcd".getBytes("utf-8"));
System.out.println("Using URL Alphabet: " + urlEncoded);
// 输出为:
Using URL Alphabet: c3ViamVjdHM_YWJjZA==
复制<br>3)MIME编码: 使用基本的字母数字产生BASE64输出，而且对MIME格式友好: 每一行输出不超过76个字符，而且每行以“\r\n”符结束。<br>StringBuilder sb = new StringBuilder();
for (int t = 0; t &lt; 10; ++t) {
  sb.append(UUID.randomUUID().toString());
}
byte[] toEncode = sb.toString().getBytes("utf-8");
String mimeEncoded = Base64.getMimeEncoder().encodeToString(toEncode);
System.out.println(mimeEncoded);
复制]]></description><link>03、java核心\05、java-版本和特性\java8\java8新特性.html</link><guid isPermaLink="false">03、Java核心/05、Java 版本和特性/Java8/Java8新特性.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:44 GMT</pubDate><enclosure url=".pic-Java8新特性\java8-jre-3.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;.pic-Java8新特性\java8-jre-3.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[00、Java-LST版本]]></title><description><![CDATA[ 
 ]]></description><link>03、java核心\05、java-版本和特性\00、java-lst版本.html</link><guid isPermaLink="false">03、Java核心/05、Java 版本和特性/00、Java-LST版本.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:44 GMT</pubDate></item><item><title><![CDATA[00、 ★ MySQL 总览 ★]]></title><description><![CDATA[ 
 ]]></description><link>04、数据库\01、mysql\00、-★-mysql-总览-★.html</link><guid isPermaLink="false">04、数据库/01、MySQL/00、 ★ MySQL 总览 ★.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Sat, 16 Mar 2024 09:41:41 GMT</pubDate></item><item><title><![CDATA[01、MySQL 查询基础]]></title><description><![CDATA[ 
 <br><br>
<br>DDL: 数据定义语言，用来定义数据库对象（数据库、表、字段）
<br>DML: 数据操作语言，用来对数据库表中的数据进行增删改
<br>DQL: 数据查询语言，用来查询数据库中表的记录
<br>DCL: 数据控制语言，用来创建数据库用户、控制数据库的控制权限
<br><br>数据定义语言<br><br>查询所有数据库：<br>
SHOW DATABASES;<br>
查询当前数据库：<br>
SELECT DATABASE();<br>
创建数据库：<br>
CREATE DATABASE [ IF NOT EXISTS ] 数据库名 [ DEFAULT CHARSET 字符集] [COLLATE 排序规则 ];<br>
删除数据库：<br>
DROP DATABASE [ IF EXISTS ] 数据库名;<br>
使用数据库：<br>
USE 数据库名;<br>
注意事项：<br>
UTF8字符集长度为3字节，有些符号占4字节（一些辅助平面字符），所以推荐用utf8mb4字符集
<br><br>查询当前数据库所有表：<br>
SHOW TABLES;<br>查询表结构：<br>
DESC 表名;<br>查询指定表的建表语句：<br>
SHOW CREATE TABLE 表名;<br>创建表：<br>CREATE TABLE 表名(
	字段1 字段1类型 [COMMENT 字段1注释],
	字段2 字段2类型 [COMMENT 字段2注释],
	字段3 字段3类型 [COMMENT 字段3注释],
	...
	字段n 字段n类型 [COMMENT 字段n注释]
)[ COMMENT 表注释 ];
复制<br>最后一个字段后面没有逗号<br>添加字段：<br>
ALTER TABLE 表名 ADD 字段名 类型(长度) [COMMENT 注释] [约束];<br>
例：ALTER TABLE emp ADD nickname varchar(20) COMMENT '昵称';<br>修改数据类型：<br>
ALTER TABLE 表名 MODIFY 字段名 新数据类型(长度);<br>修改字段名和字段类型：<br>
ALTER TABLE 表名 CHANGE 旧字段名 新字段名 类型(长度) [COMMENT 注释] [约束];<br>
例：将emp表的nickname字段修改为username，类型为varchar(30)<br>
ALTER TABLE emp CHANGE nickname username varchar(30) COMMENT '昵称';<br>删除字段：<br>
ALTER TABLE 表名 DROP 字段名;<br>修改表名：<br>
ALTER TABLE 表名 RENAME TO 新表名<br>删除表：<br>
DROP TABLE [IF EXISTS] 表名;<br>
删除表，并重新创建该表：<br>
TRUNCATE TABLE 表名;<br>
注意事项：
<br>
<br>DROP TABLE用于完全删除表，包括结构和数据，而TRUNCATE TABLE仅删除表中的数据。
<br>DROP TABLE 操作是不可撤销的，而 TRUNCATE TABLE 操作是可撤销的，可以通过恢复备份或回滚事务来还原数据。
<br><br><br>指定字段：<br>
INSERT INTO 表名 (字段名1, 字段名2, ...) VALUES (值1, 值2, ...);<br>
全部字段：<br>
INSERT INTO 表名 VALUES (值1, 值2, ...);<br>批量添加数据：<br>
INSERT INTO 表名 (字段名1, 字段名2, ...) VALUES (值1, 值2, ...), (值1, 值2, ...), (值1, 值2, ...);<br>
INSERT INTO 表名 VALUES (值1, 值2, ...), (值1, 值2, ...), (值1, 值2, ...);<br>
注意事项：
<br>
<br>字符串和日期类型数据应该包含在引号中
<br>插入的数据大小应该在字段的规定范围内
<br><br>修改数据：<br>
UPDATE 表名 SET 字段名1 = 值1, 字段名2 = 值2, ... [ WHERE 条件 ];<br>
例：<br>
UPDATE emp SET name = 'Jack' WHERE id = 1;<br>删除数据：<br>
DELETE FROM 表名 [ WHERE 条件 ];<br><br>语法：<br>SELECT
	字段列表
FROM
	表名字段
WHERE
	条件列表
GROUP BY
	分组字段列表
HAVING
	分组后的条件列表
ORDER BY
	排序字段列表
LIMIT
	分页参数
复制<br><br>查询多个字段：<br>
SELECT 字段1, 字段2, 字段3, ... FROM 表名;<br>
SELECT * FROM 表名;<br>设置别名：<br>
SELECT 字段1 [ AS 别名1 ], 字段2 [ AS 别名2 ], 字段3 [ AS 别名3 ], ... FROM 表名;<br>
SELECT 字段1 [ 别名1 ], 字段2 [ 别名2 ], 字段3 [ 别名3 ], ... FROM 表名;<br>去除重复记录：<br>
SELECT DISTINCT 字段列表 FROM 表名;<br>转义：<br>
SELECT * FROM 表名 WHERE name LIKE '/_张三' ESCAPE '/'<br>
/ 之后的_不作为通配符<br><br>语法：<br>
SELECT 字段列表 FROM 表名 WHERE 条件列表;<br>条件：<br><br><br>例子：<br>-- 年龄等于30
select * from employee where age = 30;
-- 年龄小于30
select * from employee where age &lt; 30;
-- 小于等于
select * from employee where age &lt;= 30;
-- 没有身份证
select * from employee where idcard is null or idcard = '';
-- 有身份证
select * from employee where idcard;
select * from employee where idcard is not null;
-- 不等于
select * from employee where age != 30;
-- 年龄在20到30之间
select * from employee where age between 20 and 30;
select * from employee where age &gt;= 20 and age &lt;= 30;
-- 下面语句不报错，但查不到任何信息
select * from employee where age between 30 and 20;
-- 性别为女且年龄小于30
select * from employee where age &lt; 30 and gender = '女';
-- 年龄等于25或30或35
select * from employee where age = 25 or age = 30 or age = 35;
select * from employee where age in (25, 30, 35);
-- 姓名为两个字
select * from employee where name like '__';
-- 身份证最后为X
select * from employee where idcard like '%X';
复制<br><br>常见聚合函数：<br><br>语法：<br>
SELECT 聚合函数(字段列表) FROM 表名;<br>
例：<br>
SELECT count(id) from employee where workaddress = "广东省";<br><br>语法：<br>
SELECT 字段列表 FROM 表名 [ WHERE 条件 ] GROUP BY 分组字段名 [ HAVING 分组后的过滤条件 ];<br>where 和 having 的区别：<br>
<br>执行时机不同：where是分组之前进行过滤，不满足where条件不参与分组；having是分组后对结果进行过滤。
<br>判断条件不同：where不能对聚合函数进行判断，而having可以。
<br>例子：<br>-- 根据性别分组，统计男性和女性数量（只显示分组数量，不显示哪个是男哪个是女）
select count(*) from employee group by gender;
-- 根据性别分组，统计男性和女性数量
select gender, count(*) from employee group by gender;
-- 根据性别分组，统计男性和女性的平均年龄
select gender, avg(age) from employee group by gender;
-- 年龄小于45，并根据工作地址分组
select workaddress, count(*) from employee where age &lt; 45 group by workaddress;
-- 年龄小于45，并根据工作地址分组，获取员工数量大于等于3的工作地址
select workaddress, count(*) address_count from employee where age &lt; 45 group by workaddress having address_count &gt;= 3;
复制<br>
注意事项
<br>
<br>执行顺序：where &gt; 聚合函数 &gt; having
<br>分组之后，查询的字段一般为聚合函数和分组字段，查询其他字段无任何意义
<br><br>语法：<br>
SELECT 字段列表 FROM 表名 ORDER BY 字段1 排序方式1, 字段2 排序方式2;<br>排序方式：<br>
<br>ASC: 升序（默认）
<br>DESC: 降序
<br>例子：<br>-- 根据年龄升序排序
SELECT * FROM employee ORDER BY age ASC;
SELECT * FROM employee ORDER BY age;
-- 两字段排序，根据年龄升序排序，入职时间降序排序
SELECT * FROM employee ORDER BY age ASC, entrydate DESC;
复制<br>
注意事项<br>
如果是多字段排序，当第一个字段值相同时，才会根据第二个字段进行排序
<br><br>语法：<br>
SELECT 字段列表 FROM 表名 LIMIT 起始索引, 查询记录数;<br>例子：<br>-- 查询第一页数据，展示10条
SELECT * FROM employee LIMIT 0, 10;
-- 查询第二页
SELECT * FROM employee LIMIT 10, 10;
复制<br>
注意事项
<br>
<br>起始索引从0开始，起始索引 = （查询页码 - 1） * 每页显示记录数
<br>分页查询是数据库的方言，不同数据库有不同实现，MySQL是LIMIT
<br>如果查询的是第一页数据，起始索引可以省略，直接简写 LIMIT 10
<br><br>FROM -&gt; WHERE -&gt; GROUP BY -&gt; SELECT -&gt; ORDER BY -&gt; LIMIT<br><br><br>查询用户：<br>USE mysql;
SELECT * FROM user;
复制<br>创建用户:<br>
CREATE USER '用户名'@'主机名' IDENTIFIED BY '密码';<br>修改用户密码：<br>
ALTER USER '用户名'@'主机名' IDENTIFIED WITH mysql_native_password BY '新密码';<br>删除用户：<br>
DROP USER '用户名'@'主机名';<br>例子：<br>-- 创建用户test，只能在当前主机localhost访问
create user 'test'@'localhost' identified by '123456';
-- 创建用户test，能在任意主机访问
create user 'test'@'%' identified by '123456';
create user 'test' identified by '123456';
-- 修改密码
alter user 'test'@'localhost' identified with mysql_native_password by '1234';
-- 删除用户
drop user 'test'@'localhost';
复制<br>
注意事项
<br>
<br>主机名可以使用 % 通配
<br><br>常用权限：<br><br>更多权限请看<a title="权限一览表" class="internal-link" data-href="#权限一览表" href="\#权限一览表" target="_self" rel="noopener">权限一览表</a><br>查询权限：<br>
SHOW GRANTS FOR '用户名'@'主机名';<br>授予权限：<br>
GRANT 权限列表 ON 数据库名.表名 TO '用户名'@'主机名';<br>撤销权限：<br>
REVOKE 权限列表 ON 数据库名.表名 FROM '用户名'@'主机名';<br>
注意事项
<br>
<br>多个权限用逗号分隔
<br>授权时，数据库名和表名可以用 * 进行通配，代表所有
<br><br>
<br>字符串函数
<br>数值函数
<br>日期函数
<br>流程函数
<br><br>常用函数：<br><br>使用示例：<br>-- 拼接
SELECT CONCAT('Hello', 'World');
-- 小写
SELECT LOWER('Hello');
-- 大写
SELECT UPPER('Hello');
-- 左填充
SELECT LPAD('01', 5, '-');
-- 右填充
SELECT RPAD('01', 5, '-');
-- 去除空格
SELECT TRIM(' Hello World ');
-- 切片（起始索引为1）
SELECT SUBSTRING('Hello World', 1, 5);
复制<br><br>常见函数：<br><br><br>常用函数：<br><br>例子：<br>-- DATE_ADD
SELECT DATE_ADD(NOW(), INTERVAL 70 YEAR);
复制<br><br>常用函数：<br><br>例子：<br>select
	name,
	(case when age &gt; 30 then '中年' else '青年' end)
from employee;
select
	name,
	(case workaddress when '北京市' then '一线城市' when '上海市' then '一线城市' else '二线城市' end) as '工作地址'
from employee;
复制<br><br>分类：<br><br>约束是作用于表中字段上的，可以再创建表/修改表的时候添加约束。<br><br><br>例子：<br>create table user(
	id int primary key auto_increment,
	name varchar(10) not null unique,
	age int check(age &gt; 0 and age &lt; 120),
	status char(1) default '1',
	gender char(1)
);
复制<br><br>添加外键：<br>CREATE TABLE 表名(
	字段名 字段类型,
	...
	[CONSTRAINT] [外键名称] FOREIGN KEY(外键字段名) REFERENCES 主表(主表列名)
);
ALTER TABLE 表名 ADD CONSTRAINT 外键名称 FOREIGN KEY (外键字段名) REFERENCES 主表(主表列名);

-- 例子
alter table emp add constraint fk_emp_dept_id foreign key(dept_id) references dept(id);
复制<br>删除外键：<br>
ALTER TABLE 表名 DROP FOREIGN KEY 外键名;<br><br><br>更改删除/更新行为：<br>
ALTER TABLE 表名 ADD CONSTRAINT 外键名称 FOREIGN KEY (外键字段) REFERENCES 主表名(主表字段名) ON UPDATE 行为 ON DELETE 行为;<br><br><br>
<br>一对一
<br>一对多（多对一）
<br>多对多
<br><br>案例：用户与用户详情<br>
关系：一对一关系，多用于单表拆分，将一张表的基础字段放在一张表中，其他详情字段放在另一张表中，以提升操作效率<br>
实现：在任意一方加入外键，关联另外一方的主键，并且设置外键为唯一的（UNIQUE）<br><br>案例：部门与员工<br>
关系：一个部门对应多个员工，一个员工对应一个部门<br>
实现：在多的一方建立外键，指向一的一方的主键<br><br>案例：学生与课程<br>
关系：一个学生可以选多门课程，一门课程也可以供多个学生选修<br>
实现：建立第三张中间表，中间表至少包含两个外键，分别关联两方主键<br><br>合并查询（笛卡尔积，会展示所有组合结果）：<br>
select * from employee, dept;<br>
笛卡尔积：两个集合A集合和B集合的所有组合情况（在多表查询时，需要消除无效的笛卡尔积）
<br>消除无效笛卡尔积：<br>
select * from employee, dept where employee.dept = dept.id;<br><br>内连接查询的是两张表交集的部分<br>隐式内连接：<br>
SELECT 字段列表 FROM 表1, 表2 WHERE 条件 ...;<br>显式内连接：<br>
SELECT 字段列表 FROM 表1 [ INNER ] JOIN 表2 ON 连接条件 ...;<br>显式性能比隐式高<br>例子：<br>-- 查询员工姓名，及关联的部门的名称
-- 隐式
select e.name, d.name from employee as e, dept as d where e.dept = d.id;
-- 显式
select e.name, d.name from employee as e inner join dept as d on e.dept = d.id;
复制<br><br>左外连接：<br>
查询左表所有数据，以及两张表交集部分数据<br>
SELECT 字段列表 FROM 表1 LEFT [ OUTER ] JOIN 表2 ON 条件 ...;<br>
相当于查询表1的所有数据，包含表1和表2交集部分数据<br>右外连接：<br>
查询右表所有数据，以及两张表交集部分数据<br>
SELECT 字段列表 FROM 表1 RIGHT [ OUTER ] JOIN 表2 ON 条件 ...;<br>例子：<br>-- 左
select e.*, d.name from employee as e left outer join dept as d on e.dept = d.id;
select d.name, e.* from dept d left outer join emp e on e.dept = d.id;  -- 这条语句与下面的语句效果一样
-- 右
select d.name, e.* from employee as e right outer join dept as d on e.dept = d.id;
复制<br>左连接可以查询到没有dept的employee，右连接可以查询到没有employee的dept<br><br>当前表与自身的连接查询，自连接必须使用表别名<br>语法：<br>
SELECT 字段列表 FROM 表A 别名A JOIN 表A 别名B ON 条件 ...;<br>自连接查询，可以是内连接查询，也可以是外连接查询<br>例子：<br>-- 查询员工及其所属领导的名字
select a.name, b.name from employee a, employee b where a.manager = b.id;
-- 没有领导的也查询出来
select a.name, b.name from employee a left join employee b on a.manager = b.id;
复制<br><br>把多次查询的结果合并，形成一个新的查询集<br>语法：<br>SELECT 字段列表 FROM 表A ...
UNION [ALL]
SELECT 字段列表 FROM 表B ...
复制<br>
注意事项
<br>
<br>UNION ALL 会有重复结果，UNION 不会
<br>联合查询比使用or效率高，不会使索引失效
<br><br>SQL语句中嵌套SELECT语句，称谓嵌套查询，又称子查询。<br>
SELECT * FROM t1 WHERE column1 = ( SELECT column1 FROM t2);<br>
子查询外部的语句可以是 INSERT / UPDATE / DELETE / SELECT 的任何一个<br>根据子查询结果可以分为：<br>
<br>标量子查询（子查询结果为单个值）
<br>列子查询（子查询结果为一列）
<br>行子查询（子查询结果为一行）
<br>表子查询（子查询结果为多行多列）
<br>根据子查询位置可分为：<br>
<br>WHERE 之后
<br>FROM 之后
<br>SELECT 之后
<br><br>子查询返回的结果是单个值（数字、字符串、日期等）。<br>
常用操作符：- &lt; &gt; &gt; &gt;= &lt; &lt;=<br>例子：<br>-- 查询销售部所有员工
select id from dept where name = '销售部';
-- 根据销售部部门ID，查询员工信息
select * from employee where dept = 4;
-- 合并（子查询）
select * from employee where dept = (select id from dept where name = '销售部');

-- 查询xxx入职之后的员工信息
select * from employee where entrydate &gt; (select entrydate from employee where name = 'xxx');
复制<br><br>返回的结果是一列（可以是多行）。<br>常用操作符：<br><br>例子：<br>-- 查询销售部和市场部的所有员工信息
select * from employee where dept in (select id from dept where name = '销售部' or name = '市场部');
-- 查询比财务部所有人工资都高的员工信息
select * from employee where salary &gt; all(select salary from employee where dept = (select id from dept where name = '财务部'));
-- 查询比研发部任意一人工资高的员工信息
select * from employee where salary &gt; any (select salary from employee where dept = (select id from dept where name = '研发部'));
复制<br><br>返回的结果是一行（可以是多列）。<br>
常用操作符：=, &lt;, &gt;, IN, NOT IN<br>例子：<br>-- 查询与xxx的薪资及直属领导相同的员工信息
select * from employee where (salary, manager) = (12500, 1);
select * from employee where (salary, manager) = (select salary, manager from employee where name = 'xxx');
复制<br><br>返回的结果是多行多列<br>
常用操作符：IN<br>例子：<br>-- 查询与xxx1，xxx2的职位和薪资相同的员工
select * from employee where (job, salary) in (select job, salary from employee where name = 'xxx1' or name = 'xxx2');
-- 查询入职日期是2006-01-01之后的员工，及其部门信息
select e.*, d.* from (select * from employee where entrydate &gt; '2006-01-01') as e left join dept as d on e.dept = d.id;
复制<br><br><br>
具体权限的作用详见<a data-tooltip-position="top" aria-label="https://dev.mysql.com/doc/refman/8.0/en/privileges-provided.html" rel="noopener" class="external-link" title="官方文档" href="https://dev.mysql.com/doc/refman/8.0/en/privileges-provided.html" target="_blank">官方文档</a>
<br>GRANT 和 REVOKE 允许的静态权限<br><br>GRANT 和 REVOKE 允许的动态权限<br><br><br>
<br>Workbench(免费): <a rel="noopener" class="external-link" href="http://dev.mysql.com/downloads/workbench/" target="_blank">http://dev.mysql.com/downloads/workbench/</a>
<br>navicat(收费，试用版30天): <a rel="noopener" class="external-link" href="https://www.navicat.com/en/download/navicat-for-mysql" target="_blank">https://www.navicat.com/en/download/navicat-for-mysql</a>
<br>Sequel Pro(开源免费，仅支持Mac OS): <a rel="noopener" class="external-link" href="http://www.sequelpro.com/" target="_blank">http://www.sequelpro.com/</a>
<br>HeidiSQL(免费): <a rel="noopener" class="external-link" href="http://www.heidisql.com/" target="_blank">http://www.heidisql.com/</a>
<br>phpMyAdmin(免费): <a rel="noopener" class="external-link" href="https://www.phpmyadmin.net/" target="_blank">https://www.phpmyadmin.net/</a>
<br>SQLyog: <a rel="noopener" class="external-link" href="https://sqlyog.en.softonic.com/" target="_blank">https://sqlyog.en.softonic.com/</a>
<br><br>
<br>在SQL语句之后加上\G会将结果的表格形式转换成行文本形式
<br>查看Mysql数据库占用空间：
<br>SELECT table_schema "Database Name"
     , SUM(data_length + index_length) / (1024 * 1024) "Database Size in MB"
FROM information_schema.TABLES
GROUP BY table_schema;
复制<br>借鉴博客：<br><a rel="noopener" class="external-link" href="https://github.com/Buildings-Lei/mysql_note/blob/main/README.md" target="_blank">https://github.com/Buildings-Lei/mysql_note/blob/main/README.md</a><br><a rel="noopener" class="external-link" href="https://blog.csdn.net/da_ge_de_nv_ren/article/details/128837934" target="_blank">https://blog.csdn.net/da_ge_de_nv_ren/article/details/128837934</a><br><a rel="noopener" class="external-link" href="https://blog.csdn.net/da_ge_de_nv_ren/article/details/128837934" target="_blank">https://blog.csdn.net/da_ge_de_nv_ren/article/details/128837934</a><br><a rel="noopener" class="external-link" href="https://dhc.pythonanywhere.com/entry/share/?key=12e4a7324f68371db3984d93e26e458962a4f0bc188ec23ec70637a4f3b4d58f" target="_blank">https://dhc.pythonanywhere.com/entry/share/?key=12e4a7324f68371db3984d93e26e458962a4f0bc188ec23ec70637a4f3b4d58f</a>]]></description><link>04、数据库\01、mysql\01、mysql-查询基础.html</link><guid isPermaLink="false">04、数据库/01、MySQL/01、MySQL 查询基础.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Fri, 05 Apr 2024 09:30:00 GMT</pubDate></item><item><title><![CDATA[02、MySQL 数据类型]]></title><description><![CDATA[ 
 <br><br><br><br>无符号在数据类型后加 unsigned 关键字。<br>其中括号的数据只是规定了交互工具显示字符的个数，对于存储和计算来说是没有意义的<br>
如 INT(11) 中的数字，表示只显示 11 位。<br><br><br>FLOAT 和 DOUBLE 为浮点类型，DECIMAL 为高精度小数类型。<br>
CPU 原生支持浮点运算，但不支持 DECIMAl 类型的计算，因此 DECIMAL 的计算比浮点类型需要更高的代价。<br>FLOAT、DOUBLE 和 DECIMAL 都可以指定列宽，例如 DECIMAL(18, 9) 表示总共 18 位，取 9 位存储小数部分，剩下 9 位存储整数部分。<br><br><br>1、DATETIME<br>
<br>使用 8 字节的存储空间。保存从 1001 年到 9999 年的日期和时间，精度为秒。
<br>DATETIME类型的值不会自动更新。如果需要更新日期和时间，需要手动进行更新操作。
<br>DATETIME类型不考虑时区，存储的值与输入的值完全一致。
<br>2、TIMESTAMP<br>
<br>使用 4 个字节的存储空间，只能表示从 1970 年到 2038 年。
<br>TIMESTAMP类型的值在插入或更新行时，如果没有显式指定值，会自动设置为当前的日期和时间。
<br>TIMESTAMP类型会自动将存储的值从当前时区转换为协调世界时（UTC）存储，并在检索时将其转换回当前时区。
<br>存储较大的日期范围，更大的灵活性，并且不需要自动更新或时区处理功能，选用 DATETIME。<br>
较少的存储空间，自动更新日期和时间，应该尽量使用 TIMESTAMP 。<br><br><br>1、 CHAR 和 VARCHAR<br>CHAR 定长，不足部分会用空格填充。字符串长度相对较小且固定时，可以提供更好的性能。<br>VARCHAR 变长类型能够节省空间，但是在执行 UPDATE 时可能会使行变得比原来长，当超出一个页所能容纳的大小时，就要执行额外的操作。<br>
MyISAM 会将行拆成不同的片段存储，而 InnoDB 则需要分裂页来使行放进页内。<br>2、VARCHAR (5) 、 VARCHAR (200) 、 VARCHAR (300)<br>VARCHAR (5) 、 VARCHAR (200) 占用相同的空间。<br>
最好只分配真正需要的空间<br>
MySQL 通常会分配固定大小的内存块来保存内部值，更长的列会消耗更多的内存。<br>
当使用内存临时表进行排序或利用磁盘临时表进行排序时会特别糟糕。<br>当 VARCHAR 存储的字符个数小于或等于 255 的时候，首部需要一个字节来记录字符的个数。<br>
当内容大于 255 的字符的时候，首部需要 2 个自己来保存长度。<br><br><br><br><br>整数类型通常是标识列的最佳选择，应该避免使用字符串类型作为标识列，因为它们很耗空间，并且比数字类型慢。<br>整数类型很快并且可以使用AUTO_INCREMENT。 <br> 对于完全随机的字符串也需要多加注意，例如MD5(),SHA1()或者UUID()产生的字符串。这些函数生成的新值会任意分布在很大的空间内，这会导致INSERT以及一些SELECT语句变得很慢：<br>
<br>因为插入值会随机的写入到索引的不同位置，所以使得INSERT语句更慢。这会导致页分裂、磁盘随机访问。
<br>SELECT语句会变的更慢，因为逻辑上相邻的行会分布在磁盘和内存的不同地方。
<br>随机值导致缓存对所有类型的查询语句效果都很差，因为会使得缓存赖以工作的局部性原理失效。
]]></description><link>04、数据库\01、mysql\02、mysql-数据类型.html</link><guid isPermaLink="false">04、数据库/01、MySQL/02、MySQL 数据类型.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Fri, 05 Apr 2024 09:36:48 GMT</pubDate></item><item><title><![CDATA[03、MySQL 索引]]></title><description><![CDATA[ 
 <br><br>索引是帮助 MySQL 高效获取数据的数据结构（有序）。在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查询算法，这种数据结构就是索引。<br>优点：<br>
<br>提高数据检索效率，降低数据库的 IO 成本
<br>通过索引列对数据进行排序，降低数据排序的成本，降低 CPU 的消耗
<br>缺点：<br>
<br>索引列也是要占用空间的
<br>索引大大提高了查询效率，但降低了更新的速度，比如 INSERT、UPDATE、DELETE
<br><br><br><br><br>![二叉树](./. Pic-MySQL/二叉树_20220316153214227108. Png "二叉树")<br>二叉树的缺点可以用红黑树来解决：<br>
![红黑树](./. Pic-MySQL/红黑树_20220316163142686602. Png "红黑树")<br>
红黑树也存在大数据量情况下，层级较深，检索速度慢的问题。<br>为了解决上述问题，可以使用 B-Tree 结构。<br>
B-Tree (多路平衡查找树) 以一棵最大度数（max-degree，指一个节点的子节点个数）为 5（5 阶）的 b-tree 为例（每个节点最多存储 4 个 key，5 个指针）<br>![B-Tree 结构](./. Pic-MySQL/B-Tree 结构_20220316163813441163. Png "B-Tree 结构")<br>
B-Tree 的数据插入过程动画参照： <a rel="noopener" class="external-link" href="https://www.bilibili.com/video/BV1Kr4y1i7ru?p=68" target="_blank">https://www.bilibili.com/video/BV1Kr4y1i7ru?p=68</a><br>
演示地址： <a rel="noopener" class="external-link" href="https://www.cs.usfca.edu/~galles/visualization/BTree.html" target="_blank">https://www.cs.usfca.edu/~galles/visualization/BTree.html</a>
<br><br>结构图：<br>![B+Tree 结构图](./. Pic-MySQL/B+Tree 结构图_20220316170700591277. Png "B+Tree 结构图")<br>
演示地址： <a rel="noopener" class="external-link" href="https://www.cs.usfca.edu/~galles/visualization/BPlusTree.html" target="_blank">https://www.cs.usfca.edu/~galles/visualization/BPlusTree.html</a>
<br>与 B-Tree 的区别：<br>
<br>所有的数据都会出现在叶子节点
<br>叶子节点形成一个单向链表
<br>MySQL 索引数据结构对经典的 B+Tree 进行了优化。在原 B+Tree 的基础上，增加一个指向相邻叶子节点的链表指针，就形成了带有顺序指针的 B+Tree，提高区间访问的性能。<br>![MySQL B+Tree 结构图](./. Pic-MySQL/结构图_20220316171730865611. Png "MySQL B+Tree 结构图")<br><br>哈希索引就是采用一定的 hash 算法，将键值换算成新的 hash 值，映射到对应的槽位上，然后存储在 hash 表中。<br>
如果两个（或多个）键值，映射到一个相同的槽位上，他们就产生了 hash 冲突（也称为 hash 碰撞），可以通过链表来解决。<br>![Hash 索引原理图](./. Pic-MySQL/Hash 索引原理图_20220317143226150679. Png "Hash 索引原理图")<br>特点：<br>
<br>Hash 索引只能用于对等比较（=、in），不支持范围查询（betwwn、&gt;、&lt;、...）
<br>无法利用索引完成排序操作
<br>查询效率高，通常只需要一次检索就可以了，效率通常要高于 B+Tree 索引
<br>存储引擎支持：<br>
<br>Memory
<br>InnoDB: 具有自适应 hash 功能，hash 索引是存储引擎根据 B+Tree 索引在指定条件下自动构建的
<br><br><br>在 InnoDB 存储引擎中，根据索引的存储形式，又可以分为以下两种：<br><br>演示图：<br>![大致原理](./. Pic-MySQL/原理图_20220318194454880073. Png "大致原理")<br>
![演示图](./. Pic-MySQL/演示图_20220319215403721066. Png "演示图")<br>聚集索引选取规则：<br>
<br>如果存在主键，主键索引就是聚集索引
<br>如果不存在主键，将使用第一个唯一 (UNIQUE) 索引作为聚集索引
<br>如果表没有主键或没有合适的唯一索引，则 InnoDB 会自动生成一个 rowid 作为隐藏的聚集索引
<br><br>1. 以下 SQL 语句，哪个执行效率高？为什么？<br>select * from user where id = 10;
select * from user where name = 'Arm';
-- 备注：id为主键，name字段创建的有索引
复制<br>答：第一条语句，因为第二条需要回表查询，相当于两个步骤。<br>2. InnoDB 主键索引的 B+Tree 高度为多少？<br>答：假设一行数据大小为 1 k，一页中可以存储 16 行这样的数据。InnoDB 的指针占用 6 个字节的空间，主键假设为 bigint，占用字节数为 8.<br>
可得公式：n * 8 + (n + 1) * 6 = 16 * 1024，其中 8 表示 bigint 占用的字节数，n 表示当前节点存储的 key 的数量，(n + 1) 表示指针数量（比 key 多一个）。算出 n 约为 1170。<br>如果树的高度为 2，那么他能存储的数据量大概为：1171 * 16 = 18736；<br>
如果树的高度为 3，那么他能存储的数据量大概为：1171 * 1171 * 16 = 21939856。<br>另外，如果有成千上万的数据，那么就要考虑分表，涉及运维篇知识。<br><br>创建索引：<br>
CREATE [ UNIQUE | FULLTEXT ] INDEX index_name ON table_name (index_col_name, ...);<br>
如果不加 CREATE 后面不加索引类型参数，则创建的是常规索引<br>查看索引：<br>
SHOW INDEX FROM table_name;<br>删除索引：<br>
DROP INDEX index_name ON table_name;<br>案例：<br>-- name字段为姓名字段，该字段的值可能会重复，为该字段创建索引
create index idx_user_name on tb_user(name);
-- phone手机号字段的值非空，且唯一，为该字段创建唯一索引
create unique index idx_user_phone on tb_user (phone);
-- 为profession, age, status创建联合索引
create index idx_user_pro_age_stat on tb_user(profession, age, status);
-- 为email建立合适的索引来提升查询效率
create index idx_user_email on tb_user(email);

-- 删除索引
drop index idx_user_email on tb_user;
复制<br><br><br>如果索引关联了多列（联合索引），要遵守最左前缀法则，最左前缀法则指的是查询从索引的最左列开始，并且不跳过索引中的列。<br>
如果跳跃某一列，索引将部分失效（后面的字段索引失效）。<br>联合索引中，出现范围查询（&lt;, &gt;），范围查询右侧的列索引失效。可以用&gt;=或者&lt;=来规避索引失效问题。<br><br>
<br>在索引列上进行运算操作，索引将失效。如：explain select * from tb_user where substring(phone, 10, 2) = '15';
<br>字符串类型字段使用时，不加引号，索引将失效。如：explain select * from tb_user where phone = 17799990015;，此处 phone 的值没有加引号
<br>模糊查询中，如果仅仅是尾部模糊匹配，索引不会是失效；如果是头部模糊匹配，索引失效。如：explain select * from tb_user where profession like '%工程';，前后都有 % 也会失效。
<br>用 or 分割开的条件，如果 or 其中一个条件的列没有索引，那么涉及的索引都不会被用到。
<br>如果 MySQL 评估使用索引比全表更慢，则不使用索引。
<br><br>是优化数据库的一个重要手段，简单来说，就是在 SQL 语句中加入一些人为的提示来达到优化操作的目的。<br>例如，使用索引：<br>
explain select * from tb_user use index(idx_user_pro) where profession="软件工程";<br>
不使用哪个索引：<br>
explain select * from tb_user ignore index(idx_user_pro) where profession="软件工程";<br>
必须使用哪个索引：<br>
explain select * from tb_user force index(idx_user_pro) where profession="软件工程";<br>Use 是建议，实际使用哪个索引 MySQL 还会自己权衡运行速度去更改，force 就是无论如何都强制使用该索引。<br><br>尽量使用覆盖索引（查询使用了索引，并且需要返回的列，在该索引中已经全部能找到），减少 select *。<br>Explain 中 extra 字段含义：<br>
using index condition：查找使用了索引，但是需要回表查询数据<br>
using where; using index;：查找使用了索引，但是需要的数据都在索引列中能找到，所以不需要回表查询<br>如果在聚集索引中直接能找到对应的行，则直接返回行数据，只需要一次查询，哪怕是 select *；如果在辅助索引中找聚集索引，如 select id, name from xxx where name='xxx';，也只需要通过辅助索引 (name) 查找到对应的 id，返回 name 和 name 索引对应的 id 即可，只需要一次查询；如果是通过辅助索引查找其他字段，则需要回表查询，如 select id, name, gender from xxx where name='xxx';<br>所以尽量不要用 select *，容易出现回表查询，降低效率，除非有联合索引包含了所有字段<br>面试题：一张表，有四个字段（id, username, password, status），由于数据量大，需要对以下 SQL 语句进行优化，该如何进行才是最优方案：<br>
select id, username, password from tb_user where username='itcast';<br>解：给 username 和 password 字段建立联合索引，则不需要回表查询，直接覆盖索引<br><br>当字段类型为字符串（varchar, text 等）时，有时候需要索引很长的字符串，这会让索引变得很大，查询时，浪费大量的磁盘 IO，影响查询效率，此时可以只降字符串的一部分前缀，建立索引，这样可以大大节约索引空间，从而提高索引效率。<br>语法：create index idx_xxxx on table_name(columnn(n));<br>
前缀长度：可以根据索引的选择性来决定，而选择性是指不重复的索引值（基数）和数据表的记录总数的比值，索引选择性越高则查询效率越高，唯一索引的选择性是 1，这是最好的索引选择性，性能也是最好的。<br>
求选择性公式：<br>select count(distinct email) / count(*) from tb_user;
select count(distinct substring(email, 1, 5)) / count(*) from tb_user;
复制<br>Show index 里面的 sub_part 可以看到接取的长度<br><br>单列索引：即一个索引只包含单个列<br>
联合索引：即一个索引包含了多个列<br>
在业务场景中，如果存在多个查询条件，考虑针对于查询字段建立索引时，建议建立联合索引，而非单列索引。<br>单列索引情况：<br>
explain select id, phone, name from tb_user where phone = '17799990010' and name = '韩信';<br>
这句只会用到 phone 索引字段<br><br>
<br>多条件联合查询时，MySQL 优化器会评估哪个字段的索引效率更高，会选择该索引完成本次查询
<br><br>
<br>针对于数据量较大，且查询比较频繁的表建立索引
<br>针对于常作为查询条件（where）、排序（order by）、分组（group by）操作的字段建立索引
<br>尽量选择区分度高的列作为索引，尽量建立唯一索引，区分度越高，使用索引的效率越高
<br>如果是字符串类型的字段，字段长度较长，可以针对于字段的特点，建立前缀索引
<br>尽量使用联合索引，减少单列索引，查询时，联合索引很多时候可以覆盖索引，节省存储空间，避免回表，提高查询效率
<br>要控制索引的数量，索引并不是多多益善，索引越多，维护索引结构的代价就越大，会影响增删改的效率
<br>如果索引列不能存储 NULL 值，请在创建表时使用 NOT NULL 约束它。当优化器知道每列是否包含 NULL 值时，它可以更好地确定哪个索引最有效地用于查询
]]></description><link>04、数据库\01、mysql\03、mysql-索引.html</link><guid isPermaLink="false">04、数据库/01、MySQL/03、MySQL 索引.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Fri, 05 Apr 2024 09:37:34 GMT</pubDate></item><item><title><![CDATA[04、MySQL 事务和隔离级别]]></title><description><![CDATA[ 
 <br><br>事务是一组操作的集合，事务会把所有操作作为一个整体一起向系统提交或撤销操作请求，这些操作要么同时成功，要么同时失败。<br><br>经典案例 - 资金转账 ：<br>-- 1. 查询张三账户余额
select * from account where name = '张三';
-- 2. 将张三账户余额-1000
update account set money = money - 1000 where name = '张三';
-- 此语句出错后张三钱减少但是李四钱没有增加
-- 模拟sql语句错误,此时李四无法收到钱
-- 3. 将李四账户余额+1000
update account set money = money + 1000 where name = '李四';
复制<br>1、MySQL 是默认自动开启事务的，可以修改事务提交方式为手动：<br>-- 查看事务提交方式，1为自动提交，0为手动提交
SELECT @@AUTOCOMMIT;
-- 设置事务提交方式，该设置只对当前会话有效
SET @@AUTOCOMMIT = 0;

-- 提交事务
COMMIT;
-- 回滚事务
ROLLBACK;

-- 设置手动提交后上面代码改为：
select * from account where name = '张三';
update account set money = money - 1000 where name = '张三';
update account set money = money + 1000 where name = '李四';
commit;
复制<br>2、语句开启事务：<br>-- 开启事务： START TRANSACTION 或 BEGIN TRANSACTION;
start transaction;
select * from account where name = '张三';
update account set money = money - 1000 where name = '张三';
update account set money = money + 1000 where name = '李四';
-- 提交事务：COMMIT  回滚事务：ROLLBACK
commit;
复制<br><br>
<br>原子性 (Atomicity)：事务是不可分割的最小操作单元，要么全部成功，要么全部失败
<br>一致性 (Consistency)：事务完成时，必须使所有数据都保持一致状态（确保正确）
<br>隔离性 (Isolation)：数据库系统提供的隔离机制，保证事务不受事物影响独立运行
<br>持久性 (Durability)：事务一旦提交或回滚，它对数据库中的数据的改变就是永久的
<br>一致性：如上面的转账，最终要保证一个扣钱，一个加钱，最终的钱的和是一致的。<br>
持久性：每个数据库对应一个文件夹，每个文件夹中存放的表会对应一个或多个文件（根据使用引擎决定），默认是 .ibd 文件。<br>
<img src="\04、数据库\01、mysql\assets\04、mysql-事务和隔离级别\img-20240408_214133.png"><br>
<img src="\04、数据库\01、mysql\assets\04、mysql-事务和隔离级别\img-20240408_214215.png"><br><br>会产生如下问题：<br><br>脏读：<br>
<img alt="assets/04、MySQL 事务和隔离级别/img-20240408_214605.png" src="\04、数据库\01、mysql\assets\04、mysql-事务和隔离级别\img-20240408_214605.png" style="width: 625px; max-width: 100%;"><br>不可重复读：<br><img alt="assets/04、MySQL 事务和隔离级别/img-20240408_215149.png" src="\04、数据库\01、mysql\assets\04、mysql-事务和隔离级别\img-20240408_215149.png" style="width: 700px; max-width: 100%;"><br>幻读：<br>
<img alt="assets/04、MySQL 事务和隔离级别/img-20240408_215305.png" src="\04、数据库\01、mysql\assets\04、mysql-事务和隔离级别\img-20240408_215305.png" style="width: 750px; max-width: 100%;"><br><br>并发事务隔离级别：<br><br>
<br>√表示在当前隔离级别下该问题会出现
<br>Serializable 性能最低；Read uncommitted 性能最高，数据安全性最差
<br>查看事务隔离级别：<br>-- 查看事务隔离级别
SELECT @@TRANSACTION_ISOLATION;

-- 设置事务隔离级别：
-- SESSION 是会话级别，表示只针对当前会话有效，GLOBAL 表示对所有会话有效
SET [ SESSION | GLOBAL ] TRANSACTION ISOLATION LEVEL {READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE };
复制<br><a rel="noopener" class="external-link" href="https://www.bilibili.com/video/BV1Kr4y1i7ru?p=55&amp;spm_id_from=pageDriver&amp;vd_source=57bf60d2c975ff5968c2cb778e3f20e0" target="_blank">https://www.bilibili.com/video/BV1Kr4y1i7ru?p=55&amp;spm_id_from=pageDriver&amp;vd_source=57bf60d2c975ff5968c2cb778e3f20e0</a><br><br><img src="\04、数据库\01、mysql\assets\04、mysql-事务和隔离级别\img-20240407_213354.png"><br><br><br>重做日志，记录的是事务提交时数据页的物理修改，MySQL 通过使用 redo log 来保证事务的持久性。如果事务提交之前系统崩溃了，数据的修改仍然可以通过 redo log 进行恢复。<br>该日志文件由两部分组成：重做日志缓冲（redo log buffer) 以及重做日志文件（redo log file），前者是在内存中，后者在磁盘中。当事务提交之后会把所有修改信息都存到该日志文件中，用于在刷新脏页到磁盘，发生错误时，进行数据恢复使用。<br><br> InnoDB 存储引擎是以页为单位来管理存储空间的，往 MySQL 插入的数据最终都是存在于页的。为了减少磁盘 IO 开销，还有一个叫做 Buffer Pool 的区域，存在于内存中。当我们的数据对应的页不存在于 Buffer Pool 中的话， MySQL 会先将磁盘上的页缓存到 Buffer Pool 中，这样后面我们直接操作的就是 Buffer Pool 中的页，这样大大提高了读写性能。<br>在事务提交时，会将 redo log 按照刷盘策略刷到磁盘上去，redo log 是先记录日志，再修改页。这样即使 MySQL 宕机了，重启之后也能恢复未能写入磁盘的数据，从而保证事务的持久性。<br><img src="\04、数据库\01、mysql\assets\04、mysql-事务和隔离级别\img-20240407_214955.png"><br>为什么每次修改 Buffer Pool 中的页之后不直接刷盘呢？这样不就不需要 redo log 了嘛！<br>这种方式必然是不行的，性能非常差。最大的问题就是 InnoDB 页的大小一般为 16 KB，而页又是磁盘和内存交互的基本单位。这就导致即使我们只修改了页中的几个字节数据，一次刷盘操作也需要将 16 KB 大小的页整个都刷新到磁盘中。而且，这些修改的页可能并不相邻，也就是说这还是随机 IO。<br>采用 redo log 的方式就可以避免这种性能问题，因为 redo log 的刷盘性能很好。首先，redo log 的写入属于顺序 IO。其次，一行 redo log 记录只占几十个字节。<br>另外，Buffer Pool 中的页（脏页）在某些情况下（比如 redo log 快写满了）也会进行刷盘操作。不过，这里的刷盘操作会合并写入，更高效地顺序写入到磁盘。<br><br>InnoDB 将 redo log 刷到磁盘上有几种情况：<br>
<br>
事务提交：当事务提交时，log buffer 里的 redo log 会被刷新到磁盘。可以通过 innodb_flush_log_at_trx_commit 参数控制，后面会提到。

<br>
Log buffer 空间不足时：log buffer 中缓存的 redo log 已经占满了 log buffer 总容量的大约一半左右，就需要把这些日志刷新到磁盘。

<br>
事务日志缓冲区满：InnoDB 使用一个事务日志缓冲区（transaction log buffer）来暂时存储事务的重做日志条目。当缓冲区满时，会触发日志的刷新，将日志写入磁盘。

<br>
Checkpoint（检查点）：InnoDB 定期会执行检查点操作，将内存中的已修改但尚未写入磁盘的数据刷新到磁盘，并且会将相应的重做日志一同刷新，以确保数据的一致性。

<br>
后台刷新线程：InnoDB 启动了一个后台线程，负责周期性（每隔 1 秒）地将已修改但尚未写入磁盘的数据页刷新到磁盘，并将相关的重做日志一同刷新。也就是说，一个没有提交事务的 redo log 记录，也可能会被刷盘。

<br>
正常关闭服务器：MySQL 关闭的时候，redo log 都会刷入到磁盘里去。

<br><br>根据 MySQL 配置的刷盘策略的不同，MySQL 宕机之后可能会存在轻微的数据丢失问题。<br>通过 innodb_flush_log_at_trx_commit 设置正确的刷盘策略。值有 3 种，也就是共有 3 种刷盘策略：<br>0：设置为 0 的时候，表示每次事务提交时不进行刷盘操作。这种方式性能最高，但是也最不安全，因为如果 MySQL 挂了或宕机了，可能会丢失最近 1 秒内的事务。<br>1：设置为 1 的时候，表示每次事务提交时都将进行刷盘操作。这种方式性能最低，但是也最安全，因为只要事务提交成功，redo log 记录就一定在磁盘里，不会有任何数据丢失。<br>2：设置为 2 的时候，表示每次事务提交时都只把 log buffer 里的 redo log 内容写入 page cache（文件系统缓存）。Page cache 是专门用来缓存文件的，这里被缓存的文件就是 redo log 文件。这种方式的性能和安全性都介于前两者中间。<br>性能：0 &gt; 2 &gt; 1 ，安全性：1 &gt; 2 &gt; 0 。<br>刷盘策略 innodb_flush_log_at_trx_commit 的默认值为 1，设置为 1 的时候才不会丢失任何数据。为了保证事务的持久性，我们必须将其设置为 1。当然了，如果你的项目能容忍轻微的数据丢失的话，那将 innodb_flush_log_at_trx_commit 的值设置为 2 或许是更好的选择。<br><br>Binlog 主要用于数据库还原，属于数据级别的数据恢复，主从复制是 binlog 最常见的一个应用场景。<br>
Redolog 主要用于保证事务的持久性，属于事务级别的数据恢复。<br>Binlog 属于所有存储引擎共有的，因为 binlog 是 MySQL 的 Server 层实现的。<br>
Redolog 属于 InnoDB 引擎特有的，<br>Binlog 属于逻辑日志，主要记录的是数据库执行的所有 DDL 和 DML 语句。<br>
Redolog 属于物理日志，主要记录的是某个页的修改。<br>Binlog 通过追加的方式进行写入，大小没有限制。<br>
Redo log 采用循环写的方式进行写入，大小固定，当写到结尾时，会回到开头循环写日志。<br><br>Undo log 如何保证事务的原子性？<br>每一个事务对数据的修改都会被记录到 undo log ，当执行事务过程中出现错误或者需要执行回滚操作的话，MySQL 可以利用 undo log 将数据恢复到事务开始之前的状态。<br>Undo log 属于逻辑日志，记录的是 SQL 语句，比如说事务执行一条 DELETE 语句，那 undo log 就会记录一条相对应的 INSERT 语句。<br>除了保证事务的原子性，undo log 还有什么用？<br>InnoDB 存储引擎中 MVCC 的实现用到了 undo log 。当用户读取一行记录时，若该记录已经被其他事务占用，当前事务可以通过 undo log 读取之前的行版本信息，以此实现非锁定读取。<br><br><br>]]></description><link>04、数据库\01、mysql\04、mysql-事务和隔离级别.html</link><guid isPermaLink="false">04、数据库/01、MySQL/04、MySQL 事务和隔离级别.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Mon, 08 Apr 2024 13:59:24 GMT</pubDate><enclosure url="04、数据库\01、mysql\assets\04、mysql-事务和隔离级别\img-20240408_214133.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;04、数据库\01、mysql\assets\04、mysql-事务和隔离级别\img-20240408_214133.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[05、MySQL 体系结构]]></title><description><![CDATA[ 
 <br><br><img src="\04、数据库\01、mysql\assets\05、mysql-体系结构\img-20240405_152756.png"><br><br>1、连接层<br>
客户端和链接的服务，主要完成连接处理、授权认证、及相关的安全方案。服务器也会为安全接入的每个客户端验证它所具有的操作权限。<br>2、服务层<br>
第二层架构主要完成大多数的核心服务功能，如 SQL 接口，并完成缓存的查询，SQL 的分析和优化，部分内置函数的执行。所有跨存储引擎的功能也在这一层实现，如存储过程、函数、触发器等。<br>3、引擎层<br>
存储引擎真正的负责了 MySQL 中数据的存储和提取，服务器通过 API 和存储引擎进行通信。不同的存储引擎具有不同的功能，可以根据来选取合适的存储引擎，而且是可拓展、可插拔的。索引实在引擎层，索引不同引擎的索引结构不一样。<br>4、存储层<br>
数据存储在文件系统之上，并完成与存储引擎的交互，存放数据和各种日志。<br><br>可以看出MySQL是由连接池、管理工具和服务、SQL接口、解析器、优化器、缓存、存储引擎、文件系统组成。<br>从上到下依次是：<br><br>由于每次建立建立需要消耗很多时间，连接池的作用就是将这些连接缓存下来，下次可以直接用已经建立好的连接，提升服务器性能。<br><br>系统管理和控制工具，例如备份恢复、Mysql复制、集群等。<br><br>接受用户的 SQL 命令，并且返回用户需要查询的结果。比如 select ... From 就是调用 SQL 接口<br><br>SQL 命令传递到解析器的时候会被解析器验证和解析。解析器主要功能：<br>
1、将 SQL 语句分解成数据结构，后续步骤的传递和处理就是基于这个结构的。<br>
2、将 SQL 语句分解成数据结构，后续步骤的传递和处理就是基于这个结构的。<br><br>查询优化器，SQL 语句在查询之前会使用查询优化器对查询进行优化。<br><br>查询缓存，如果查询缓存有命中的查询结果，查询语句就可以直接去查询缓存中取数据。这个缓存机制是由一系列小缓存组成的。比如表缓存，记录缓存，key 缓存，权限缓存等。<br><br>存储引擎是基于表的，而不是数据库。<br>
查询优化器会调用存储引擎的接口，去执行 SQL，也就是说真正执行 SQL 的动作是在存储引擎中完成的。数据是被存放在内存或者是磁盘中的<br>执行器（待确定）<br>
为前面那些组件的操作最终必须通过执行器去调用存储引擎接口才能被执行。执行器最终最根据一系列的执行计划去调用存储引擎的接口去完成 SQL 的执行<br><br>存放数据和各种日志文件。<br><br><br>JDBC 是 Java 提供的一种标准化的数据库访问方式，而数据库驱动则是实现了 JDBC 规范的具体库，用于与数据库的交互。<br>通过使用JDBC接口，开发人员可以编写与数据库无关的代码，只需更换相应的数据库驱动即可连接到不同的数据库系统。<br><br>Java 层的数据库连接池有 Druid、C3P0、DBCP。<br>&nbsp;MySQL 的架构体系中也已经提供了这样的一个池子，也是数据库连池。双方都是通过数据库连接池来管理各个连接的，这样一方面线程之前不需要是争抢连接，更重要的是不需要反复的创建的销毁连接。<br><img src="\04、数据库\01、mysql\assets\05、mysql-体系结构\img-20240405_154736.png"><br><br>MySQL 中处理请求的线程在获取到请求以后获取 SQL 语句去交给 SQL 接口去处理。<br>SQL 是写给我们人看的，解析器翻译成 MySQL 自己能认识的语言。<br><br>IO 成本: 即从磁盘把数据加载到内存的成本，默认情况下，读取数据页的 IO 成本是 1，MySQL 是以页的形式读取数据的，即当用到某个数据时，并不会只读取这个数据，而会把这个数据相邻的数据也一起读到内存中，这就是有名的程序局部性原理，所以 MySQL 每次会读取一整页，一页的成本就是 1。所以 IO 的成本主要和页的大小有关<br>CPU 成本：将数据读入内存后，还要检测数据是否满足条件和排序等 CPU 操作的成本，显然它与行数有关，默认情况下，检测记录的成本是 0.2。<br>MySQL 优化器 会计算 「IO 成本 + CPU」 成本最小的那个索引来执行<br>查询优化器会调用存储引擎的接口，去执行 SQL，也就是说真正执行 SQL 的动作是在存储引擎中完成的。数据是被存放在内存或者是磁盘中的（存储引擎是一个非常重要的组件，后面会详细介绍）<br><br>查询优化器会调用存储引擎的接口，去执行 SQL，也就是说真正执行 SQL 的动作是在存储引擎中完成的。数据是被存放在内存或者是磁盘中的（存储引擎是一个非常重要的组件，后面会详细介绍）<br><br>存储引擎就是存储数据、建立索引、更新/查询数据等技术的实现方式。<br>
存储引擎是基于表而不是基于库的，所以存储引擎也可以被称为表引擎。<br>
默认存储引擎是 InnoDB。<br>相关操作：<br>-- 查询建表语句
show create table account;
-- 建表时指定存储引擎
CREATE TABLE 表名(
	...
) ENGINE=INNODB;
-- 查看当前数据库支持的存储引擎
show engines;
复制<br><br>InnoDB 是一种兼顾高可靠性和高性能的通用存储引擎，在 MySQL 5.5 之后，InnoDB 是默认的 MySQL 引擎。<br>特点：<br>
<br>DML 操作遵循 ACID 模型，支持事务
<br>行级锁，提高并发访问性能
<br>支持外键约束，保证数据的完整性和正确性
<br>文件结构：<br>
<img src="\04、数据库\01、mysql\assets\05、mysql-体系结构\img-20240407_201315.png"><br>{}.ibd: {} 代表表名，InnoDB 引擎的每张表都会对应这样一个表空间文件，存储该表的表结构（frm、8.0 后 sdi）、数据和索引。<br>查看 Mysql 变量 innodb_file_per_table  ：<br>
show variables like 'innodb_file_per_table';<br>
决定多张表共享一个表空间还是每张表对应一个表空间，默认打开。<br>从 idb 文件提取表结构数据：<br>
（在 cmd 运行）<br>
ibd2sdi xxx. Ibd <br><br><img src="\04、数据库\01、mysql\assets\05、mysql-体系结构\img-20240405_163109.png"><br><img src="\04、数据库\01、mysql\assets\05、mysql-体系结构\img-20240405_162451.png"><br>1）表空间 - TableSpace<br>
每个 ibd 文件对应一个表空间，一个 mysql 实例可以对应多个表空间，用于存储记录、索引等数据。<br>2）段 - Segment<br>
分为数据段（Leaf node segment）、索引段（Non-leaf node segment）、回滚段（Rollback segment）。<br>
InnoDB 是索引组织表，数据段就是 B+ 树的叶子节点，索引段即为 B+树的非叶子节点。<br>
段用来管理多个 Extent（区）。<br>3）区 - Extent<br>
表空间的单元结构，每一个区的大小为 1 M。<br>
默认情况下，InnoDB 存储引擎页大小为 16 K，即一个区中一共有 64 个连续的页。<br>4）页 - Page<br>
是 InnoDB 存储引擎磁盘管理的最小单元，每个页的大小默认为 16 KB。<br>
为了保证页的连续性，InnoDB 存储引擎每次从磁盘申请 4-5 个区。<br>5）行 - row<br>
InnoDB 存储引擎数据是按行进行存放的。<br>
Trx_id：每次对某条记录进行改动时，都会把对应的事务 id 赋值给 Trx_id 隐藏列。<br>
Roll_pointer：每次对某条记录进行改动时，都会把旧版本写入到 undo 日志中，然后这个隐藏列就相当于一个指针，可以通过它来找到该记录修改前的信息。<br><br><br><br>MyISAM 是 MySQL 早期的默认存储引擎。<br>特点：<br>
<br>不支持事务，不支持外键
<br>支持表锁，不支持行锁
<br>访问速度快
<br>文件结构：<br><img src="\04、数据库\01、mysql\assets\05、mysql-体系结构\img-20240407_202231.png"><br>
<br>{}.sdi: 存储表结构信息
<br>{}.MYD: 存储数据
<br>{}.MYI: 存储索引
<br><br>Memory 引擎的表数据是存储在内存中的，受硬件问题、断电问题的影响，只能将这些表作为临时表或缓存使用。<br>特点：<br>
<br>存放在内存中，速度快
<br>Hash 索引（默认）
<br>文件结构：<br>
<br>{}.sdi : 存储表结构信息
<br><br><br>在选择存储引擎时，应该根据应用系统的特点选择合适的存储引擎。对于复杂的应用系统，还可以根据实际情况选择多种存储引擎进行组合。<br>
<br>InnoDB: 如果应用对事物的完整性有比较高的要求，在并发条件下要求数据的一致性，数据操作除了插入和查询之外，还包含很多的更新、删除操作，则 InnoDB 是比较合适的选择
<br>MyISAM: 如果应用是以读操作和插入操作为主，只有很少的更新和删除操作，并且对事务的完整性、并发性要求不高，那这个存储引擎是非常合适的。
<br>Memory: 将所有数据保存在内存中，访问速度快，通常用于临时表及缓存。Memory 的缺陷是对表的大小有限制，太大的表无法缓存在内存中，而且无法保障数据的安全性
<br>电商中的足迹和评论适合使用 MyISAM 引擎，缓存适合使用 Memory 引擎。<br>但是现在 MyISAM 功能基本上被 MongoDB 取代，Memory 功能基本上被 redis 取代。<br><br>数据文件和上面的存储引擎挂钩，已经说明过。<br><br>在服务器运行过程中，会产生各种各样的日志，比如常规的查询日志、错误日志、二进制日志、redo 日志、Undo 日志等等，日志文件记录了影响 MySQL 数据库的各种类型活动。<br>MySQL 中常见的日志类型主要有下面几类：<br>错误日志：<br>
<br>错误日志（Error Log）：对 MySQL 的启动、运行、关闭过程进行了记录。
<br>二进制日志：<br>
<br>二进制日志（Binary Log ）：记录了 SQL 执行的所有修改操作
<br>中继日志（Relay Log）：&nbsp;主从复制过程中使用的一种日志类型，在从服务器上记录主服务器上所有的二进制日志（Binary log）的信息  
<br> SQL 日志：<br>
<br>DDL Log ： (Metadata log) &nbsp;：记录DDL操作的一种日志类型。  
<br>查询日志（General Log）：」&nbsp;记录MySQL Server层的所有查询语句  
<br>慢查询日志 （Slow Query Log）：记录执行时间过长的查询语句
<br>针对 InnoDB 存储引擎，有事务日志 (redo log 和 undo log) ：<br>
<br>Redo Log&nbsp;：重做日志，记录事务过程中的修改操作，以保证事务的安全性。  
<br>Undo Log：&nbsp;回滚日志，用于撤销与事务相关的修改操作，以保证事务的原子性
<br><br>错误日志文件对 MySQL 的启动、运行、关闭过程进行了记录。<br>
帮助管理员或开发人员定位原因并进行问题排查。<br>
常见的错误信息包括数据库启动失败、连接错误、SQL 语句错误、权限不足、磁盘空间不足等，以及由于系统和硬件等因素导致的程序崩溃和运行时错误。<br>用户可以通过下面命令来查看错误日志文件的位置：<br>show variables like '%log_error%';
复制<br><img src="\04、数据库\01、mysql\assets\05、mysql-体系结构\img-20240405_163450.png"><br><br>Binlog 是指二进制日志文件，主要记录了对 MySQL 数据库执行了更改的所有操作，包括表结构变更（CREATE、ALTER、DROP TABLE…）、表数据修改（INSERT、UPDATE、DELETE...），不包括 SELECT、SHOW 这类没有对数据库造成更改的操作。即 DDL、DML，不包含 DQL。主要用于 MySQL 的数据恢复、备份和主从复制等方面。<br><br>查看是否开启：<br>show variables like '%log_bin%'
复制<br><img src="\04、数据库\01、mysql\assets\05、mysql-体系结构\img-20240407_204400.png"><br><img src="\04、数据库\01、mysql\assets\05、mysql-体系结构\img-20240407_204422.png"><br>可以使用如下命令查看所有二进制日志列表：<br>show binary logs;
复制<br>可以看到，binlog 日志文件名为 文件名. 00000* 形式。可以通过下面的命令查看日志的具体内容。<br>show binlog events in 'binlog. 000008' limit 10; 
复制<br>这里一定要指定 limit，不然查询出来的日志文件内容太多。另外， MySQL 内置了 binlog 查看工具 mysqlbinlog，可以解析二进制文件。<br>
`<br>
binlog 通过追加的方式进行写入，大小没有限制。并且，我们可以通过 max_binlog_size 参数设置每个 binlog 文件的最大容量，当文件大小达到给定值之后，会生成新的 binlog 文件来保存日志，不会出现前面写的日志被覆盖的情况。<br><br>一共有 3 种类型二进制记录方式，推荐使用 Row 模式：<br>
<br>
Statement 模式 ：每一条会修改数据的 SQL 都会被记录在 binlog 中，如 inserts, updates, deletes。

<br>
Row 模式：影响的每一行具体变更都会被记录在 binlog 中。Row 模式记录了修改前的表记录和修改后的表记录

<br>
Mixed 模式 ：Statement 模式和 Row 模式的混合。默认使用 Statement 模式，少数特殊场景自动切换到 Row 模式。

<br>MySQL 5.1.5 之前 binlog 的格式只有 Statement，<br>
MySQL 5.1.5 开始支持 ROW 格式的 binlog，<br>
MySQL 5.1.8 版本开始，MySQL 开始支持 MIXED 格式的 binlog。<br>
MySQL 5.7.7 之前，默认使用 Statement 模式。<br>
MySQL 5.7.7 开始默认使用 Row 模式。<br>相比较于 Row 模式来说，Statement 模式下的日志文件更小，磁盘 IO 压力也较小，性能更好。不过，其准确性相比于 Row 模式要差。<br>可以使用如下命令查看 binlog 使用的格式：<br> show variables like '%binlog_format%';<br>
<img src="\04、数据库\01、mysql\assets\05、mysql-体系结构\img-20240407_205447.png"><br><br>Binlog 最主要的应用场景是主从复制，主备、主主、主从都离不开 binlog，需要依靠 binlog 来同步数据，保证数据一致性。<br>Master 主库在事务提交时，会把数据变更记录在二进制日志文件 binlog 中。<br>从库读取主库的二进制日志文件 binlog ，写入到从库的中继日志 Relay Log 。<br><br>对于 InnoDB 存储引擎而言，事务在执行过程中，会先把日志写入到 binlog cache 中，只有在事务提交的时候，才会把 binlog cache 中的日志持久化到磁盘上的 binlog 文件中。写入内存的速度更快，这样做也是为了效率考虑。<br>因为一个事务的 binlog 不能被拆开，无论这个事务多大，也要确保一次性写入，所以系统会给每个线程分配一个块内存作为 binlog cache。我们可以通过 binlog_cache_size 参数控制单个线程 binlog cache 大小，如果存储内容超过了这个参数，就要暂存到磁盘。<br>那么 binlog 是什么时候刷到磁盘中的呢？ 可以通过 sync_binlog 参数控制 biglog 的刷盘时机，取值范围是 0-N，默认为 0：<br>0：不去强制要求，由系统自行判断何时写入磁盘<br>1：每次提交事务的时候都要将 binlog 写入磁盘<br>N：每 N 个事务，才会将 binlog 写入磁盘<br>MySQL 5.7 之前， sync_binlog 默认值为 0。<br>
在 MySQL 5.7 之后， sync_binlog 默认值为 1。<br>
如果对性能要求比较高或者出现磁盘 IO 瓶颈的话，可以适当将 sync_binlog 的值调大，不过，这样会增加数据丢失的风险。<br><br>当遇到以下 3 种情况时，MySQL 会重新生成一个新的日志文件，文件序号递增：<br>
MySQL 服务器停止或重启；<br>
使用 flush logs 命令后；<br>
binlog 文件大小超过 max_binlog_size 变量的阈值后；<br><br><br>查询日志中记录了客户端的所有操作语句，而二进制日志不包含查询数据的 SQL 语句。<br>show variables like '%general%';
复制<br><img src="\04、数据库\01、mysql\assets\05、mysql-体系结构\img-20240407_205922.png"><br>默认情况下，查询日志是未开启的。<br>可在配置文件中打开：<br>
<img src="\04、数据库\01、mysql\assets\05、mysql-体系结构\img-20240407_210009.png"><br>可显示所有结果：<br>
<img src="\04、数据库\01、mysql\assets\05、mysql-体系结构\img-20240407_210110.png"><br><br>慢查询日志记录了执行时间超过参数 long_query_time 的所有查询语句。<br>
long_query_time 默认是 10s，通常设置为 1s，在解决 SQL 慢查询问题时经常会用到。<br> show variables like "slow_query_log"; 
复制<br><img src="\04、数据库\01、mysql\assets\05、mysql-体系结构\img-20240405_163604.png"><br>开启慢日志：<br>可在配置中修改：<br>
<img src="\04、数据库\01、mysql\assets\05、mysql-体系结构\img-20240407_210255.png"><br>可执行语句调整：<br>SET GLOBAL slow_query_log=ON
复制<br>设置时间：<br>查询时间：<br>SHOW VARIABLES LIKE '%long_query_time%';
复制<br><img src="\04、数据库\01、mysql\assets\05、mysql-体系结构\img-20240405_164012.png"><br>可以对 long_query_time 参数进行修改：<br>SET GLOBAL long_query_time=1
复制<br>在实际项目中，慢查询日志可能会比较大，直接分析的话不太方便，我们可以借助 MySQL 官方的慢查询分析调优工具 mysqldumpslow。<br>慢查询语句个数：<br>在MySQL中有一个变量专门记录当前慢查询语句的个数，可以通过以下命令查看。<br>show global status like '%slow_queries%';
复制<br><img src="https://img-blog.csdnimg.cn/fb5ab5e5620a4742999bbcf2c04e51c0.png" referrerpolicy="no-referrer"><br>查看慢查询日志：<br>
<img src="\04、数据库\01、mysql\assets\05、mysql-体系结构\img-20240407_210612.png"><br>默认情况下，不会记录管理语句，也不会记录不使用索引进行查找的查询。<br>
可以修改 log_slow_admin_statements 和更改此行为 log_queries_not_using_indexes，如下：<br>#记录执行较慢的管理语句
log_slow_admin_statements = 1 
#记录执行较慢的未使用索引的语句
log_queries_not_using_indexes = 1
复制<br>MySQL 为我们提供了 EXPLAIN 命令，来获取执行计划的相关信息。<br><br><br><br>关于事务具体如何保障，请参考：<br><br><a rel="noopener" class="external-link" href="https://blog.csdn.net/weixin_45690465/article/details/129437688" target="_blank">https://blog.csdn.net/weixin_45690465/article/details/129437688</a><br><a rel="noopener" class="external-link" href="https://cloud.tencent.com/developer/article/2331274" target="_blank">https://cloud.tencent.com/developer/article/2331274</a><br><a rel="noopener" class="external-link" href="https://zhuanlan.zhihu.com/p/684441867" target="_blank">https://zhuanlan.zhihu.com/p/684441867</a>]]></description><link>04、数据库\01、mysql\05、mysql-体系结构.html</link><guid isPermaLink="false">04、数据库/01、MySQL/05、MySQL 体系结构.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Sun, 07 Apr 2024 13:36:38 GMT</pubDate><enclosure url="04、数据库\01、mysql\assets\05、mysql-体系结构\img-20240405_152756.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;04、数据库\01、mysql\assets\05、mysql-体系结构\img-20240405_152756.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[06、SQL 优化]]></title><description><![CDATA[ 
 <br><br><br>查看当前数据库的 INSERT, UPDATE, DELETE, SELECT 访问频次：<br>
SHOW GLOBAL STATUS LIKE 'Com_______'; 或者 SHOW SESSION STATUS LIKE 'Com_______';<br>
例：show global status like 'Com_______'<br><br>慢查询日志记录了所有执行时间超过指定参数（long_query_time，单位：秒，默认 10 秒）的所有 SQL 语句的日志。<br>
MySQL 的慢查询日志默认没有开启，需要在 MySQL 的配置文件（/etc/my. Cnf）中配置如下信息：<br>
# 开启慢查询日志开关<br>
Slow_query_log=1<br>
# 设置慢查询日志的时间为 2 秒，SQL 语句执行时间超过 2 秒，就会视为慢查询，记录慢查询日志<br>
Long_query_time=2<br>
更改后记得重启 MySQL 服务，日志文件位置：/var/lib/mysql/localhost-slow. Log<br>查看慢查询日志开关状态：<br>
show variables like 'slow_query_log';<br><br>Show profile 能在做 SQL 优化时帮我们了解时间都耗费在哪里。通过 have_profiling 参数，能看到当前 MySQL 是否支持 profile 操作：<br>
SELECT @@have_profiling;<br>
Profiling 默认关闭，可以通过 set 语句在 session/global 级别开启 profiling：<br>
SET profiling = 1;<br>
查看所有语句的耗时：<br>
show profiles;<br>
查看指定 query_id 的 SQL 语句各个阶段的耗时：<br>
show profile for query query_id;<br>
查看指定 query_id 的 SQL 语句 CPU 的使用情况<br>
show profile cpu for query query_id;<br><br>EXPLAIN 或者 DESC 命令获取 MySQL 如何执行 SELECT 语句的信息，包括在 SELECT 语句执行过程中表如何连接和连接的顺序。<br>
语法：<br>
# 直接在 select 语句之前加上关键字 explain / desc<br>
EXPLAIN SELECT 字段列表 FROM 表名 HWERE 条件;<br>EXPLAIN 各字段含义：<br>
<br>Id：select 查询的序列号，表示查询中执行 select 子句或者操作表的顺序（id 相同，执行顺序从上到下；id 不同，值越大越先执行）
<br>Select_type：表示 SELECT 的类型，常见取值有 SIMPLE（简单表，即不适用表连接或者子查询）、PRIMARY（主查询，即外层的查询）、UNION（UNION 中的第二个或者后面的查询语句）、SUBQUERY（SELECT/WHERE 之后包含了子查询）等
<br>Type：表示连接类型，性能由好到差的连接类型为 NULL、system、const、eq_ref、ref、range、index、all
<br>Possible_key：可能应用在这张表上的索引，一个或多个
<br>Key：实际使用的索引，如果为 NULL，则没有使用索引
<br>Key_len：表示索引中使用的字节数，该值为索引字段最大可能长度，并非实际使用长度，在不损失精确性的前提下，长度越短越好
<br>Rows：MySQL 认为必须要执行的行数，在 InnoDB 引擎的表中，是一个估计值，可能并不总是准确的
<br>Filtered：表示返回结果的行数占需读取行数的百分比，filtered 的值越大越好
<br><br><br>普通插入：<br>
<br>采用批量插入（一次插入的数据不建议超过 1000 条）
<br>手动提交事务
<br>主键顺序插入
<br>大批量插入：<br>
如果一次性需要插入大批量数据，使用 insert 语句插入性能较低，此时可以使用 MySQL 数据库提供的 load 指令插入。<br># 客户端连接服务端时，加上参数 --local-infile（这一行在bash/cmd界面输入）
mysql --local-infile -u root -p
# 设置全局参数local_infile为1，开启从本地加载文件导入数据的开关
set global local_infile = 1;
select @@local_infile;
# 执行load指令将准备好的数据，加载到表结构中
load data local infile '/root/sql1.log' into table 'tb_user' fields terminated by ',' lines terminated by '\n';
复制<br><br>数据组织方式：在 InnoDB 存储引擎中，表数据都是根据主键顺序组织存放的，这种存储方式的表称为索引组织表（Index organized table, IOT）<br>页分裂：页可以为空，也可以填充一般，也可以填充 100%，每个页包含了 2-N 行数据（如果一行数据过大，会行溢出），根据主键排列。<br>
页合并：当删除一行记录时，实际上记录并没有被物理删除，只是记录被标记（flaged）为删除并且它的空间变得允许被其他记录声明使用。当页中删除的记录到达 MERGE_THRESHOLD（默认为页的 50%），InnoDB 会开始寻找最靠近的页（前后）看看是否可以将这两个页合并以优化空间使用。<br>MERGE_THRESHOLD：合并页的阈值，可以自己设置，在创建表或创建索引时指定<br>
文字说明不够清晰明了，具体可以看视频里的 PPT 演示过程： <a rel="noopener" class="external-link" href="https://www.bilibili.com/video/BV1Kr4y1i7ru?p=90" target="_blank">https://www.bilibili.com/video/BV1Kr4y1i7ru?p=90</a>
<br>主键设计原则：<br>
<br>满足业务需求的情况下，尽量降低主键的长度
<br>插入数据时，尽量选择顺序插入，选择使用 AUTO_INCREMENT 自增主键
<br>尽量不要使用 UUID 做主键或者是其他的自然主键，如身份证号
<br>业务操作时，避免对主键的修改
<br><br>
<br>Using filesort：通过表的索引或全表扫描，读取满足条件的数据行，然后在排序缓冲区 sort buffer 中完成排序操作，所有不是通过索引直接返回排序结果的排序都叫 FileSort 排序
<br>Using index：通过有序索引顺序扫描直接返回有序数据，这种情况即为 using index，不需要额外排序，操作效率高
<br>如果 order by 字段全部使用升序排序或者降序排序，则都会走索引，但是如果一个字段升序排序，另一个字段降序排序，则不会走索引，explain 的 extra 信息显示的是 Using index, Using filesort，如果要优化掉 Using filesort，则需要另外再创建一个索引，如：create index idx_user_age_phone_ad on tb_user(age asc, phone desc);，此时使用 select id, age, phone from tb_user order by age asc, phone desc; 会全部走索引<br>总结：<br>
<br>根据排序字段建立合适的索引，多字段排序时，也遵循最左前缀法则
<br>尽量使用覆盖索引
<br>多字段排序，一个升序一个降序，此时需要注意联合索引在创建时的规则（ASC/DESC）
<br>如果不可避免出现 filesort，大数据量排序时，可以适当增大排序缓冲区大小 sort_buffer_size（默认 256 k）
<br><br>
<br>在分组操作时，可以通过索引来提高效率
<br>分组操作时，索引的使用也是满足最左前缀法则的
<br>如索引为 idx_user_pro_age_stat，则句式可以是 select ... where profession order by age，这样也符合最左前缀法则<br><br>常见的问题如 limit 2000000, 10，此时需要 MySQL 排序前 2000000 条记录，但仅仅返回 2000000 - 2000010 的记录，其他记录丢弃，查询排序的代价非常大。<br>
优化方案：一般分页查询时，通过创建覆盖索引能够比较好地提高性能，可以通过覆盖索引加子查询形式进行优化<br>例如：<br>-- 此语句耗时很长
select * from tb_sku limit 9000000, 10;
-- 通过覆盖索引加快速度，直接通过主键索引进行排序及查询
select id from tb_sku order by id limit 9000000, 10;
-- 下面的语句是错误的，因为 MySQL 不支持 in 里面使用 limit
-- select * from tb_sku where id in (select id from tb_sku order by id limit 9000000, 10);
-- 通过连表查询即可实现第一句的效果，并且能达到第二句的速度
select * from tb_sku as s, (select id from tb_sku order by id limit 9000000, 10) as a where s.id = a.id;
复制<br><br>MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count (*) 的时候会直接返回这个数，效率很高（前提是不适用 where）；<br>
InnoDB 在执行 count (*) 时，需要把数据一行一行地从引擎里面读出来，然后累计计数。<br>
优化方案：自己计数，如创建 key-value 表存储在内存或硬盘，或者是用 redis<br>Count 的几种用法：<br>
<br>如果 count 函数的参数（count 里面写的那个字段）不是 NULL（字段值不为 NULL），累计值就加一，最后返回累计值
<br>用法：count (*)、count (主键)、count (字段)、count (1)
<br>Count (主键) 跟 count (*) 一样，因为主键不能为空；count (字段) 只计算字段值不为 NULL 的行；count (1) 引擎会为每行添加一个 1，然后就 count 这个 1，返回结果也跟 count (*) 一样；count (null) 返回 0
<br>各种用法的性能：<br>
<br>Count (主键)：InnoDB 引擎会遍历整张表，把每行的主键 id 值都取出来，返回给服务层，服务层拿到主键后，直接按行进行累加（主键不可能为空）
<br>Count (字段)：没有 not null 约束的话，InnoDB 引擎会遍历整张表把每一行的字段值都取出来，返回给服务层，服务层判断是否为 null，不为 null，计数累加；有 not null 约束的话，InnoDB 引擎会遍历整张表把每一行的字段值都取出来，返回给服务层，直接按行进行累加
<br>Count (1)：InnoDB 引擎遍历整张表，但不取值。服务层对于返回的每一层，放一个数字 1 进去，直接按行进行累加
<br>Count (*)：InnoDB 引擎并不会把全部字段取出来，而是专门做了优化，不取值，服务层直接按行进行累加
<br>按效率排序：count (字段) &lt; count (主键) &lt; count (1) &lt; count (*)，所以尽量使用 count (*)<br><br>InnoDB 的行锁是针对索引加的锁，不是针对记录加的锁，并且该索引不能失效，否则会从行锁升级为表锁。<br>如以下两条语句：<br>
update student set no = '123' where id = 1;，这句由于 id 有主键索引，所以只会锁这一行；<br>
update student set no = '123' where name = 'test';，这句由于 name 没有索引，所以会把整张表都锁住进行数据更新，解决方法是给 name 字段添加索引]]></description><link>04、数据库\01、mysql\06、sql-优化.html</link><guid isPermaLink="false">04、数据库/01、MySQL/06、SQL 优化.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Fri, 05 Apr 2024 09:21:48 GMT</pubDate></item><item><title><![CDATA[07、主从复制和读写分离]]></title><description><![CDATA[ 
 <br><br>主要涉及三个线程: binlog 线程、I/O 线程和 SQL 线程。<br>
<br>binlog 线程 : 负责将主服务器上的数据更改写入二进制日志中。
<br>I/O 线程 : 负责从主服务器上读取二进制日志，并写入从服务器的中继日志中。
<br>SQL 线程 : 负责读取中继日志并重放其中的 SQL 语句。
<br><br>主服务器处理写操作以及实时性要求比较高的读操作，而从服务器处理读操作。<br>读写分离能提高性能的原因在于:<br>
<br>主从服务器负责各自的读和写，极大程度缓解了锁的争用；
<br>从服务器可以使用 MyISAM，提升查询性能以及节约系统开销；
<br>增加冗余，提高可用性。
<br>读写分离常用代理方式来实现，代理服务器接收应用层传来的读写请求，然后决定转发到哪个服务器。]]></description><link>04、数据库\01、mysql\07、主从复制和读写分离.html</link><guid isPermaLink="false">04、数据库/01、MySQL/07、主从复制和读写分离.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Fri, 05 Apr 2024 07:21:19 GMT</pubDate></item><item><title><![CDATA[08、分表分库]]></title><description><![CDATA[ 
 <br><br><br>水平切分又称为 Sharding，它是将同一个表中的记录拆分到多个结构相同的表中。<br>当一个表的数据不断增多时，Sharding 是必然的选择，它可以将数据分布到集群的不同节点上，从而缓存单个数据库的压力。<br>]]></description><link>04、数据库\01、mysql\08、分表分库.html</link><guid isPermaLink="false">04、数据库/01、MySQL/08、分表分库.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Fri, 05 Apr 2024 09:26:21 GMT</pubDate></item><item><title><![CDATA[100、★ MySQL面试题汇总 ★]]></title><description><![CDATA[ 
 <br><br>
<br>为什么 InnoDB 存储引擎选择使用 B+Tree 索引结构？
<br>
<br>相对于二叉树，层级更少，搜索效率高
<br>对于 B-Tree，无论是叶子节点还是非叶子节点，都会保存数据，这样导致一页中存储的键值减少，指针也跟着减少，要同样保存大量数据，只能增加树的高度，导致性能降低
<br>相对于 Hash 索引，B+Tree 支持范围匹配及排序操作
]]></description><link>04、数据库\01、mysql\100、★-mysql面试题汇总-★.html</link><guid isPermaLink="false">04、数据库/01、MySQL/100、★ MySQL面试题汇总 ★.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Fri, 05 Apr 2024 09:24:33 GMT</pubDate></item><item><title><![CDATA[00、 ★ Redis 总览 ★]]></title><description><![CDATA[ 
 ]]></description><link>04、数据库\02、redis\00、-★-redis-总览-★.html</link><guid isPermaLink="false">04、数据库/02、Redis/00、 ★ Redis 总览 ★.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Sat, 16 Mar 2024 09:41:41 GMT</pubDate></item><item><title><![CDATA[01、Redis 概念和基础]]></title><description><![CDATA[ 
 <br><br>Redis 全称为：Remote Dictionary Server（远程词典服务），是一款内存高速缓存数据库。<br>使用 C 语言编写，是一个 key-value 存储系统（键值存储系统），基于内存的键值型 NoSQL 数据库，支持丰富的数据类型。<br><br>
<br>读写性能优异

<br>Redis能读的速度是110000次/s,写的速度是81000次/s （测试条件见下一节）。


<br>数据类型丰富

<br>Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。


<br>原子性

<br>Redis的所有操作都是原子性的，同时Redis还支持对几个操作全并后的原子性执行。


<br>丰富的特性

<br>Redis支持 publish/subscribe, 通知, key 过期等特性。


<br>持久化

<br>Redis支持RDB, AOF等持久化方式


<br>发布订阅

<br>Redis支持发布/订阅模式


<br>分布式

<br>Redis Cluster


<br><br><br>缓存是Redis最常见的应用场景，之所有这么使用，主要是因为Redis读写性能优异。而且逐渐有取代 memcached 成为首选服务端缓存的组件。而且，Redis内部是支持事务的，在使用时候能有效保证数据的一致性。 <br>作为缓存使用时，一般有两种方式保存数据：<br>1、方案一：读取前，先去读 Redis，如果没有数据，读取数据库，将数据拉入 Redis。<br>适用：对于数据实时性要求不是特别高的场景。<br>
实施起来简单，需要注意：<br>
<br>避免缓存击穿。（数据库没有就需要命中的数据，导致 Redis 一直没有数据，而一直命中数据库。）
<br>数据的实时性相对会差一点。
<br>2、方案二：插入数据时，同时写入Redis。<br>适用：字典表、数据量不大的数据存储。<br>
数据实时性强，但是开发时不便于统一处理。<br><br>Redis  使用 incrby 命令可以实现原子性的递增。<br>可以运用于高并发的秒杀活动、分布式序列号的生成、具体业务还体现在比如限制一个手机号发多少条短信、一个接口一分钟限制多少请求、一个接口一天限制调用多少次等等。<br><br>利用 Redis 的 setnx 命令（set if not exists），如果不存在则成功设置缓存同时返回 1，否则返回 0 。<br>一般服务器是集群的，定时任务可能在两台机器上都会运行，所以在定时任务中首先通过 setnx 设置一个 lock，如果成功设置则执行，如果没有成功设置，则表明该定时任务已执行。<br>结合具体业务，可以给这个 lock 加一个过期时间，如 30 分钟执行一次的定时任务，那么这个过期时间设置为小于 30 分钟的时间，这个与定时任务的周期以及定时任务执行消耗时间相关。<br>在分布式锁的场景中，主要用在比如秒杀系统等。<br><br>利用 Redis 的 expire 命令设置一个键的生存时间，到时间后 Redis 会删除它。<br>可以运用在限时的优惠活动信息、手机验证码等业务场景。 <br><br>提供 Keyspace Notifications 功能，允许客户订阅 Pub/Sub 频道，以便以某种方式接收影响 Redis 数据集的事件。<br>比如在订单生产后我们占用了库存，10 分钟后去检验用户是否真正购买，如果没有购买将该单据设置无效，同时还原库存。<br>
在订单生产时，设置一个 key，同时设置 10 分钟后过期，我们在后台实现一个监听器，监听 key 的实效，监听到 key 失效时将后续逻辑加上。<br>当然也可以利用 RocketMQ 等消息中间件的延迟队列服务实现该需求。<br><br>由于 Redis 有 list push 和 list pop 这样的命令，所以能够很方便的执行队列操作。<br><br>Redis 利用集合的一些命令，比如求交集、并集、差集等。<br>在微博应用中，每个用户关注的人存在一个集合中，就很容易实现求两个人的共同好友功能。<br><br>借助 Redis 的 SortedSet 进行热点数据的排序，而关系型数据库在排行榜方面查询速度普遍偏慢。<br>比如点赞排行榜，做一个 SortedSet, 然后以用户的 openid 作为上面的 username, 以用户的点赞数作为上面的 score, 然后针对每个用户做一个 hash, 通过 zrangebyscore 就可以按照点赞数获取排行榜，然后再根据 username 获取用户的 hash 信息，这个当时在实际运用中性能体验也蛮不错的。<br><br>
<br>
<a data-tooltip-position="top" aria-label="http://redis.io/" rel="noopener" class="external-link" href="http://redis.io/" target="_blank">Redis 官网</a>:

<br>
<a data-tooltip-position="top" aria-label="http://redis.io/documentation" rel="noopener" class="external-link" href="http://redis.io/documentation" target="_blank">Redis 官方文档:</a>

<br>
<a data-tooltip-position="top" aria-label="http://redis.io/download" rel="noopener" class="external-link" href="http://redis.io/download" target="_blank">Redis 下载</a>

]]></description><link>04、数据库\02、redis\01、redis-概念和基础.html</link><guid isPermaLink="false">04、数据库/02、Redis/01、Redis 概念和基础.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Mon, 18 Mar 2024 11:41:18 GMT</pubDate></item><item><title><![CDATA[02、Redis 的安装说明]]></title><description><![CDATA[ 
 <br>本章是基于 CentOS 7 下的 Redis 集群教程，包括：<br>
<br>单机安装 Redis
<br>Redis 主从
<br>Redis 分片集群
<br><br>需要安装 Redis 所需要的依赖：<br>yum install -y gcc tcl
复制<br>将提供的 Redis 安装包上传到虚拟机的任意目录：<br><img src="\04、数据库\02、redis\assets\02、redis-的安装说明\img-20240314_200522.png"><br>例如，我放到了 /tmp 目录：<br>
<img src="\04、数据库\02、redis\assets\02、redis-的安装说明\img-20240314_200545.png"><br>解压缩：<br>tar -xzf redis-6.2.4.tar.gz
复制<br>解压后：<br>
<img src="\04、数据库\02、redis\assets\02、redis-的安装说明\img-20240314_200754.png"><br>进入 redis 目录：<br>cd redis-6.2.4
复制<br>运行编译命令：<br>make &amp;&amp; make install
复制<br>如果没有出错，应该就安装成功了。<br>然后修改 redis. Conf 文件中的一些配置：<br># 绑定地址，默认是127.0.0.1，会导致只能在本地访问。修改为0.0.0.0则可以在任意IP访问
bind 0.0.0.0
# 保护模式，关闭保护模式
protected-mode no
# 数据库数量，设置为1
databases 1
复制<br>启动 Redis：<br>redis-server redis.conf
复制<br>停止 redis 服务：<br>Redis-cli shutdown<br><br><br>我们搭建的主从集群结构如图：<br><img src="\04、数据库\02、redis\assets\02、redis-的安装说明\img-20240314_201125.png"><br>共包含三个节点，一个主节点，两个从节点。<br>这里我们会在同一台虚拟机中开启 3 个 redis 实例，模拟主从集群，信息如下：<br><br><br>要在同一台虚拟机开启 3 个实例，必须准备三份不同的配置文件和目录，配置文件所在目录也就是工作目录。<br><br>我们创建三个文件夹，名字分别叫 7001、7002、7003：<br># 进入/tmp目录
cd /tmp
# 创建目录
mkdir 7001 7002 7003
复制<br>如图：<br>
<img src="\04、数据库\02、redis\assets\02、redis-的安装说明\img-20240314_201954.png"><br><br>修改 redis-6.2.4/redis.conf 文件，将其中的持久化模式改为默认的 RDB 模式，AOF 保持关闭状态。<br># 开启RDB
# save ""
save 3600 1
save 300 100
save 60 10000

# 关闭AOF
appendonly no
复制<br><br>然后将 redis-6.2.4/redis. Conf 文件拷贝到三个目录中（在 /tmp 目录执行下列命令）：<br># 方式一：逐个拷贝
cp redis-6.2.4/redis.conf 7001
cp redis-6.2.4/redis.conf 7002
cp redis-6.2.4/redis.conf 7003

# 方式二：管道组合命令，一键拷贝
echo 7001 7002 7003 | xargs -t -n 1 cp redis-6.2.4/redis.conf
复制<br><br>修改每个文件夹内的配置文件，将端口分别修改为 7001、7002、7003，将 rdb 文件保存位置都修改为自己所在目录（在 /tmp 目录执行下列命令）：<br>sed -i -e 's/6379/7001/g' -e 's/dir .\//dir \/tmp\/7001\//g' 7001/redis.conf
sed -i -e 's/6379/7002/g' -e 's/dir .\//dir \/tmp\/7002\//g' 7002/redis.conf
sed -i -e 's/6379/7003/g' -e 's/dir .\//dir \/tmp\/7003\//g' 7003/redis.conf
复制<br><br>虚拟机本身有多个 IP，为了避免将来混乱，我们需要在 redis. Conf 文件中指定每一个实例的绑定 ip 信息，格式如下：<br># redis实例的声明 IP
replica-announce-ip 192.168.150.101
复制<br>每个目录都要改，我们一键完成修改（在 /tmp 目录执行下列命令）：<br># 逐一执行
sed -i '1a replica-announce-ip 192.168.150.101' 7001/redis.conf
sed -i '1a replica-announce-ip 192.168.150.101' 7002/redis.conf
sed -i '1a replica-announce-ip 192.168.150.101' 7003/redis.conf

# 或者一键修改
printf '%s\n' 7001 7002 7003 | xargs -I{} -t sed -i '1a replica-announce-ip 192.168.150.101' {}/redis.conf
复制<br><br>为了方便查看日志，我们打开 3 个 ssh 窗口，分别启动 3 个 redis 实例，启动命令：<br># 第1个
redis-server 7001/redis.conf
# 第2个
redis-server 7002/redis.conf
# 第3个
redis-server 7003/redis.conf
复制<br>启动后：<br>
<img src="\04、数据库\02、redis\assets\02、redis-的安装说明\img-20240314_202631.png"><br>如果要一键停止，可以运行下面命令：<br>printf '%s\n' 7001 7002 7003 | xargs -I{} -t redis-cli -p {} shutdown
复制<br>开启主从关系<br>
现在三个实例还没有任何关系，要配置主从可以使用 replicaof 或者 slaveof（5.0 以前）命令。<br>有临时和永久两种模式：<br>
<br>修改配置文件（永久生效）

<br>在 redis.conf 中添加一行配置：slaveof &lt;masterip&gt; &lt;masterport&gt;


<br>执行 slaveof 命令（重启后失效）

<br>使用 redis-cli 客户端连接到 redis 服务，执行 slaveof &lt;masterip&gt; &lt;masterport&gt; 命令


<br>在 5.0 以后新增命令 replicaof，与 salveof 效果一致。<br>这里我们为了演示方便，使用方式二。<br>通过 redis-cli 命令连接 7002，执行下面命令：<br># 连接 7002
redis-cli -p 7002
# 执行slaveof
slaveof 192.168.150.101 7001
复制<br>通过 redis-cli 命令连接 7003，执行下面命令：<br># 连接 7002
redis-cli -p 7002
# 执行slaveof
slaveof 192.168.150.101 7001
复制<br>然后连接 7001 节点，查看集群状态：<br># 连接 7001
redis-cli -p 7001
# 查看状态
info replication
复制<br>结果：<br>
<img src="\04、数据库\02、redis\assets\02、redis-的安装说明\img-20240314_203055.png"><br><br>执行下列操作以测试：<br>
<br>利用 redis-cli 连接 7001，执行 set num 123
<br>利用 redis-cli 连接 7002，执行 get num，再执行 set num 666
<br>利用 redis-cli 连接 7003，执行 get num，再执行 set num 888
<br>只有在 7001 这个 master 节点上可以执行写操作，<br>
7002 和 7003 这两个 slave 节点只能执行读操作。<br><br><br>这里我们搭建一个三节点形成的 Sentinel 集群，来监管之前的 Redis 主从集群。如图：<br><img src="\04、数据库\02、redis\assets\02、redis-的安装说明\img-20240314_203237.png"><br>三个 sentinel 实例信息如下：<br><br><br>要在同一台虚拟机开启 3 个实例，必须准备三份不同的配置文件和目录，配置文件所在目录也就是工作目录。<br>我们创建三个文件夹，名字分别叫 s1、s2、s3：<br># 进入/tmp目录
cd /tmp
# 创建目录
mkdir s1 s2 s3
复制<br>如图：<br>
<img src="\04、数据库\02、redis\assets\02、redis-的安装说明\img-20240314_203447.png"><br>然后我们在 s 1 目录创建一个 sentinel.conf 文件，添加下面的内容：<br>port 27001
sentinel announce-ip 192.168.150.101
sentinel monitor mymaster 192.168.150.101 7001 2
sentinel down-after-milliseconds mymaster 5000
sentinel failover-timeout mymaster 60000
dir "/tmp/s1"
复制<br>解读：<br>
<br>port 27001：是当前 sentinel 实例的端口
<br>sentinel monitor mymaster 192.168.150.101 7001 2   (指定主节点信息)

<br>mymaster：主节点名称，自定义，任意写
<br>192.168.150.101 7001：主节点的 ip 和端口
<br>2：选举 master 时的 quorum 值


<br>然后将 s 1/sentinel. Conf 文件拷贝到 s 2、s 3 两个目录中（在 /tmp 目录执行下列命令）：<br># 方式一：逐个拷贝
cp s1/sentinel.conf s2
cp s1/sentinel.conf s3
# 方式二：管道组合命令，一键拷贝
echo s2 s3 | xargs -t -n 1 cp s1/sentinel.conf
复制<br>修改 s 2、s 3 两个文件夹内的配置文件，将端口分别修改为 27002、27003：<br>sed -i -e 's/27001/27002/g' -e 's/s1/s2/g' s2/sentinel.conf
sed -i -e 's/27001/27003/g' -e 's/s1/s3/g' s3/sentinel.conf
复制<br><br>为了方便查看日志，我们打开 3 个 ssh 窗口，分别启动 3 个 redis 实例，启动命令：<br># 第1个
redis-sentinel s1/sentinel.conf
# 第2个
redis-sentinel s2/sentinel.conf
# 第3个
redis-sentinel s3/sentinel.conf
复制<br>启动后：<br>
<img src="\04、数据库\02、redis\assets\02、redis-的安装说明\img-20240314_204825.png"><br><br>尝试让 master 节点 7001 宕机，查看 sentinel 日志：<br>
<img src="\04、数据库\02、redis\assets\02、redis-的安装说明\img-20240314_204845.png"><br>查看 7003 的日志：<br>
<img src="\04、数据库\02、redis\assets\02、redis-的安装说明\img-20240314_204954.png"><br>查看 7002 的日志：<br>
<img src="\04、数据库\02、redis\assets\02、redis-的安装说明\img-20240314_205019.png"><br><br><br>分片集群需要的节点数量较多，这里我们搭建一个最小的分片集群，包含 3 个 master 节点，每个 master 包含一个 slave 节点，结构如下：<br><img src="\04、数据库\02、redis\assets\02、redis-的安装说明\img-20240314_205437.png"><br>这里我们会在同一台虚拟机中开启 6 个 redis 实例，模拟分片集群，信息如下：<br><br><br>删除之前的 7001、7002、7003 这几个目录，重新创建出 7001、7002、7003、8001、8002、8003 目录：<br># 进入/tmp目录
cd /tmp
# 删除旧的，避免配置干扰
rm -rf 7001 7002 7003
# 创建目录
mkdir 7001 7002 7003 8001 8002 8003
复制<br>在 /tmp 下准备一个新的 redis.conf 文件，内容如下：<br>port 6379
# 开启集群功能
cluster-enabled yes
# 集群的配置文件名称，不需要我们创建，由redis自己维护
cluster-config-file /tmp/6379/nodes.conf
# 节点心跳失败的超时时间
cluster-node-timeout 5000
# 持久化文件存放目录
dir /tmp/6379
# 绑定地址
bind 0.0.0.0
# 让redis后台运行
daemonize yes
# 注册的实例ip
replica-announce-ip 192.168.150.101
# 保护模式
protected-mode no
# 数据库数量
databases 1
# 日志
logfile /tmp/6379/run.log
复制<br>将这个文件拷贝到每个目录下:<br># 进入/tmp目录
cd /tmp
# 执行拷贝
echo 7001 7002 7003 8001 8002 8003 | xargs -t -n 1 cp redis.conf
复制<br>修改每个目录下的 redis. Conf，将其中的 6379 修改为与所在目录一致：<br># 进入/tmp目录
cd /tmp
# 修改配置文件
printf '%s\n' 7001 7002 7003 8001 8002 8003 | xargs -I{} -t sed -i 's/6379/{}/g' {}/redis.conf
复制<br><br>因为已经配置了后台启动模式，所以可以直接启动服务：<br># 进入/tmp目录
cd /tmp
# 一键启动所有服务
printf '%s\n' 7001 7002 7003 8001 8002 8003 | xargs -I{} -t redis-server {}/redis.conf
复制<br>通过 ps 查看状态：<br>ps -ef | grep redis
复制<br>发现服务都已经正常启动：<br><img src="\04、数据库\02、redis\assets\02、redis-的安装说明\img-20240314_210433.png"><br>如果要关闭所有进程，可以执行命令：<br>ps -ef | grep redis | awk '{print $2}' | xargs kill
复制<br>或者（推荐这种方式）：<br>printf '%s\n' 7001 7002 7003 8001 8002 8003 | xargs -I{} -t redis-cli -p {} shutdown
复制<br><br>虽然服务启动了，但是目前每个服务之间都是独立的，没有任何关联。<br>我们需要执行命令来创建集群，在 Redis 5.0 之前创建集群比较麻烦，5.0 之后集群管理命令都集成到了 redis-cli 中。<br><br>Redis 5.0 之前集群命令都是用 redis 安装包下的 src/redis-trib.rb 来实现的。因为 redis-trib.rb 是有 ruby 语言编写的所以需要安装 ruby 环境。<br># 安装依赖
yum -y install zlib ruby rubygems
gem install redis
复制<br>然后通过命令来管理集群：<br># 进入redis的src目录
cd /tmp/redis-6.2.4/src
# 创建集群
./redis-trib.rb create --replicas 1 192.168.150.101:7001 192.168.150.101:7002 192.168.150.101:7003 192.168.150.101:8001 192.168.150.101:8002 192.168.150.101:8003
复制<br><br>我们使用的是 Redis 6.2.4 版本，集群管理以及集成到了 redis-cli 中，格式如下：<br>redis-cli --cluster create --cluster-replicas 1 192.168.150.101:7001 192.168.150.101:7002 192.168.150.101:7003 192.168.150.101:8001 192.168.150.101:8002 192.168.150.101:8003
复制<br>命令说明：<br>
<br>redis-cli --cluster 或者./redis-trib.rb：代表集群操作命令

<br>create：代表是创建集群
<br>--replicas 1 或者 --cluster-replicas 1 ：指定集群中每个 master 的副本个数为 1，此时节点总数 ÷ (replicas + 1) 得到的就是 master 的数量。因此节点列表中的前 n 个就是 master，其它节点都是 slave 节点，随机分配到不同 master


<br>运行后的样子：<br>
<img src="\04、数据库\02、redis\assets\02、redis-的安装说明\img-20240314_210936.png"><br>这里输入 yes，则集群开始创建：<br>
<img src="\04、数据库\02、redis\assets\02、redis-的安装说明\img-20240314_211000.png"><br>通过命令可以查看集群状态：<br>redis-cli -p 7001 cluster nodes
复制<br><br>尝试连接 7001 节点，存储一个数据：<br># 连接
redis-cli -p 7001
# 存储数据
set num 123
# 读取数据
get num
# 再次存储
set a 1
复制<br>结果悲剧了：<br>
<img src="\04、数据库\02、redis\assets\02、redis-的安装说明\img-20240314_211130.png"><br>集群操作时，需要给 redis-cli 加上 -c 参数，这个命令启用了 Redis 集群模式（Cluster Mode）<br>redis-cli -c -p 7001
复制<br><img src="\04、数据库\02、redis\assets\02、redis-的安装说明\img-20240314_211158.png">]]></description><link>04、数据库\02、redis\02、redis-的安装说明.html</link><guid isPermaLink="false">04、数据库/02、Redis/02、Redis 的安装说明.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Sun, 17 Mar 2024 06:52:16 GMT</pubDate><enclosure url="04、数据库\02、redis\assets\02、redis-的安装说明\img-20240314_200522.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;04、数据库\02、redis\assets\02、redis-的安装说明\img-20240314_200522.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[03、常见命令&数据类型]]></title><description><![CDATA[ 
 <br><br>首先对 redis 来说，所有的 key（键）都是字符串。我们在谈基础数据结构时，讨论的是存储值的数据类型，主要包括常见的5种数据类型，分别是：String、List、Set、Zset、Hash。<br><br><br>
<br>KEYS pattern：查看复合模版的所有 keys, 不建议在生产坏境下使用
<br>DEL key：删除一个指定的 key
<br>EXISTS key：判断 key 是否存在
<br>EXPIRE key seconds：给一个 key 设置过期时间单位是秒
<br>TTL key：查看指定 key 的剩余有效时间。-1 表示当前 key 没有设置有效时间，-2 表示当前 key 不存在
<br>PERSIST key：持久化指定 key
<br>TYPE key：查看指定 key 的类型
<br>MOVE key num：移动指定 key 到指定数据库
<br>RANDOMKEY：随即返回库中的一个 key
<br>127.0.0.1:6379&gt; select 0
OK
127.0.0.1:6379&gt; set k1 v1
OK
127.0.0.1:6379&gt; get k1
"v1"
127.0.0.1:6379&gt; exists k1
(integer) 1
127.0.0.1:6379&gt; exists k2
(integer) 0
127.0.0.1:6379&gt; expire k1 10
(integer) 1
127.0.0.1:6379&gt; ttl k1
(integer) 7
127.0.0.1:6379&gt; persist k1
(integer) 1
127.0.0.1:6379&gt; ttl k1
(integer) -1
127.0.0.1:6379&gt; type k1
string
复制<br><br><br>String类型是二进制安全的，意思是 redis 的 string 可以包含任何数据。如数字，字符串，jpg图片或者序列化的对象。<br><br>Redis 中的 String 是动态字符串，内部结构类似 ArrayList。采用预分配冗余空间的方式减少内存的频繁分配。<br>内部为字符串分配的实际空间一般高于字符串长度。<br>
当字符串长度 &lt; 1 MB 时，扩容方式是加倍也就是原来的两倍。<br>
当字符串长度 &gt; 1 MB 时，一次扩容 1 MB，直到最大 512 MB。<br><br><br><br># SET key value:设置key的值
127.0.0.1:6379&gt; set id 42022220018718
OK

# GET key:获取key的值
127.0.0.1:6379&gt; get id
"42022220018718"

# DEL key:删除指定key
127.0.0.1:6379&gt; del id
(integer) 1

# GETSET key value:修改key的值 并返回原来得到值
127.0.0.1:6379&gt; getset id 420222200102058719
"420222200102058718"

# setex key seconds value:给指定key值赋值的同时，设置该key的有效时间
127.0.0.1:6379&gt; setex house 50 三室一厅
OK
127.0.0.1:6379&gt; ttl house
(integer) 41

# setnx house value:设置key值，如果key已存在，则不存储
127.0.0.1:6379&gt; setnx name chen-zikang
(integer) 0
127.0.0.1:6379&gt; setnx house 三室一厅
(integer) 1

# mget key [key...]:同时获取多个key值
127.0.0.1:6379&gt; mget name sex age
1) "chen-zi-kang"
2) "aman"
3) "18"

# mset key value [key value...]：同时设置多个key值
127.0.0.1:6379&gt; mset hieght 170cm weight 110
OK

# msetnx key value [key value...]： 同时设置多个key值，如已经存在，则不存储 ，这是一个原子操作。
127.0.0.1:6379&gt; msetnx hieght 170cm money 100000
(integer) 0

# append key value:在该key值的后边加上value
127.0.0.1:6379&gt; append name is-a-good-boy
(integer) 25

# strlen key:返回这个key值得长度
127.0.0.1:6379&gt; strlen name
(integer) 25

# getrange key begin end: 获取该key值  索引从begin到end的字符串  包头包尾
127.0.0.1:6379&gt; set name czk-is-handsame
OK
127.0.0.1:6379&gt; getrange name 0 10
"czk-is-hand"

# setrange key offset value : 修改offset位以后的 value值
127.0.0.1:6379&gt; setrange name 10 man
(integer) 15
127.0.0.1:6379&gt; get name
"czk-is-hanmanme"
复制<br><br>
<br>缓存： 经典使用场景，把常用信息，字符串，图片或者视频等信息放到 redis 中，redis 作为缓存层，mysql 做持久化层，降低 mysql 的读写压力。
<br>计数器：redis 是单线程模型，一个命令执行完才会执行下一个，同时数据可以一步落地到其他的数据源。
<br>session：常见方案 spring session + redis 实现 session 共享
<br><br>redis 的列表是一个字符链表，内部结构类似 LinkedList。left，right 都可以添加。<br>
如果键不在，则创建新链表，如果已存在则新加内容。<br>
如果当前链表没有值，则该链表也会自动删除。<br>
redis 的列表最多可存储 2^32-1 个元素（4294967295，每个列表可以存储 40 多亿个元素）<br><br>底层是一个快速链表（quickList）的结构。<br>在列表元素较少时，使用内存存储压缩列表 ziplist。<br>
当元素数量较多时，改成 quickList，也就是将多个 zipList 串起来使用，以减少内存的碎片化。<br><br><br>使用列表的技巧:<br>
<br>lpush+lpop=Stack(栈)
<br>lpush+rpop=Queue（队列）
<br>lpush+ltrim=Capped Collection（有限集合）
<br>lpush+brpop=Message Queue（消息队列）
<br><br># lpush key value : 从头部（左边）压进（新增）一个新元素
127.0.0.1:6379&gt; lpush list1 v1 v2 v3 v4 v5
(integer) 5

# rpush key value : 从尾部（右边）压进（新增）一个新元素
rpush list1 v6
(integer) 6

# lpop key value : 从头部（左边）弹出（删除）一个元素并返回
127.0.0.1:6379&gt; lpop list1
"v5"

# rpop key value : 从尾部（右边）弹出（删除）一个元素并返回
127.0.0.1:6379&gt; rpop list1
"v1"

# lset key index value : 修改索引号为index的元素的值为value
127.0.0.1:6379&gt; lset list1 4 v7
OK

# lrem key count value : 删除count个元素值为value
127.0.0.1:6379&gt; lrem list1 0 v0
(integer) 1

# linsert key before/after old_value new_value : 在某一个旧元素值的前边或后边插入一个新的值
127.0.0.1:6379&gt; linsert list1 before v7 v6
(integer) 6

# lindex key index : 查询当前list中索引为index的值
127.0.0.1:6379&gt; lindex list1 5
"v6"

# lrange key start end : 遍历list的所有元素并显示
127.0.0.1:6379&gt; lrange list1 0 -1
1) "v3"
2) "v4"
3) "v5"
4) "v6"
5) "v7"

# ltrim key start end : 截取list从stater到end位置的值并保留
127.0.0.1:6379&gt; ltrim list1 2 6
OK

# llen key : 返回一个list的元素个数 
127.0.0.1:6379&gt; llen list1
(integer) 5著作权归https://pdai.tech所有。 链接：&lt;https://pdai.tech/md/db/nosql-redis/db-redis-data-types.html&gt;
复制<br><br>
<br>微博TimeLine: 有人发布微博，用lpush加入时间轴，展示新的列表信息。
<br>消息队列
<br><br>Redis hash 是一个 string 类型的 field（字段） 和 value（值） 的映射表，hash 特别适合用于存储对象。<br><br>​底层的实现结构，与 HashMap 一样，是 “数组 + 链表” 的二维结构，第一维 hash 的数据位置碰撞时，将碰撞元素用链表串接起来。<br>不同的是，redis 字典的值只能是字符串，而且两者的 rehash 方式不同。<br>
Java 的 hashmap 是一次全部 rehash，耗时较高，<br>
Redis 为了提高性能，采用渐进式 rehash 策略。具体方式为，同时保留新旧两个 hash 结构，然后逐步搬迁，最后取代。<br><br><br><br># hset key field value : 给hash设置field和value
127.0.0.1:6379&gt; hset hash1 k1 v1
(integer) 1

# hget key field : 获取hash中健值为field的值
127.0.0.1:6379&gt; hget hash1 k1
"v1"

# hmset key field value [field value...] : 同时给hash设置多个field和value
127.0.0.1:6379&gt; hmset hash1 k2 v2 k3 v3 k4 v4
OK

# hmget key field [field...] : 同时获取hash中多个健值为field的值
127.0.0.1:6379&gt; hmget hash1 k1 k2 k3 k4
1) "v1"
2) "v2"
3) "v3"
4) "v4"

# hsetnx key field value : 判断hash中是否存在 该field值，不存在则添加
127.0.0.1:6379&gt; hsetnx hash1 k5 v5
(integer) 1

# hgetall key : 获取hash中所有的field和value的值
127.0.0.1:6379&gt; hgetall hash1
 1) "k3"
 2) "v3"
 3) "k4"
 4) "v4"
 5) "k5"
 6) "v5"
 7) "k1"
 8) "3"
 9) "k2"
10) "81.83635"

# hkeys key : 获取hash中所有的field的值
127.0.0.1:6379&gt; hkeys hash1
1) "k3"
2) "k4"
3) "k5"

# hvals key : 获取hash中所有value的值
127.0.0.1:6379&gt; hvals hash1
1) "v3"
2) "v4"
3) "v5"

# hexists key field : 判断hash中是否存在field值 
127.0.0.1:6379&gt; hexists hash1 k1
(integer) 1

# hlen key : 获取hash中键值对的个数
127.0.0.1:6379&gt; hlen hash1
(integer) 5

# hincrby key field increment : 设置hash中field属性自增，前提是整数，自增步长为increment
127.0.0.1:6379&gt; hincrby hash1 k2 10
(integer) 10

# hincrbyfloat key field increment : 设置hash中field属性自增 ，可以是小数，自增步长为increment
127.0.0.1:6379&gt; hincrbyfloat hash1 k2 10.1
"40.1"
复制<br><br>
<br>缓存： 能直观，相比 string 更节省空间，的维护缓存信息，如用户信息，视频信息等。
<br><br>Redis 的集合是 String 类型的无序不重复的元素集，同时提供交集、并集、差集等操作，集合中最大的成员数为 2^32-1（40 多亿）。Redis 中集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O (1)。<br><br>​ 类似 HashSet, 也是通过哈希表实现的，相当于所有的 value 都为空。通过计算 hash 的方式来快速排重，也是 set 能提供判断一个成员是否在集合内的原因<br><br><br><br># sadd key member [member...] : 添加set集合的member
127.0.0.1:6379&gt; sadd set1 value1 value2 value3
(integer) 3

# srem key member [member...] : 删除set集合中的member
127.0.0.1:6379&gt; srem set1 value1
(integer) 1

# spop key [count] : 随机弹出count个member  
127.0.0.1:6379&gt; spop set1 1
1) "menber2"

# scard key : 获取set的成员个数 
127.0.0.1:6379&gt; scard set2
(integer) 2

# smembers key :  获取set的所有成员
127.0.0.1:6379&gt; smembers set2
1) "value3"
2) "member1"

# sismember key member : 判断member是否是set中的成员
127.0.0.1:6379&gt; sismember set1 member1
(integer) 1

# srandmember key count : 随机返回count个成员
127.0.0.1:6379&gt; srandmember set1 1
(integer) 1

# smove sourse destination member : 移动source中的成员member到destination中
127.0.0.1:6379&gt; smove set1 set2  member1 
(integer) 1

# sdiff key1 key2 [key3...] : 返回key1与key2的差集
127.0.0.1:6379&gt; sdiff set2 set1
1) "value3"

# sinter key1 key2 [key3...] : 返回key1与key2的交集
127.0.0.1:6379&gt; sinter set1 set2
1) "member1"

# sunion key1 key2 [key3...] : 返回key1与key2的交集
127.0.0.1:6379&gt; sunion set2 set1
1) "value3"
2) "value1"
3) "menber3"
4) "member1"
5) "member2"
复制<br><br>
<br>标签（tag）,给用户添加标签，或者用户给消息添加标签，这样有同一标签或者类似标签的可以给推荐关注的事或者关注的人。
<br>点赞，或点踩，收藏等，可以放到set中实现
<br><br>
Redis 有序集合和集合一样也是 string 类型元素的集合，且不允许重复的成员。不同的是每个元素都会关联一个 double 类型的分数。<br>
Redis 正是通过分数来为集合中的成员进行从小到大的排序。Zset 的成员是唯一的，但分数是可以重复的。
<br><br>压缩列表 (ziplist): ziplist 是为了提高存储效率而设计的一种特殊编码的双向链表。它可以存储字符串或者整数，存储整数时是采用整数的二进制而不是字符串形式存储。它能在 O (1) 的时间复杂度下完成 list 两端的 push 和 pop 操作。但是因为每次操作都需要重新分配 ziplist 的内存，所以实际复杂度和 ziplist 的内存使用量相关<br>跳跃表（zSkiplist): 跳跃表的性能可以保证在查找，删除，添加等操作的时候在对数期望时间内完成，这个性能是可以和平衡树来相比较的，而且在实现方面比平衡树要优雅，这是采用跳跃表的主要原因。跳跃表的复杂度是 O (log (n))。<br><br><br><br># zadd key score member [score member...]:添加zset集合新的成员分数和成员。
127.0.0.1:6379&gt; zadd k1 10 c1 20 c2 30 c3 40 c4 50 c5 60 c6 70 c7 80 c8 90 c9 
(integer) 9

# zrem key member [member...]:删除zset中的成员member
127.0.0.1:6379&gt; zrem zset key1
(integer) 1

# zrange key start stop [withscores]:遍历zset，获取所有成员 ，若加上withscores，则分数被同时返回
127.0.0.1:6379&gt; zrange k1 0 -1
1) "c1"
2) "c2"
3) "c3"
4) "c4"
5) "c5"
6) "c6"
7) "c7"
8) "c8"
9) "c9"

# zrangebyscore key min max [withscores] [limit offset count] : 获取指定范围内分数的所有成员 （升序） withscores表示带上分数，limit表示分页
127.0.0.1:6379&gt; zrevrangebyscore k1 50 (10
1) "c5"
2) "c4"
3) "c3"
4) "c2"

# zcard key:获取zset成员个数
127.0.0.1:6379&gt;zcard k1
(integer)8
# zcount key min max :获取zset在指定分数范围内的成员个数,“（”左括号表示闭区间
127.0.0.1:6379&gt; zcount k1 0 (60
(integer) 5

# zrank key member : 获取zset中成员member的排名（升序）
127.0.0.1:6379&gt; zvrank k1 c9
(integer) 8

# zrevrank key member:获取zset中成员member的排名（降序）
127.0.0.1:6379&gt; zrevrank k1 c9
(integer) 0

# zrevrange key [withscores]: 获取zset中所有的成员（降序）
127.0.0.1:6379&gt; zrevrange k1 0 -1
1) "c9"
2) "c8"
3) "c7"
4) "c6"
5) "c5"
6) "c4"
7) "c3"
8) "c2"
9) "c1"
复制<br><br>
<br>排行榜：有序集合经典使用场景。例如小说视频等网站需要对用户上传的小说视频做排行榜，榜单可以按照用户关注数，更新时间，字数等打分，做排行。
<br><br><br><br>基数是指一个集合中不同元素的数量。<br>举个例子，A = {1, 2, 3, 4, 5}， B = {3, 5, 6, 7, 9}；那么基数（不重复的元素）= {1, 2, 4, 6, 7, 9}<br><br>这个结构可以使用极少量内存的情况下估算出非常大的数据集中的基数。<br>对于可以接受一定容错的业务场景，比如注册 IP 数、每日访问 IP 数、页面实时 UV、在线用户数，共同好友数等。<br><br>一个大型的网站，每天 IP 比如有 100 万，粗算一个 IP 消耗 15 字节，那么 100 万个 IP 就是 15 M。<br>
<br>HyperLogLog 在 Redis 中每个键占用的内容都是 12 K，理论存储近似接近 2^64 个值，在处理大规模数据时不需要存储所有的元素，而是通过一种概率算法来估计不同元素的数量。
<br>估算的基数是近似值，但相对准确，是一个带有 0.81%（不到百分之一）标准错误的值。
<br><br>127.0.0.1:6379&gt; pfadd key1 a b c d e f g h i	# 创建第一组元素
(integer) 1
127.0.0.1:6379&gt; pfcount key1					# 统计元素的基数数量
(integer) 9
127.0.0.1:6379&gt; pfadd key2 c j k l m e g a		# 创建第二组元素
(integer) 1
127.0.0.1:6379&gt; pfcount key2
(integer) 8
127.0.0.1:6379&gt; pfmerge key3 key1 key2			# 合并两组：key1 key2 -&gt; key3 并集
OK
127.0.0.1:6379&gt; pfcount key3
(integer) 13
复制<br><br>Bitmap 即位图数据结构，都是操作二进制位来进行记录，只有 0 和 1 两个状态。<br><br>只要是两个状态的，都可以使用 Bitmaps。<br>比如：统计用户信息，活跃，不活跃！ 登录，未登录！ 打卡，不打卡！ ！<br>如果存储一年的打卡状态需要多少内存呢？ 365 天 = 365 bit 1 字节 = 8 bit 46 个字节左右！<br><br>使用 bitmap 来记录周一到周日的打卡！ 周一：1 周二：0 周三：0 周四：1 ……<br>127.0.0.1:6379&gt; setbit sign 0 1
(integer) 0
127.0.0.1:6379&gt; setbit sign 1 1
(integer) 0
127.0.0.1:6379&gt; setbit sign 2 0
(integer) 0
127.0.0.1:6379&gt; setbit sign 3 1
(integer) 0
127.0.0.1:6379&gt; setbit sign 4 0
(integer) 0
127.0.0.1:6379&gt; setbit sign 5 0
(integer) 0
127.0.0.1:6379&gt; setbit sign 6 1
(integer) 0
复制<br>查看某一天是否有打卡！<br>127.0.0.1:6379&gt; getbit sign 3
(integer) 1
127.0.0.1:6379&gt; getbit sign 5
(integer) 0
复制<br>统计操作，统计打卡的天数！<br>127.0.0.1:6379&gt; bitcount sign # 统计这周的打卡记录，就可以看到是否有全勤！
(integer) 3
复制<br><br><br>添加地理位置<br>127.0.0.1:6379&gt; geoadd china:city 118.76 32.04 manjing 112.55 37.86 taiyuan 123.43 41.80 shenyang
(integer) 3
127.0.0.1:6379&gt; geoadd china:city 144.05 22.52 shengzhen 120.16 30.24 hangzhou 108.96 34.26 xian
(integer) 3
复制<br>两级无法直接添加，我们一般会下载城市数据(这个网址可以查询 GEO： <a data-tooltip-position="top" aria-label="http://www.jsons.cn/lngcode)%EF%BC%81" rel="noopener" class="external-link" href="http://www.jsons.cn/lngcode)%EF%BC%81" target="_blank">http://www.jsons.cn/lngcode)！</a><br>
<br>有效的经度从-180度到180度。
<br>有效的纬度从-85.05112878度到85.05112878度。
<br># 当坐标位置超出上述指定范围时，该命令将会返回一个错误。
127.0.0.1:6379&gt; geoadd china:city 39.90 116.40 beijin
(error) ERR invalid longitude,latitude pair 39.900000,116.400000 
复制<br><br>获取指定的成员的经度和纬度<br>127.0.0.1:6379&gt; geopos china:city taiyuan manjing
1) 1) "112.54999905824661255"
   1) "37.86000073876942196"
2) 1) "118.75999957323074341"
   1) "32.03999960287850968"
复制<br><br>如果不存在，返回空<br>127.0.0.1:6379&gt; geodist china:city taiyuan shenyang m
"1026439.1070"
127.0.0.1:6379&gt; geodist china:city taiyuan shenyang km
"1026.4391" 
复制<br>单位如下<br>
<br>M
<br>Km
<br>Mi 英里
<br>Ft 英尺
<br><br>
附近的人 ==&gt; 获得所有附近的人的地址, 定位, 通过半径来查询
<br>获得指定数量的人<br>#以 100,30 这个坐标为中心, 寻找半径为1000km的城市
127.0.0.1:6379&gt; georadius china:city 110 30 1000 km			
1) "xian"
2) "hangzhou"
3) "manjing"
4) "taiyuan"
127.0.0.1:6379&gt; georadius china:city 110 30 500 km
1) "xian"
127.0.0.1:6379&gt; georadius china:city 110 30 500 km withdist
1) 1) "xian"
   2) "483.8340"
127.0.0.1:6379&gt; georadius china:city 110 30 1000 km withcoord withdist count 2
1) 1) "xian"
   2) "483.8340"
   3) 1) "108.96000176668167114"
      2) "34.25999964418929977"
2) 1) "manjing"
   2) "864.9816"
   3) 1) "118.75999957323074341"
      2) "32.03999960287850968"
复制<br>参数 key 经度 纬度 半径 单位 [显示结果的经度和纬度] [显示结果的距离] [显示的结果的数量]<br><br>
显示与指定成员一定半径范围内的其他成员
<br>127.0.0.1:6379&gt; georadiusbymember china:city taiyuan 1000 km
1) "manjing"
2) "taiyuan"
3) "xian"
127.0.0.1:6379&gt; georadiusbymember china:city taiyuan 1000 km withcoord withdist count 2
1) 1) "taiyuan"
   2) "0.0000"
   3) 1) "112.54999905824661255"
      2) "37.86000073876942196"
2) 1) "xian"
   2) "514.2264"
   3) 1) "108.96000176668167114"
      2) "34.25999964418929977"
复制<br>参数与 georadius 一样<br><br>
该命令返回11个字符的hash字符串
<br>127.0.0.1:6379&gt; geohash china:city taiyuan shenyang
1) "ww8p3hhqmp0"
2) "wxrvb9qyxk0"
复制<br>将二维的经纬度转换为一维的字符串, 如果两个字符串越接近, 则距离越近<br><br>
geo底层的实现原理实际上就是Zset, 我们可以通过Zset命令来操作geo
<br>127.0.0.1:6379&gt; type china:city
zset
复制<br>查看全部元素 删除指定的元素<br>127.0.0.1:6379&gt; zrange china:city 0 -1 withscores
 1) "xian"
 2) "4040115445396757"
 3) "hangzhou"
 4) "4054133997236782"
 5) "manjing"
 6) "4066006694128997"
 7) "taiyuan"
 8) "4068216047500484"
 9) "shenyang"
1)  "4072519231994779"
2)  "shengzhen"
3)  "4154606886655324"
127.0.0.1:6379&gt; zrem china:city manjing
(integer) 1
127.0.0.1:6379&gt; zrange china:city 0 -1
1) "xian"
2) "hangzhou"
3) "taiyuan"
4) "shenyang"
5) "shengzhen"
复制<br><br><br>
Redis5.0 中还增加了一个数据结构Stream，从字面上看是流类型，但其实从功能上看，应该是Redis对消息队列（MQ，Message Queue）的完善实现。
<br>用过Redis做消息队列的都了解，基于Reids的消息队列实现有很多种，例如：<br>
<br>PUB/SUB，订阅/发布模式

<br>但是发布订阅模式是无法持久化的，如果出现网络断开、Redis 宕机等，消息就会被丢弃；


<br>基于 List LPUSH + BRPOP 或者基于 Sorted-Set 的实现 

<br>支持了持久化，但是不支持多播，分组消费等


<br>为什么上面的结构无法满足广泛的MQ场景？ 这里便引出一个核心的问题：如果我们期望设计一种数据结构来实现消息队列，最重要的就是要理解设计一个消息队列需要考虑什么？初步的我们很容易想到<br>
<br>消息的生产
<br>消息的消费

<br>单播和多播（多对多）
<br>阻塞和非阻塞读取


<br>消息有序性
<br>消息的持久化
<br><img src="\04、数据库\02、redis\assets\03、常见命令&amp;数据类型\img-20240317_162235.png"><br>我们不妨看看Redis考虑了哪些设计？<br>
<br>消息ID的序列化生成
<br>消息遍历
<br>消息的阻塞和非阻塞读取
<br>消息的分组消费
<br>未完成消息的处理
<br>消息队列监控
<br>...
<br>
这也是我们需要理解Stream的点，但是结合上面的图，我们也应该理解 Redis Stream 也是一种超轻量MQ并没有完全实现消息队列所有设计要点，这决定着它适用的场景。
<br><br>
经过梳理总结，我认为从以下几个大的方面去理解Stream是比较合适的
<br>
<br>Stream的结构设计
<br>生产和消费

<br>基本的增删查改
<br>单一消费者的消费
<br>消费组的消费


<br>监控状态
<br><br>每个 Stream 都有唯一的名称，它就是 Redis 的 key，在我们首次使用 xadd 指令追加消息时自动创建。<br><img src="\04、数据库\02、redis\assets\03、常见命令&amp;数据类型\img-20240317_162313.png"><br>上图解析：<br>
<br>Consumer Group ：消费组，使用 XGROUP CREATE 命令创建，一个消费组有多个消费者(Consumer), 这些消费者之间是竞争关系。
<br>last_delivered_id ：游标，每个消费组会有个游标 last_delivered_id，任意一个消费者读取了消息都会使游标 last_delivered_id 往前移动。
<br>pending_ids ：消费者(Consumer)的状态变量，作用是维护消费者的未确认的 id。 pending_ids 记录了当前已经被客户端读取的消息，但是还没有 ack (Acknowledge character：确认字符）。如果客户端没有ack，这个变量里面的消息ID会越来越多，一旦某个消息被ack，它就开始减少。这个pending_ids变量在Redis官方被称之为PEL，也就是Pending Entries List，这是一个很核心的数据结构，它用来确保客户端至少消费了消息一次，而不会在网络传输的中途丢失了没处理。
<br>此外我们还需要理解两点：<br>
<br>消息ID: 消息ID的形式是timestampInMillis-sequence，例如1527846880572-5，它表示当前的消息在毫米时间戳1527846880572时产生，并且是该毫秒内产生的第5条消息。消息ID可以由服务器自动生成，也可以由客户端自己指定，但是形式必须是整数-整数，而且必须是后面加入的消息的ID要大于前面的消息ID。
<br>消息内容: 消息内容就是键值对，形如hash结构的键值对，这没什么特别之处。
<br><br>消息队列相关命令：<br>
<br>XADD - 添加消息到末尾
<br>XTRIM - 对流进行修剪，限制长度
<br>XDEL - 删除消息
<br>XLEN - 获取流包含的元素数量，即消息长度
<br>XRANGE - 获取消息列表，会自动过滤已经删除的消息
<br>XREVRANGE - 反向获取消息列表，ID 从大到小
<br>XREAD - 以阻塞或非阻塞方式获取消息列表
<br># *号表示服务器自动生成ID，后面顺序跟着一堆key/value

127.0.0.1:6379&gt; xadd codehole * name laoqian age 30  #  名字叫laoqian，年龄30岁
1527849609889-0  # 生成的消息ID
127.0.0.1:6379&gt; xadd codehole * name xiaoyu age 29
1527849629172-0
127.0.0.1:6379&gt; xadd codehole * name xiaoqian age 1
1527849637634-0

#  获取长度
127.0.0.1:6379&gt; xlen codehole
(integer) 3

# -表示最小值, +表示最大值
127.0.0.1:6379&gt; xrange codehole - +  
1) 1) 1527849609889-0
   1) 1) "name"
      1) "laoqian"
      2) "age"
      3) "30"
2) 1) 1527849629172-0
   1) 1) "name"
      1) "xiaoyu"
      2) "age"
      3) "29"
3) 1) 1527849637634-0
   1) 1) "name"
      1) "xiaoqian"
      2) "age"
      3) "1"

# 指定最小消息ID的列表 到 后面所有
127.0.0.1:6379&gt; xrange codehole 1527849629172-0 +  # 指定最小消息ID的列表
1) 1) 1527849629172-0
   2) 1) "name"
      2) "xiaoyu"
      3) "age"
      4) "29"
2) 1) 1527849637634-0
   2) 1) "name"
      2) "xiaoqian"
      3) "age"
      4) "1"

# 指定当前  到 最大消息ID的列表
127.0.0.1:6379&gt; xrange codehole - 1527849629172-0 
1) 1) 1527849609889-0
   2) 1) "name"
      2) "laoqian"
      3) "age"
      4) "30"
2) 1) 1527849629172-0
   2) 1) "name"
      2) "xiaoyu"
      3) "age"
      4) "29"

 # 删除一个小希
127.0.0.1:6379&gt; xdel codehole 1527849609889-0
(integer) 1
127.0.0.1:6379&gt; xlen codehole  # 长度不受影响
(integer) 3

127.0.0.1:6379&gt; xrange codehole - +  # 被删除的消息没了
1) 1) 1527849629172-0
   2) 1) "name"
      2) "xiaoyu"
      3) "age"
      4) "29"
2) 1) 1527849637634-0
   2) 1) "name"
      2) "xiaoqian"
      3) "age"
      4) "1"

# 删除整个Stream
127.0.0.1:6379&gt; del codehole 
(integer) 1
复制<br><br>我们可以在不定义消费组的情况下进行Stream消息的独立消费，当Stream没有新消息时，甚至可以阻塞等待。Redis设计了一个单独的消费指令xread，可以将Stream当成普通的消息队列(list)来使用。使用xread时，我们可以完全忽略消费组(Consumer Group)的存在，就好比Stream就是一个普通的列表(list)。<br># 从Stream头部读取两条消息
127.0.0.1:6379&gt; xread count 2 streams codehole 0-0
1) 1) "codehole"
   2) 1) 1) 1527851486781-0
         2) 1) "name"
            2) "laoqian"
            3) "age"
            4) "30"
      2) 1) 1527851493405-0
         2) 1) "name"
            2) "yurui"
            3) "age"
            4) "29"

# 从Stream尾部读取一条消息，毫无疑问，这里不会返回任何消息
127.0.0.1:6379&gt; xread count 1 streams codehole $
(nil)

# 从尾部阻塞等待新消息到来，下面的指令会堵住，直到新消息到来
127.0.0.1:6379&gt; xread block 0 count 1 streams codehole $

# 我们从新打开一个窗口，在这个窗口往Stream里塞消息
127.0.0.1:6379&gt; xadd codehole * name youming age 60
1527852774092-0

# 再切换到前面的窗口，我们可以看到阻塞解除了，返回了新的消息内容
# 而且还显示了一个等待时间，这里我们等待了93s
127.0.0.1:6379&gt; xread block 0 count 1 streams codehole $
1) 1) "codehole"
   2) 1) 1) 1527852774092-0
         2) 1) "name"
            2) "youming"
            3) "age"
            4) "60"
(93.11s)
复制<br>客户端如果想要使用xread进行顺序消费，一定要记住当前消费到哪里了，也就是返回的消息ID。下次继续调用xread时，将上次返回的最后一个消息ID作为参数传递进去，就可以继续消费后续的消息。<br>block 0表示永远阻塞，直到消息到来，block 1000表示阻塞1s，如果1s内没有任何消息到来，就返回nil<br>127.0.0.1:6379&gt; xread block 1000 count 1 streams codehole $
(nil)
(1.07s)
复制<br><br>
<br>消费组消费图
<br><img alt="assets/03、常见命令&amp;数据类型/img-20240317_162705.png" src="\04、数据库\02、redis\assets\03、常见命令&amp;数据类型\img-20240317_162705.png" style="width: 600px; max-width: 100%;"><br>
<br>相关命令：

<br>XGROUP CREATE - 创建消费者组
<br>XREADGROUP GROUP - 读取消费者组中的消息
<br>XACK - 将消息标记为"已处理"
<br>XGROUP SETID - 为消费者组设置新的最后递送消息ID
<br>XGROUP DELCONSUMER - 删除消费者
<br>XGROUP DESTROY - 删除消费者组
<br>XPENDING - 显示待处理消息的相关信息
<br>XCLAIM - 转移消息的归属权
<br>XINFO - 查看流和消费者组的相关信息；
<br>XINFO GROUPS - 打印消费者组的信息；
<br>XINFO STREAM - 打印流信息


<br>创建消费组<br>

<br>Stream通过xgroup create指令创建消费组(Consumer Group)，需要传递起始消息ID参数用来初始化last_delivered_id变量。<br>127.0.0.1:6379&gt; xgroup create codehole cg1 0-0  #  表示从头开始消费
OK
# $表示从尾部开始消费，只接受新消息，当前Stream消息会全部忽略
127.0.0.1:6379&gt; xgroup create codehole cg2 $
OK
127.0.0.1:6379&gt; xinfo stream codehole  # 获取Stream信息
 1) length
 2) (integer) 3  # 共3个消息
 3) radix-tree-keys
 4) (integer) 1
 5) radix-tree-nodes
 6) (integer) 2
 7) groups
 8) (integer) 2  # 两个消费组
 9) first-entry  # 第一个消息
10) 1) 1527851486781-0
    2) 1) "name"
       2) "laoqian"
       3) "age"
       4) "30"
11) last-entry  # 最后一个消息
12) 1) 1527851498956-0
    2) 1) "name"
       2) "xiaoqian"
       3) "age"
       4) "1"
127.0.0.1:6379&gt; xinfo groups codehole  # 获取Stream的消费组信息
1) 1) name
   2) "cg1"
   3) consumers
   4) (integer) 0  # 该消费组还没有消费者
   5) pending
   6) (integer) 0  # 该消费组没有正在处理的消息
2) 1) name
   2) "cg2"
   3) consumers  # 该消费组还没有消费者
   4) (integer) 0
   5) pending
   6) (integer) 0  # 该消费组没有正在处理的消息
复制<br>
<br>消费组消费
<br>Stream提供了xreadgroup指令可以进行消费组的组内消费，需要提供消费组名称、消费者名称和起始消息ID。它同xread一样，也可以阻塞等待新消息。读到新消息后，对应的消息ID就会进入消费者的PEL(正在处理的消息)结构里，客户端处理完毕后使用xack指令通知服务器，本条消息已经处理完毕，该消息ID就会从PEL中移除。<br># &gt;号表示从当前消费组的last_delivered_id后面开始读
# 每当消费者读取一条消息，last_delivered_id变量就会前进
127.0.0.1:6379&gt; xreadgroup GROUP cg1 c1 count 1 streams codehole &gt;
1) 1) "codehole"
   2) 1) 1) 1527851486781-0
         2) 1) "name"
            2) "laoqian"
            3) "age"
            4) "30"

127.0.0.1:6379&gt; xreadgroup GROUP cg1 c1 count 1 streams codehole &gt;
1) 1) "codehole"
   2) 1) 1) 1527851493405-0
         2) 1) "name"
            2) "yurui"
            3) "age"
            4) "29"

127.0.0.1:6379&gt; xreadgroup GROUP cg1 c1 count 2 streams codehole &gt;
1) 1) "codehole"
   2) 1) 1) 1527851498956-0
         2) 1) "name"
            2) "xiaoqian"
            3) "age"
            4) "1"
      2) 1) 1527852774092-0
         2) 1) "name"
            2) "youming"
            3) "age"
            4) "60"

# 再继续读取，就没有新消息了
127.0.0.1:6379&gt; xreadgroup GROUP cg1 c1 count 1 streams codehole &gt;
(nil)

# 那就阻塞等待吧
127.0.0.1:6379&gt; xreadgroup GROUP cg1 c1 block 0 count 1 streams codehole &gt;

# 开启另一个窗口，往里塞消息
127.0.0.1:6379&gt; xadd codehole * name lanying age 61
1527854062442-0

# 回到前一个窗口，发现阻塞解除，收到新消息了
127.0.0.1:6379&gt; xreadgroup GROUP cg1 c1 block 0 count 1 streams codehole &gt;
1) 1) "codehole"
   2) 1) 1) 1527854062442-0
         2) 1) "name"
            2) "lanying"
            3) "age"
            4) "61"
(36.54s)

127.0.0.1:6379&gt; xinfo groups codehole  # 观察消费组信息
1) 1) name
   2) "cg1"
   3) consumers
   4) (integer) 1  # 一个消费者
   5) pending
   6) (integer) 5  # 共5条正在处理的信息还有没有ack
2) 1) name
   2) "cg2"
   3) consumers
   4) (integer) 0  # 消费组cg2没有任何变化，因为前面我们一直在操纵cg1
   5) pending
   6) (integer) 0

# 如果同一个消费组有多个消费者，我们可以通过xinfo consumers指令观察每个消费者的状态
127.0.0.1:6379&gt; xinfo consumers codehole cg1  # 目前还有1个消费者
1) 1) name
   2) "c1"
   3) pending
   4) (integer) 5  # 共5条待处理消息
   5) idle
   6) (integer) 418715  # 空闲了多长时间ms没有读取消息了

# 接下来我们ack一条消息
127.0.0.1:6379&gt; xack codehole cg1 1527851486781-0
(integer) 1
127.0.0.1:6379&gt; xinfo consumers codehole cg1
1) 1) name
   2) "c1"
   3) pending
   4) (integer) 4  # 变成了5条
   5) idle
   6) (integer) 668504

# 下面ack所有消息
127.0.0.1:6379&gt; xack codehole cg1 1527851493405-0 1527851498956-0 1527852774092-0 1527854062442-0
(integer) 4
127.0.0.1:6379&gt; xinfo consumers codehole cg1
1) 1) name
   2) "c1"
   3) pending
   4) (integer) 0  # pel空了
   5) idle
   6) (integer) 745505
复制<br><br>Stream提供了XINFO来实现对服务器信息的监控，可以查询：<br>
<br>查看队列信息
<br>127.0.0.1:6379&gt; Xinfo stream mq
 1) "length"
 2) (integer) 7
 3) "radix-tree-keys"
 4) (integer) 1
 5) "radix-tree-nodes"
 6) (integer) 2
 7) "groups"
 8) (integer) 1
 9) "last-generated-id"
10) "1553585533795-9"
11) "first-entry"
12) 1) "1553585533795-3"
    2) 1) "msg"
       2) "4"
13) "last-entry"
14) 1) "1553585533795-9"
    2) 1) "msg"
       2) "10"
复制<br>
<br>消费组信息
<br>127.0.0.1:6379&gt; Xinfo groups mq
1) 1) "name"
   2) "mqGroup"
   3) "consumers"
   4) (integer) 3
   5) "pending"
   6) (integer) 3
   7) "last-delivered-id"
   8) "1553585533795-4"
复制<br>
<br>消费者组成员信息
<br>127.0.0.1:6379&gt; XINFO CONSUMERS mq mqGroup
1) 1) "name"
   2) "consumerA"
   3) "pending"
   4) (integer) 1
   5) "idle"
   6) (integer) 18949894
2) 1) "name"
   2) "consumerB"
   3) "pending"
   4) (integer) 1
   5) "idle"
   6) (integer) 3092719
3) 1) "name"
   2) "consumerC"
   3) "pending"
   4) (integer) 1
   5) "idle"
   6) (integer) 23683256
复制<br>至此，消息队列的操作说明大体结束！<br><br>
我们结合MQ中常见问题，看Redis是如何解决的，来进一步理解Redis。
<br><br>可用作时通信等，大数据分析，异地数据备份等<br><img alt="assets/03、常见命令&amp;数据类型/img-20240317_162936.png" src="\04、数据库\02、redis\assets\03、常见命令&amp;数据类型\img-20240317_162936.png" style="width: 675px; max-width: 100%;"><br>客户端可以平滑扩展，提高处理能力<br><img alt="assets/03、常见命令&amp;数据类型/img-20240317_162950.png" src="\04、数据库\02、redis\assets\03、常见命令&amp;数据类型\img-20240317_162950.png" style="width: 700px; max-width: 100%;"><br><br>
在 <a class="internal-link" data-href="/md/algorithm/alg-domain-id-snowflake.html" href="\md\algorithm\alg-domain-id-snowflake.html" target="_self" rel="noopener">分布式算法 - ID算法</a>设计中, 一个常见的问题就是时间回拨问题，那么Redis的消息ID设计中是否考虑到这个问题呢？
<br>Redis XADD 生成的消息ID，由两部分组成：时间戳-序号。<br>
时间戳是毫秒级单位，是生成消息的Redis服务器时间，它是个64位整型（int64）。序号是在这个毫秒时间点内的消息序号，它也是个64位整型。<br>可以通过multi批处理，来验证序号的递增：<br>127.0.0.1:6379&gt; MULTI
OK
127.0.0.1:6379&gt; XADD memberMessage * msg one
QUEUED
127.0.0.1:6379&gt; XADD memberMessage * msg two
QUEUED
127.0.0.1:6379&gt; XADD memberMessage * msg three
QUEUED
127.0.0.1:6379&gt; XADD memberMessage * msg four
QUEUED
127.0.0.1:6379&gt; XADD memberMessage * msg five
QUEUED
127.0.0.1:6379&gt; EXEC
1) "1553441006884-0"
2) "1553441006884-1"
3) "1553441006884-2"
4) "1553441006884-3"
5) "1553441006884-4"
复制<br>由于一个redis命令的执行很快，所以可以看到在同一时间戳内，是通过序号递增来表示消息的。<br>为了保证消息是有序的，因此Redis生成的ID是单调递增有序的。由于ID中包含时间戳部分，为了避免服务器时间错误而带来的问题（例如服务器时间延后了），Redis的每个Stream类型数据都维护一个latest_generated_id属性，用于记录最后一个消息的ID。若发现当前时间戳退后（小于latest_generated_id所记录的），则采用时间戳不变而序号递增的方案来作为新消息ID（这也是序号为什么使用int64的原因，保证有足够多的的序号），从而保证ID的单调递增性质。<br>强烈建议使用Redis的方案生成消息ID，因为这种时间戳+序号的单调递增的ID方案，几乎可以满足你全部的需求。<br>
但同时，记住ID是支持自定义的，别忘了！<br><br>为了解决组内消息读取但处理期间消费者崩溃带来的消息丢失问题，STREAM 设计了 Pending 列表，用于记录读取但并未处理完毕的消息。<br>命令XPENDIING 用来获消费组或消费内消费者的未处理完毕的消息。演示如下：<br>127.0.0.1:6379&gt; XPENDING mq mqGroup # mpGroup的Pending情况
1) (integer) 5 # 5个已读取但未处理的消息
2) "1553585533795-0" # 起始ID
3) "1553585533795-4" # 结束ID
4) 1) 1) "consumerA" # 消费者A有3个
      2) "3"
   2) 1) "consumerB" # 消费者B有1个
      2) "1"
   3) 1) "consumerC" # 消费者C有1个
      2) "1"

127.0.0.1:6379&gt; XPENDING mq mqGroup - + 10 # 使用 start end count 选项可以获取详细信息
1) 1) "1553585533795-0" # 消息ID
   2) "consumerA" # 消费者
   3) (integer) 1654355 # 从读取到现在经历了1654355ms，IDLE
   4) (integer) 5 # 消息被读取了5次，delivery counter
2) 1) "1553585533795-1"
   2) "consumerA"
   3) (integer) 1654355
   4) (integer) 4
# 共5个，余下3个省略 ...

127.0.0.1:6379&gt; XPENDING mq mqGroup - + 10 consumerA # 在加上消费者参数，获取具体某个消费者的Pending列表
1) 1) "1553585533795-0"
   2) "consumerA"
   3) (integer) 1641083
   4) (integer) 5
# 共3个，余下2个省略 ...
复制<br>每个Pending的消息有4个属性：<br>
<br>消息ID
<br>所属消费者
<br>IDLE，已读取时长
<br>delivery counter，消息被读取次数
<br>上面的结果我们可以看到，我们之前读取的消息，都被记录在Pending列表中，说明全部读到的消息都没有处理，仅仅是读取了。那如何表示消费者处理完毕了消息呢？使用命令 XACK 完成告知消息处理完成，演示如下：<br>127.0.0.1:6379&gt; XACK mq mqGroup 1553585533795-0 # 通知消息处理结束，用消息ID标识
(integer) 1

127.0.0.1:6379&gt; XPENDING mq mqGroup # 再次查看Pending列表
1) (integer) 4 # 已读取但未处理的消息已经变为4个
2) "1553585533795-1"
3) "1553585533795-4"
4) 1) 1) "consumerA" # 消费者A，还有2个消息处理
      2) "2"
   2) 1) "consumerB"
      2) "1"
   3) 1) "consumerC"
      2) "1"
127.0.0.1:6379&gt;
复制<br>有了这样一个Pending机制，就意味着在某个消费者读取消息但未处理后，消息是不会丢失的。等待消费者再次上线后，可以读取该Pending列表，就可以继续处理该消息了，保证消息的有序和不丢失。<br><br>
还有一个问题，就是若某个消费者宕机之后，没有办法再上线了，那么就需要将该消费者Pending的消息，转义给其他的消费者处理，就是消息转移。
<br>消息转移的操作时将某个消息转移到自己的Pending列表中。使用语法XCLAIM来实现，需要设置组、转移的目标消费者和消息ID，同时需要提供IDLE（已被读取时长），只有超过这个时长，才能被转移。演示如下：<br># 当前属于消费者A的消息1553585533795-1，已经15907,787ms未处理了
127.0.0.1:6379&gt; XPENDING mq mqGroup - + 10
1) 1) "1553585533795-1"
   2) "consumerA"
   3) (integer) 15907787
   4) (integer) 4

# 转移超过3600s的消息1553585533795-1到消费者B的Pending列表
127.0.0.1:6379&gt; XCLAIM mq mqGroup consumerB 3600000 1553585533795-1
1) 1) "1553585533795-1"
   2) 1) "msg"
      2) "2"

# 消息1553585533795-1已经转移到消费者B的Pending中。
127.0.0.1:6379&gt; XPENDING mq mqGroup - + 10
1) 1) "1553585533795-1"
   2) "consumerB"
   3) (integer) 84404 # 注意IDLE，被重置了
   4) (integer) 5 # 注意，读取次数也累加了1次
复制<br>以上代码，完成了一次消息转移。转移除了要指定ID外，还需要指定IDLE，保证是长时间未处理的才被转移。被转移的消息的IDLE会被重置，用以保证不会被重复转移，以为可能会出现将过期的消息同时转移给多个消费者的并发操作，设置了IDLE，则可以避免后面的转移不会成功，因为IDLE不满足条件。例如下面的连续两条转移，第二条不会成功。<br>127.0.0.1:6379&gt; XCLAIM mq mqGroup consumerB 3600000 1553585533795-1
127.0.0.1:6379&gt; XCLAIM mq mqGroup consumerC 3600000 1553585533795-1
复制<br>这就是消息转移。至此我们使用了一个Pending消息的ID，所属消费者和IDLE的属性，还有一个属性就是消息被读取次数，delivery counter，该属性的作用由于统计消息被读取的次数，包括被转移也算。这个属性主要用在判定是否为错误数据上。<br><br>正如上面所说，如果某个消息，不能被消费者处理，也就是不能被XACK，这是要长时间处于Pending列表中，即使被反复的转移给各个消费者也是如此。此时该消息的delivery counter就会累加（上一节的例子可以看到），当累加到某个我们预设的临界值时，我们就认为是坏消息（也叫死信，DeadLetter，无法投递的消息），由于有了判定条件，我们将坏消息处理掉即可，删除即可。删除一个消息，使用XDEL语法，演示如下：<br># 删除队列中的消息
127.0.0.1:6379&gt; XDEL mq 1553585533795-1
(integer) 1
# 查看队列中再无此消息
127.0.0.1:6379&gt; XRANGE mq - +
1) 1) "1553585533795-0"
   2) 1) "msg"
      2) "1"
2) 1) "1553585533795-2"
   2) 1) "msg"
      2) "3"
复制<br>注意本例中，并没有删除Pending中的消息因此你查看Pending，消息还会在。可以执行XACK标识其处理完毕！<br><br>
<br><a rel="noopener" class="external-link" href="https://www.runoob.com/redis/redis-stream.html" target="_blank">https://www.runoob.com/redis/redis-stream.html</a>
<br><a rel="noopener" class="external-link" href="https://www.zhihu.com/question/279540635" target="_blank">https://www.zhihu.com/question/279540635</a>
<br><a rel="noopener" class="external-link" href="https://zhuanlan.zhihu.com/p/60501638" target="_blank">https://zhuanlan.zhihu.com/p/60501638</a>
]]></description><link>04、数据库\02、redis\03、常见命令&amp;数据类型.html</link><guid isPermaLink="false">04、数据库/02、Redis/03、常见命令&amp;数据类型.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Mon, 18 Mar 2024 11:47:13 GMT</pubDate><enclosure url="04、数据库\02、redis\assets\03、常见命令&amp;数据类型\img-20240317_162235.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;04、数据库\02、redis\assets\03、常见命令&amp;数据类型\img-20240317_162235.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[04、Redis 的 Java 客户端]]></title><description><![CDATA[ 
 <br>在 Redis 官网中提供了各种语言的客户端，地址： <a rel="noopener" class="external-link" href="https://redis.io/docs/clients/" target="_blank">https://redis.io/docs/clients/</a><br>
<img alt="assets/04、Redis 的 Java 客户端/img-20240317_093601.png" src="\04、数据库\02、redis\assets\04、redis-的-java-客户端\img-20240317_093601.png" style="width: 725px; max-width: 100%;"><br>
其中 Java 客户端也包含很多：<br><img alt="assets/04、Redis 的 Java 客户端/img-20240317_093735.png" src="\04、数据库\02、redis\assets\04、redis-的-java-客户端\img-20240317_093735.png" style="width: 700px; max-width: 100%;"><br>标记为 ❤ 的就是推荐使用的 java 客户端，包括：<br>
<br>
Jedis 和 Lettuce：这两个主要是提供了 Redis 命令对应的 API，方便我们操作 Redis，而 SpringDataRedis 又对这两种做了抽象和封装，因此我们后期会直接以 SpringDataRedis 来学习。

<br>
Redisson：是在 Redis 基础上实现了分布式的可伸缩的 java 数据结构，例如 Map、Queue 等，而且支持跨进程的同步机制：Lock、Semaphore 等待，比较适合用来实现特殊的功能需求。

<br><br><br>Jedis 的官网地址： <a rel="noopener" class="external-link" href="https://github.com/redis/jedis" target="_blank">https://github.com/redis/jedis</a><br>1、引入依赖：<br>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;project xmlns=" http://maven.apache.org/POM/4.0.0"
         xmlns:xsi=" http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation=" http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;
    &lt;parent&gt;
        &lt;artifactId&gt;redis_code&lt;/artifactId&gt;
        &lt;groupId&gt;tech. Chen&lt;/groupId&gt;
        &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;
    &lt;/parent&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;artifactId&gt;redis-client-jedis&lt;/artifactId&gt;

    &lt;dependencies&gt;
        &lt;!-- https://mvnrepository.com/artifact/redis.clients/jedis --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;redis. Clients&lt;/groupId&gt;
            &lt;artifactId&gt;jedis&lt;/artifactId&gt;
            &lt;version&gt;3.7.0&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;!--common-pool--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org. Apache. Commons&lt;/groupId&gt;
            &lt;artifactId&gt;commons-pool 2&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;!--单元测试--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org. Junit. Jupiter&lt;/groupId&gt;
            &lt;artifactId&gt;junit-jupiter&lt;/artifactId&gt;
            &lt;version&gt;5.7.0&lt;/version&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
&lt;/project&gt;
复制<br>2、建立连接<br>新建一个单元测试类，内容如下：<br>private Jedis jedis;
    @BeforeEach
    void setUp() {
        jedis = new Jedis("192.168.200.130",6379);
        jedis.auth("123321");
        jedis.select(0);
    }
复制<br>3、测试<br>@Test
void string() {
    String set = jedis.set("name", "czk");
    System.out.println("set = " + set);//set = OK
    String name = jedis.get("name");
    System.out.println("name = " + name);//name = czk
}

@Test
void hash() {
    long hset = jedis.hset("login:user:1", "name", "阿陈");
    System.out.println("hset = " + hset);//hset = 1
    String name = jedis.hget("login:user:1", "name");
    System.out.println("name = " + name);//name = 阿陈
}
复制<br>4、释放资源<br>@AfterEach
void afterAll() {
    if(jedis!=null){
        jedis.close();
    }
}
复制<br><br>Jedis 本身是线程不安全的，并且频繁的创建和销毁连接会有性能损耗，因此我们推荐大家使用 Jedis 连接池代替 Jedis 的直连方式。<br>/**
 * @Date 2022/8/1 19:17
 * @Author c-z-k
 */
public class JedisPoolTest {
    private static JedisPool jedisPool;
    @BeforeEach
    void setUp() {
        JedisPoolConfig config = new JedisPoolConfig();
        config.setMaxWaitMillis(1000);
        config.setMinIdle(0);
        config.setMaxIdle(8);
        config.setMaxTotal(8);
        jedisPool = new JedisPool(config,"192.168.200.130",6379,1000,"123321");
    }
    public static Jedis getJedis(){
        return jedisPool.getResource();
    }

    @Test
    void string() {
        String set = getJedis().set("name", "小猪");
        System.out.println("set = " + set);
        String name = getJedis().get("name");
        System.out.println("name = " + name);
    }

    @Test
    void hash() {
        long hset = getJedis().hset("login:user:2", "name", "小猪");
        System.out.println("hset = " + hset);//hset = 1
        String name = getJedis().hget("login:user:2", "name");
        System.out.println("name = " + name);//name = 小猪
    }
}
复制<br><br>SpringData 是 Spring 中数据操作的模块，包含对各种数据库的集成，其中对 Redis 的集成模块就叫做 SpringDataRedis。<br>
官网地址： <a rel="noopener" class="external-link" href="https://spring.io/projects/spring-data-redis" target="_blank">https://spring.io/projects/spring-data-redis</a><br>
<br>提供了对不同 Redis 客户端的整合（Lettuce 和 Jedis）
<br>提供了 RedisTemplate 统一 API 来操作 Redis
<br>支持 Redis 的发布订阅模型
<br>支持 Redis 哨兵和 Redis 集群
<br>支持基于 Lettuce 的响应式编程
<br>支持基于 JDK、JSON、字符串、Spring 对象的数据序列化及反序列化
<br>支持基于 Redis 的 JDKCollection 实现
<br>SPringDataRedis 中提供了 RedisTemplate 工具类，其中封装了各种对 Redis 的操作。并且将不同数据类型的操作 API 封装到了不同的类型中：<br><img src="\04、数据库\02、redis\assets\04、redis-的-java-客户端\img-20240317_163857.png"><br><br>SpringBoot 已经提供了对 SpringDataRedis 的支持，使用非常简单。<br>
首先，新建一个 maven 项目，然后按照下面步骤执行：<br>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
    &lt;parent&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
        &lt;version&gt;2.5.6&lt;/version&gt;
        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;
    &lt;/parent&gt;
    &lt;groupId&gt;tech.chen&lt;/groupId&gt;
    &lt;artifactId&gt;spring-client-spring-data-redis&lt;/artifactId&gt;
    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;
    &lt;name&gt;spring-client-spring-data-redis&lt;/name&gt;
    &lt;description&gt;Demo project for Spring Boot&lt;/description&gt;
    &lt;properties&gt;
        &lt;java.version&gt;1.8&lt;/java.version&gt;
    &lt;/properties&gt;
    &lt;dependencies&gt;
        &lt;!--redis依赖--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;!--common-pool--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;
            &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
            &lt;optional&gt;true&lt;/optional&gt;
        &lt;/dependency&gt;
        &lt;!--Jackson依赖 ,springmvc中自带依赖，这里由于没有，故引用--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;
            &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

    &lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
                &lt;configuration&gt;
                    &lt;excludes&gt;
                        &lt;exclude&gt;
                            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
                            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
                        &lt;/exclude&gt;
                    &lt;/excludes&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
&lt;/project&gt;
复制<br>2）配置 Redis<br>spring:
  redis:
    host: 192.168.200.130
    port: 6379
    password: 123321
    lettuce:
      pool:
        max-active: 8
        max-idle: 8
        min-idle: 0
        max-wait: 1000ms
复制<br>3）注入 RedisTemplate<br>因为有了 SpringBoot 的自动装配，我们可以拿来就用：<br>@SpringBootTest
class RedisStringTests {
    @Autowired
    private RedisTemplate redisTemplate;
}
复制<br>4）编写测试<br>@SpringBootTest
class SpringClientSpringDataRedisApplicationTests {
    @Autowired
    private RedisTemplate redisTemplate;
    @Test
    void string() {
        // 写入一条String数据
        redisTemplate.opsForValue().set("name", "阿陈");
        // 获取string数据
        Object name = redisTemplate.opsForValue().get("name");
        System.out.println("name = " + name);//name = 阿陈
    }
}
复制<br>查看 redisGUI, 发现 redis 中存的数据并不像我们预期的那样 name: 阿陈<br><img src="\04、数据库\02、redis\assets\04、redis-的-java-客户端\img-20240317_164501.png"><br><br>Redis 序列化器有以下几种：<br><img src="\04、数据库\02、redis\assets\04、redis-的-java-客户端\img-20240317_164538.png"><br>常用的是 StringRedisSerializer 和 Jackson2JsonRedisSerializer 。<br>RedisTemplate 可以接收任意 Object 作为值写入 Redis：<br><img src="\04、数据库\02、redis\assets\04、redis-的-java-客户端\img-20240317_164603.png"><br>只不过写入前会把 Object 序列化为字节形式，默认是采用 JDK 序列化，得到的结果是这样的：<br><img alt="assets/04、Redis 的 Java 客户端/img-20240317_164624.png" src="\04、数据库\02、redis\assets\04、redis-的-java-客户端\img-20240317_164624.png" style="width: 975px; max-width: 100%;"><br>缺点：<br>
<br>可读性差
<br>内存占用较大
<br>我们可以自定义 RedisTemplate 的序列化方式，代码如下：<br>@Configuration
public class RedisConfig {

    @Bean
    public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory connectionFactory) {
        // 创建RedisTemplate对象
        RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;&gt;();
        // 设置连接工厂
        template.setConnectionFactory(connectionFactory);
        // 创建JSON序列化工具
        GenericJackson2JsonRedisSerializer jsonRedisSerializer = new GenericJackson2JsonRedisSerializer();
        // 设置Key和hashKey的序列化
        template.setKeySerializer(RedisSerializer.string());
        template.setHashKeySerializer(RedisSerializer.string());
        // 设置Value和hashValue的序列化
        template.setValueSerializer(jsonRedisSerializer);
        template.setHashValueSerializer(jsonRedisSerializer);
        // 返回
        return template;
    }
}
复制<br>这里采用了 JSON 序列化来代替默认的 JDK 序列化方式，一般我们使用 redis 的时候，redis 的 key 都是 String 类型的，故在对 key 使用序列化器时，都采用 RedisSerializer.String () 的方式。再次测试，结果如图：<br><img src="\04、数据库\02、redis\assets\04、redis-的-java-客户端\img-20240317_164810.png"><br>如果我们是存 java 对象，那 redis 会怎样显示？<br>@Test
void stringObjTest() {
    User user = new User();
    user.setName("阿陈");
    user.setAge(21);
    // 写入一条String数据
    redisTemplate.opsForValue().set("login:user:101", user);
    // 获取string数据
    User user1 = (User) redisTemplate.opsForValue().get("login:user:101");
    System.out.println("user1 = " + user1);//user1 = tech.chen.springclientspringdataredis.entity.User@516592b1
}
复制<br><img src="\04、数据库\02、redis\assets\04、redis-的-java-客户端\img-20240317_164919.png"><br>整体可读性有了很大提升，并且能将 Java 对象自动的序列化为 JSON 字符串，并且查询时能自动把 JSON 反序列化为 Java 对象。不过，其中记录了序列化时对应的 class 名称，目的是为了查询时实现自动反序列化。这会带来额外的内存开销。<br><br>为了节省内存空间，我们可以不使用 JSON 序列化器来处理 value，而是统一使用 String 序列化器，要求只能存储 String 类型的 key 和 value。当需要存储 Java 对象时，手动完成对象的序列化和反序列化。<br><img src="\04、数据库\02、redis\assets\04、redis-的-java-客户端\img-20240317_165035.png"><br>因为存入和读取时的序列化及反序列化都是我们自己实现的，SpringDataRedis 就不会将 class 信息写入 Redis 了。<br>这种用法比较普遍，因此 SpringDataRedis 就提供了 RedisTemplate 的子类：StringRedisTemplate ，它的 key 和 value 的序列化方式默认就是 String 方式。<br><img src="\04、数据库\02、redis\assets\04、redis-的-java-客户端\img-20240317_165047.png"><br>省去了我们自定义 RedisTemplate 的序列化方式的步骤，而是直接使用：<br>/**
 * @Date 2022/8/2 20:55
 * @Author c-z-k
 */
@SpringBootTest
public class StringRedisTemplateTest {
    @Autowired
    private StringRedisTemplate stringRedisTemplate;

    private static final ObjectMapper objectMapper = new ObjectMapper();
    @Test
    void stringTest() {
        // 写入一条String数据
        stringRedisTemplate.opsForValue().set("name", "阿陈");
        // 获取string数据
        Object name = stringRedisTemplate.opsForValue().get("name");
        System.out.println("name = " + name);//name = 阿陈
    }
    @Test
    void stringObjTest() {
        User user = new User();
        user.setName("阿陈");
        user.setAge(21);
        // 写入一条String数据
        String userJson = null;
        try {
            userJson = objectMapper.writeValueAsString(user);
            stringRedisTemplate.opsForValue().set("login:user:101", userJson);
            // 获取string数据
            String result = stringRedisTemplate.opsForValue().get("login:user:101");
            User user1 = objectMapper.readValue(result, User.class);
            System.out.println("user1 = " + user1);//user1 = tech.chen.springclientspringdataredis.entity.User@3878be7b
        } catch (JsonProcessingException e) {
            e.printStackTrace();
        }
    }
}
复制<br><img src="\04、数据库\02、redis\assets\04、redis-的-java-客户端\img-20240317_165131.png">]]></description><link>04、数据库\02、redis\04、redis-的-java-客户端.html</link><guid isPermaLink="false">04、数据库/02、Redis/04、Redis 的 Java 客户端.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Mon, 18 Mar 2024 11:47:38 GMT</pubDate><enclosure url="04、数据库\02、redis\assets\04、redis-的-java-客户端\img-20240317_093601.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;04、数据库\02、redis\assets\04、redis-的-java-客户端\img-20240317_093601.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[05、持久化：RDB 和 AOF 机制详解]]></title><description><![CDATA[ 
 <br><br>Redis 是个基于内存的数据库。那服务一旦宕机，内存中的数据将全部丢失。<br>通常的解决方案是从后端数据库恢复这些数据，但后端数据库有性能瓶颈，如果是大数据量的恢复：<br>
1、会对数据库带来巨大的压力。<br>
2、数据库的性能不如Redis。导致程序响应慢。所以对Redis来说，实现数据的持久化，避免从后端数据库中恢复数据，是至关重要的。<br><br>RDB 就是 Redis DataBase 的缩写，中文名为快照/内存快照，RDB 持久化是把当前进程数据生成快照保存到磁盘上的过程，由于是某一时刻的快照，那么快照中的值要早于或者等于内存中的值。<br>
触发rdb持久化的方式有2种，分别是手动触发和自动触发。
<br><br><br>
<br>save命令：阻塞当前Redis服务器，直到RDB过程完成为止，对于内存 比较大的实例会造成长时间阻塞，线上环境不建议使用
<br>bgsave命令：Redis进程执行fork操作创建子进程，RDB持久化过程由子 进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短
<br>具体流程如下：<br>
<br>redis客户端执行bgsave命令或者自动触发bgsave命令；
<br>主进程判断当前是否已经存在正在执行的子进程，如果存在，那么主进程直接返回；
<br>如果不存在正在执行的子进程，那么就fork一个新的子进程进行持久化数据，fork过程是阻塞的，fork操作完成后主进程即可执行其他操作；
<br>子进程先将数据写入到临时的rdb文件中，待快照数据写入完成后再原子替换旧的rdb文件；
<br>同时发送信号给主进程，通知主进程rdb持久化完成，主进程更新相关的统计信息（info Persitence下的 rdb_* 相关选项）。
<br><img src="\04、数据库\02、redis\assets\05、持久化：rdb-和-aof-机制详解\img-20240315_210729.png"><br><br>在以下4种情况时会自动触发：<br>❶ redis.conf 中配置 save m n，即在 m 秒内有 n 次修改时，自动触发 bgsave 生成 rdb 文件；<br>
❷ 主从复制时，从节点要从主节点进行全量复制时也会触发 bgsave 操作，生成当时的快照发送到从节点；<br>
❸ 执行 debug reload 命令重新加载 redis 时也会触发 bgsave 操作；（争议，"DEBUG RELOAD"命令被认为是调试命令）<br>
❹ 默认情况下执行 shutdown 命令时，如果没有开启 aof 持久化，那么也会触发 bgsave 操作。<br><br>快照周期：内存快照虽然可以通过技术人员手动执行 SAVE 或 BGSAVE 命令来进行，但生产环境下多数情况都会设置其周期性执行条件。<br>
<br>Redis中默认的周期新设置
<br># 周期性执行条件的设置格式为
save &lt;seconds&gt; &lt;changes&gt;

# 默认的设置为：读者可以按照这个规则，根据自己的实际请求压力进行设置调整。
#如果900秒内有1条Key信息发生变化，则进行快照；
save 900 1
#如果300秒内有10条Key信息发生变化，则进行快照；
save 300 10
#如果60秒内有10000条Key信息发生变化，则进行快照。
save 60 10000

# 以下设置方式为关闭RDB快照功能
save ""
复制<br>
<br>其它相关配置
<br># 文件名称
dbfilename dump.rdb

# 文件保存路径
dir /home/work/app/redis/data/

# 如果持久化出错，主进程是否停止写入
stop-writes-on-bgsave-error yes

# 是否压缩
rdbcompression yes

# 导入时是否检查
rdbchecksum yes
复制<br>dbfilename：RDB 文件在磁盘上的名称。<br>dir：RDB 文件的存储路径。默认设置为“./”，也就是 Redis 服务的主目录。<br>stop-writes-on-bgsave-error：上文提到的在快照进行过程中，主进程照样可以接受客户端的任何写操作的特性，是指在快照操作正常的情况下。如果快照操作出现异常（例如操作系统用户权限不够、磁盘空间写满等等）时，Redis 就会禁止写操作。这个特性的主要目的是使运维人员在第一时间就发现 Redis 的运行错误，并进行解决。一些特定的场景下，您可能需要对这个特性进行配置，这时就可以调整这个参数项。该参数项默认情况下值为 yes，如果要关闭这个特性，指定即使出现快照错误 Redis 一样允许写操作，则可以将该值更改为 no。<br>rdbcompression：该属性将在字符串类型的数据被快照到磁盘文件时，启用 LZF 压缩算法。Redis 官方的建议是请保持该选项设置为 yes，因为“it’s almost always a win”。<br>rdbchecksum：从RDB快照功能的version 5 版本开始，一个64位的CRC冗余校验编码会被放置在RDB文件的末尾，以便对整个RDB文件的完整性进行验证。这个功能大概会多损失10%左右的性能，但获得了更高的数据可靠性。所以如果您的Redis服务需要追求极致的性能，就可以将这个选项设置为no。<br><br>
由于生产环境中我们为Redis开辟的内存区域都比较大（例如6GB），那么将内存中的数据同步到硬盘的过程可能就会持续比较长的时间，而实际情况是这段时间Redis服务一般都会收到数据写操作请求。那么如何保证数据一致性呢？
<br>RDB中的核心思路是Copy-on-Write，来保证在进行快照操作的这段时间，需要压缩写入磁盘上的数据在内存中不会发生变化。在正常的快照操作中，一方面Redis主进程会fork一个新的快照进程专门来做这个事情，这样保证了Redis服务不会停止对客户端包括写请求在内的任何响应。另一方面这段时间发生的数据变化会以副本的方式存放在另一个新的内存区域，待快照操作结束后才会同步到原来的内存区域。<br>举个例子：如果主线程对这些数据也都是读操作（例如图中的键值对 A），那么，主线程和 bgsave 子进程相互不影响。但是，如果主线程要修改一块数据（例如图中的键值对 C），那么，这块数据就会被复制一份，生成该数据的副本。然后，bgsave 子进程会把这个副本数据写入 RDB 文件，而在这个过程中，主线程仍然可以直接修改原来的数据。<br><img src="\04、数据库\02、redis\assets\05、持久化：rdb-和-aof-机制详解\img-20240316_101519.png"><br>
为什么生产环境预留一半的内存？
<br>在 Copy-on-Write 过程中，极端情况下会对所有的 key 进行重写，此时数据拷贝将会完全拷贝当前物理内存中所有数据。<br>
所以预留一半，以防止内存溢出，导致无法写入。<br>
在进行快照操作的这段时间，如果发生服务崩溃怎么办？
<br>很简单，在没有将数据全部写入到磁盘前，这次快照操作都不算成功。如果出现了服务崩溃的情况，将以上一次完整的RDB快照文件作为恢复内存数据的参考。在快照操作过程中不能影响上一次的备份数据。Redis服务会在磁盘上创建一个临时文件进行数据操作，待操作成功后才会用这个临时文件替换掉上一次的备份。<br>
可以每秒做一次快照吗？
<br>如果频繁地执行全量快照，也会带来两方面的开销：<br>
<br>频繁将全量数据写入磁盘，会给磁盘带来很大压力，多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。
<br>另一方面，bgsave 子进程需要通过 fork 操作从主线程创建出来。虽然，子进程在创建后不会再阻塞主线程，但是，fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。如果频繁 fork 出 bgsave 子进程，这就会频繁阻塞主线程了。
<br>那么，有什么其他好方法吗？此时，我们可以做增量快照，也就是AOF持久化，是指做了一次全量快照后，后续的快照只对修改的数据进行快照记录，这样可以避免每次全量快照的开销。这个比较好理解。<br><br>
<br>
优点

<br>RDB 文件是某个时间节点的快照，默认使用 LZF 算法进行压缩，压缩后的文件体积远远小于内存大小，适用于备份、全量复制等场景；
<br>Redis 加载 RDB 文件恢复数据要远远快于 AOF 方式；


<br>
缺点

<br>RDB 方式实时性不够，无法做到秒级的持久化；
<br>每次调用 bgsave 都需要 fork 子进程，fork 子进程属于重量级操作，频繁执行成本较高；
<br>RDB 文件是二进制的，没有可读性，AOF 文件在了解其结构的情况下可以手动修改或者补全；
<br>版本兼容 RDB 文件问题；


<br>针对 RDB 不适合实时持久化的问题，Redis 提供了 AOF 持久化方式来解。<br><br>Append Only file（追加文件），日志里记录的是 Redis 收到的每一条命令，这些命令是以文本形式保存。<br><br>日志采用写后日志，先写内存，后写日志。<br>
PS: 大多数的数据库采用的是写前日志（WAL），例如 MySQL，通过写前日志和两阶段提交，实现数据和逻辑的一致性。
<br><img alt="assets/05、持久化：RDB 和 AOF 机制详解/img-20240315_212409.png" src="\04、数据库\02、redis\assets\05、持久化：rdb-和-aof-机制详解\img-20240315_212409.png" style="width: 550px; max-width: 100%;"><br>采用后写日志有两方面好处：<br>
<br>避免额外的检查开销：如果先记日志再执行命令的话，日志中就有可能记录了错误的命令，Redis 在使用日志恢复数据时，就可能会出错。Redis 在向 AOF 里面记录日志的时候，并不会先去对这些命令进行语法检查。
<br>不会阻塞当前的写操作
<br>但这种方式存在潜在风险：<br>
<br>
如果命令执行完成，写日志之前宕机了，会丢失数据。

<br>
如果磁盘写入速度跟不上 Redis 的写命令速度，主线程在写入 AOF 时将会被阻塞，可能导致整体性能下降。
4.0 前的版本，Redis 的主线程负责写 AOF 文件。<br>
4.0 后的版本，通过使用后台 I/O 线程和内存缓冲区来改善 AOF 持久化的性能，减少了主线程的 I/O 阻塞问题。

<br><br>AOF日志记录Redis的每个写命令，步骤分为：命令追加（append）、文件写入（write）和文件同步（sync）。<br>
<br>命令追加 当AOF持久化功能打开了，服务器在执行完一个写命令之后，会以协议格式将被执行的写命令追加到服务器的 aof_buf 缓冲区。
<br>文件写入和同步 关于何时将 aof_buf 缓冲区的内容写入AOF文件中
<br>Redis 提供了三种写回策略：<br>Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；<br>Everysec，每秒写回：每个写命令执行完，只是先把日志写到AOF文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；<br>No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。<br><img alt="assets/05、持久化：RDB 和 AOF 机制详解/img-20240315_214448.png" src="\04、数据库\02、redis\assets\05、持久化：rdb-和-aof-机制详解\img-20240315_214448.png" style="width: 700px; max-width: 100%;"><br><br>默认情况下，Redis 是没有开启 AOF 的。<br>可以通过配置 redis.conf 文件来开启 AOF 持久化，关于 AOF 的配置如下：<br># appendonly参数开启AOF持久化
appendonly no

# AOF持久化的文件名，默认是appendonly.aof
appendfilename "appendonly.aof"

# AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的
dir ./

# 同步策略
# appendfsync always
appendfsync everysec
# appendfsync no

# aof重写期间是否同步
no-appendfsync-on-rewrite no

# 重写触发配置
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb

# 加载 aof出错如何处理
aof-load-truncated yes

# 文件重写策略
aof-rewrite-incremental-fsync yes
复制<br>以下是Redis中关于AOF的主要配置信息：<br>appendonly：默认情况下AOF功能是关闭的，将该选项改为yes以便打开Redis的AOF功能。<br>appendfilename：这个参数项很好理解了，就是AOF文件的名字。<br>appendfsync：这个参数项是AOF功能最重要的设置项之一，主要用于设置“真正执行”操作命令向AOF文件中同步的策略。<br>为了保证操作系统中I/O队列的操作效率，应用程序提交的I/O操作请求一般是被放置在linux Page Cache中的，然后再由Linux操作系统中的策略自行决定正在写到磁盘上的时机。而Redis中有一个fsync()函数，可以将Page Cache中待写的数据真正写入到物理设备上，而缺点是频繁调用这个fsync()函数干预操作系统的既定策略，可能导致I/O卡顿的现象频繁 。<br>与上节对应，appendfsync参数项可以设置三个值，分别是：always、everysec、no，默认的值为everysec。<br>no-appendfsync-on-rewrite：always和everysec的设置会使真正的I/O操作高频度的出现，甚至会出现长时间的卡顿情况，这个问题出现在操作系统层面上，所有靠工作在操作系统之上的Redis是没法解决的。为了尽量缓解这个情况，Redis提供了这个设置项，保证在完成fsync函数调用时，不会将这段时间内发生的命令操作放入操作系统的Page Cache（这段时间Redis还在接受客户端的各种写操作命令）。<br>Redis 中用于配置 AOF 文件自动重写策略的设置项（手动调用“bgrewriteaof”命令，则不受这两个限制条件左右。）：<br>auto-aof-rewrite-percentage：当前AOF文件的大小超过上次重写后AOF文件大小的百分比时，会触发自动重写AOF文件的操作。默认设置是100，即AOF文件大小超过上次重写后的1倍时触发重写操作。<br>auto-aof-rewrite-min-size：启动AOF文件重写操作的最小AOF文件大小。如果AOF文件大小低于这个值，将不会触发重写操作。<br><br>
AOF会记录每个写命令到AOF文件，随着时间越来越长，AOF文件会变得越来越大。如果不加以控制，会对Redis服务器，甚至对操作系统造成影响，而且AOF文件越大，数据恢复也越慢。为了解决AOF文件体积膨胀的问题，Redis提供AOF文件重写机制来对AOF文件进行“瘦身”。
<br>
<br>图例解释AOF重写
<br>Redis 通过创建一个新的 AOF 文件来替换现有的 AOF，新旧两个 AOF 文件保存的数据相同，但新 AOF 文件没有了冗余命令。<br><img alt="assets/05、持久化：RDB 和 AOF 机制详解/img-20240316_091542.png" src="\04、数据库\02、redis\assets\05、持久化：rdb-和-aof-机制详解\img-20240316_091542.png" style="width: 1075px; max-width: 100%;"><br>
<br>AOF重写会阻塞吗？
<br>AOF重写过程是由后台进程bgrewriteaof来完成的。主线程fork出后台的bgrewriteaof子进程，fork会把主线程的内存拷贝一份给bgrewriteaof子进程，这里面就包含了数据库的最新数据。然后，bgrewriteaof子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志。<br>所以aof在重写时，在fork进程时是会阻塞住主线程的。<br>
<br>AOF日志何时会重写？
<br>手动触发：手动调用“bgrewriteaof”命令<br>自动触发：auto-aof-rewrite-percentage 和 auto-aof-rewrite-min-size<br>
<br>重写日志时，有新数据写入咋整？
<br>重写过程总结为：“一个拷贝，两处日志”。在fork出子进程时的拷贝，以及在重写时，如果有新数据写入，主线程就会将命令记录到两个aof日志内存缓冲区中。如果AOF写回策略配置的是always，则直接将命令写回旧的日志文件，并且保存一份命令至AOF重写缓冲区，这些操作对新的日志文件是不存在影响的。（旧的日志文件：主线程使用的日志文件，新的日志文件：bgrewriteaof进程使用的日志文件）<br>而在bgrewriteaof子进程完成会日志文件的重写操作后，会提示主线程已经完成重写操作，主线程会将AOF重写缓冲中的命令追加到新的日志文件后面。这时候在高并发的情况下，AOF重写缓冲区积累可能会很大，这样就会造成阻塞，Redis后来通过Linux管道技术让aof重写期间就能同时进行回放，这样aof重写结束后只需回放少量剩余的数据即可。<br>最后通过修改文件名的方式，保证文件切换的原子性。<br>在AOF重写日志期间发生宕机的话，因为日志文件还没切换，所以恢复数据时，用的还是旧的日志文件。<br>
<br>
总结操作：

<br>
主线程fork出子进程重写aof日志

<br>
子进程重写日志完成后，主线程追加aof日志缓冲

<br>
替换日志文件

<br><img alt="assets/05、持久化：RDB 和 AOF 机制详解/img-20240316_094029.png" src="\04、数据库\02、redis\assets\05、持久化：rdb-和-aof-机制详解\img-20240316_094029.png" style="width: 750px; max-width: 100%;"><br>
<br>主线程fork出子进程的是如何复制内存数据的？
<br>fork采用操作系统提供的写时复制（copy on write）机制，就是为了避免一次性拷贝大量内存数据给子进程造成阻塞。fork子进程时，子进程时会拷贝父进程的页表，即虚实映射关系（虚拟内存和物理内存的映射索引表），而不会拷贝物理内存。这个拷贝会消耗大量cpu资源，并且拷贝完成前会阻塞主线程，阻塞时间取决于内存中的数据量，数据量越大，则内存页表越大。拷贝完成后，父子进程使用相同的内存地址空间。<br>但主进程是可以有数据写入的，这时候就会拷贝物理内存中的数据。如下图（进程1看做是主进程，进程2看做是子进程）：<br><img alt="assets/05、持久化：RDB 和 AOF 机制详解/img-20240316_094131.png" src="\04、数据库\02、redis\assets\05、持久化：rdb-和-aof-机制详解\img-20240316_094131.png" style="width: 825px; max-width: 100%;"><br>在主进程有数据写入时，而这个数据刚好在页c中，操作系统会创建这个页面的副本（页c的副本），即拷贝当前页的物理数据，将其映射到主进程中，而子进程还是使用原来的的页c。<br>
<br>在重写日志整个过程时，主线程有哪些地方会被阻塞？
<br>
<br>fork子进程时，需要拷贝虚拟页表，会对主线程阻塞。
<br>主进程有bigkey写入时，操作系统会创建页面的副本，并拷贝原有的数据，会对主线程阻塞。
<br>子进程重写日志完成后，主进程追加aof重写缓冲区时可能会对主线程阻塞。
<br>
<br>为什么AOF重写不复用原AOF日志？
<br>两方面原因：<br>
<br>父子进程写同一个文件会产生竞争问题，影响父进程的性能。
<br>如果AOF重写过程中失败了，相当于污染了原本的AOF文件，无法做恢复数据使用。
<br><br><img src="\04、数据库\02、redis\assets\05、持久化：rdb-和-aof-机制详解\img-20240316_102906.png"><br><br>
内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。
<br>这样一来，快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。而且，AOF 日志也只用记录两次快照间的操作，也就是说，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。<br>如下图所示，T1 和 T2 时刻的修改，用 AOF 日志记录，等到第二次做全量快照时，就可以清空 AOF 日志，因为此时的修改都已经记录到快照中了，恢复时就不再用日志了。<br><img alt="assets/05、持久化：RDB 和 AOF 机制详解/img-20240316_094358.png" src="\04、数据库\02、redis\assets\05、持久化：rdb-和-aof-机制详解\img-20240316_094358.png" style="width: 950px; max-width: 100%;"><br>这个方法既能享受到 RDB 文件快速恢复的好处，又能享受到 AOF 只记录操作命令的简单优势, 实际环境中用的很多。<br><br>
数据的备份、持久化做完了，我们如何从这些持久化文件中恢复数据呢？如果一台服务器上有既有RDB文件，又有AOF文件，该加载谁呢？
<br><img alt="assets/05、持久化：RDB 和 AOF 机制详解/img-20240316_094541.png" src="\04、数据库\02、redis\assets\05、持久化：rdb-和-aof-机制详解\img-20240316_094541.png" style="width: 425px; max-width: 100%;"><br>
<br>redis重启时判断是否开启aof，如果开启了aof，那么就优先加载aof文件；
<br>如果aof存在，那么就去加载aof文件，加载成功的话redis重启成功，如果aof文件加载失败，那么会打印日志表示启动失败，此时可以去修复aof文件后重新启动；
<br>若aof文件不存在，那么redis就会转而去加载rdb文件，如果rdb文件不存在，redis直接启动成功；
<br>如果rdb文件存在就会去加载rdb文件恢复数据，如加载失败则打印日志提示启动失败，如加载成功，那么redis重启成功，且使用rdb文件恢复数据；
<br>那么为什么会优先加载AOF呢？因为AOF保存的数据更完整，通过上面的分析我们知道AOF基本上最多损失1s的数据。<br><br>通过上面的分析，我们都知道RDB的快照、AOF的重写都需要fork，这是一个重量级操作，会对Redis造成阻塞。因此为了不影响Redis主进程响应，我们需要尽可能降低阻塞。<br>内存如何控制分配：<br>
<br>更好的硬件
<br>合理配置 Linux 的内存分配策略，避免因为物理内存不足导致 fork 失败
<br>控制单个 Redis 实例内存上限，如 4 G 或 8 G。可以加快 fork 的速度、减少主从同步、数据迁移压力（可以单机部署多台 redis 实例）
<br>物理机部署多个 Redis 实例，要防止同时运行持久化、重写操作，防止资源竞争，尝试让持久化变为串行；
<br>不要与 CPU 内存密集型应用（ES）、高硬盘负载（数据库、消息队列）应用一起部署。
<br>线上备份怎么做最优：<br>
<br>用来做缓存的 Redis 关闭持久化，数据不敏感或可以通过其它方式重写生成数据；
<br>脚本或程序定期触发备份、重写数据（制定策略定期检查 Redis 的情况）；
<br>主从机器，让从机器进行备份处理；
<br>4.0 以上让 RDB 与 AOF 持久化同时存在，结合使用。
<br>使用 AOF 持久化时：<br>
<br>设置合理的 rewrite 阈值，避免频繁的 bgrewrite
<br>配置 no-appendfsync-on-rewrite = yes，禁止在 rewrite 期间做 aof，避免因 AOF 引起的阻塞。简单说就是，禁止在重写期间 fsync 刷盘
]]></description><link>04、数据库\02、redis\05、持久化：rdb-和-aof-机制详解.html</link><guid isPermaLink="false">04、数据库/02、Redis/05、持久化：RDB 和 AOF 机制详解.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Sun, 07 Apr 2024 14:04:08 GMT</pubDate><enclosure url="04、数据库\02、redis\assets\05、持久化：rdb-和-aof-机制详解\img-20240315_210729.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;04、数据库\02、redis\assets\05、持久化：rdb-和-aof-机制详解\img-20240315_210729.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[06、高可用：主从复制详解]]></title><description><![CDATA[ 
 <br><br>
主从复制，是指将一台 Redis 服务器的数据，复制到其他的 Redis 服务器。前者称为主节点(master)，后者称为从节点(slave)；<br>
数据的复制是单向的，主 ==&gt; 从
<br>主从复制的作用主要包括：<br>
<br>数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。
<br>故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。
<br>负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。
<br>高可用基石：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。
<br>主从库之间采用的是读写分离的方式。<br>
<br>读操作：主库、从库都可以接收；
<br>写操作：首先到主库执行，然后，主库将写操作同步给从库。
<br><img alt="assets/06、高可用：主从复制详解/img-20240316_112111.png" src="\04、数据库\02、redis\assets\06、高可用：主从复制详解\img-20240316_112111.png" style="width: 900px; max-width: 100%;"><br><br>
注意：在2.8版本之前只有全量复制，而2.8版本后有全量和增量复制：
<br>
<br>全量（同步）复制：比如第一次同步时
<br>增量（同步）复制：只会把主从库网络断连期间主库收到的命令，同步给从库
<br><br>
当我们启动多个 Redis 实例的时候，它们相互之间就可以通过 replicaof（Redis 5.0 之前使用 slaveof）命令形成主库和从库的关系，之后会按照三个阶段完成数据的第一次同步。
<br>
<br>确立主从关系
<br>例：现在有实例 1（ip：172.16.19.3）和实例 2（ip：172.16.19.5）<br>
在实例 2 上执行以下这个命令后，实例 2 就变成了实例 1 的从库，并从实例 1 上复制数据：<br>replicaof 172.16.19.3 6379
复制<br>
<br>全量复制的三个阶段<br>
<img src="\04、数据库\02、redis\assets\06、高可用：主从复制详解\img-20240316_112913.png">
<br>第一阶段是主从库间建立连接、协商同步的过程，主要是为全量复制做准备。<br>从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从库间就可以开始同步了。<br>从库给主库发送 psync 命令，表示要进行数据同步，主库根据这个命令的参数来启动复制。psync 命令包含了主库的 runID 和复制进度 offset 两个参数。<br>
<br>replica ID（也称为runID）是每个 Redis 实例启动时生成的一个唯一标识符，用来唯一标记该实例。当从库和主库第一次复制时，由于从库不知道主库的replica ID，因此将其设为"?"。
<br>offset表示复制的进度，对于第一次复制来说，它被设为-1以表示初始状态。主库收到psync命令后，会用FULLRESYNC响应命令携带两个参数：主库的replica ID和当前的复制进度offset，返回给从库。从库在接收到响应后会记录下这两个参数。
<br>FULLRESYNC 响应表示第一次复制采用的全量复制，也就是说，主库会把当前所有的数据都复制给从库。<br>第二阶段，主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。这个过程依赖于内存快照生成的 RDB 文件。<br>主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。<br>
从库接收到 RDB 文件后，会先清空当前数据库，然后加载 RDB 文件。这是因为从库在通过 replicaof 命令开始和主库同步前，可能保存了其他数据。为了避免之前数据的影响，从库需要先把当前数据库清空。<br>在主库将数据同步给从库的过程中，主库不会被阻塞，仍然可以正常接收请求。<br>第三个阶段，主库会把第二阶段执行过程中新收到的写命令，再发送给从库。<br>新的请求中的写操作并没有记录到刚刚生成的 RDB 文件中。为了保证主从库的数据一致性，主库会在内存中用专门的 replication buffer，记录 RDB 文件生成后收到的所有写操作。<br>当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了。<br><br>
在 Redis 2.8 版本引入了增量复制。
<br>
<br>为什么会设计增量复制？
<br>如果主从库在命令传播时出现了网络闪断，那么，从库就会和主库重新进行一次全量复制，开销非常大。从 Redis 2.8 开始，网络断了之后，主从库会采用增量复制的方式继续同步。<br>
<br>增量复制的流程
<br><img src="\04、数据库\02、redis\assets\06、高可用：主从复制详解\img-20240316_113651.png"><br><img alt="assets/06、高可用：主从复制详解/img-20240316_113846.png" src="\04、数据库\02、redis\assets\06、高可用：主从复制详解\img-20240316_113846.png" style="width: 180px; max-width: 100%;"> <img alt="assets/06、高可用：主从复制详解/img-20240316_113907.png" src="\04、数据库\02、redis\assets\06、高可用：主从复制详解\img-20240316_113907.png" style="width: 176px; max-width: 100%;"><br>
先看两个概念： replication buffer 和 repl_backlog_buffer<br>repl_backlog_buffer：它是为了从库断开之后，如何找到主从差异数据而设计的环形缓冲区，从而避免全量复制带来的性能开销。如果从库断开时间太久，repl_backlog_buffer环形缓冲区被主库的写命令覆盖了，那么从库连上主库后只能乖乖地进行一次全量复制，所以repl_backlog_buffer配置尽量大一些，可以降低主从断开后全量复制的概率。而在repl_backlog_buffer中找主从差异的数据后，如何发给从库呢？这就用到了replication buffer。<br>replication buffer：Redis和客户端通信也好，和从库通信也好，Redis都需要给分配一个 内存buffer进行数据交互，客户端是一个client，从库也是一个client，我们每个client连上Redis后，Redis都会分配一个client buffer，所有数据交互都是通过这个buffer进行的：Redis先把数据写到这个buffer中，然后再把buffer中的数据发到client socket中再通过网络发送出去，这样就完成了数据交互。所以主从在增量同步时，从库作为一个client，也会分配一个buffer，只不过这个buffer专门用来传播用户的写命令到从库，保证主从数据一致，我们通常把它叫做replication buffer。<br>
<br>如果在网络断开期间，repl_backlog_size环形缓冲区写满之后，从库是会丢失掉那部分被覆盖掉的数据，还是直接进行全量复制呢？
<br>对于这个问题来说，有两个关键点：<br>
<br>一个从库如果和主库断连时间过长，造成它在主库repl_backlog_buffer的slave_repl_offset位置上的数据已经被覆盖掉了，此时从库和主库间将进行全量复制。
<br>每个从库会记录自己的slave_repl_offset，每个从库的复制进度也不一定相同。在和主库重连进行恢复时，从库会通过psync命令把自己记录的slave_repl_offset发给主库，主库会根据从库各自的复制进度，来决定这个从库可以进行增量复制，还是全量复制。
<br><br><br>
在进行主从复制设置时，强烈建议在主服务器上开启持久化。<br>
当不能这么做时，比如考虑到延迟的问题，应该将实例配置为避免自动重启。
<br>为什么不持久化的主服务器自动重启非常危险呢？<br>
容易导致主服务器和从服务器中数据库都被删除。<br>
<br>我们设置节点A为主服务器，关闭持久化，节点B和C从节点A复制数据。
<br>这时出现了一个崩溃，但Redis具有自动重启系统，重启了进程，因为关闭了持久化，节点重启后只有一个空的数据集。
<br>节点B和C从节点A进行复制，现在节点A是空的，所以节点B和C上的复制数据也会被删除。
<br>当在高可用系统中使用Redis Sentinel，关闭了主服务器的持久化，并且允许自动重启，这种情况是很危险的。比如主服务器可能在很短的时间就完成了重启，以至于Sentinel都无法检测到这次失败，那么上面说的这种失败的情况就发生了。
<br>如果数据比较重要，并且在使用主从复制时关闭了主服务器持久化功能的场景中，都应该禁止实例自动重启。<br><br>选择 RDB 的原因：<br>1）RDB文件内容是经过压缩的二进制数据（不同数据类型数据做了针对性优化），文件很小，降低对主库机器网络带宽的消耗，按照 RDB 协议解析还原速度快。<br>2）RDB 只有在需要定时备份和主从全量复制数据时才会触发生成一次快照。<br>不选 AOF 的原因：<br>1）打开 AOF 功能，打开 AOF 就要选择文件刷盘的策略，选择不当会严重影响 Redis 性能。而在很多丢失数据不敏感的业务场景，其实是不需要开启 AOF 的。<br>2）AOF 文件记录的是每一次写操作的命令，写操作越多文件就越大，其中还包括很多对同一个 key 的多次冗余操作。<br>3）即使重写过的 AOF，复制依次重放每个写命令，也会经历冗长的处理逻辑。<br><br>Redis 默认是磁盘复制，但是如果使用比较低速的磁盘，这种操作会给主服务器带来较大的压力。Redis从2.8.18版本开始尝试支持无磁盘的复制。使用这种设置时，子进程直接将RDB通过网络发送给从服务器，不使用磁盘作为中间存储。<br>无磁盘复制模式：master创建一个新进程直接dump RDB到slave的socket，不经过主进程，不经过硬盘。适用于disk较慢，并且网络较快的时候。<br>使用repl-diskless-sync配置参数来启动无磁盘复制。<br>使用repl-diskless-sync-delay 参数来配置传输开始的延迟时间；master等待一个repl-diskless-sync-delay的秒数，如果没slave来的话，就直接传，后来的得排队等了; 否则就可以一起传。<br><br>一次全量复制中，对于主库来说，需要完成两个耗时的操作：生成 RDB 文件和传输 RDB 文件。<br>如果从库数量很多，而且都要和主库进行全量复制的话，就会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量复制。fork 这个操作会阻塞主线程处理正常请求，从而导致主库响应应用程序的请求速度变慢。此外，传输 RDB 文件也会占用主库的网络带宽，同样会给主库的资源使用带来压力。<br>可以通过“主 - 从 - 从”模式将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上。<br>在部署主从集群的时候，可以手动选择一个从库（比如选择内存资源配置较高的从库），用于级联其他的从库。<br>replicaof 所选从库的IP 6379
复制<br>如下图所示：<br><img alt="assets/06、高可用：主从复制详解/img-20240316_112513.png" src="\04、数据库\02、redis\assets\06、高可用：主从复制详解\img-20240316_112513.png" style="width: 875px; max-width: 100%;"><br>一旦主从库完成了全量复制，它们之间就会一直维护一个网络连接，主库会通过这个连接将后续陆续收到的命令操作再同步给从库，这个过程也称为基于长连接的命令传播，可以避免频繁建立连接的开销。<br><br>在主从复制基础上实现的读写分离，可以实现Redis的读负载均衡：由主节点提供写服务，由一个或多个从节点提供读服务（多个从节点既可以提高数据冗余程度，也可以最大化读负载能力）；在读负载较大的应用场景下，可以大大提高Redis服务器的并发量。<br>但在使用Redis读写分离时，需要注意一些问题。<br>
<br>延迟与不一致问题
<br>由于主从复制的命令传播是异步的，延迟与数据的不一致不可避免。<br>
如果应用对数据不一致的接受程度程度较低，可能的优化措施包括：<br>
<br>优化主从节点之间的网络环境（如在同机房部署）；
<br>监控主从节点延迟（通过offset）判断，如果从节点延迟过大，通知应用不再通过该从节点读取数据；
<br>使用集群同时扩展写负载和读负载等。
<br>在命令传播阶段以外的其他情况下，从节点的数据不一致可能更加严重，例如连接在数据同步阶段，或从节点失去与主节点的连接时等。<br>
从节点的 slave-serve-stale-data  参数便与此有关：它控制这种情况下从节点的表现；<br>1）值为 yes（默认值），则从节点仍能够响应客户端的命令<br>
2）值为 no，则从节点只能响应info、slaveof等少数命令。如果对数据一致性要求很高，则应设置为 no。<br>
<br>数据过期问题
<br>在单机版Redis中，存在两种删除策略：<br>
<br>惰性删除：服务器不会主动删除数据，只有当客户端查询某个数据时，服务器判断该数据是否过期，如果过期则删除。
<br>定期删除：服务器执行定时任务删除过期数据，但是考虑到内存和CPU的折中（删除会释放内存，但是频繁的删除操作对CPU不友好），该删除的频率和执行时间都受到了限制。
<br>在主从复制场景下，为了主从节点的数据一致性，从节点不会主动删除数据，而是由主节点控制从节点中过期数据的删除。由于主节点的惰性删除和定期删除策略，都不能保证主节点及时对过期数据执行删除操作，因此，当客户端通过Redis从节点读取数据时，很容易读取到已经过期的数据。<br>Redis 3.2中，从节点在读取数据时，增加了对数据是否过期的判断：如果该数据已过期，则不返回给客户端；将Redis升级到3.2可以解决数据过期问题。<br>
<br>故障切换问题
<br>在没有使用哨兵的读写分离场景下，应用针对读和写分别连接不同的Redis节点；<br>
当主节点或从节点出现问题而发生更改时，需要及时修改应用程序读写Redis数据的连接；<br>
连接的切换可以手动进行，或者自己写监控程序进行切换，但前者响应慢、容易出错，后者实现复杂，成本都不算低。<br>
<br>总结
<br>在使用读写分离之前，可以考虑其他方法增加 Redis 的读负载能力：<br>
如尽量优化主节点（减少慢查询、减少持久化等其他情况带来的阻塞等）提高负载能力；<br>哨兵：<br>
如果使用读写分离，可以使用哨兵，使主从节点的故障切换尽可能自动化，并减少对应用程序的侵入。<br>集群：<br>
同时提高读负载能力和写负载能力等。<br>]]></description><link>04、数据库\02、redis\06、高可用：主从复制详解.html</link><guid isPermaLink="false">04、数据库/02、Redis/06、高可用：主从复制详解.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Mon, 18 Mar 2024 12:37:32 GMT</pubDate><enclosure url="04、数据库\02、redis\assets\06、高可用：主从复制详解\img-20240316_112111.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;04、数据库\02、redis\assets\06、高可用：主从复制详解\img-20240316_112111.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[07、高可用：哨兵机制（Redis Sentinel）详解]]></title><description><![CDATA[ 
 <br><br>
slave 节点宕机恢复后可以找 master 节点同步数据，那 master 节点宕机怎么办?
<br>只有主从，没有哨兵的情况下：<br>
1、数据没有持久化，会丢数据。<br>
2、主不启动，只能读<br><br>
<br>监控：Sentinel 会不断检查您的 master 和 slave 是否按预期工作
<br>自动故障恢复：如果 master 故障，Sentinel 会将一个 slave 提升为 master。当故障实例恢复后也以新的 master 为主
<br>通知：Sentinel 充当 Redis 客户端的服务发现来源，当集群发生故障转移时，会将最新信息推送给 Redis 的客户端
<br>配置提供者（Configuration provider）：客户端在初始化时，通过连接哨兵来获得当前 Redis 服务的主节点地址。
<br>其中，监控和自动故障转移功能，使得哨兵可以及时发现主节点故障并完成转移；<br>
而配置提供者和通知功能，则需要在与客户端的交互中才能体现。<br><img src="\04、数据库\02、redis\assets\07、高可用：哨兵机制（redis-sentinel）详解\img-20240316_115425.png"><br><br>
哨兵实例之间可以相互发现，归功于 Redis 提供的发布 / 订阅（pub/sub）机制。
<br>在主从集群中，主库上有一个名为 __sentinel__:hello 的频道，不同哨兵就是通过它来相互发现，实现互相通信的。<br>
所以在搭建哨兵时配置某一个哨兵而不需要配置其他哨兵地址和端口。<br>例：<br>
哨兵 1 把自己的 IP和端口（26579）发布到 __sentinel__:hello 频道上，哨兵 2 和 3 订阅了该频道。<br>
哨兵 2 和 3 就可以从这个频道直接获取哨兵 1 的 IP 地址和端口号。然后，哨兵 2、3 可以和哨兵 1 建立网络连接。<br>
通过这个方式，哨兵 2 和 3 也可以建立网络连接，这样一来，哨兵集群就形成了。<br>相互间可以通过网络连接进行通信，对主库是否下线进行判断和协商。<br><br>
哨兵监控什么呢？怎么监控呢？
<br>这是由哨兵向主库发送 INFO 命令来完成的。<br>
哨兵 2 给主库发送 INFO 命令，主库接受到这个命令后，就会把从库列表返回给哨兵。<br>
哨兵就可以根据从库列表中的连接信息，和每个从库建立连接，并在这个连接上持续地对从库进行监控。<br>
哨兵 1 和 3 可以通过相同的方法和从库建立连接。<br><img alt="assets/07、高可用：哨兵机制（Redis Sentinel）详解/img-20240316_153246.png" src="\04、数据库\02、redis\assets\07、高可用：哨兵机制（redis-sentinel）详解\img-20240316_153246.png" style="width: 475px; max-width: 100%;"><br><br>首先要理解两个概念：主观下线和客观下线<br>
<br>主观下线：任何一个哨兵都是可以监控探测，并作出Redis节点下线的判断；
<br>客观下线：有哨兵集群共同决定Redis节点是否下线；
<br>当某个哨兵（如下图中的哨兵2）判断主库“主观下线”后，就会给其他哨兵发送 is-master-down-by-addr 命令。接着，其他哨兵会根据自己和主库的连接情况，做出 Y 或 N 的响应，Y 相当于赞成票，N 相当于反对票。<br><img src="\04、数据库\02、redis\assets\07、高可用：哨兵机制（redis-sentinel）详解\img-20240316_153130.png"><br>如果赞成票数（这里是2）是大于等于哨兵配置文件中的 quorum 配置项（比如这里如果是quorum=2）, 则可以判定主库客观下线了。<br><br>
<br>为什么必然会出现选举/共识机制？
<br>为了避免哨兵的单点情况发生，所以需要一个哨兵的分布式集群。作为分布式集群，必然涉及共识问题（即选举问题）；同时故障的转移和通知都只需要一个主的哨兵节点就可以了。<br>
<br>哨兵的选举机制是什么样的？
<br>哨兵的选举机制其实很简单，选举算法 <a class="internal-link" data-href="../../01、通用基础/04、数据结构算法/03、其他领域算法/Raft算法.md" href="\01、通用基础\04、数据结构算法\03、其他领域算法\raft算法.html" target="_self" rel="noopener">Raft算法</a>： 选举的票数大于等于 num(sentinels)/2+1时，将成为领导者，如果没有超过，继续选举<br>
<br>任何一个想成为 Leader 的哨兵，要满足两个条件：

<br>第一，拿到半数以上的赞成票；
<br>第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。


<br>以 3 个哨兵为例，假设此时的 quorum 设置为 2，那么，任何一个想成为 Leader 的哨兵只要拿到 2 张赞成票，就可以了。<br>
这里很多人会搞混 判定客观下线 和 是否能够主从切换（用到选举机制） 两个概念，我们再看一个例子。
<br>Redis 1 主 4 从，5 个哨兵，哨兵配置 quorum 为 2，如果 3 个哨兵故障，当主库宕机时，哨兵能否判断主库“客观下线”？能否自动切换？<br>经过实际测试：<br>
1、哨兵集群可以判定主库“主观下线”。由于 quorum=2，所以当一个哨兵判断主库“主观下线”后，询问另外一个哨兵后也会得到同样的结果，2 个哨兵都判定“主观下线”，达到了 quorum 的值，因此，哨兵集群可以判定主库为“客观下线”。<br>2、但哨兵不能完成主从切换。哨兵标记主库“客观下线后”，在选举“哨兵领导者”时，一个哨兵必须拿到超过多数的选票 (5/2+1=3 票)。但目前只有 2 个哨兵活着，无论怎么投票，一个哨兵最多只能拿到 2 票，永远无法达到 N/2+1 选票的结果。<br><br>
主库既然判定客观下线了，那么如何从剩余的从库中选择一个新的主库呢？
<br>
<br>过滤掉不健康的（下线或断线），没有回复过哨兵ping响应的从节点
<br>选择salve-priority从节点优先级最高（redis.conf）的
<br>选择复制偏移量最大，只复制最完整的从节点
<br>最后是判断 slave 节点的运行 id 大小，越小优先级越高。
<br><br>
新的主库选择出来后，就可以开始进行故障的转移了。
<br><img src="\04、数据库\02、redis\assets\07、高可用：哨兵机制（redis-sentinel）详解\img-20240316_154049.png"><br>故障转移流程如下：<br>
<br>sentinel 给被选中的 slave 节点发送 slaveof no one 命令，让该节点成为 master
<br>sentinel 给所有其它 slave 发送 slaveof masterIP masterPort 命令，让这些 slave 成为新 master 的从节点，开始从新的 master 上同步数据。
<br>sentinel 将故障节点标记为 slave，当故障节点恢复后会自动成为新的 master 的 slave 节点
<br><br>在 Sentinel 集群监管下的 Redis 主从集群，其节点会因为自动故障转移而发生变化，Redis 的客户端必须感知这种变化，及时更新连接信息。Spring 的 RedisTemplate 底层利用 lettuce 实现了节点的感知和自动切换。<br>下面，我们通过一个测试来实现 RedisTemplate 集成哨兵机制。<br>1、引入依赖<br>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;
&lt;/dependency&gt;
复制<br>2、配置 Redis 地址<br>spring:
  redis:
    sentinel:
      master: mymaster
      nodes:
        - 192.168.150.101:27001
        - 192.168.150.101:27002
        - 192.168.150.101:27003
复制<br>3、配置读写分离<br>@Bean
public LettuceClientConfigurationBuilderCustomizer clientConfigurationBuilderCustomizer(){
    return clientConfigurationBuilder -&gt; clientConfigurationBuilder.readFrom(ReadFrom.REPLICA_PREFERRED);
}
复制<br>这个 bean 中配置的就是读写策略，包括四种：<br>
<br>MASTER：从主节点读取
<br>MASTER_PREFERRED：优先从 master 节点读取，master 不可用才读取 replica
<br>REPLICA：从 slave（replica）节点读取
<br>REPLICA _PREFERRED：优先从 slave（replica）节点读取，所有的 slave 都不可用才读取 master
]]></description><link>04、数据库\02、redis\07、高可用：哨兵机制（redis-sentinel）详解.html</link><guid isPermaLink="false">04、数据库/02、Redis/07、高可用：哨兵机制（Redis Sentinel）详解.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Mon, 18 Mar 2024 12:41:39 GMT</pubDate><enclosure url="04、数据库\02、redis\assets\07、高可用：哨兵机制（redis-sentinel）详解\img-20240316_115425.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;04、数据库\02、redis\assets\07、高可用：哨兵机制（redis-sentinel）详解\img-20240316_115425.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[08、高可拓展：分片技术（Redis Cluster）详解]]></title><description><![CDATA[ 
 <br><br>
Redis-cluster是一种服务器Sharding技术，Redis3.0以后版本正式提供支持。
<br><br>高性能可线性扩展至最多1000节点。集群中没有代理，（集群节点间）使用异步复制，没有归并操作(merge operations on values)<br>
<br>高性能：集群中没有代理，使用异步复制，系统避免了值的合并操作，以维持性能和简单性。
<br>高扩展：可以扩展到最多 1000 个节点，能处理更多的操作并存储更多的数据。
<br>高可用：当多数主节点可用时，即使少数主节点不可用，Redis 集群总是可用的。此外，通过副本迁移技术，没有副本节点的主节点可以从有多个副本的主节点那里获得一个新副本，以确保可用性。
<br>写入安全：Redis 集群试图使用最大努力原则保留对主节点的所有写操作。然而，在故障转移过程中存在一个小的时间窗口，在此期间确认的写操作可能会丢失。
<br><img src="\04、数据库\02、redis\assets\08、高可拓展：分片技术（redis-cluster）详解\img-20240316_154508.png"><br><br>
Redis 集群采用了一种方式来处理数据的复制和在故障发生时的数据保护，这种方式有一些特点和潜在的风险。
<br>
<br>
数据复制是异步进行的<br>
当一个客户端向主节点（master）写入数据后，这个数据就会被标记为已写入，然后才慢慢复制到从节点（slave）。<br>
因为这个过程是异步的，所以有可能出现主节点已经告诉客户端“写入成功”，但是数据还没有完全复制到从节点上的情况。

<br>
最后故障转移获胜(last failover wins)<br>
如果一个主节点出现问题，它的一个从节点会被提升为新的主节点。在这种故障转移（failover）过程中，最新提升的主节点上的数据会成为“真实”的数据，即使其他从节点上可能有不同版本的数据。

<br>
多数派和少数派<br>
连接到多数派主节点的客户端写入的数据更有可能被保留，因为当主节点故障时，从节点可以迅速接替成为主节点，减少数据丢失的风险。<br>
连接到少数派主节点的客户端写入的数据丢失风险较大，因为如果这个主节点因为网络分区问题和其他大部分节点失联，它的数据可能会在故障转移后被忽略。<br>
主节点感知到自己可能成为少数派，它会拒绝写入操作以防止数据丢失。

<br><br><br>Redis-cluster 没有使用一致性 hash（通过环状空间分布数据），而是引入了哈希槽（固定数量的哈希槽）的概念。<br>Redis-cluster 中有 16384 (即 2 的 14 次方）个哈希槽，每个节点负责一部分 hash 槽（hash slot），每个 key 通过 CRC16校验后对16383取模来决定放置哪个槽。<br>比如集群中存在三个节点，则可能存在的一种分配如下：<br>
<br>节点A包含0到5500号哈希槽；
<br>节点B包含5501到11000号哈希槽；
<br>节点C包含11001 到 16384号哈希槽。
<br><br>Hash tags提供了一种途径，用来将多个(相关的)key分配到相同的hash slot中。这时Redis Cluster中实现multi-key操作的基础。<br>hash tag规则如下，如果满足如下规则，{和}之间的字符将用来计算HASH_SLOT，以保证这样的key保存在同一个slot中。<br>
<br>key包含一个{字符
<br>并且 如果在这个{的右面有一个}字符
<br>并且 如果在{和}之间存在至少一个字符
<br>例如：<br>
<br>{user1000}.following和{user1000}.followers这两个key会被hash到相同的hash slot中，因为只有user1000会被用来计算hash slot值。
<br>foo{}{bar}这个key不会启用hash tag因为第一个{和}之间没有字符。
<br>foozap这个key中的{bar部分会被用来计算hash slot
<br>foo{bar}{zap}这个key中的bar会被用来计算计算hash slot，而zap不会
<br><br>
<br>Node ID：节点 ID，节点启动时第一次获得 (通常通过/dev/urandom)，是一个唯一标识每个 Redis 集群节点的 40 个十六进制字符的字符串。这个 ID 在集群中唯一且不变，即使是在节点重启之后。除非被管理员使用 CLUSTER RESET HARD 命令。一个节点可以修改自己的 IP 地址而不需要修改自己的 ID。Cluster 可以检测到 IP /port 的改动并通过运行在 cluster bus 上的 gossip 协议重新配置该节点。 
<br>Address:Port：地址和端口号，代表了一个 Redis 集群节点的网络地址和监听端口，用于节点之间的通信。
<br>Flags：节点的角色和状态标志，例如&nbsp;master&nbsp;表示节点是一个主节点，slave&nbsp;表示节点是一个从节点，fail&nbsp;表示节点被认为已经失败或不可达，还有其它标志如&nbsp;myself&nbsp;表示当前的节点信息。
<br>Last Ping Sent：上一次发送 PING 命令到其他节点的时间戳。PING 是集群节点用来检查其他节点是否可达的命令。
<br>Last Pong Received：上一次从其他节点收到 PONG 回复的时间戳。当一个节点收到来自另一个节点的 PING 命令时，它会回复 PONG。
<br>Configuration Epoch：配置纪元，是一个可以在故障转移时改变的版本号。如果一个主节点失败并且有一个从节点晋升为新的主节点，新的主节点会获得一个新的、更高的配置纪元，这有助于其他节点了解集群最新的状态。
<br>Link State：连接状态，指示节点与其他节点连接的当前状态，通常是&nbsp;connected&nbsp;或&nbsp;disconnected。
<br>Slots：槽位，Redis 集群将所有的键根据 CRC 16 校验和算法分散到 16384 个槽位中。每个节点负责维护一部分槽位，槽位信息表明哪些槽位由当前节点负责。
<br>下面是一个发送到一个拥有3个节点的小集群的master节点的CLUSTER NODES输出的例子。<br>$ redis-cli cluster nodes

d1861060fe6a534d42d8a19aeb36600e18785e04 127.0.0.1:6379 myself - 0 1318428930 1 connected 0-1364
3886e65cc906bfd9b1f7e7bde468726a052d1dae 127.0.0.1:6380 master - 1318428930 1318428931 2 connected 1365-2729
d289c575dcbc4bdd2931585fd4339089e461a27d 127.0.0.1:6381 master - 1318428931 1318428931 3 connected 2730-4095
复制<br><br>Redis Cluster 每个节点通过集群总线（Cluster Bus）连接所有其他节点。来实现集群的节点自动发现、故障节点探测、slave 升级为 master 等任务。<br>Redis 集群总线是一个基于 TCP 的网络通信通道，使用一种专门设计的基于 Gossip 的二进制协议。<br>总线端口：<br>
每个 Redis 集群节点确实会使用两个 TCP 端口：客户端连接、集群节点之间的内部通信。<br>
节点间通信只使用集群总线端口，而不是客户端端口。<br>集群总线端口的号码是通过在客户端命令端口的基础上加上一个固定的偏移量（默认是10000）来计算的。<br>
如果一个节点的客户端命令端口是 6379，那么它的集群总线端口将会是 16379。<br><br>Redis 集群使用了一种全连接网状拓扑结构，这意味着集群中的每个节点都直接与其他所有节点保持开放的 TCP 连接。这样做的目的是为了确保节点间可以快速通信。<br>对于一个包含 N 个节点的集群，每个节点都将与其他 N-1 个节点建立连接。因为每个连接都是单向的（一个传出，一个传入），每个节点实际上维护了 2 * (N-1) 个 TCP 连接。<br>这些 TCP 连接被保持活跃，即使在没有数据传输的时候也不会关闭。这是通过 TCP 的 keepalive 机制来实现的，它可以检测到当对方不再响应时，即认为对方已经宕机或不可达。<br><br>无论节点是否已知或可信，每个节点总是接受来自集群总线端口的连接，并且回复 ping 请求。这有助于节点了解集群中的其他节点是否仍然活跃。<br>节点要被认为是集群的一部分，有两种方式：<br>
<br>MEET 消息：这是一种特殊的消息，用于通知一个节点，有一个新的节点应该被认为是集群的一部分。当系统管理员执行&nbsp;CLUSTER MEET ip port&nbsp;命令时，会发送 MEET 消息。这通常是在添加新节点到集群时发生的。
<br>Gossip 通信：节点通过 gossip 交换信息。如果一个节点从另一个已经信任的节点那里接收到关于第三方节点的信息，它将接受这个第三方节点为集群的一部分。这就像是一个朋友介绍你认识他的朋友，随后你也将那个人视为朋友。
<br>一旦一个节点通过上述任一方式被认为是集群的一部分，集群中的节点将自动开始尝试与它建立直接的 TCP 连接。这样做的结果是，最终所有的节点都直接连接到彼此，形成一个全连接图。不需要系统管理员介入，节点之间会自动处理这些连接。<br><br>
Redis cluster采用去中心化的架构，集群的主节点各自负责一部分槽，客户端如何确定key到底会映射到哪个节点上呢？这就是我们要讲的请求重定向。
<br>在cluster模式下，节点对请求的处理过程如下：<br>
<br>检查当前key是否存在当前NODE？

<br>通过crc16（key）/16384计算出slot
<br>查询负责该slot负责的节点，得到节点指针
<br>该指针与自身节点比较


<br>若slot不是由自身负责，则返回MOVED重定向
<br>若slot由自身负责，且key在slot中，则返回该key对应结果
<br>若key不存在此slot中，检查该slot是否正在迁出（MIGRATING）？
<br>若key正在迁出，返回ASK错误重定向客户端到迁移的目的服务器上
<br>若Slot未迁出，检查Slot是否导入中？
<br>若Slot导入中且有ASKING标记，则直接操作
<br>否则返回MOVED重定向
<br>这个过程中有两点需要具体理解下： MOVED重定向 和 ASK重定向。<br><br>
<br>槽命中：直接返回结果
<br>槽不命中：即当前键命令所请求的键不在当前请求的节点中，则当前节点会向客户端发送一个Moved 重定向，客户端根据Moved 重定向所包含的内容找到目标节点，再一次发送命令。
<br>从下面可以看出 php 的槽位9244不在当前节点中，所以会重定向到节点 192.168.2.23:7001中。redis-cli会帮你自动重定向（如果没有集群方式启动，即没加参数 -c，redis-cli不会自动重定向），并且编写程序时，寻找目标节点的逻辑需要交予程序员手动完成。<br>cluster keyslot keyName # 得到keyName的槽
复制<br><img alt="assets/08、高可拓展：分片技术（Redis Cluster）详解/img-20240316_194517.png" src="\04、数据库\02、redis\assets\08、高可拓展：分片技术（redis-cluster）详解\img-20240316_194517.png" style="width: 725px; max-width: 100%;"><br><br>Ask 重定向发生于集群伸缩时，集群伸缩会导致槽迁移，当我们去源节点访问时，此时数据已经可能已经迁移到了目标节点，使用 Ask 重定向来解决此种情况。<br><img src="\04、数据库\02、redis\assets\08、高可拓展：分片技术（redis-cluster）详解\img-20240316_194503.png"><br><br>上述两种重定向的机制使得客户端的实现更加复杂，提供了smart客户端（JedisCluster）来减低复杂性，追求更好的性能。客户端内部负责计算/维护键-&gt; 槽 -&gt; 节点映射，用于快速定位目标节点。<br>实现原理：<br>
<br>从集群中选取一个可运行节点，使用 cluster slots得到槽和节点的映射关系
<br>将上述映射关系存到本地，通过映射关系就可以直接对目标节点进行操作（CRC16(key) -&gt; slot -&gt; node），很好地避免了Moved重定向，并为每个节点创建JedisPool
<br>至此就可以用来进行命令操作
<br><img src="\04、数据库\02、redis\assets\08、高可拓展：分片技术（redis-cluster）详解\img-20240316_194631.png"><br><br>
Redis Cluster中节点状态如何维护呢？这里便涉及 有哪些状态，底层协议Gossip，及具体的通讯（心跳）机制。
<br>Cluster中的每个节点都维护一份在自己看来当前整个集群的状态，主要包括：<br>
<br>当前集群状态
<br>集群中各节点所负责的 slots 信息，及其 migrate 状态 
<br>集群中各节点的 master-slave 状态 
<br>集群中各节点的存活状态及不可达投票
<br>当集群状态变化时，如新节点加入、slot迁移、节点宕机、slave提升为新Master，我们希望这些变化尽快的被发现，传播到整个集群的所有节点并达成一致。节点之间相互的心跳（PING，PONG，MEET）及其携带的数据是集群状态传播最主要的途径。<br><br>gossip 协议（gossip protocol）又称 epidemic 协议（epidemic protocol），是基于流行病传播方式的节点或者进程之间信息交换的协议。 在分布式系统中被广泛使用，比如我们可以使用 gossip 协议来确保网络中所有节点的数据一样。<br>Gossip协议已经是P2P网络中比较成熟的协议了。Gossip协议的最大的好处是，即使集群节点的数量增加，每个节点的负载也不会增加很多，几乎是恒定的。这就允许Consul管理的集群规模能横向扩展到数千个节点。<br>Gossip算法又被称为反熵（Anti-Entropy），熵是物理学上的一个概念，代表杂乱无章，而反熵就是在杂乱无章中寻求一致，这充分说明了Gossip的特点：在一个有界网络中，每个节点都随机地与其他节点通信，经过一番杂乱无章的通信，最终所有节点的状态都会达成一致。每个节点可能知道所有其他节点，也可能仅知道几个邻居节点，只要这些节可以通过网络连通，最终他们的状态都是一致的，当然这也是疫情传播的特点。<br>上面的描述都比较学术，其实Gossip协议对于我们吃瓜群众来说一点也不陌生，Gossip协议也成为流言协议，说白了就是八卦协议，这种传播规模和传播速度都是非常快的，你可以体会一下。所以计算机中的很多算法都是源自生活，而又高于生活的。<br><br>Redis 集群是去中心化的，彼此之间状态同步靠 gossip 协议通信，集群的消息有以下几种类型：<br>
<br>Meet 通过「cluster meet ip port」命令，已有集群的节点会向新的节点发送邀请，加入现有集群。
<br>Ping 节点每秒会向集群中其他节点发送 ping 消息，消息中带有自己已知的两个节点的地址、槽、状态信息、最后一次通信时间等。
<br>Pong 节点收到 ping 消息后会回复 pong 消息，消息中同样带有自己已知的两个节点信息。
<br>Fail 节点 ping 不通某节点后，会向集群所有节点广播该节点挂掉的消息。其他节点收到消息后标记已下线。
<br><br>集群中的每个节点都会定期地向集群中的其他节点发送PING消息，以此交换各个节点状态信息，检测各个节点状态：在线状态、疑似下线状态PFAIL、已下线状态FAIL。<br>自己保存信息：当主节点A通过消息得知主节点B认为主节点D进入了疑似下线(PFAIL)状态时,主节点A会在自己的clusterState.nodes字典中找到主节点D所对应的clusterNode结构，并将主节点B的下线报告添加到clusterNode结构的fail_reports链表中，并后续关于结点D疑似下线的状态通过Gossip协议通知其他节点。<br>一起裁定：如果集群里面，半数以上的主节点都将主节点D报告为疑似下线，那么主节点D将被标记为已下线(FAIL)状态，将主节点D标记为已下线的节点会向集群广播主节点D的FAIL消息，所有收到FAIL消息的节点都会立即更新nodes里面主节点D状态标记为已下线。<br>最终裁定：将 node 标记为 FAIL 需要满足以下两个条件：<br>
<br>有半数以上的主节点将 node 标记为 PFAIL 状态。
<br>当前节点也将 node 标记为 PFAIL 状态。
<br><br>
我们理解了Gossip协议基础后，就可以进一步理解Redis节点之间相互的通讯心跳（PING，PONG，MEET）实现和维护了。我们通过几个问题来具体理解。
<br><br>Redis节点会记录其向每一个节点上一次发出ping和收到pong的时间，心跳发送时机与这两个值有关。通过下面的方式既能保证及时更新集群状态，又不至于使心跳数过多：<br>
<br>每次Cron向所有未建立链接的节点发送ping或meet
<br>每1秒从所有已知节点中随机选取5个，向其中上次收到pong最久远的一个发送ping
<br>每次Cron向收到pong超过timeout/2的节点发送ping
<br>收到ping或meet，立即回复pong
<br><br>
<br>Header，发送者自己的信息

<br>所负责slots的信息
<br>主从信息
<br>ip port信息
<br>状态信息


<br>Gossip，发送者所了解的部分其他节点的信息

<br>ping_sent, pong_received
<br>ip, port信息
<br>状态信息，比如发送者认为该节点已经不可达，会在状态信息中标记其为PFAIL或FAIL


<br><br>❶ 新节点加入<br>
<br>发送meet包加入集群
<br>从 pong 包中的 gossip 得到未知的其他节点 
<br>循环上述过程，直到最终加入集群
<br><img alt="assets/08、高可拓展：分片技术（Redis Cluster）详解/img-20240316_195202.png" src="\04、数据库\02、redis\assets\08、高可拓展：分片技术（redis-cluster）详解\img-20240316_195202.png" style="width: 550px; max-width: 100%;"><br>❷ Slots信息<br>
<br>判断发送者声明的 slots 信息，跟本地记录的是否有不同 
<br>如果不同，且发送者 epoch 较大，更新本地记录
<br>如果不同，且发送者 epoch 小，发送 Update 信息通知发送者
<br>❸ Master slave信息<br>发现发送者的master、slave信息变化，更新本地状态<br>❹ 节点Fail探测(故障发现)<br>
<br>超过超时时间仍然没有收到 pong 包的节点会被当前节点标记为 PFAIL 
<br>PFAIL 标记会随着 gossip 传播 
<br>每次收到心跳包会检测其中对其他节点的 PFAIL 标记，当做对该节点 FAIL 的投票维护在本机 
<br>对某个节点的 PFAIL 标记达到大多数时，将其变为 FAIL 标记并广播 FAIL 消息 
<br>
注：Gossip的存在使得集群状态的改变可以更快的达到整个集群。每个心跳包中会包含多个Gossip包，那么多少个才是合适的呢，redis的选择是N/10，其中N是节点数，这样可以保证在PFAIL投票的过期时间内，节点可以收到80%机器关于失败节点的gossip，从而使其顺利进入FAIL状态。
<br><br>当需要发布一些非常重要需要立即送达的信息时，上述心跳加Gossip的方式就显得捉襟见肘了，这时就需要向所有集群内机器的广播信息，使用广播发的场景：<br>
<br>节点的 Fail 信息：当发现某一节点不可达时，探测节点会将其标记为 PFAIL 状态，并通过心跳传播出去。当某一节点发现这个节点的 PFAIL 超过半数时修改其为 FAIL 并发起广播。 
<br>Failover Request 信息：slave 尝试发起 FailOver 时广播其要求投票的信息 
<br>新 Master 信息：Failover 成功的节点向整个集群广播自己的信息 
<br><br>
master节点挂了之后，如何进行故障恢复呢？
<br>详细流程：<br>
<br>slave 发现自己的 master 变为疑似失败（PFAIL）
<br>自己记录的集群当前事件值（currentEpoch）加1，并广播故障恢复（Failover Request） 信息
<br>其他节点收到该信息，只有 master 响应，判断请求者的合法性，并发送 FAILOVER_AUTH_ACK，对每一个 epoch 只发送一次 ack 
<br>尝试 failover 的 slave 收集 FAILOVER_AUTH_ACK 
<br>超过半数后变成新Master
<br>广播Pong通知其他集群节点
<br><img src="\04、数据库\02、redis\assets\08、高可拓展：分片技术（redis-cluster）详解\img-20240316_165837.png"><br><br>
Redis Cluster是如何进行扩容和缩容的呢？
<br><br>当集群出现容量限制或者其他一些原因需要扩容时，redis cluster提供了比较优雅的集群扩容方案。<br><br>将新节点加入到集群：<br>redis-cli --cluster add-node &lt;new-node-ip&gt;:&lt;new-node-port&gt; &lt;existing-node-ip&gt;:&lt;existing-node-port&gt;
复制<br> &lt;new-node-ip&gt;:&lt;new-node-port&gt; 是新节点的 IP 地址和端口，而 &lt;existing-node-ip&gt;:&lt;existing-node-port&gt; 是集群中已存在节点的 IP 地址和端口。<br><br>
<br>确定需要迁移的槽
<br>将这些槽中的所有key迁移到新的主节点
<br>通知集群中的所有其他主节点这些槽已迁移
<br>假设你想将节点A的槽位10迁移到节点B，你需要按照以下步骤操作：<br>1）节点 B 准备接收槽，使节点 B 知道它将从节点 A 导入槽位10。<br>redis-cli -h &lt;target-node-ip&gt; -p &lt;target-node-port&gt; CLUSTER SETSLOT 10 IMPORTING &lt;source-node-id&gt;
复制<br>2）使节点 A 知道它将槽位10迁移到节点 B<br>redis-cli -h &lt;source-node-ip&gt; -p &lt;source-node-port&gt; CLUSTER SETSLOT 10 MIGRATING &lt;target-node-id&gt;
复制<br>3）命令开始迁移过程<br>redis-cli -h &lt;source-node-ip&gt; -p &lt;source-node-port&gt; MIGRATE &lt;target-node-ip&gt; &lt;target-node-port&gt; "" 0 5000 KEYS &lt;key1&gt; &lt;key2&gt; ... &lt;keyN&gt;
复制<br>4）命令通知集群槽位 10 已经迁移到节点 B。<br>redis-cli --cluster setslot 10 node &lt;target-node-id&gt;
复制<br><br>缩容的大致过程与扩容一致，需要判断下线的节点是否是主节点，以及主节点上是否有槽。<br>若主节点上有槽，需要将槽迁移到集群中其他主节点，槽迁移完成之后，需要向其他节点广播该节点准备下线（cluster forget nodeId）。最后需要将该下线主节点的从节点指向其他主节点，当然最好是先将从节点下线。<br><br>
通过几个例子，再深入理解Redis Cluster
<br><br>我们知道一致性hash算法是2的16次方，为什么hash slot是2的14次方呢？<br>Redis 集群通过在心跳包中使用一个2K 大小的 bitmap 来有效地传递包含16384个槽的状态信息。<br>在redis节点发送心跳包时需要把所有的槽放到这个心跳包里，以便让节点知道当前集群信息，16384=16k，在发送心跳包时使用char进行bitmap压缩后是2k（2  8 (8 bit)  1024(1k) = 16K），也就是说使用2k的空间创建了16k的槽数。<br>虽然使用CRC16算法最多可以分配65535（2^16-1）个槽位，65535=65k，压缩后就是8k（8  8 (8 bit)  1024(1k) =65K），也就是说需要需要8k的心跳包，作者认为这样做不太值得；并且一般情况下一个redis集群不会有超过1000个master节点，所以16k的槽位是个比较合适的选择。<br><br>在集群模式下，所有的publish命令都会向所有节点（包括从节点）进行广播，造成每条publish数据都会在集群内所有节点传播一次，加重了带宽负担，对于在有大量节点的集群中频繁使用pub，会严重消耗带宽，不建议使用。（虽然官网上讲有时候可以使用Bloom过滤器或其他算法进行优化的）<br>]]></description><link>04、数据库\02、redis\08、高可拓展：分片技术（redis-cluster）详解.html</link><guid isPermaLink="false">04、数据库/02、Redis/08、高可拓展：分片技术（Redis Cluster）详解.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Mon, 18 Mar 2024 12:53:46 GMT</pubDate><enclosure url="04、数据库\02、redis\assets\08、高可拓展：分片技术（redis-cluster）详解\img-20240316_154508.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;04、数据库\02、redis\assets\08、高可拓展：分片技术（redis-cluster）详解\img-20240316_154508.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[09、缓存问题：一致性, 穿击, 穿透, 雪崩, 污染]]></title><description><![CDATA[ 
 <br>在高并发的业务场景下，数据库大多数情况都是用户并发访问最薄弱的环节。所以，就需要使用redis做一个缓冲操作，让请求先访问到redis，而不是直接访问Mysql等数据库。这样可以大大缓解数据库的压力。<br>当缓存库出现时，必须要考虑如下问题：<br>
<br>缓存穿透
<br>缓存穿击
<br>缓存雪崩
<br>缓存污染
<br>缓存和数据库一致性
<br><br><br>缓存和数据库中都没有的数据。<br>用户不断发起请求，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。<br>在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。<br>如发起为id为“-1”的数据或id为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大。<br><br>1、接口层增加校验<br>如用户鉴权校验，id 做基础校验，id&lt;=0的直接拦截；<br>2、设置 key 值为 null<br>将 key-value 对写为 key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。<br>
这样可以防止攻击用户反复用同一个 id 暴力攻击<br>3、布隆过滤器。<br>bloomfilter 就类似于一个 hash set，用于快速判某个元素是否存在于集合中，其典型的应用场景就是快速判断一个 key 是否存在于某容器，不存在就直接返回。布隆过滤器的关键就在于 hash 算法和容器大小。<br><br><br>缓存中没有但数据库中有的数据。<br>缓存击穿是指（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。<br><br>1、设置热点数据永远不过期。<br>2、接口限流与熔断，降级。重要的接口一定要做好限流策略，防止用户恶意刷接口，同时要降级准备，当接口中的某些服务不可用时候，进行熔断，失败快速返回机制。<br>3、加互斥锁<br><br><br>数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至 down 机。<br>和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。<br><br>1、缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。<br>2、如果缓存数据库是分布式部署，将热点数据均匀分布在不同的缓存数据库中。<br>3、设置热点数据永远不过期。<br><br><br>低频数据依然留存在缓存中，消耗缓存空间。<br>一些只会被访问一次或者几次的的数据，被访问完后，再也不会被访问到，缓存污染会随着数据的持续增加而逐渐显露。<br>缓存空间是有限的，如果缓存空间满了，再往缓存里写数据时就会有额外开销，包括判断淘汰策略，影响 Redis 性能。<br><br>淘汰策略，根据淘汰策略去选择要淘汰的数据，然后进行删除操作。<br><br>Redis 共支持八种淘汰策略。<br>主要看分三类看：<br>
<br>不淘汰

<br>noeviction （v4.0后默认的）


<br>对设置了过期时间的数据中进行淘汰

<br>随机：volatile-random
<br>ttl：volatile-ttl
<br>lru：volatile-lru
<br>lfu：volatile-lfu


<br>全部数据进行淘汰

<br>随机：allkeys-random
<br>lru：allkeys-lru
<br>lfu：allkeys-lfu


<br>
具体对照下：
<br>
<br>noeviction
<br>该策略是Redis的默认策略。在这种策略下，一旦缓存被写满了，再有写请求来时，Redis 不再提供服务，而是直接返回错误。这种策略不会淘汰数据，所以无法解决缓存污染问题。一般生产环境不建议使用。<br>其他七种规则都会根据自己相应的规则来选择数据进行删除操作。<br>
<br>volatile-random
<br>这个算法比较简单，在设置了过期时间的键值对中，进行随机删除。因为是随机删除，无法把不再访问的数据筛选出来，所以可能依然会存在缓存污染现象，无法解决缓存污染问题。<br>
<br>volatile-ttl
<br>这种算法判断淘汰数据时参考的指标比随机删除时多进行一步过期时间的排序。Redis在筛选需删除的数据时，越早过期的数据越优先被选择。<br>
<br>volatile-lru
<br>LRU算法：LRU 算法的全称是 Least Recently Used，按照最近最少使用的原则来筛选数据。这种模式下会使用 LRU 算法筛选设置了过期时间的键值对。<br>Redis优化的LRU算法实现：<br>Redis会记录每个数据的最近一次被访问的时间戳。在Redis在决定淘汰的数据时，第一次会随机选出 N 个数据，把它们作为一个候选集合。接下来，Redis 会比较这 N 个数据的 lru 字段，把 lru 字段值最小的数据从缓存中淘汰出去。通过随机读取待删除集合，可以让Redis不用维护一个巨大的链表，也不用操作链表，进而提升性能。<br>Redis 选出的数据个数 N，通过 配置参数 maxmemory-samples 进行配置。个数N越大，则候选集合越大，选择到的最久未被使用的就更准确，N越小，选择到最久未被使用的数据的概率也会随之减小。<br>
<br>volatile-lfu
<br>会使用 LFU 算法选择设置了过期时间的键值对。<br>LFU 算法：LFU 缓存策略是在 LRU 策略基础上，为每个数据增加了一个计数器，来统计这个数据的访问次数。当使用 LFU 策略筛选淘汰数据时，首先会根据数据的访问次数进行筛选，把访问次数最低的数据淘汰出缓存。如果两个数据的访问次数相同，LFU 策略再比较这两个数据的访问时效性，把距离上一次访问时间更久的数据淘汰出缓存。 Redis的LFU算法实现:<br>当 LFU 策略筛选数据时，Redis 会在候选集合中，根据数据 lru 字段的后 8bit 选择访问次数最少的数据进行淘汰。当访问次数相同时，再根据 lru 字段的前 16bit 值大小，选择访问时间最久远的数据进行淘汰。<br>Redis 只使用了 8bit 记录数据的访问次数，而 8bit 记录的最大值是 255，这样在访问快速的情况下，如果每次被访问就将访问次数加一，很快某条数据就达到最大值255，可能很多数据都是255，那么退化成LRU算法了。所以Redis为了解决这个问题，实现了一个更优的计数规则，并可以通过配置项，来控制计数器增加的速度。<br>参数 ：<br>lfu-log-factor ，用计数器当前的值乘以配置项 lfu_log_factor 再加 1，再取其倒数，得到一个 p 值；然后，把这个 p 值和一个取值范围在（0，1）间的随机数 r 值比大小，只有 p 值大于 r 值时，计数器才加 1。<br>lfu-decay-time， 控制访问次数衰减。LFU 策略会计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位。然后，LFU 策略再把这个差值除以 lfu_decay_time 值，所得的结果就是数据 counter 要衰减的值。<br>lfu-log-factor设置越大，递增概率越低，lfu-decay-time设置越大，衰减速度会越慢。<br>我们在应用 LFU 策略时，一般可以将 lfu_log_factor 取值为 10。 如果业务应用中有短时高频访问的数据的话，建议把 lfu_decay_time 值设置为 1。可以快速衰减访问次数。<br>volatile-lfu 策略是 Redis 4.0 后新增。<br>
<br>allkeys-lru
<br>使用 LRU 算法在所有数据中进行筛选。具体LFU算法跟上述 volatile-lru 中介绍的一致，只是筛选的数据范围是全部缓存，这里就不在重复。<br>
<br>allkeys-random
<br>从所有键值对中随机选择并删除数据。volatile-random 跟 allkeys-random算法一样，随机删除就无法解决缓存污染问题。<br>
<br>allkeys-lfu 使用 LFU 算法在所有数据中进行筛选。具体LFU算法跟上述 volatile-lfu 中介绍的一致，只是筛选的数据范围是全部缓存，这里就不在重复。
<br>allkeys-lfu 策略是 Redis 4.0 后新增。<br><br><br>因为写和读是并发的，没法保证顺序, 就会出现缓存和数据库的数据不一致的问题。<br>不管是先写 MySQL 数据库，再删除 Redis 缓存；还是先删除缓存，再写库，都有可能出现数据不一致的情况。<br>例子：<br>
<br>
如果删除了缓存 Redis，还没有来得及写库 MySQL，另一个线程就来读取，发现缓存为空，则去数据库中读取数据写入缓存，此时缓存中为脏数据。

<br>
如果先写了库，在删除缓存前，写库的线程宕机了，没有删除掉缓存，则也会出现数据不一致情况。

<br><br>由于我们的缓存的数据源来自于数据库 , 而数据库的数据是会发生变化的 , 因此，如果当数据库中数据发生变化，而缓存却没有同步 , 此时就会有一致性问题存在 , 其后果是:<br>用户使用缓存中的过时数据，就会产生类似多线程数据安全问题，从而影响业务，产品口碑等；<br>怎么解决呢？有如下几种方案：<br>
<br>
Cache Aside Pattern 人工编码方式：缓存调用者在更新完数据库后再去更新缓存，也称之为双写方案

<br>
Read/Write Through Pattern : 由系统本身完成，数据库与缓存的问题交由系统本身去处理

<br>
Write Behind Caching Pattern ：调用者只操作缓存，其他线程去异步处理数据库，实现最终一致

<br><img alt="assets/09、缓存问题：一致性, 穿击, 穿透, 雪崩, 污染/img-20240316_214619.png" src="\04、数据库\02、redis\assets\09、缓存问题：一致性,-穿击,-穿透,-雪崩,-污染\img-20240316_214619.png" style="width: 975px; max-width: 100%;"><br><br>节选最最常用的Cache Aside Pattern, 总结来说就是<br>
<br>读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。
<br>更新的时候，先更新数据库，然后再删除缓存。
<br>其具体逻辑如下：<br>
<br>失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。
<br>命中：应用程序从cache中取数据，取到后返回。
<br>更新：先把数据存到数据库中，成功后，再让缓存失效。
<br><img alt="assets/09、缓存问题：一致性, 穿击, 穿透, 雪崩, 污染/img-20240316_214840.png" src="\04、数据库\02、redis\assets\09、缓存问题：一致性,-穿击,-穿透,-雪崩,-污染\img-20240316_214840.png" style="width: 900px; max-width: 100%;"><br><br>流程如下所示<br>
<img src="\04、数据库\02、redis\assets\09、缓存问题：一致性,-穿击,-穿透,-雪崩,-污染\img-20240316_215143.png"><br>
<br>更新数据库数据；
<br>缓存因为种种问题删除失败
<br>将需要删除的key发送至消息队列
<br>自己消费消息，获得需要删除的key
<br>继续重试删除操作，直到成功
<br>然而，该方案有一个缺点，对业务线代码造成大量的侵入。于是有了方案二，在方案二中，启动一个订阅程序去订阅数据库的binlog，获得需要操作的数据。在应用程序中，另起一段程序，获得这个订阅程序传来的信息，进行删除缓存操作。<br><br><img src="\04、数据库\02、redis\assets\09、缓存问题：一致性,-穿击,-穿透,-雪崩,-污染\img-20240316_215130.png"><br>
<br>技术整体思路：
<br>MySQL binlog增量订阅消费+消息队列+增量数据更新到redis<br>1）读Redis：热数据基本都在Redis<br>2）写MySQL: 增删改都是操作MySQL<br>3）更新 Redis 数据：MySQL的数据操作 binlog，来更新到 Redis<br>
<br>Redis更新
<br>1）数据操作主要分为两大块：<br>
<br>一个是全量（将全部数据一次写入到 redis）
<br>一个是增量（实时更新）
<br>这里说的是增量，指的是 mysql 的 update、insert、delate 变更数据。 <br>2）读取 binlog 后分析，利用消息队列，推送更新各台的 redis 缓存数据。<br>这样一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，Redis再根据binlog中的记录，对Redis进行更新。<br>其实这种机制，很类似MySQL的主从备份机制，因为MySQL的主备也是通过binlog来实现的数据一致性。<br>这里可以结合使用 canal(阿里的一款开源框架)，通过该框架可以对 MySQL 的 binlog 进行订阅，而 canal 正是模仿了 mysql 的 slave 数据库的备份请求，使得 Redis 的数据更新达到了相同的效果。 <br>当然，这里的消息推送工具你也可以采用别的第三方：kafka、rabbitMQ 等来实现推送更新 Redis。 ]]></description><link>04、数据库\02、redis\09、缓存问题：一致性,-穿击,-穿透,-雪崩,-污染.html</link><guid isPermaLink="false">04、数据库/02、Redis/09、缓存问题：一致性, 穿击, 穿透, 雪崩, 污染.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Mon, 18 Mar 2024 12:51:06 GMT</pubDate><enclosure url="04、数据库\02、redis\assets\09、缓存问题：一致性,-穿击,-穿透,-雪崩,-污染\img-20240316_214619.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;04、数据库\02、redis\assets\09、缓存问题：一致性,-穿击,-穿透,-雪崩,-污染\img-20240316_214619.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[10、Redis 监控详解]]></title><description><![CDATA[ 
 <br><br>
如果只是想简单看一下Redis的负载情况的话，完全可以用它提供的一些命令来完成。
<br><br>Redis提供的INFO命令不仅能够查看实时的吞吐量(ops/sec)，还能看到一些有用的运行时信息。<br>
<br>info查看所有状态信息
<br>[root@redis_test_vm ~]# redis-cli -h 127.0.0.1
127.0.0.1:6379&gt; auth xxxxx
OK
127.0.0.1:6379&gt; info
# Server
redis_version:3.2.3 #redis版本号
redis_git_sha1:00000000 #git sha1摘要值
redis_git_dirty:0  #git dirty标识
redis_build_id:443e50c39cbcdbe0 #redis构建id
redis_mode:standalone  #运行模式：standalone、sentinel、cluster
os:Linux 3.10.0-514.16.1.el7.x86_64 x86_64 #服务器宿主机操作系统
arch_bits:64 服务器宿主机CUP架构（32位/64位）
multiplexing_api:epoll #redis IO机制
gcc_version:4.8.5  #编译 redis 时所使用的 GCC 版本
process_id:1508  #服务器进程的 PID
run_id:b4ac0f9086659ce54d87e41d4d2f947e19c28401 #redis 服务器的随机标识符 （用于 Sentinel 和集群）
tcp_port:6380  #redis服务监听端口
uptime_in_seconds:520162 #redis服务启动以来经过的秒数
uptime_in_days:6 #redis服务启动以来经过的天数
hz:10  #redis内部调度（进行关闭timeout的客户端，删除过期key等等）频率，程序规定serverCron每秒运行10次
lru_clock:16109450 #自增的时钟，用于LRU管理,该时钟100ms(hz=10,因此每1000ms/10=100ms执行一次定时任务)更新一次
executable:/usr/local/bin/redis-server
config_file:/data/redis-6380/redis.conf 配置文件的路径

# Clients
connected_clients:2   #已连接客户端的数量（不包括通过从属服务器连接的客户端）
client_longest_output_list:0 #当前连接的客户端当中，最长的输出列表
client_biggest_input_buf:0 #当前连接的客户端当中，最大输入缓存
blocked_clients:0 #正在等待阻塞命令（BLPOP、BRPOP、BRPOPLPUSH）的客户端的数量

# Memory
used_memory:426679232 #由 redis 分配器分配的内存总量，以字节（byte）为单位
used_memory_human:406.91M   #以可读的格式返回 redis 分配的内存总量（实际是used_memory的格式化）
used_memory_rss:443179008 #从操作系统的角度，返回 redis 已分配的内存总量（俗称常驻集大小）。这个值和 top 、 ps等命令的输出一致
used_memory_rss_human:422.65M # redis 的内存消耗峰值(以字节为单位) 
used_memory_peak:426708912
used_memory_peak_human:406.94M
total_system_memory:16658403328
total_system_memory_human:15.51G
used_memory_lua:37888   # Lua脚本存储占用的内存
used_memory_lua_human:37.00K
maxmemory:0
maxmemory_human:0B
maxmemory_policy:noeviction
mem_fragmentation_ratio:1.04 # used_memory_rss/ used_memory
mem_allocator:jemalloc-4.0.3

# Persistence
loading:0 #服务器是否正在载入持久化文件，0表示没有，1表示正在加载
rdb_changes_since_last_save:3164272  #离最近一次成功生成rdb文件，写入命令的个数，即有多少个写入命令没有持久化
rdb_bgsave_in_progress:0 #服务器是否正在创建rdb文件，0表示否
rdb_last_save_time:1559093160  #离最近一次成功创建rdb文件的时间戳。当前时间戳 - rdb_last_save_time=多少秒未成功生成rdb文件
rdb_last_bgsave_status:ok  #最近一次rdb持久化是否成功
rdb_last_bgsave_time_sec:-1  #最近一次成功生成rdb文件耗时秒数
rdb_current_bgsave_time_sec:-1 #如果服务器正在创建rdb文件，那么这个域记录的就是当前的创建操作已经耗费的秒数
aof_enabled:0 #是否开启了aof
aof_rewrite_in_progress:0 #标识aof的rewrite操作是否在进行中
aof_rewrite_scheduled:0  #rewrite任务计划，当客户端发送bgrewriteaof指令，如果当前rewrite子进程正在执行，那么将客户端请求的bgrewriteaof变为计划任务，待aof子进程结束后执行rewrite
aof_last_rewrite_time_sec:-1 #最近一次aof rewrite耗费的时长
aof_current_rewrite_time_sec:-1 #如果rewrite操作正在进行，则记录所使用的时间，单位秒
aof_last_bgrewrite_status:ok #上次bgrewriteaof操作的状态
aof_last_write_status:ok #上次aof写入状态

# Stats
total_connections_received:10   #服务器已经接受的连接请求数量
total_commands_processed:9510792   #redis处理的命令数
instantaneous_ops_per_sec:1   #redis当前的qps，redis内部较实时的每秒执行的命令数
total_net_input_bytes:1104411373   #redis网络入口流量字节数
total_net_output_bytes:66358938 #redis网络出口流量字节数
instantaneous_input_kbps:0.04  #redis网络入口kps
instantaneous_output_kbps:3633.35  #redis网络出口kps
rejected_connections:0  #拒绝的连接个数，redis连接个数达到maxclients限制，拒绝新连接的个数
sync_full:0  #主从完全同步成功次数
sync_partial_ok:0  #主从部分同步成功次数
sync_partial_err:0  #主从部分同步失败次数
expired_keys:0   #运行以来过期的key的数量
evicted_keys:0  #运行以来剔除(超过了maxmemory后)的key的数量
keyspace_hits:87  #命中次数
keyspace_misses:17   #没命中次数
pubsub_channels:0  #当前使用中的频道数量
pubsub_patterns:0  #当前使用的模式的数量
latest_fork_usec:0   #最近一次fork操作阻塞redis进程的耗时数，单位微秒
migrate_cached_sockets:0   #是否已经缓存了到该地址的连接

# Replication
role:master  #实例的角色，是master or slave
connected_slaves:0  #连接的slave实例个数
master_repl_offset:0 #主从同步偏移量,此值如果和上面的offset相同说明主从一致没延迟，与master_replid可被用来标识主实例复制流中的位置
repl_backlog_active:0   #复制积压缓冲区是否开启
repl_backlog_size:1048576  #复制积压缓冲大小
repl_backlog_first_byte_offset:0  #复制缓冲区里偏移量的大小
repl_backlog_histlen:0   #此值等于 master_repl_offset - repl_backlog_first_byte_offset,该值不会超过repl_backlog_size的大小

# CPU
used_cpu_sys:507.00  #将所有redis主进程在核心态所占用的CPU时求和累计起来
used_cpu_user:280.48   #将所有redis主进程在用户态所占用的CPU时求和累计起来
used_cpu_sys_children:0.00  #将后台进程在核心态所占用的CPU时求和累计起来
used_cpu_user_children:0.00  #将后台进程在用户态所占用的CPU时求和累计起来

# Cluster
cluster_enabled:0

# Keyspace
db0:keys=5557407,expires=362,avg_ttl=604780497
db15:keys=1,expires=0,avg_ttl=0
复制<br>
<br>查看某个模块的信息 
<br>127.0.0.1:6379&gt; info memory
# Memory
used_memory:1067440
used_memory_human:1.02M
used_memory_rss:9945088
used_memory_rss_human:9.48M
used_memory_peak:1662736
used_memory_peak_human:1.59M
total_system_memory:10314981376
total_system_memory_human:9.61G
used_memory_lua:37888
used_memory_lua_human:37.00K
maxmemory:0
maxmemory_human:0B
maxmemory_policy:noeviction
mem_fragmentation_ratio:9.32
mem_allocator:jemalloc-4.0.3
复制<br><br>monitor 用来监视服务端收到的命令。<br>127.0.0.1:6379&gt; monitor
OK
1616045629.853032 [10 192.168.0.101:37990] "PING"
1616045629.858214 [10 192.168.0.101:37990] "PING"
1616045632.193252 [10 192.168.0.101:37990] "EXISTS" "test_key_from_app"
1616045632.193607 [10 192.168.0.101:37990] "GET" "test_key_from_app"
1616045632.200572 [10 192.168.0.101:37990] "SET" "test_key_from_app" "1616045625017"
1616045632.200973 [10 192.168.0.101:37990] "SET" "test_key_from_app" "1616045622621"
复制<br><br><br>[root@redis_test_vm ~] redis-cli --latency -h 127.0.0.1
min: 0, max: 1, avg: 0.21
复制<br>如果我们故意用DEBUG命令制造延迟，就能看到一些输出上的变化：<br>[root@redis_test_vm ~] redis-cli -h 127.0.0.1
127.0.0.1:6379&gt; debug sleep 2
OK
(2.00s)
127.0.0.1:6379&gt; debug sleep 3
OK
(3.00s)
复制<br>观测延迟<br>[root@redis_test_vm ~] redis-cli --latency -h 127.0.0.1
min: 0, max: 1995, avg: 1.60 (492 samples)
复制<br><br>127.0.0.1:6379&gt; ping
PONG
127.0.0.1:6379&gt; ping
PONG
复制<br>同时monitor<br>127.0.0.1:6379&gt; monitor
OK
1616045629.853032 [10 192.168.0.101:37990] "PING"
1616045629.858214 [10 192.168.0.101:37990] "PING"
复制<br><br>服务端内部的延迟监控稍微麻烦一些，因为延迟记录的默认阈值是0。尽管空间和时间耗费很小，Redis为了高性能还是默认关闭了它。所以首先我们要开启它，设置一个合理的阈值，例如下面命令中设置的100ms：<br>127.0.0.1:6379&gt; CONFIG SET latency-monitor-threshold 100
OK
复制<br>因为Redis执行命令非常快，所以我们用DEBUG命令人为制造一些慢执行命令：<br>127.0.0.1:6379&gt; debug sleep 2
OK
(2.00s)
127.0.0.1:6379&gt; debug sleep .15
OK
127.0.0.1:6379&gt; debug sleep .5
OK
复制<br>下面就用LATENCY的各种子命令来查看延迟记录：<br>
<br>LATEST：四列分别表示事件名、最近延迟的Unix时间戳、最近的延迟、最大延迟。
<br>HISTORY：延迟的时间序列。可用来产生图形化显示或报表。
<br>GRAPH：以图形化的方式显示。最下面以竖行显示的是指延迟在多久以前发生。
<br>RESET：清除延迟记录。
<br>127.0.0.1:6379&gt; latency latest
1) 1) "command"
   1) (integer) 1616058778
   2) (integer) 500
   3) (integer) 2000

127.0.0.1:6379&gt; latency history command
1) 1) (integer) 1616058773
   2) (integer) 2000
2) 1) (integer) 1616058776
   2) (integer) 150
3) 1) (integer) 1616058778
   2) (integer) 500

127.0.0.1:6379&gt; latency graph command
command - high 2000 ms, low 150 ms (all time high 2000 ms)
--------------------------------------------------------------------------------
#  
|  
|  
|_#

666
mmm
复制<br>在执行一条DEBUG命令会发现GRAPH图的变化，多出一条新的柱状线，下面的时间2s就是指延迟刚发生两秒钟：<br>127.0.0.1:6379&gt; debug sleep 1.5
OK
(1.50s)
127.0.0.1:6379&gt; latency graph command
command - high 2000 ms, low 150 ms (all time high 2000 ms)
--------------------------------------------------------------------------------
#   
|  #
|  |
|_#|

2222
333s
mmm 
复制<br>还有一个子命令DOCTOR，它能列出一些指导建议，例如开启慢日志进一步追查问题原因，查看是否有大对象被踢出或过期，以及操作系统的配置建议等。<br>127.0.0.1:6379&gt; latency doctor
Dave, I have observed latency spikes in this Redis instance. You don't mind talking about it, do you Dave?

1. command: 3 latency spikes (average 883ms, mean deviation 744ms, period 210.00 sec). Worst all time event 2000ms.

I have a few advices for you:

- Check your Slow Log to understand what are the commands you are running which are too slow to execute. Please check http://redis.io/commands/slowlog for more information.
- Deleting, expiring or evicting (because of maxmemory policy) large objects is a blocking operation. If you have very large objects that are often deleted, expired, or evicted, try to fragment those objects into multiple smaller objects.
- I detected a non zero amount of anonymous huge pages used by your process. This creates very serious latency events in different conditions, especially when Redis is persisting on disk. To disable THP support use the command 'echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled', make sure to also add it into /etc/rc.local so that the command will be executed again after a reboot. Note that even if you have already disabled THP, you still need to restart the Redis process to get rid of the huge pages already created.
复制<br>如果你沒有配置 CONFIG SET latency-monitor-threshold &lt;milliseconds&gt;., 会返回如下信息<br>127.0.0.1:6379&gt; latency doctor
I'm sorry, Dave, I can't do that. Latency monitoring is disabled in this Redis instance. You may use "CONFIG SET latency-monitor-threshold &lt;milliseconds&gt;." in order to enable it. If we weren't in a deep space mission I'd suggest to take a look at http://redis.io/topics/latency-monitor.
复制<br><br>延迟中的一部分是来自环境的，比如操作系统内核、虚拟化环境等等。Redis提供了让我们度量这一部分延迟基线(Baseline)的方法：<br>[root@redis_test_vm ~]# redis-cli --intrinsic-latency 100 -h 127.0.0.1
Could not connect to Redis at 127.0.0.1:6379: Connection refused
Max latency so far: 1 microseconds.
Max latency so far: 62 microseconds.
Max latency so far: 69 microseconds.
Max latency so far: 72 microseconds.
Max latency so far: 102 microseconds.
Max latency so far: 438 microseconds.
Max latency so far: 5169 microseconds.
Max latency so far: 9923 microseconds.

1435096059 total runs (avg latency: 0.0697 microseconds / 69.68 nanoseconds per run).
Worst run took 142405x longer than the average latency.
复制<br>–intrinsic-latency后面是测试的时长(秒)，一般100秒足够了。<br><br>
在谈Redis可视化监控工具时，要分清工具到底是仅仅指标的可视化，还是可以融入监控体系(比如包含可视化，监控，报警等; 这是生产环境长期监控生态的基础）
<br>
<br>只能可视化指标不能监控： redis-stat、RedisLive、redmon 等工具
<br>用于生产环境： 基于redis_exporter以及grafana可以做到指标可视化，持久化，监控以及报警等
<br><br>
<a data-tooltip-position="top" aria-label="https://github.com/junegunn/redis-stat" rel="noopener" class="external-link" href="https://github.com/junegunn/redis-stat" target="_blank">redis-stat在新窗口打开</a>是一个比较有名的redis指标可视化的监控工具，采用ruby开发，基于redis的info和monitor命令来统计，不影响redis性能。
<br>它提供了命令行彩色控制台展示模式<br><img src="\04、数据库\02、redis\assets\10、redis-监控详解\img-20240317_203104.png"><br>和web模式<br><img src="\04、数据库\02、redis\assets\10、redis-监控详解\img-20240317_203115.png"><br><br>
<a data-tooltip-position="top" aria-label="https://github.com/nkrode/RedisLive" rel="noopener" class="external-link" href="https://github.com/nkrode/RedisLive" target="_blank">RedisLive在新窗口打开</a>是采用python开发的redis的可视化及查询分析工具
<br>docker运行<br>docker run --name redis-live -p 8888:8888 -d snakeliwei/redislive
复制<br>运行实例图<br><img src="\04、数据库\02、redis\assets\10、redis-监控详解\img-20240317_203142.png"><br><br>
<a data-tooltip-position="top" aria-label="https://github.com/steelThread/redmon" rel="noopener" class="external-link" href="https://github.com/steelThread/redmon" target="_blank">redmon在新窗口打开</a>提供了cli、admin的web界面，同时也能够实时监控redis
<br>docker运行<br>docker run -p 4567:4567 -d  vieux/redmon -r redis://192.168.99.100:6379
复制<br>监控<br><img src="\04、数据库\02、redis\assets\10、redis-监控详解\img-20240317_203213.png"><br>cli<br><img src="\04、数据库\02、redis\assets\10、redis-监控详解\img-20240317_203222.png"><br>动态更新配置<br><img src="\04、数据库\02、redis\assets\10、redis-监控详解\img-20240317_203232.png"><br><br>
<a data-tooltip-position="top" aria-label="https://github.com/oliver006/redis_exporter" rel="noopener" class="external-link" href="https://github.com/oliver006/redis_exporter" target="_blank">redis_exporter在新窗口打开</a>为Prometheus提供了redis指标的exporter，支持Redis 2.x, 3.x, 4.x, 5.x, and 6.x，配合Prometheus以及grafana的Prometheus Redis插件，可以在grafana进行可视化及监控
<br>运行实例图<br><img src="\04、数据库\02、redis\assets\10、redis-监控详解\img-20240317_203249.png"><br><img src="\04、数据库\02、redis\assets\10、redis-监控详解\img-20240317_203257.png"><br><br>
那么上面我们谈到的监控体系到底应该考虑什么？ redis这类敏感的纯内存、高并发和低延时的服务，一套完善的监控告警方案，是精细化运营的前提。
<br>我们从以下几个角度来理解：<br>
<br>什么样的场景会谈到redis监控体系？
<br>构建Redis监控体系具备什么价值？
<br>监控体系化包含哪些维度？
<br>具体的监控指标有哪些呢？
<br>有哪些成熟的监控方案呢？
<br><br>一个大型系统引入了Redis作为缓存中间件，具体描述如下：<br>
<br>部署架构采用Redis-Cluster模式;
<br>后台应用系统有几十个，应用实例数超过二百个;
<br>所有应用系统共用一套缓存集群;
<br>集群节点数几十个，加上容灾备用环境，节点数量翻倍;
<br>集群节点内存配置较高。
<br><img src="\04、数据库\02、redis\assets\10、redis-监控详解\img-20240317_203336.png"><br>问题描述<br>系统刚开始关于Redis的一切都很正常，随着应用系统接入越来越多，应用系统子模块接入也越来越多，开始出现一些问题，应用系统有感知，集群服务端也有感知，如下描述：<br>
<br>集群节点崩溃;
<br>集群节点假死;
<br>某些后端应用访问集群响应特别慢。
<br>其实问题的根源都是架构运维层面的欠缺，对于Redis集群服务端的运行监控其实很好做，上文也介绍了很多直接的命令方式，但只能看到服务端的一些常用指标信息，无法深入分析，治标不治本，对于Redis的内部运行一无所知，特别是对于业务应用如何使用Redis集群一无所知：<br>
<br>Redis集群使用的热度问题?
<br>哪些应用占用的Redis内存资源多?
<br>哪些应用占用Redis访问数最高?
<br>哪些应用使用Redis类型不合理?
<br>应用系统模块使用Redis资源分布怎么样?
<br>应用使用Redis集群的热点问题?
<br><br>Redis监控告警的价值对每个角色都不同，重要的几个方面：<br>
<br>redis故障快速通知，定位故障点；
<br>分析redis故障的Root cause
<br>redis容量规划和性能管理
<br>redis硬件资源利用率和成本
<br><br>当redis出现故障时，运维人员应在尽可能短时间内发现告警；如果故障对服务是有损的(如大面积网络故障或程序BUG)，需立即通知SRE和RD启用故障预案(如切换机房或启用emergency switch）止损。<br>如果没完善监控告警; 假设由RD发现服务故障，再排查整体服务调用链去定位；甚于用户发现用问题，通过客服投诉，再排查到redis故障的问题；整个redis故障的发现、定位和解决时间被拉长，把一个原本的小故障被”无限”放大。<br><br>任何一个故障和性能问题，其根本“诱因”往往只有一个，称为这个故障的Root cause。<br>一个故障从DBA发现、止损、分析定位、解决和以后规避措施；最重要一环就是DBA通过各种问题表象，层层分析到Root cause；找到问题的根据原因，才能根治这类问题，避免再次发生。<br>完善的redis监控数据，是我们分析root cause的基础和证据。<br>问题表现是综合情的，一般可能性较复杂，这里举2个例子：<br>
<br>服务调用Redis响应时间变大的性能总是；可能网络问题，redis慢查询，redis QPS增高达到性能瓶颈，redis fork阻塞和请求排队，redis使用swap, cpu达到饱和(单核idle过低),aof fsync阻塞，网络进出口资源饱和等等
<br>redis使用内存突然增长，快达到maxmemory; 可能其个大键写入，键个数增长，某类键平均长度突增，fork COW, 客户端输入/输出缓冲区,lua程序占用等等
<br>Root cause是要直观的监控数据和证据，而非有技术支撑的推理分析。<br>
<br>redis响应抖动，分析定位root casue是bgsave时fork导致阻塞200ms的例子。而不是分析推理：redis进程rss达30gb,响应抖动时应该有同步，fork子进程时，页表拷贝时要阻塞父进程，估计页表大小xx，再根据内存copy连续1m数据要xx 纳秒，分析出可能fork阻塞导致的。（要的不是这种分析）
<br><br>通过分析redis资源使用和性能指标的监控历史趋势数据；对集群进行合理扩容(Scale-out)、缩容(Scale-back)；对性能瓶颈优化处理等。<br>Redis资源使用饱和度监控，设置合理阀值；<br>一些常用容量指标：redis内存使用比例，swap使用，cpu单核的饱和度等；当资源使用容量预警时，能及时扩容，避免因资源使用过载，导致故障。<br>另一方面，如果资源利用率持续过低，及时通知业务，并进行redis集群缩容处理，避免资源浪费。<br>进一步，容器化管理redis后，根据监控数据，系统能自动地弹性扩容和缩容。<br>Redis性能监控管理，及时发现性能瓶颈，进行优化或扩容，把问题扼杀在”萌芽期“，避免它”进化“成故障。<br><br>从老板角度来看，最关心的是成本和资源利用率是否达标。<br>如果资源不达标，就得推进资源优化整合；提高硬件利用率，减少资源浪费。砍预算，减成本。<br>资源利用率是否达标的数据，都是通过监控系统采集的数据。<br><br>监控的目的不仅仅是监控Redis本身，而是为了更好的使用Redis。传统的监控一般比较单一化，没有系统化，但对于Redis来说，个人认为至少包括：一是服务端，二是应用端，三是服务端与应用端联合分析。<br><br>服务端首先是操作系统层面，常用的CPU、内存、网络IO，磁盘IO，服务端运行的进程信息等；<br>Redis运行进程信息，包括服务端运行信息、客户端连接数、内存消耗、持久化信息 、键值数量、主从同步、命令统计、集群信息等；<br>Redis运行日志，日志中会记录一些重要的操作进程，如运行持久化时，可以有效帮助分析崩溃假死的程序。<br><br>应用端、获取应用端使用Redis的一些行为，具体哪些应用哪些模块最占用 Redis资源、哪些应用哪些模块最消耗Redis资源、哪些应用哪些模块用法有误等。<br><br>联合分析结合服务端的运行与应用端使用的行为，如：一些造成服务端突然阻塞的原因，可能是应用端设置了一个很大的缓存键值，或者使用的键值列表，数据量超大造成阻塞。<br><br>redis监控的数据采集，数据采集1分钟一次，分为下面几个方面：<br>
<br>服务器系统数据采集
<br>Redis Server数据采集
<br>Redis响应时间数据采集
<br>Redis监控Screen
<br><br>服务器系统的数据采集，这部分包含数百个指标. 采集方式现在监控平台自带的agent都会支持<br>我们从redis使用资源的特性，分析各个子系统的重要监控指标。<br>
<br>服务器存活监控

<br>ping监控告警


<br>CPU

<br>平均负载 (Load Average): 综合负载指标(暂且归类cpu子系统)，当系统的子系统出现过度使用时，平均负载会升高。可说明redis的处理性能下降(平均响应时间变长、吞吐量降低)。
<br>CPU整体利用率或饱和度 (cpu.busy): redis在高并发或时间复杂度高的指令，cpu整体资源饱和，导致redis性能下降，请求堆积。
<br>CPU单核饱和度 (cpu.core.idle/core=0): redis是单进程模式，常规情况只使用一个cpu core, 单某个实例出现cpu性能瓶颈，导致性能故障，但系统一般24线程的cpu饱和度却很低。所以监控cpu单核心利用率也同样重样。
<br>CPU上下文切换数 (cpu.switches)：context swith过高xxxxxx


<br>内存和swap

<br>系统内存余量大小 (mem.memfree)：redis是纯内存系统，系统内存必须保有足够余量，避免出现OOM，导致redis进程被杀，或使用swap导致redis性能骤降。
<br>系统swap使用量大小 (mem.swapused)：redis的”热数据“只要进入swap,redis处理性能就会骤降； 不管swap分区的是否是SSD介质。OS对swap的使用材质还是disk store. 这也是作者早期redis实现VM,后来又放弃的原因。


<br>磁盘

<br>磁盘分区的使用率 （df.bytes.used.percent)：磁盘空间使用率监控告警，确保有足磁盘空间用AOF/RDB, 日志文件存储。不过 redis服务器一般很少出现磁盘容量问题
<br>磁盘IOPS的饱和度(disk.io.util)：如果有AOF持久化时，要注意这类情况。如果AOF持久化，每秒sync有堆积，可能导致写入stall的情况。 另外磁盘顺序吞吐量还是很重要，太低会导致复制同步RDB时，拉长同步RDB时间。（期待diskless replication）


<br>网络

<br>网络吞吐量饱和度(net.if.out.bytes/net.if.in.bytes)：如果服务器是千兆网卡（Speed: 1000Mb/s），单机多实例情况，有异常的大key容量导致网卡流量打滿。redis整体服务等量下降，苦于出现故障切换。
<br>丢包率 ：Redis服务响应质量受影响


<br><br>通过redis实例的状态数据采集，采集监控数据的命令<br>ping,info all, slowlog get/len/reset/cluster info/config get<br>
<br>Redis存活监控

<br>redis存活监控 (redis_alive):redis本地监控agent使用ping，如果指定时间返回PONG表示存活，否则redis不能响应请求，可能阻塞或死亡。
<br>redis uptime监控 (redis_uptime)：uptime_in_seconds


<br>Redis 连接数监控

<br>连接个数 (connected_clients)：客户端连接个数，如果连接数过高，影响redis吞吐量。常规建议不要超过5000.
<br>连接数使用率(connected_clients_pct): 连接数使用百分比，通过(connected_clients/macclients)计算；如果达到1，redis开始拒绝新连接创建。
<br>拒绝的连接个数(rejected_connections): redis连接个数达到maxclients限制，拒绝新连接的个数。
<br>新创建连接个数 (total_connections_received): 如果新创建连接过多，过度地创建和销毁连接对性能有影响，说明短连接严重或连接池使用有问题，需调研代码的连接设置。
<br>list阻塞调用被阻塞的连接个数 (blocked_clients): BLPOP这类命令没使用过，如果监控数据大于0，还是建议排查原因。


<br>Redis内存监控

<br>redis分配的内存大小 (used_memory): redis真实使用内存，不包含内存碎片；单实例的内存大小不建议过大，常规10~20GB以内。
<br>redis内存使用比例(used_memory_pct): 已分配内存的百分比，通过(used_memory/maxmemory)计算；对于redis存储场景会比较关注，未设置淘汰策略(maxmemory_policy)的，达到maxmemory限制不能写入数据。
<br>redis进程使用内存大小(used_memory_rss): 进程实际使用的物理内存大小，包含内存碎片；如果rss过大导致内部碎片大，内存资源浪费，和fork的耗时和cow内存都会增大。
<br>redis内存碎片率 (mem_fragmentation_ratio): 表示(used_memory_rss/used_memory)，碎片率过大，导致内存资源浪费；


<br><br>
<br>Redis Keyspace: redis键空间的状态监控

<br>键个数 (keys): redis实例包含的键个数。建议控制在1kw内；单实例键个数过大，可能导致过期键的回收不及时。
<br>设置有生存时间的键个数 (keys_expires): 是纯缓存或业务的过期长，都建议对键设置TTL; 避免业务的死键问题. （expires字段）
<br>估算设置生存时间键的平均寿命 (avg_ttl): redis会抽样估算实例中设置TTL键的平均时长，单位毫秒。如果无TTL键或在Slave则avg_ttl一直为0
<br>LRU淘汰的键个数 (evicted_keys): 因used_memory达到maxmemory限制，并设置有淘汰策略的实例；（对排查问题重要，可不设置告警）
<br>过期淘汰的键个数 (expired_keys): 删除生存时间为0的键个数；包含主动删除和定期删除的个数。


<br>Redis qps

<br>redis处理的命令数 (total_commands_processed): 监控采集周期内的平均qps,
<br>redis单实例处理达数万，如果请求数过多，redis过载导致请求堆积。
<br>redis当前的qps (instantaneous_ops_per_sec): redis内部较实时的每秒执行的命令数；可和total_commands_processed监控互补。


<br>Redis cmdstat_xxx

<br>通过info all的Commandstats节采集数据.
<br>每类命令执行的次数 (cmdstat_xxx): 这个值用于分析redis抖动变化比较有用
<br>以下表示：每个命令执行次数，总共消耗的CPU时长(单个微秒)，平均每次消耗的CPU时长（单位微秒）


<br># Commandstats
cmdstat_set:calls=6,usec=37,usec_per_call=6.17
cmdstat_lpush:calls=4,usec=32,usec_per_call=8.00
cmdstat_lpop:calls=4,usec=33,usec_per_call=8.25
复制<br>
<br>Redis Keysapce hit ratio
<br>redis键空间请求命中率监控，通过此监控来度量redis缓存的质量，如果未命中率或次数较高，可能因热点数据已大于redis的内存限制，导致请求落到后端存储组件，可能需要扩容redis缓存集群的内存容量。当然也有可能是业务特性导致。<br>
<br>请求键被命中次数 (keyspace_hits): redis请求键被命中的次数<br>

<br>请求键未被命中次数 (keyspace_misses): redis请求键未被命中的次数；当命中率较高如95%，如果请求量大，未命中次数也会很多。<br>

<br>请求键的命中率 (keyspace_hit_ratio):使用keyspace_hits/(keyspace_hits+keyspace_misses)计算所得，是度量Redis缓存服务质量的标准<br>

<br>Redis fork<br>

<br>redis在执行BGSAVE,BGREWRITEAOF命令时，redis进程有 fork 操作。而fork会对redis进程有个短暂的卡顿,这个卡顿redis不能响应任务请求。所以监控fork阻塞时长，是相当重要。<br>如果你的系统不能接受redis有500ms的阻塞，那么就要监控fork阻塞时长的变化，做好容量规划。<br>最近一次fork阻塞的微秒数 (latest_fork_usec): 最近一次Fork操作阻塞redis进程的耗时数，单位微秒。 redis network traffic redis一般单机多实例部署，当服务器网络流量增长很大，需快速定位是网络流量被哪个redis实例所消耗了； 另外redis如果写流量过大，可能导致slave线程“客户端输出缓冲区”堆积，达到限制后被Maser强制断开连接，出现复制中断故障。所以我们需监控每个redis实例网络进出口流量，设置合适的告警值。<br>说明：网络监控指标 ，需较高的版本才有，应该是2.8.2x以后<br>
<br>redis网络入口流量字节数 (total_net_input_bytes)
<br>redis网络出口流量字节数 (total_net_output_bytes)
<br>redis网络入口kps （instantaneous_input_kbps）
<br>redis网络出口kps (instantaneous_output_kbps)
<br>前两者是累计值，根据监控平台1个采集周期(如1分钟)内平均每秒的流量字节数。<br><br>redis慢查询 是排查性能问题关键监控指标。因redis是单线程模型(single-threaded server),即一次只能执行一个命令，如果命令耗时较长，其他命令就会被阻塞，进入队列排队等待；这样对程序性能会较大。<br>redis慢查询保存在内存中，最多保存slowlog-max-len(默认128）个慢查询命令，当慢查询命令日志达到128个时，新慢查询被加入前，会删除最旧的慢查询命令。因慢查询不能持久化保存，且不能实时监控每秒产生的慢查询个数。<br>我们建议的慢查询监控方法：<br>
<br>设置合理慢查询日志阀值,slowlog-log-slower-than, 建议1ms(如果平均1ms, redis qps也就只有1000) 设+ 置全理慢查询日志队列长度，slowlog-max-len建议大于1024个，因监控采集周期1分钟，建议，避免慢查询日志被删除；另外慢查询的参数过多时，会被省略，对内存消耗很小
<br>每次采集使用slowlog len获取慢查询日志个数
<br>每次彩集使用slowlog get 1024 获取所慢查询，并转存储到其他地方，如MongoDB或MySQL等，方便排查问题；并分析当前慢查询日志最长耗时微秒数。
<br>然后使用slowlog reset把慢查询日志清空，下个采集周期的日志长度就是最新产生的。
<br>redis慢查询的监控项：<br>
<br>redis慢查询日志个数 （slowlog_len):每个采集周期出现慢查询个数，如1分钟出现10次大于1ms的慢查询
<br>redis慢查询日志最长耗时值 (slowlog_max_time)：获取慢查询耗时最长值，因有的达10秒以下的慢查询，可能导致复制中断，甚至出来主从切换等故障。
<br><br>redis存储场景的集群，就得 redis持久化 保障数据落地，减少故障时数据丢失。这里分析redis rdb数据持久化的几个监控指标。<br>
<br>最近一次rdb持久化是否成功 (rdb_last_bgsave_status):如果持久化未成功，建议告警，说明备份或主从复制同步不正常。或redis设置有”stop-writes-on-bgsave-error”为yes，当save失败后，会导致redis不能写入操作
<br>最近一次成功生成rdb文件耗时秒数 (rdb_last_bgsave_time_sec):rdb生成耗时反应同步时数据是否增长； 如果远程备份使用redis-cli –rdb方式远程备份rdb文件，时间长短可能影响备份线程客户端输出缓冲内存使用大小。
<br>离最近一次成功生成rdb文件，写入命令的个数 （rdb_changes_since_last_save):即有多少个写入命令没有持久化，最坏情况下会丢失的写入命令数。建议设置监控告警
<br>离最近一次成功rdb持久化的秒数 (rdb_last_save_time): 最坏情况丢失多少秒的数据写入。使用当前时间戳 - 采集的rdb_last_save_time(最近一次rdb成功持久化的时间戳)，计算出多少秒未成功生成rdb文件
<br><br>不论使用何种redis集群方案， redis复制 都会被使用。<br>复制相关的监控告警项：<br>
<br>redis角色 (redis_role):实例的角色，是master or slave
<br>复制连接状态 (master_link_status): slave端可查看它与master之间同步状态；当复制断开后表示down,影响当前集群的可用性。需设置监控告警。
<br>复制连接断开时间长度 (master_link_down_since_seconds):主从服务器同步断开的秒数，建议设置时长告警。
<br>主库多少秒未发送数据到从库 (master_last_io_seconds):如果主库超过repl-timeout秒未向从库发送命令和数据，会导致复制断开重连。 在slave端可监控，建议设置大于10秒告警
<br>从库多少秒未向主库发送REPLCONF命令 (slave_lag): 正常情况从库每秒都向主库，发送REPLCONF ACK命令；如果从库因某种原因，未向主库上报命令，主从复制有中断的风险。通过在master端监控每个slave的lag值。
<br>从库是否设置只读 (slave_read_only)：从库默认只读禁止写入操作，监控从库只读状态；如果关闭从库只读，有写入数据风险。
<br>主库挂载的从库个数 (connected_slaves):主库至少保证一个从库，不建议设置超过2个从库。
<br>复制积压缓冲区是否开启 (repl_backlog_active):主库默认开启复制积压缓冲区，用于应对短时间复制中断时，使用 部分同步 方式。
<br>复制积压缓冲大小 (repl_backlog_size):主库复制积压缓冲大小默认1MB,因为是redis server共享一个缓冲区，建议设置100MB.
<br>说明： 关于根据实际情况，设置合适大小的复制缓冲区。可以通过master_repl_offset指标计算每秒写入字节数，同时乘以希望多少秒内闪断使用“部分同步”方式。<br><br>这里所写 redis官方集群方案 的监控指标<br>数据基本通过cluster info和info命令采集。<br>
<br>实例是否启用集群模式 (cluster_enabled): 通过info的cluster_enabled监控是否启用集群模式。
<br>集群健康状态 （clusster_state):如果当前redis发现有failed的slots，默认为把自己cluster_state从ok个性为fail, 写入命令会失败。如果设置cluster-require-full-coverage为NO,则无此限制。
<br>集群数据槽slots分配情况 (cluster_slots_assigned):集群正常运行时，默认16384个slots
<br>检测下线的数据槽slots个数 (cluster_slots_fail):集群正常运行时，应该为0. 如果大于0说明集群有slot存在故障。
<br>集群的分片数 (cluster_size）：集群中设置的分片个数
<br>集群的节点数 （cluster_known_nodes）：集群中redis节点的个数
<br><br>响应时间 是衡量一个服务组件性能和质量的重要指标。使用redis的服务通常对响应时间都十分敏感，比如要求99%的响应时间达10ms以内。<br>因redis的慢查询日志只计算命令的cpu占用时间，不会考虑排队或其他耗时。<br>
<br>最长响应时间 （respond_time_max):最长响应时间的毫秒数
<br>99%的响应时间长度 (respond_time_99_max):
<br>99%的平均响应时间长度 (respond_time_99_avg):
<br>95%的响应时间长度 （respond_time_95_max):
<br>95%的平均响应时间长度 (respond_time_95_avg):
<br><br>
无论哪种，要体系化，必然要考虑如下几点。
<br>
<br>指标采集，即采集redis提供的metric指标，所以方案中有时候会出现Agent，比如metricBeat；
<br>监控的数据持久化，只有将监控数据放到数据库，才能对比和长期监控；
<br>时序化，因为很多场景都会按照时间序列去展示 - 所以通常是用时序库或者针对时间列优化；
<br>可视化，比如常见的kibana，grafana等
<br>按条件报警，因为运维不可能盯着看，只有引入报警配置，触发报警条件时即发出报警，比如短息提醒等；基于不同报警方式，平台可以提供插件支持等；
<br><br>
经典的ELK
<br>
<br>采集agent: metricBeat
<br>收集管道：logstash
<br>DB: elasticSearch
<br>view和告警: kibana及插件
<br><br>
推荐使用这种
<br>
<br>采集指标来源: redis-export
<br>收集管道：fluentd
<br>DB: Prometheus
<br>view和告警: Grafana及插件
<br><img src="\04、数据库\02、redis\assets\10、redis-监控详解\img-20240317_203646.png"><br><img src="\04、数据库\02、redis\assets\10、redis-监控详解\img-20240317_203650.png">]]></description><link>04、数据库\02、redis\10、redis-监控详解.html</link><guid isPermaLink="false">04、数据库/02、Redis/10、Redis 监控详解.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Sun, 17 Mar 2024 12:37:19 GMT</pubDate><enclosure url="04、数据库\02、redis\assets\10、redis-监控详解\img-20240317_203104.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;04、数据库\02、redis\assets\10、redis-监控详解\img-20240317_203104.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[11、Redis 最佳实践&性能调优]]></title><description><![CDATA[ 
 <br><br>Redis 是一款非常优秀的 NoSQL 数据库，但更重要的是，作为使用者应该学会在不同的场景中如何更好的使用它，更大的发挥它的价值，以及扼杀问题于摇篮。<br><br><br>Redis 的 Key 虽然可以自定义，但最好遵循下面的几个最佳实践约定：<br>
<br>遵循基本格式：[业务名称]:[数据名]:[id]
<br>长度不超过 44 字节
<br>不包含特殊字符
<br>例如：登录业务，保存用户信息，其 key 可以设计成如下格式：<br>
<img src="\04、数据库\02、redis\assets\11、redis-最佳实践&amp;性能调优\img-20240317_212716.png"><br><br>BigKey 通常以 Key 的大小和 Key 中成员的数量来综合判定，例如：<br>
<br>Key 本身的数据量过大：一个 String 类型的 Key ，它的值为 5 MB
<br>Key 中的成员数过多：一个 ZSET 类型的 Key ，它的成员数量为 10,000 个
<br>Key 中成员的数据量过大：一个 Hash 类型的 Key ，它的成员数量虽然只有 1,000 个但这些成员的 Value（值）总大小为 100 MB
<br>判断元素的大小：<br>MEMORY USAGE KEY
复制<br>推荐值：<br>
<br>单个 key 的 value 小于 10 KB
<br>对于集合类型的 key，建议元素数量小于 1000
<br><br><br>Redis 处理指令是很快的，花费的主要时间在于网络传输。<br>单次 N 条命令的执行流程<br>
<img alt="assets/11、Redis 最佳实践&amp;性能调优/img-20240317_213922.png" src="\04、数据库\02、redis\assets\11、redis-最佳实践&amp;性能调优\img-20240317_213922.png" style="width: 775px; max-width: 100%;"><br>批量发送以减少时间：<br>
<img alt="assets/11、Redis 最佳实践&amp;性能调优/img-20240317_214119.png" src="\04、数据库\02、redis\assets\11、redis-最佳实践&amp;性能调优\img-20240317_214119.png" style="width: 775px; max-width: 100%;"><br><br>Redis 提供了很多  这样的，可以实现批量插入数据，例如：<br>
<br>Mset
<br>Hmset<br>
利用 mset 批量插入 10 万条数据
<br>@Test
void testMxx() {
    String[] arr = new String[2000];
    int j;
    long b = System.currentTimeMillis();
    for (int i = 1; i &lt;= 100000; i++) {
        j = (i % 1000) &lt;&lt; 1;
        arr[j] = "test:key_" + i;
        arr[j + 1] = "value_" + i;
        if (j == 0) {
            jedis.mset(arr);
        }
    }
    long e = System.currentTimeMillis();
    System.out.println("time: " + (e - b));
}
复制<br><br>MSET 虽然可以批处理，但是却只能操作部分数据类型，因此如果有对复杂数据类型的批处理需要，建议使用 Pipeline<br>@Test
void testPipeline() {
    // 创建管道
    Pipeline pipeline = jedis.pipelined();
    long b = System.currentTimeMillis();
    for (int i = 1; i &lt;= 100000; i++) {
        // 放入命令到管道
        pipeline.set("test:key_" + i, "value_" + i);
        if (i % 1000 == 0) {
            // 每放入1000条命令，批量执行
            pipeline.sync();
        }
    }
    long e = System.currentTimeMillis();
    System.out.println("time: " + (e - b));
}
复制<br><br>如 MSET 或 Pipeline 这样的批处理需要在一次请求中携带多条命令，而此时如果 Redis 是一个集群，那批处理命令的多个 key 必须落在一个插槽中，否则就会导致执行失败。大家可以想一想这样的要求其实很难实现，因为我们在批处理时，可能一次要插入很多条数据，这些数据很有可能不会都落在相同的节点上，这就会导致报错了。<br><img src="\04、数据库\02、redis\assets\11、redis-最佳实践&amp;性能调优\img-20240318_210458.png"><br>第一种方案：串行执行，所以这种方式没有什么意义，当然，执行起来就很简单了，缺点就是耗时过久。<br>第二种方案：串行 slot，简单来说，就是执行前，客户端先计算一下对应的 key 的 slot ，一样 slot 的 key 就放到一个组里边，不同的，就放到不同的组里边，然后对每个组执行 pipeline 的批处理，他就能串行执行各个组的命令，这种做法比第一种方法耗时要少，但是缺点呢，相对来说复杂一点，所以这种方案还需要优化一下<br>第三种方案：并行 slot，相较于第二种方案，在分组完成后串行执行，第三种方案，就变成了并行执行各个命令，所以他的耗时就非常短，但是实现呢，也更加复杂。<br>第四种：hash_tag，redis 计算 key 的 slot 的时候，其实是根据 key 的有效部分来计算的，通过这种方式就能一次处理所有的 key，这种方式耗时最短，实现也简单，但是如果通过操作 key 的有效部分，那么就会导致所有的 key 都落在一个节点上，产生数据倾斜的问题，所以我们推荐使用第三种方式。<br>串行化代码实现<br>public class JedisClusterTest {

    private JedisCluster jedisCluster;

    @BeforeEach
    void setUp() {
        // 配置连接池
        JedisPoolConfig poolConfig = new JedisPoolConfig();
        poolConfig.setMaxTotal(8);
        poolConfig.setMaxIdle(8);
        poolConfig.setMinIdle(0);
        poolConfig.setMaxWaitMillis(1000);
        HashSet&lt;HostAndPort&gt; nodes = new HashSet&lt;&gt;();
        nodes.add(new HostAndPort("192.168.150.101", 7001));
        nodes.add(new HostAndPort("192.168.150.101", 7002));
        nodes.add(new HostAndPort("192.168.150.101", 7003));
        nodes.add(new HostAndPort("192.168.150.101", 8001));
        nodes.add(new HostAndPort("192.168.150.101", 8002));
        nodes.add(new HostAndPort("192.168.150.101", 8003));
        jedisCluster = new JedisCluster(nodes, poolConfig);
    }

    @Test
    void testMSet() {
        jedisCluster.mset("name", "Jack", "age", "21", "sex", "male");

    }

    @Test
    void testMSet2() {
        Map&lt;String, String&gt; map = new HashMap&lt;&gt;(3);
        map.put("name", "Jack");
        map.put("age", "21");
        map.put("sex", "Male");
        //对Map数据进行分组。根据相同的slot放在一个分组
        //key就是slot，value就是一个组
        Map&lt;Integer, List&lt;Map.Entry&lt;String, String&gt;&gt;&gt; result = map.entrySet()
                .stream()
                .collect(Collectors.groupingBy(
                        entry -&gt; ClusterSlotHashUtil.calculateSlot(entry.getKey()))
                );
        //串行的去执行mset的逻辑
        for (List&lt;Map.Entry&lt;String, String&gt;&gt; list : result.values()) {
            String[] arr = new String[list.size() * 2];
            int j = 0;
            for (int i = 0; i &lt; list.size(); i++) {
                j = i&lt;&lt;2;
                Map.Entry&lt;String, String&gt; e = list.get(0);
                arr[j] = e.getKey();
                arr[j + 1] = e.getValue();
            }
            jedisCluster.mset(arr);
        }
    }

    @AfterEach
    void tearDown() {
        if (jedisCluster != null) {
            jedisCluster.close();
        }
    }
}
复制<br>Spring 集群环境下批处理代码<br>@Test
 void testMSetInCluster() {
     Map&lt;String, String&gt; map = new HashMap&lt;&gt;(3);
     map.put("name", "Rose");
     map.put("age", "21");
     map.put("sex", "Female");
     stringRedisTemplate.opsForValue().multiSet(map);
     List&lt;String&gt; strings = stringRedisTemplate.opsForValue().multiGet(Arrays.asList("name", "age", "sex"));
     strings.forEach(System.out::println);
 }
复制<br><br><br>Redis 的持久化虽然可以保证数据安全，但也会带来很多额外的开销。<br>因此持久化请遵循下列建议：<br><br><br><br>通过上面的分析，我们都知道RDB的快照、AOF的重写都需要fork，这是一个重量级操作，会对Redis造成阻塞。因此为了不影响Redis主进程响应，我们需要尽可能降低阻塞。<br>内存如何控制分配：<br>
<br>更好的硬件
<br>合理配置 Linux 的内存分配策略，避免因为物理内存不足导致 fork 失败
<br>控制单个 Redis 实例内存上限，如 4 G 或 8 G。可以加快 fork 的速度、减少主从同步、数据迁移压力（可以单机部署多台 redis 实例）
<br>物理机部署多个 Redis 实例，要防止同时运行持久化、重写操作，防止资源竞争，尝试让持久化变为串行；
<br>不要与 CPU 内存密集型应用（ES）、高硬盘负载（数据库、消息队列）应用一起部署。
<br>线上备份怎么做最优：<br>
<br>用来做缓存的 Redis 关闭持久化，数据不敏感或可以通过其它方式重写生成数据；
<br>脚本或程序定期触发备份、重写数据（制定策略定期检查 Redis 的情况）；
<br>主从机器，让从机器进行备份处理；
<br>4.0 以上让 RDB 与 AOF 持久化同时存在，结合使用。
<br>使用 AOF 持久化时：<br>
<br>设置合理的 rewrite 阈值，避免频繁的 bgrewrite
<br>配置 no-appendfsync-on-rewrite = yes，禁止在 rewrite 期间做 aof，避免因 AOF 引起的阻塞。简单说就是，禁止在重写期间 fsync 刷盘
<br><br>单体 Redis（主从 Redis）已经能达到万级别的 QPS，并且也具备很强的高可用特性。<br>
如果主从能满足业务需求的情况下，尽量不搭建 Redis 集群。<br>Lua 和事务都是要保证原子性问题，如果你的 key 不在一个节点，那么是无法保证 lua 的执行和事务的特性的，所以在集群模式是没有办法执行 lua 和事务的。<br><br>安全可以说是服务器端一个非常重要的话题，如果安全出现了问题，那么一旦这个漏洞被一些坏人知道了之后，并且进行攻击，那么这就会给咱们的系统带来很多的损失，所以我们这节课就来解决这个问题。<br>Redis 会绑定在 0.0.0. 0:6379，这样将会将 Redis 服务暴露到公网上，而 Redis 如果没有做身份认证，会出现严重的安全漏洞.<br>
漏洞重现方式： <a rel="noopener" class="external-link" href="https://cloud.tencent.com/developer/article/1039000" target="_blank">https://cloud.tencent.com/developer/article/1039000</a><br>为什么会出现不需要密码也能够登录呢，主要是 Redis 考虑到每次登录都比较麻烦，所以 Redis 就有一种 ssh 免秘钥登录的方式，生成一对公钥和私钥，私钥放在本地，公钥放在 redis 端，当我们登录时服务器，再登录时候，他会去解析公钥和私钥，如果没有问题，则不需要利用 redis 的登录也能访问，这种做法本身也很常见，但是这里有一个前提，前提就是公钥必须保存在服务器上，才行，但是 Redis 的漏洞在于在不登录的情况下，也能把秘钥送到 Linux 服务器，从而产生漏洞<br>漏洞出现的核心的原因有以下几点：<br>
<br>Redis 未设置密码
<br>利用了 Redis 的 config set 命令动态修改 Redis 配置
<br>使用了 Root 账号权限启动 Redis
<br>为了避免这样的漏洞，这里给出一些建议：、<br>
<br>Redis 一定要设置密码
<br>禁止线上使用下面命令：keys、flushall、flushdb、config set 等命令。可以利用 rename-command 禁用。
<br>Bind：限制网卡，禁止外网网卡访问
<br>开启防火墙
<br>不要使用 Root 账户启动 Redis
<br>尽量不使用默认的端口
<br># 将 FLUSHALL 命令重命名为空字符串,使其无法被调用
rename-command FLUSHALL ""

# 将 CONFIG 命令重命名为空字符串,防止修改配置
rename-command CONFIG ""

# 将 DEBUG 命令重命名为空字符串,防止调试级别的命令被误用
rename-command DEBUG ""

# 你也可以将其重命名为其他命令
rename-command SHUTDOWN MOCK_SHUTDOWN

rename-command FLUSHALL "" 
rename-command FLUSHDB ""
rename-command KEYS *

复制<br><br>如果有几个 slot 不能使用，那么此时整个集群都不能用了！<br>其实最重要的是可用性，所以需要把配置 Cluster-require-full-coverage  修改成 no，即有 slot 不能使用时，Redis 集群还是可以对外提供服务。<br><br>集群中节点越多，集群状态信息数据量也越大，10 个节点的相关信息可能达到 1 kb。<br>
此时每次集群互通需要的带宽会非常高，这样会导致集群中大量的带宽都会被 ping 信息所占用。<br>解决途径：<br>
<br>避免大集群，集群节点数不要太多，最好少于 1000，如果业务庞大，则建立多个集群。
<br>避免在单个物理机中运行太多 Redis 实例
<br>配置合适的 cluster-node-timeout 值
<br><br>针对 Redis 变慢的场景，本文将协助排查，并给出高效的解决方案。<br><br>发现业务服务 API 响应延迟变长，首先你需要先排查服务内部，究竟是哪个环节拖慢了整个服务。<br>在服务内部集成链路追踪，也就是在服务访问外部依赖的出入口，记录下每次请求外部依赖的响应延时。<br><img src="\04、数据库\02、redis\assets\11、redis-最佳实践&amp;性能调优\img-20240317_204104.png"><br>发现确实是操作 Redis 的这条链路耗时变长了，此刻才需要把焦点关注在业务服务到 Redis 这条链路上。<br><br>基准性能就是指 Redis 在一台负载正常的机器上，最大的响应延迟和平均响应延迟的值。<br>Redis 在不同的软硬件环境下，它的性能是各不相同的，所以不能参考其他性能。<br>
例如：我的机器配置比较低，当延迟为 2ms 时，我就认为 Redis 变慢了，但是如果你的硬件配置比较高，那么在你的运行环境下，可能延迟是 0.5ms 时就可以认为 Redis 变慢了。<br>
<br>在 Redis 服务器上测试实例的响应延迟情况：
<br>$ redis-cli -h 127.0.0.1 -p 6379 --intrinsic-latency 60
Max latency so far: 1 microseconds.
Max latency so far: 15 microseconds.
Max latency so far: 17 microseconds.
Max latency so far: 18 microseconds.
Max latency so far: 31 microseconds.
Max latency so far: 32 microseconds.
Max latency so far: 59 microseconds.
Max latency so far: 72 microseconds.
 
1428669267 total runs (avg latency: 0.0420 microseconds / 42.00 nanoseconds per run).
Worst run took 1429x longer than the average latency.
复制<br>从输出结果可以看到，这 60 秒内的最大响应延迟为 72 微秒（0.072毫秒）。<br>
<br>还可以使用以下命令，查看一段时间内 Redis 的最小、最大、平均访问延迟：
<br>$ redis-cli -h 127.0.0.1 -p 6379 --latency-history -i 1
min: 0, max: 1, avg: 0.13 (100 samples) -- 1.01 seconds range
min: 0, max: 1, avg: 0.12 (99 samples) -- 1.01 seconds range
min: 0, max: 1, avg: 0.13 (99 samples) -- 1.01 seconds range
min: 0, max: 1, avg: 0.10 (99 samples) -- 1.01 seconds range
min: 0, max: 1, avg: 0.13 (98 samples) -- 1.00 seconds range
min: 0, max: 1, avg: 0.08 (99 samples) -- 1.01 seconds range
...
复制<br>以上输出结果是，每间隔 1 秒，采样 Redis 的平均操作耗时，其结果分布在 0.08 ~ 0.13 毫秒之间。<br>了解了基准性能测试方法，那么你就可以按照以下几步，来判断你的 Redis 是否真的变慢了：<br>
<br>在相同配置的服务器上，测试一个正常 Redis 实例的基准性能
<br>找到你认为可能变慢的 Redis 实例，测试这个实例的基准性能
<br>如果你观察到，这个实例的运行延迟是正常 Redis 基准性能的 2 倍以上，即可认为这个 Redis 实例确实变慢了
<br>确认是 Redis 变慢了，那如何排查是哪里发生了问题呢？<br><br>Redis 提供了慢日志命令的统计功能，它记录了有哪些命令在执行时耗时比较久。<br>查看 Redis 慢日志之前，你需要设置慢日志的阈值。例如，设置慢日志的阈值为 5 毫秒，并且保留最近 500 条慢日志记录：<br># 命令执行耗时超过 5 毫秒，记录慢日志
CONFIG SET slowlog-log-slower-than 5000
# 只保留最近 500 条慢日志
CONFIG SET slowlog-max-len 500
复制<br>设置完成之后，所有执行的命令如果操作耗时超过了 5 毫秒，都会被 Redis 记录下来。<br>此时，你可以执行以下命令，就可以查询到最近记录的慢日志：<br>127.0.0.1:6379&gt; SLOWLOG get 5
1) 1) (integer) 32693       # 慢日志ID
   2) (integer) 1593763337  # 执行时间戳
   3) (integer) 5299        # 执行耗时(微秒)
   4) 1) "LRANGE"           # 具体执行的命令和参数
      2) "user_list:2000"
      3) "0"
      4) "-1"
2) 1) (integer) 32692
   2) (integer) 1593763337
   3) (integer) 5044
   4) 1) "GET"
      2) "user_info:1000"
...
复制<br>通过查看慢日志，我们就可以知道在什么时间点，执行了哪些命令比较耗时。<br><br><br><br>○　成因危害<br>如果你的应用程序执行的 Redis 命令有以下特点，那么有可能会导致操作延迟变大：<br>
<br>经常使用 O (N) 以上复杂度的命令，例如 SORT、SUNION、ZUNIONSTORE 聚合类命令
<br>使用 O (N) 复杂度的命令，但 N 的值非常大
<br>Redis 是单线程处理客户端请求的，如果经常使用以上命令，当 Redis 处理客户端请求时复杂命令发生耗时，就会导致后面的请求发生排队，对于客户端来说，响应延迟会变长。<br>1）Redis 在操作内存数据时，时间复杂度过高，要花费更多的 CPU 资源。<br>
2）Redis 一次需要返回给客户端的数据过多，更多时间花费在数据协议的组装和网络传输过程中。<br>○　问题排查<br>可以从资源使用率层面来分析，如果你的应用程序操作 Redis 的 OPS 不是很大，但 Redis 实例的 CPU 使用率却很高，那么很有可能是使用了复杂度过高的命令导致的。<br><img src="\04、数据库\02、redis\assets\11、redis-最佳实践&amp;性能调优\img-20240317_205043.png"><br>○　优化方案<br>
<br>尽量不使用 O(N) 以上复杂度过高的命令，对于数据的聚合操作，放在客户端做
<br>执行 O(N) 命令，保证 N 尽量的小（推荐 N &lt;= 300），每次获取尽量少的数据，让 Redis 可以及时处理返回
<br><br>○　成因危害<br>Bigkey 导致 Redis 在创建（分配内存）、删除（释放内存）时，都会很耗时。<br>1）网络阻塞<br>
对 BigKey 执行读请求时，少量的 QPS 就可能导致带宽使用率被占满，导致 Redis 实例，乃至所在物理机变慢<br>2）数据倾斜<br>
BigKey 所在的 Redis 实例内存使用率远超其他实例，无法使数据分片的内存资源达到均衡<br>3）Redis 阻塞<br>
对元素较多的 hash、list、zset 等做运算会耗时较旧，使主线程被阻塞<br>4）CPU 压力<br>
对 BigKey 的数据序列化和反序列化会导致 CPU 的使用率飙升，影响 Redis 实例和本机其它应用<br>5）其他<br>
bigkey 在分片集群模式下，对于数据的迁移也有性能影响，数据过期、数据淘汰、透明大页等都会受到 bigkey 的影响。<br>○　问题排查<br>Redis 提供了扫描 bigkey 的命令，输出结果是以类型维度展示的：<br>$ redis-cli -h 127.0.0.1 -p 6379 --bigkeys -i 0.01
 
...
-------- summary -------
 
Sampled 829675 keys in the keyspace!
Total key length in bytes is 10059825 (avg len 12.13)
 
Biggest string found 'key:291880' has 10 bytes
Biggest   list found 'mylist:004' has 40 items
Biggest    set found 'myset:2386' has 38 members
Biggest   hash found 'myhash:3574' has 37 fields
Biggest   zset found 'myzset:2704' has 42 members
 
36313 strings with 363130 bytes (04.38% of keys, avg size 10.00)
787393 lists with 896540 items (94.90% of keys, avg size 1.14)
1994 sets with 40052 members (00.24% of keys, avg size 20.09)
1990 hashs with 39632 fields (00.24% of keys, avg size 19.92)
1985 zsets with 39750 members (00.24% of keys, avg size 20.03)
复制<br>返回的结果：<br>
<br>每种数据类型所占用的最大内存 / 拥有最多元素的 key 。
<br>每种数据类型在整个实例中的占比和平均大小 / 元素数量。
<br>这个命令的原理： Redis 在内部执行了 SCAN 命令，遍历整个实例中所有的 key，针对 key 的类型，分别执行 STRLEN、LLEN、HLEN、SCARD、ZCARD 命令，来获取 String 类型的长度、容器类型（List、Hash、Set、ZSet）的元素个数。<br>执行这个命令时，要注意 2 个问题：<br>1、对线上实例进行 bigkey 扫描时，Redis 的 OPS 会突增，为了降低扫描过程中对 Redis 的影响，最好控制一下扫描的频率，指定 -i 参数即可，它表示扫描过程中每次扫描后休息的时间间隔，单位是秒<br>2、扫描结果中，对于容器类型（List、Hash、Set、ZSet）的 key，只能扫描出元素最多的 key。但一个 key 的元素多，不一定表示占用内存也多，你还需要根据业务情况，进一步评估内存占用情况<br>
建议在控制台或者业务逻辑中加入扫描逻辑，在低业务时段采用 SCAN 扫描，可以排查出更详细的信息，而非仅关键时刻的扫描。
<br>○　优化方案<br>有两点可以优化：<br>1）业务应用尽量避免写入 bigkey<br>
2）如果你使用的 Redis 是 4.0 以上版本，用 UNLINK 命令替代 DEL，此命令可以把释放 key 内存的操作，放到后台线程中去执行，从而降低对 Redis 的影响<br>
如果你使用的 Redis 是 6.0 以上版本，可以开启 lazy-free 机制（lazyfree-lazy-user-del = yes），在执行 DEL 命令时，释放内存也会放到后台线程中执行<br>即便可以使用方案 2，也不建议你在实例中存入 bigkey。因为 bigkey 在很多场景下，依旧会产生性能问题。<br><br>○　成因危害<br>平时在操作 Redis 时，并没有延迟很大的情况发生，变慢的时间点很有规律，例如某个整点，或者每间隔多久就会发生一波延迟。<br>
业务代码中是否存在设置大量 key 集中过期的情况，在这个时间点访问 Redis 时，就可能会导致延时变大。<br>Redis 的过期数据采用被动过期 + 主动过期两种策略：<br>
<br>被动过期：只有当访问某个 key 时，才判断这个 key 是否已过期，如果已过期，则从实例中删除
<br>主动过期：Redis 内部维护了一个定时任务，默认每隔 100 毫秒（1秒10次）就会从全局的过期哈希表中随机取出 20 个 key，然后删除其中过期的 key，如果过期 key 的比例超过了 25%，则继续重复此过程，直到过期 key 的比例下降到 25% 以下，或者这次任务的执行耗时超过了 25 毫秒，才会退出循环
<br>这个主动过期 key 的定时任务，是在 Redis 主线程中执行的。<br>○　问题排查<br>在执行主动过期的过程中，出现了需要大量删除过期 key 的情况，此时应用程序在访问 Redis 时，必须要等待这个过期任务执行结束，Redis 才可以服务这个客户端请求。此时就会出现，应用访问 Redis 延时变大。<br>如果此时需要过期删除的是一个 bigkey，那么这个耗时会更久。而且，这个操作延迟的命令并不会记录在慢日志中。<br>因为慢日志中只记录一个命令真正操作内存数据的耗时，而 Redis 主动删除过期 key 的逻辑，是在命令真正执行之前执行的。<br>慢日志中没有操作耗时的命令，但应用程序却感知到了延迟变大，其实时间都花费在了删除过期 key 上，这种情况我们需要尤为注意。<br>○　优化方案<br>
<br>集中过期 key 增加一个随机过期时间，把集中过期的时间打散，降低 Redis 清理过期 key 的压力
<br>如果你使用的 Redis 是 4.0 以上版本，可以开启 lazy-free 机制，当删除过期 key 时，把释放内存的操作放到后台线程中执行，避免阻塞主线程
<br>1）代码调整<br>需要检查你的业务代码，是否存在集中过期 key 的逻辑。<br>一般集中过期使用的是 expireat / pexpireat 命令，你需要在代码中搜索这个关键字。<br>排查代码后，如果确实存在集中过期 key 的逻辑存在，但这种逻辑又是业务所必须的，那此时如何优化，同时又不对 Redis 有性能影响呢？<br>在设置 key 的过期时间时，增加一个随机时间，伪代码可以这么写：<br># 在过期时间点之后的 5 分钟内随机过期掉
redis.expireat(key, expire_time + random(300))
复制<br>这样一来，Redis 在处理过期时，不会因为集中删除过多的 key 导致压力过大，从而避免阻塞主线程。<br>2）修改配置<br>第二种方案，Redis 4.0 以上版本，开启 lazy-free 机制：<br># 释放过期 key 的内存，放到后台线程执行
lazyfree-lazy-expire yes
复制<br>3）增强监控<br>运维层面，需要把 Redis 的各项运行状态数据监控起来，在 Redis 上执行 INFO 命令就可以拿到这个实例所有的运行状态数据。<br>这里重点关注 expired_keys 这一项，它代表整个实例到目前为止，累计删除过期 key 的数量。<br>当这个指标在很短时间内出现了突增，需要及时报警出来，然后与业务应用报慢的时间点进行对比分析，确认时间是否一致，如果一致，则可以确认确实是因为集中过期 key 导致的延迟变大。<br><br>业务应用，应使用长连接操作 Redis，避免频繁的短连接。<br>频繁的短连接会导致 Redis 大量时间耗费在连接的建立和释放上，TCP 的三次握手和四次挥手同样也会增加访问延迟。<br><br><br>○　成因危害<br>
为了保证 Redis 数据的安全性，我们可能会开启后台定时 RDB 和 AOF rewrite 功能。但如果你发现，操作 Redis 延迟变大，<br>
都发生在 Redis 后台 RDB 和 AOF rewrite 期间，那你就需要排查，在这期间有可能导致变慢的情况。
<br>当 Redis 开启了后台 RDB 和 AOF rewrite 后，在执行时，它们都需要主进程创建出一个子进程进行数据的持久化。<br>主进程创建子进程，会调用操作系统提供的 fork 函数。<br>而 fork 在执行过程中，主进程需要拷贝自己的内存页表给子进程，如果这个实例很大，那么这个拷贝的过程也会比较耗时。<br>而且这个 fork 过程会消耗大量的 CPU 资源，在完成 fork 之前，整个 Redis 实例会被阻塞住，无法处理任何客户端请求。<br>如果此时你的 CPU 资源本来就很紧张，那么 fork 的耗时会更长，甚至达到秒级，这会严重影响 Redis 的性能。<br>○　问题排查<br>可以在 Redis 上执行 INFO 命令，查看 latest_fork_usec 项，单位微秒。<br># 上一次 fork 耗时，单位微秒
latest_fork_usec:59477
复制<br>这个时间就是主进程在 fork 子进程期间，整个实例阻塞无法处理客户端请求的时间。<br>如果你发现这个耗时很久，就要警惕起来了，这意味在这期间，你的整个 Redis 实例都处于不可用的状态。<br>除了数据持久化会生成 RDB 之外，当主从节点第一次建立数据同步时，主节点也创建子进程生成 RDB，然后发给从节点进行一次全量同步，所以，这个过程也会对 Redis 产生性能影响。<br><img src="\04、数据库\02、redis\assets\11、redis-最佳实践&amp;性能调优\img-20240318_213949.png"><br>○　优化方案<br>优化：<br>
<br>控制 Redis 实例的内存：尽量在 10 G 以下，执行 fork 的耗时与实例大小有关，实例越大，耗时越久
<br>合理配置数据持久化策略：在 slave 节点执行 RDB 备份，推荐在低峰期执行，而对于丢失数据不敏感的业务（例如把 Redis 当做纯缓存使用），可以关闭 AOF 和 AOF rewrite
<br>Redis 实例不要部署在虚拟机上：fork 的耗时也与系统也有关，虚拟机比物理机耗时更久
<br>降低主从库全量同步的概率：适当调大 repl-backlog-size 参数，避免主从全量同步
<br><br>其实，关于数据持久化方面，还有影响 Redis 性能的因素，这次我们重点来看 AOF 数据持久化。<br>如果你的 AOF 配置不合理，还是有可能会导致性能问题。<br>当 Redis 开启 AOF 后，其工作原理如下：<br>
<br>Redis 执行写命令后，把这个命令写入到 AOF 文件内存中（write 系统调用）
<br>Redis 根据配置的 AOF 刷盘策略，把 AOF 内存数据刷到磁盘上（fsync 系统调用）
<br>为了保证 AOF 文件数据的安全性，Redis 提供了 3 种刷盘机制：<br>
<br>Appendfsync always：
<br>Appendfsync no：
<br>Appendfsync everysec：主线程每次写操作只写内存就返回，然后由后台线程每隔 1 秒执行一次刷盘操作（触发 fsync 系统调用），此方案对性能影响相对较小，但当 Redis 宕机时会丢失 1 秒的数据
<br>○　成因危害<br>下面我们依次来分析，这几个机制对性能的影响。<br>1）always<br>虽然数据安全性最高，但Redis 每处理一次写操作，都会把这个命令写入到磁盘中才返回，整个过程都是在主线程执行的，这个过程必然会加重 Redis 写负担。<br>2）no<br>安全性也最低，性能影响最小。<br>
如果你的 Redis 只用作纯缓存，对于数据丢失不敏感，采用配置 appendfsync no 也是可以的。
<br>3）everysec<br>这个方案优势在于，Redis 主线程写完内存后就返回，具体的刷盘操作是放到后台线程中执行的，后台线程每隔 1 秒把内存中的数据刷到磁盘中。<br>但是这种方案还是存在导致 Redis 延迟变大的情况发生，甚至会阻塞整个 Redis。<br>当 Redis 后台线程在执行 AOF 文件刷盘时，如果此时磁盘的 IO 负载很高，那这个后台线程在执行刷盘操作（fsync 系统调用）时就会被阻塞住。<br>此时的主线程依旧会接收写请求，紧接着，主线程又需要把数据写到文件内存中（write 系统调用），但此时的后台子线程由于磁盘负载过高，导致 fsync 发生阻塞，迟迟不能返回，那主线程在执行 write 系统调用时，也会被阻塞住，直到后台线程 fsync 执行完成后，主线程执行 write 才能成功返回。<br><img src="\04、数据库\02、redis\assets\11、redis-最佳实践&amp;性能调优\img-20240319_204647.png"><br>尽管配置为 appendfsync everysec，也不能掉以轻心，要警惕磁盘压力过大导致的 Redis 有性能问题。<br>
<br>子进程正在执行 AOF rewrite，这个过程会占用大量的磁盘 IO 资源（Redis 的 AOF 后台子线程刷盘操作，撞上了子进程 AOF rewrite！）
<br>有其他应用程序在执行大量的写文件操作，也会占用磁盘 IO 资源
<br>○　优化方案<br>Redis 提供了一个配置项，当子进程在 AOF rewrite 期间，可以让后台子线程不执行刷盘（不触发 fsync 系统调用）操作。<br>
这相当于在 AOF rewrite 期间，临时把 appendfsync 设置为了 none，配置如下：<br># AOF rewrite 期间，AOF 后台子线程不进行刷盘操作
# 相当于在这期间，临时把 appendfsync 设置为了 none
no-appendfsync-on-rewrite yes
复制<br>开启这个配置项，在 AOF rewrite 期间，如果实例发生宕机，那么此时会丢失更多的数据，性能和数据安全性，你需要权衡后进行选择。<br>如果占用磁盘资源的是其他应用程序，那就比较简单了，你需要定位到是哪个应用程序在大量写磁盘，然后把这个应用程序迁移到其他机器上执行就好了，避免对 Redis 产生影响。<br>当然，如果你对 Redis 的性能和数据安全都有很高的要求，那么我建议从硬件层面来优化，更换为 SSD 磁盘，提高磁盘的 IO 能力，保证 AOF 期间有充足的磁盘资源可以使用。<br><br><br>
很多时候，我们在部署服务时，为了提高服务性能，降低应用程序在多个 CPU 核心之间的上下文切换带来的性能损耗，通常采用的方案是进程绑定 CPU 的方式提高性能。
<br>但在部署 Redis 时，如果你需要绑定 CPU 来提高其性能，我建议你仔细斟酌后再做操作。<br>○　成因危害<br>一般现代的服务器会有多个 CPU，而每个 CPU 又包含多个物理核心，每个物理核心又分为多个逻辑核心，每个物理核下的逻辑核共用 L1/L2 Cache。<br>而 Redis Server 除了主线程服务客户端请求之外，还会创建子进程、子线程。<br>其中子进程用于数据持久化，而子线程用于执行一些比较耗时操作，例如异步释放 fd、异步 AOF 刷盘、异步 lazy-free 等等。<br>如果你把 Redis 进程只绑定了一个 CPU 逻辑核心上，那么当 Redis 在进行数据持久化时，fork 出的子进程会继承父进程的 CPU 使用偏好。<br>而此时的子进程会消耗大量的 CPU 资源进行数据持久化（把实例数据全部扫描出来需要耗费 CPU），这就会导致子进程会与主进程发生 CPU 争抢，进而影响到主进程服务客户端请求，访问延迟变大。<br>这就是 Redis 绑定 CPU 带来的性能问题。<br>○　优化方案<br>如果你确实想要绑定 CPU，可以优化的方案是，不要让 Redis 进程只绑定在一个 CPU 逻辑核上，而是绑定在多个逻辑核心上，而且，绑定的多个逻辑核心最好是同一个物理核心，这样它们还可以共用 L1/L2 Cache。<br>当然，即便我们把 Redis 绑定在多个逻辑核心上，也只能在一定程度上缓解主线程、子进程、后台线程在 CPU 资源上的竞争。<br>因为这些子进程、子线程还是会在这多个逻辑核心上进行切换，存在性能损耗。<br>如何再进一步优化？<br>可能你已经想到了，我们是否可以让主线程、子进程、后台线程，分别绑定在固定的 CPU 核心上，不让它们来回切换，这样一来，他们各自使用的 CPU 资源互不影响。<br>其实，这个方案 Redis 官方已经想到了。<br>Redis 在 6.0 版本已经推出了这个功能，我们可以通过以下配置，对主线程、后台线程、后台 RDB 进程、AOF rewrite 进程，绑定固定的 CPU 逻辑核心：<br># Redis Server 和 IO 线程绑定到 CPU核心 0,2,4,6
server_cpulist 0-7:2
 
# 后台子线程绑定到 CPU核心 1,3
bio_cpulist 1,3
 
# 后台 AOF rewrite 进程绑定到 CPU 核心 8,9,10,11
aof_rewrite_cpulist 8-11
 
# 后台 RDB 进程绑定到 CPU 核心 1,10,11
# bgsave_cpulist 1,10-1
复制<br>一般来说，Redis 的性能已经足够优秀，除非你对 Redis 的性能有更加严苛的要求，否则不建议你绑定 CPU。<br>绑定 CPU 需要你对计算机体系结构有非常清晰的了解，随意绑定 CPU 不仅不会提高性能，甚至有可能会带来相反的效果。<br><br>○　成因危害<br>实例内存达到上限，Redis 必须先从实例中踢出一部分数据，让整个实例的内存维持在 maxmemory 之下，然后才能把新数据写进来。<br>这个踢出旧数据的逻辑也是需要消耗时间的，而具体耗时的长短，要取决于你配置的淘汰策略：<br>
<br>allkeys-lru：不管 key 是否设置了过期，淘汰最近最少访问的 key
<br>volatile-lru：只淘汰最近最少访问、并设置了过期时间的 key
<br>allkeys-random：不管 key 是否设置了过期，随机淘汰 key
<br>volatile-random：只随机淘汰设置了过期时间的 key
<br>allkeys-ttl：不管 key 是否设置了过期，淘汰即将过期的 key
<br>noeviction：不淘汰任何 key，实例内存达到 maxmeory 后，再写入新数据直接返回错误
<br>allkeys-lfu：不管 key 是否设置了过期，淘汰访问频率最低的 key（4.0+版本支持）
<br>volatile-lfu：只淘汰访问频率最低、并设置了过期时间 key（4.0+版本支持）
<br>一般最常使用的是 allkeys-lru 或  volatile-lru 淘汰策略：<br>
每次从实例中随机取出一批 key（这个数量可配置），然后淘汰一个最少访问的 key，之后把剩下的 key 暂存到一个池子中，继续随机取一批 key，并与之前池子中的 key 比较，再淘汰一个最少访问的 key。以此往复，直到实例内存降到 maxmemory 之下。<br>○　问题排查<br>Redis 的淘汰数据的逻辑与删除过期 key 的一样，也是在命令真正执行之前执行的，也就是说它也会增加我们操作 Redis 的延迟，而且，写 OPS 越高，延迟也会越明显。<br>
<img src="\04、数据库\02、redis\assets\11、redis-最佳实践&amp;性能调优\img-20240318_213604.png"><br>
如果此时 Redis 实例中还存储了 bigkey，那么在淘汰删除 bigkey 释放内存时，耗时会更久。<br>○　优化方案<br>
<br>避免存储 bigkey，降低释放内存的耗时
<br>淘汰策略改为随机淘汰，随机淘汰比 LRU 要快很多（视业务情况调整）
<br>拆分实例，把淘汰 key 的压力分摊到多个实例上
<br>如果使用的是 Redis 4.0 以上版本，开启 layz-free 机制，把淘汰 key 释放内存的操作放到后台线程中执行（配置 lazyfree-lazy-eviction = yes）
<br><br>什么是内存大页？<br>应用程序向操作系统申请内存时，是按内存页进行申请的，而常规的内存页大小是 4 KB。<br>Linux 内核从 2.6.38 开始，支持了内存大页机制，该机制允许应用程序以 2 MB 大小为单位，向操作系统申请内存。<br>应用程序每次向操作系统申请的内存单位变大了，但这也意味着申请内存的耗时变长。<br>○　成因危害<br>当 Redis 在执行后台 RDB 和 AOF rewrite 时，采用 fork 子进程的方式来处理。但主进程 fork 子进程后，此时的主进程依旧是可以接收写请求的，而进来的写请求，会采用 Copy On Write（写时复制）的方式操作内存数据。<br>也就是说，主进程一旦有数据需要修改，Redis 并不会直接修改现有内存中的数据，而是先将这块内存数据拷贝出来，再修改这块新内存的数据，这就是所谓的「写时复制」。<br>写时复制你也可以理解成，谁需要发生写操作，谁就需要先拷贝，再修改。<br>这样做的好处是，父进程有任何写操作，并不会影响子进程的数据持久化（子进程只持久化 fork 这一瞬间整个实例中的所有数据即可，不关心新的数据变更，因为子进程只需要一份内存快照，然后持久化到磁盘上）。<br>但是请注意，主进程在拷贝内存数据时，这个阶段就涉及到新内存的申请，如果此时操作系统开启了内存大页，那么在此期间，客户端即便只修改 10 B 的数据，Redis 在申请内存时也会以 2 MB 为单位向操作系统申请，申请内存的耗时变长，进而导致每个写请求的延迟增加，影响到 Redis 性能。<br>同样地，如果这个写请求操作的是一个 bigkey，那主进程在拷贝这个 bigkey 内存块时，一次申请的内存会更大，时间也会更久。可见，bigkey 在这里又一次影响到了性能。<br><img src="\04、数据库\02、redis\assets\11、redis-最佳实践&amp;性能调优\img-20240319_205517.png"><br>○　优化方案<br>关闭内存大页机制。<br>首先，你需要查看 Redis 机器是否开启了内存大页：<br>$ cat /sys/kernel/mm/transparent_hugepage/enabled
[always] madvise never
复制<br>如果输出选项是 always，就表示目前开启了内存大页机制，我们需要关掉它：<br>$ echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled
复制<br>其实，操作系统提供的内存大页机制，其优势是，可以在一定程序上降低应用程序申请内存的次数。<br>但是对于 Redis 这种对性能和延迟极其敏感的数据库来说，希望 Redis 在每次申请内存时，耗时尽量短，所以不建议你在 Redis 机器上开启这个机制。<br><br>如果你发现 Redis 突然变得非常慢，每次的操作耗时都达到了几百毫秒甚至秒级，那此时你就需要检查 Redis 是否使用到了 Swap，在这种情况下 Redis 基本上已经无法提供高性能的服务了。<br>什么是 Swap？<br>操作系统为了缓解内存不足对应用程序的影响，允许把一部分内存中的数据换到磁盘上，以达到应用程序对内存使用的缓冲，这些内存数据被换到磁盘上的区域，就是 Swap。<br>○　成因危害<br>当内存中的数据被换到磁盘上后，Redis 再访问这些数据时，就需要从磁盘上读取，访问磁盘的速度要比访问内存慢几百倍！<br>尤其是针对 Redis 这种对性能要求极高、性能极其敏感的数据库来说，这个操作延时是无法接受的。<br>○　问题排查<br>可以通过以下方式来查看 Redis 进程是否使用到了 Swap：<br># 先找到 Redis 的进程 ID
$ ps -aux | grep redis-server
 
# 查看 Redis Swap 使用情况
$ cat /proc/$pid/smaps | egrep '^(Swap|Size)'
复制<br>输出结果如下：<br>Size:               1256 kB
Swap:                  0 kB
Size:                  4 kB
Swap:                  0 kB
Size:                132 kB
Swap:                  0 kB
Size:              63488 kB
Swap:                  0 kB
Size:                132 kB
Swap:                  0 kB
Size:              65404 kB
Swap:                  0 kB
Size:            1921024 kB
Swap:                  0 kB
...
复制<br>这个结果会列出 Redis 进程的内存使用情况。<br>每一行 Size 表示 Redis 所用的一块内存大小，Size 下面的 Swap 就表示这块 Size 大小的内存，有多少数据已经被换到磁盘上了，如果这两个值相等，说明这块内存的数据都已经完全被换到磁盘上了。<br>如果只是少量数据被换到磁盘上，例如每一块 Swap 占对应 Size 的比例很小，那影响并不是很大。如果是几百兆甚至上 GB 的内存被换到了磁盘上，那么你就需要警惕了，这种情况 Redis 的性能肯定会急剧下降。<br>○　优化方案<br>
<br>增加机器的内存，让 Redis 有足够的内存可以使用
<br>整理内存空间，释放出足够的内存供 Redis 使用，然后释放 Redis 的 Swap，让 Redis 重新使用内存
<br>释放 Redis 的 Swap 过程通常要重启实例，为了避免重启实例对业务的影响，一般会先进行主从切换，然后释放旧主节点的 Swap，重启旧主节点实例，待从库数据同步完成后，再进行主从切换即可。<br>可见，当 Redis 使用到 Swap 后，此时的 Redis 性能基本已达不到高性能的要求（你可以理解为武功被废），所以你也需要提前预防这种情况。<br>预防的办法就是，你需要对 Redis 机器的内存和 Swap 使用情况进行监控，在内存不足或使用到 Swap 时报警出来，及时处理。<br><br>
○　成因危害
<br> Redis 的数据都存储在内存中，当我们的应用程序频繁修改 Redis 中的数据时，会导致 Redis 产生内存碎片，内存碎片会降低 Redis 的内存使用率<br>○　问题排查<br>可以通过执行 INFO 命令，得到这个实例的内存碎片率：<br># Memory
used_memory:5709194824
used_memory_human:5.32G
used_memory_rss:8264855552
used_memory_rss_human:7.70G
...
mem_fragmentation_ratio:1.45
复制<br>这个内存碎片率是怎么计算的？<br>很简单，mem_fragmentation_ratio = used_memory_rss / used_memory。<br>其中 used_memory 表示 Redis 存储数据的内存大小，而 used_memory_rss 表示操作系统实际分配给 Redis 进程的大小。<br>如果 mem_fragmentation_ratio &gt; 1.5，说明内存碎片率已经超过了 50%，这时我们就需要采取一些措施来降低内存碎片了。<br>○　优化方案<br>
<br>如果你使用的是 Redis 4.0 以下版本，只能通过重启实例来解决
<br>如果你使用的是 Redis 4.0 版本，它正好提供了自动碎片整理的功能，可以通过配置开启碎片自动整理
<br>但开启内存碎片整理，它也有可能会导致 Redis 性能下降。<br>
原因在于，Redis 的碎片整理工作是也在主线程中执行的，当其进行碎片整理时，必然会消耗 CPU 资源，产生更多的耗时，从而影响到客户端的请求。<br>Redis 碎片整理的参数配置如下：<br># 开启自动内存碎片整理（总开关）
activedefrag yes
 
# 内存使用 100MB 以下，不进行碎片整理
active-defrag-ignore-bytes 100mb
 
# 内存碎片率超过 10%，开始碎片整理
active-defrag-threshold-lower 10
# 内存碎片率超过 100%，尽最大努力碎片整理
active-defrag-threshold-upper 100
 
# 内存碎片整理占用 CPU 资源最小百分比
active-defrag-cycle-min 1
# 内存碎片整理占用 CPU 资源最大百分比
active-defrag-cycle-max 25
 
# 碎片整理期间，对于 List/Set/Hash/ZSet 类型元素一次 Scan 的数量
active-defrag-max-scan-fields 1000
复制<br>需要结合 Redis 机器的负载情况，以及应用程序可接受的延迟范围进行评估，合理调整碎片整理的参数，尽可能降低碎片整理期间对 Redis 的影响。<br><br><br>
如果以上产生性能问题的场景，你都规避掉了，而且 Redis 也稳定运行了很长时间，但在某个时间点之后开始，操作 Redis 突然开始变慢了，而且一直持续下去，这种情况又是什么原因导致？
<br>此时你需要排查一下 Redis 机器的网络带宽是否过载，是否存在某个实例把整个机器的网路带宽占满的情况。<br>网络带宽过载的情况下，服务器在 TCP 层和网络层就会出现数据包发送延迟、丢包等情况。<br>Redis 的高性能，除了操作内存之外，就在于网络 IO 了，如果网络 IO 存在瓶颈，那么也会严重影响 Redis 的性能。<br>如果确实出现这种情况，你需要及时确认占满网络带宽 Redis 实例，如果属于正常的业务访问，那就需要及时扩容或迁移实例了，避免因为这个实例流量过大，影响这个机器的其他实例。<br><br>最后需要提醒你的是，你的 Redis 机器最好专项专用，只用来部署 Redis 实例，不要部署其他应用程序，尽量给 Redis 提供一个相对「安静」的环境，避免其它程序占用 CPU、内存、磁盘资源，导致分配给 Redis 的资源不足而受到影响。<br><br>想提前预知 Redis 变慢的情况发生，必不可少的就是做好完善的监控。<br>监控其实就是对采集 Redis 的各项运行时指标，通常的做法是监控程序定时采集 Redis 的 INFO 信息，然后根据 INFO 信息中的状态数据做数据展示和报警。<br>这里我需要提醒你的是，在写一些监控脚本，或使用开源的监控组件时，也不能掉以轻心。<br>在写监控脚本访问 Redis 时，尽量采用长连接的方式采集状态信息，避免频繁短连接。同时，你还要注意控制访问 Redis 的频率，避免影响到业务请求。<br>在使用一些开源的监控组件时，最好了解一下这些组件的实现原理，以及正确配置这些组件，防止出现监控组件发生 Bug，导致短时大量操作 Redis，影响 Redis 性能的情况发生。<br>我们当时就发生过，DBA 在使用一些开源组件时，因为配置和使用问题，导致监控程序频繁地与 Redis 建立和断开连接，导致 Redis 响应变慢。<br><br>Redis 的性能问题，涉及到的知识点非常广，几乎涵盖了 CPU、内存、网络、甚至磁盘，同时还需要了解计算机的体系结构，以及操作系统的各种机制。<br>从使用角度来看：<br>
<br>业务使用
<br>持久化配置（磁盘）
<br>CPU、内存
<br>其他
<br>从资源使用角度来看，包含的知识点如下：<br>
<br>
CPU 相关：使用复杂度过高命令、数据的持久化，都与耗费过多的 CPU 资源有关

<br>
内存相关：bigkey 内存的申请和释放、数据过期、数据淘汰、碎片整理、内存大页、内存写时复制都与内存息息相关

<br>
磁盘相关：数据持久化、AOF 刷盘策略，也会受到磁盘的影响

<br>
网络相关：短连接、实例流量过载、网络流量过载，也会降低 Redis 性能

<br>
计算机系统：CPU 结构、内存分配，都属于最基础的计算机系统知识

<br>
操作系统：写时复制、内存大页、Swap、CPU 绑定，都属于操作系统层面的知识

<br>
CPU 相关：使用复杂度过高命令、数据的持久化，都与耗费过多的 CPU 资源有关

<br>
内存相关：bigkey 内存的申请和释放、数据过期、数据淘汰、碎片整理、内存大页、内存写时复制都与内存息息相关

<br>
磁盘相关：数据持久化、AOF 刷盘策略，也会受到磁盘的影响

<br>
网络相关：短连接、实例流量过载、网络流量过载，也会降低 Redis 性能

<br>
计算机系统：CPU 结构、内存分配，都属于最基础的计算机系统知识

<br>
操作系统：写时复制、内存大页、Swap、CPU 绑定，都属于操作系统层面的知识

]]></description><link>04、数据库\02、redis\11、redis-最佳实践&amp;性能调优.html</link><guid isPermaLink="false">04、数据库/02、Redis/11、Redis 最佳实践&amp;性能调优.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Sun, 07 Apr 2024 14:04:08 GMT</pubDate><enclosure url="04、数据库\02、redis\assets\11、redis-最佳实践&amp;性能调优\img-20240317_212716.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;04、数据库\02、redis\assets\11、redis-最佳实践&amp;性能调优\img-20240317_212716.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[12、底层原理：数据结构]]></title><description><![CDATA[ 
 <br><br>在对对象机制（redisObject）有了初步认识之后，我们便可以继续理解如下的底层数据结构部分：<br>“/images/db/redis/db-redis-object-2-3.png” could not be found.<br>
<br>简单动态字符串 - sds
<br>压缩列表 - ZipList
<br>快表 - QuickList
<br>字典/哈希表 - Dict
<br>整数集 - IntSet
<br>跳表 - ZSkipList
<br><br>
Redis 是用 C 语言写的，但是对于Redis的字符串，却不是 C 语言中的字符串（即以空字符’\0’结尾的字符数组），它是自己构建了一种名为 简单动态字符串（simple dynamic string,SDS）的抽象类型，并将 SDS 作为 Redis的默认字符串表示。
<br><br>
这是一种用于存储二进制数据的一种结构, 具有动态扩容的特点. 其实现位于src/sds.h与src/sds.c中。
<br>
<br>SDS的总体概览如下图:
<br>“/images/db/redis/db-redis-ds-x-3.png” could not be found.<br>其中sdshdr是头部, buf是真实存储用户数据的地方. 另外注意, 从命名上能看出来, 这个数据结构除了能存储二进制数据, 显然是用于设计作为字符串使用的, 所以在buf中, 用户数据后总跟着一个\0. 即图中 "数据" + "\0" 是为所谓的buf。<br>
<br>如下是6.0源码中sds相关的结构：
<br>“/images/db/redis/db-redis-ds-x-1.png” could not be found.<br>通过上图我们可以看到，SDS有五种不同的头部. 其中sdshdr5实际并未使用到. 所以实际上有四种不同的头部, 分别如下:<br>“/images/db/redis/db-redis-ds-x-2.png” could not be found.<br>其中：<br>
<br>len 保存了SDS保存字符串的长度
<br>buf[] 数组用来保存字符串的每个元素
<br>alloc分别以uint8, uint16, uint32, uint64表示整个SDS, 除过头部与末尾的\0, 剩余的字节数.
<br>flags 始终为一字节, 以低三位标示着头部的类型, 高5位未使用.
<br><br>
为什么不使用C语言字符串实现，而是使用 SDS呢？这样实现有什么好处？
<br>
<br>常数复杂度获取字符串长度
<br>由于 len 属性的存在，我们获取 SDS 字符串的长度只需要读取 len 属性，时间复杂度为 O(1)。而对于 C 语言，获取字符串的长度通常是经过遍历计数来实现的，时间复杂度为 O(n)。通过 strlen key 命令可以获取 key 的字符串长度。<br>
<br>杜绝缓冲区溢出
<br>我们知道在 C 语言中使用 strcat 函数来进行两个字符串的拼接，一旦没有分配足够长度的内存空间，就会造成缓冲区溢出。而对于 SDS 数据类型，在进行字符修改的时候，会首先根据记录的 len 属性检查内存空间是否满足需求，如果不满足，会进行相应的空间扩展，然后在进行修改操作，所以不会出现缓冲区溢出。<br>
<br>减少修改字符串的内存重新分配次数
<br>C语言由于不记录字符串的长度，所以如果要修改字符串，必须要重新分配内存（先释放再申请），因为如果没有重新分配，字符串长度增大时会造成内存缓冲区溢出，字符串长度减小时会造成内存泄露。<br>而对于SDS，由于len属性和alloc属性的存在，对于修改字符串SDS实现了空间预分配和惰性空间释放两种策略：<br>1、空间预分配：对字符串进行空间扩展的时候，扩展的内存比实际需要的多，这样可以减少连续执行字符串增长操作所需的内存重分配次数。<br>2、惰性空间释放：对字符串进行缩短操作时，程序不立即使用内存重新分配来回收缩短后多余的字节，而是使用 alloc 属性将这些字节的数量记录下来，等待后续使用。（当然SDS也提供了相应的API，当我们有需要时，也可以手动释放这些未使用的空间。）<br>
<br>二进制安全
<br>因为C字符串以空字符作为字符串结束的标识，而对于一些二进制文件（如图片等），内容可能包括空字符串，因此C字符串无法正确存取；而所有 SDS 的API 都是以处理二进制的方式来处理 buf 里面的元素，并且 SDS 不是以空字符串来判断是否结束，而是以 len 属性表示的长度来判断字符串是否结束。<br>
<br>兼容部分 C 字符串函数
<br>虽然 SDS 是二进制安全的，但是一样遵从每个字符串都是以空字符串结尾的惯例，这样可以重用 C 语言库&lt;string.h&gt; 中的一部分函数。<br><br>当执行追加操作时，比如现在给key=‘Hello World’的字符串后追加‘ again!’则这时的len=18，free由0变成了18，此时的buf='Hello World again!\0....................'(.表示空格)，也就是buf的内存空间是18+18+1=37个字节，其中‘\0’占1个字节redis给字符串多分配了18个字节的预分配空间，所以下次还有append追加的时候，如果预分配空间足够，就无须在进行空间分配了。在当前版本中，当新字符串的长度小于1M时，redis会分配他们所需大小一倍的空间，当大于1M的时候，就为他们额外多分配1M的空间。<br>思考：这种分配策略会浪费内存资源吗？<br>答：执行过APPEND 命令的字符串会带有额外的预分配空间，这些预分配空间不会被释放，除非该字符串所对应的键被删除，或者等到关闭Redis 之后，再次启动时重新载入的字符串对象将不会有预分配空间。因为执行APPEND 命令的字符串键数量通常并不多，占用内存的体积通常也不大，所以这一般并不算什么问题。另一方面，如果执行APPEND 操作的键很多，而字符串的体积又很大的话，那可能就需要修改Redis 服务器，让它定时释放一些字符串键的预分配空间，从而更有效地使用内存。<br><br>redis的字符串表示为sds，而不是C字符串（以\0结尾的char*）， 它是Redis 底层所使用的字符串表示，它被用在几乎所有的Redis 模块中。可以看如下对比：<br>“/images/db/redis/redis-ds-2.png” could not be found.<br>一般来说，SDS 除了保存数据库中的字符串值以外，SDS 还可以作为缓冲区（buffer）：包括 AOF 模块中的AOF缓冲区以及客户端状态中的输入缓冲区。<br><br>
ziplist是为了提高存储效率而设计的一种特殊编码的双向链表。它可以存储字符串或者整数，存储整数时是采用整数的二进制而不是字符串形式存储。它能在O(1)的时间复杂度下完成list两端的push和pop操作。但是因为每次操作都需要重新分配ziplist的内存，所以实际复杂度和ziplist的内存使用量相关。
<br><br>先看下6.0中对应的源码和介绍<br>“/images/db/redis/db-redis-ds-x-5.png” could not be found.<br>整个ziplist在内存中的存储格式如下：<br>“/images/db/redis/db-redis-ds-x-6.png” could not be found.<br>
<br>zlbytes字段的类型是uint32_t, 这个字段中存储的是整个ziplist所占用的内存的字节数
<br>zltail字段的类型是uint32_t, 它指的是ziplist中最后一个entry的偏移量. 用于快速定位最后一个entry, 以快速完成pop等操作
<br>zllen字段的类型是uint16_t, 它指的是整个ziplit中entry的数量. 这个值只占2bytes（16位）: 如果ziplist中entry的数目小于65535(2的16次方), 那么该字段中存储的就是实际entry的值. 若等于或超过65535, 那么该字段的值固定为65535, 但实际数量需要一个个entry的去遍历所有entry才能得到.
<br>zlend是一个终止字节, 其值为全F, 即0xff. ziplist保证任何情况下, 一个entry的首字节都不会是255
<br><br>那么entry是什么结构呢？<br>
<br>先看下源码中相关介绍
<br>“/images/db/redis/db-redis-ds-x-7.png” could not be found.<br>第一种情况：一般结构 &lt;prevlen&gt; &lt;encoding&gt; &lt;entry-data&gt;<br>prevlen：前一个entry的大小，编码方式见下文；<br>encoding：不同的情况下值不同，用于表示当前entry的类型和长度；<br>entry-data：真是用于存储entry表示的数据；<br>第二种情况：在entry中存储的是int类型时，encoding和entry-data会合并在encoding中表示，此时没有entry-data字段；<br>redis中，在存储数据时，会先尝试将string转换成int存储，节省空间；<br>此时entry结构：&lt;prevlen&gt; &lt;encoding&gt;<br>
<br>prevlen编码
<br>当前一个元素长度小于254（255用于zlend）的时候，prevlen长度为1个字节，值即为前一个entry的长度，如果长度大于等于254的时候，prevlen用5个字节表示，第一字节设置为254，后面4个字节存储一个小端的无符号整型，表示前一个entry的长度；<br>&lt;prevlen from 0 to 253&gt; &lt;encoding&gt; &lt;entry&gt;      //长度小于254结构
0xFE &lt;4 bytes unsigned little endian prevlen&gt; &lt;encoding&gt; &lt;entry&gt;   //长度大于等于254
复制<br>
<br>encoding编码
<br>encoding的长度和值根据保存的是int还是string，还有数据的长度而定；<br>前两位用来表示类型，当为“11”时，表示entry存储的是int类型，其它表示存储的是string；<br>存储string时：<br>|00pppppp| ：此时encoding长度为1个字节，该字节的后六位表示entry中存储的string长度，因为是6位，所以entry中存储的string长度不能超过63；<br>|01pppppp|qqqqqqqq| 此时encoding长度为两个字节；此时encoding的后14位用来存储string长度，长度不能超过16383；<br>|10000000|qqqqqqqq|rrrrrrrr|ssssssss|ttttttt| 此时encoding长度为5个字节，后面的4个字节用来表示encoding中存储的字符串长度，长度不能超过2^32 - 1;<br>存储int时：<br>|11000000| encoding为3个字节，后2个字节表示一个int16；<br>|11010000| encoding为5个字节，后4个字节表示一个int32;<br>|11100000| encoding 为9个字节，后8字节表示一个int64;<br>|11110000| encoding为4个字节，后3个字节表示一个有符号整型；<br>|11111110| encoding为2字节，后1个字节表示一个有符号整型；<br>|1111xxxx| encoding长度就只有1个字节，xxxx表示一个0 - 12的整数值；<br>|11111111| 还记得zlend么？<br>
<br>源码中数据结构支撑
<br>你可以看到为了操作上的简易实际还增加了几个属性<br>/* We use this function to receive information about a ziplist entry.
 * Note that this is not how the data is actually encoded, is just what we
 * get filled by a function in order to operate more easily. */
typedef struct zlentry {
    unsigned int prevrawlensize; /* Bytes used to encode the previous entry len*/
    unsigned int prevrawlen;     /* Previous entry len. */
    unsigned int lensize;        /* Bytes used to encode this entry type/len.
                                    For example strings have a 1, 2 or 5 bytes
                                    header. Integers always use a single byte.*/
    unsigned int len;            /* Bytes used to represent the actual entry.
                                    For strings this is just the string length
                                    while for integers it is 1, 2, 3, 4, 8 or
                                    0 (for 4 bit immediate) depending on the
                                    number range. */
    unsigned int headersize;     /* prevrawlensize + lensize. */
    unsigned char encoding;      /* Set to ZIP_STR_* or ZIP_INT_* depending on
                                    the entry encoding. However for 4 bits
                                    immediate integers this can assume a range
                                    of values and must be range-checked. */
    unsigned char *p;            /* Pointer to the very start of the entry, that
                                    is, this points to prev-entry-len field. */
} zlentry;
复制<br>
<br>prevrawlensize表示 previous_entry_length字段的长度
<br>prevrawlen表示 previous_entry_length字段存储的内容
<br>lensize表示 encoding字段的长度
<br>len表示数据内容长度
<br>headersize 表示当前元素的首部长度，即previous_entry_length字段长度与encoding字段长度之和
<br>encoding表示数据类型
<br>p表示当前元素首地址
<br><br>
所以只有理解上面的Entry结构，我们才会真正理解ZipList为什么是特别节省内存的数据结构。@pdai
<br>
<br>ziplist节省内存是相对于普通的list来说的，如果是普通的数组，那么它每个元素占用的内存是一样的且取决于最大的那个元素（很明显它是需要预留空间的）；
<br>所以ziplist在设计时就很容易想到要尽量让每个元素按照实际的内容大小存储，所以增加encoding字段，针对不同的encoding来细化存储大小；
<br>这时候还需要解决的一个问题是遍历元素时如何定位下一个元素呢？在普通数组中每个元素定长，所以不需要考虑这个问题；但是ziplist中每个data占据的内存不一样，所以为了解决遍历，需要增加记录上一个元素的length，所以增加了prelen字段。
<br>为什么我们去研究ziplist特别节省内存的数据结构？ 在实际应用中，大量存储字符串的优化是需要你对底层的数据结构有一定的理解的，而ziplist在场景优化的时候也被考虑采用的首选。<br><br>最后我们再看看它的一些缺点：<br>
<br>ziplist也不预留内存空间, 并且在移除结点后, 也是立即缩容, 这代表每次写操作都会进行内存分配操作.
<br>结点如果扩容, 导致结点占用的内存增长, 并且超过254字节的话, 可能会导致链式反应: 其后一个结点的entry.prevlen需要从一字节扩容至五字节. 最坏情况下, 第一个结点的扩容, 会导致整个ziplist表中的后续所有结点的entry.prevlen字段扩容. 虽然这个内存重分配的操作依然只会发生一次, 但代码中的时间复杂度是o(N)级别, 因为链式扩容只能一步一步的计算. 但这种情况的概率十分的小, 一般情况下链式扩容能连锁反映五六次就很不幸了. 之所以说这是一个蛋疼问题, 是因为, 这样的坏场景下, 其实时间复杂度并不高: 依次计算每个entry新的空间占用, 也就是o(N), 总体占用计算出来后, 只执行一次内存重分配, 与对应的memmove操作, 就可以了.
<br><br>
quicklist这个结构是Redis在3.2版本后新加的, 之前的版本是list(即linkedlist)， 用于String数据类型中。
<br>它是一种以ziplist为结点的双端链表结构. 宏观上, quicklist是一个链表, 微观上, 链表中的每个结点都是一个ziplist。<br><br>
<br>如下是6.0源码中quicklist相关的结构：
<br>/* Node, quicklist, and Iterator are the only data structures used currently. */

/* quicklistNode is a 32 byte struct describing a ziplist for a quicklist.
 * We use bit fields keep the quicklistNode at 32 bytes.
 * count: 16 bits, max 65536 (max zl bytes is 65k, so max count actually &lt; 32k).
 * encoding: 2 bits, RAW=1, LZF=2.
 * container: 2 bits, NONE=1, ZIPLIST=2.
 * recompress: 1 bit, bool, true if node is temporarry decompressed for usage.
 * attempted_compress: 1 bit, boolean, used for verifying during testing.
 * extra: 10 bits, free for future use; pads out the remainder of 32 bits */
typedef struct quicklistNode {
    struct quicklistNode *prev;
    struct quicklistNode *next;
    unsigned char *zl;
    unsigned int sz;             /* ziplist size in bytes */
    unsigned int count : 16;     /* count of items in ziplist */
    unsigned int encoding : 2;   /* RAW==1 or LZF==2 */
    unsigned int container : 2;  /* NONE==1 or ZIPLIST==2 */
    unsigned int recompress : 1; /* was this node previous compressed? */
    unsigned int attempted_compress : 1; /* node can't compress; too small */
    unsigned int extra : 10; /* more bits to steal for future usage */
} quicklistNode;

/* quicklistLZF is a 4+N byte struct holding 'sz' followed by 'compressed'.
 * 'sz' is byte length of 'compressed' field.
 * 'compressed' is LZF data with total (compressed) length 'sz'
 * NOTE: uncompressed length is stored in quicklistNode-&gt;sz.
 * When quicklistNode-&gt;zl is compressed, node-&gt;zl points to a quicklistLZF */
typedef struct quicklistLZF {
    unsigned int sz; /* LZF size in bytes*/
    char compressed[];
} quicklistLZF;

/* Bookmarks are padded with realloc at the end of of the quicklist struct.
 * They should only be used for very big lists if thousands of nodes were the
 * excess memory usage is negligible, and there's a real need to iterate on them
 * in portions.
 * When not used, they don't add any memory overhead, but when used and then
 * deleted, some overhead remains (to avoid resonance).
 * The number of bookmarks used should be kept to minimum since it also adds
 * overhead on node deletion (searching for a bookmark to update). */
typedef struct quicklistBookmark {
    quicklistNode *node;
    char *name;
} quicklistBookmark;


/* quicklist is a 40 byte struct (on 64-bit systems) describing a quicklist.
 * 'count' is the number of total entries.
 * 'len' is the number of quicklist nodes.
 * 'compress' is: -1 if compression disabled, otherwise it's the number
 *                of quicklistNodes to leave uncompressed at ends of quicklist.
 * 'fill' is the user-requested (or default) fill factor.
 * 'bookmakrs are an optional feature that is used by realloc this struct,
 *      so that they don't consume memory when not used. */
typedef struct quicklist {
    quicklistNode *head;
    quicklistNode *tail;
    unsigned long count;        /* total count of all entries in all ziplists */
    unsigned long len;          /* number of quicklistNodes */
    int fill : QL_FILL_BITS;              /* fill factor for individual nodes */
    unsigned int compress : QL_COMP_BITS; /* depth of end nodes not to compress;0=off */
    unsigned int bookmark_count: QL_BM_BITS;
    quicklistBookmark bookmarks[];
} quicklist;

typedef struct quicklistIter {
    const quicklist *quicklist;
    quicklistNode *current;
    unsigned char *zi;
    long offset; /* offset in current ziplist */
    int direction;
} quicklistIter;

typedef struct quicklistEntry {
    const quicklist *quicklist;
    quicklistNode *node;
    unsigned char *zi;
    unsigned char *value;
    long long longval;
    unsigned int sz;
    int offset;
} quicklistEntry;
复制<br>这里定义了6个结构体:<br>
<br>quicklistNode, 宏观上, quicklist是一个链表, 这个结构描述的就是链表中的结点. 它通过zl字段持有底层的ziplist. 简单来讲, 它描述了一个ziplist实例
<br>quicklistLZF, ziplist是一段连续的内存, 用LZ4算法压缩后, 就可以包装成一个quicklistLZF结构. 是否压缩quicklist中的每个ziplist实例是一个可配置项. 若这个配置项是开启的, 那么quicklistNode.zl字段指向的就不是一个ziplist实例, 而是一个压缩后的quicklistLZF实例
<br>quicklistBookmark, 在quicklist尾部增加的一个书签，它只有在大量节点的多余内存使用量可以忽略不计的情况且确实需要分批迭代它们，才会被使用。当不使用它们时，它们不会增加任何内存开销。
<br>quicklist. 这就是一个双链表的定义. head, tail分别指向头尾指针. len代表链表中的结点. count指的是整个quicklist中的所有ziplist中的entry的数目. fill字段影响着每个链表结点中ziplist的最大占用空间, compress影响着是否要对每个ziplist以LZ4算法进行进一步压缩以更节省内存空间.
<br>quicklistIter是一个迭代器
<br>quicklistEntry是对ziplist中的entry概念的封装. quicklist作为一个封装良好的数据结构, 不希望使用者感知到其内部的实现, 所以需要把ziplist.entry的概念重新包装一下.
<br><br>quicklist的内存布局图如下所示:<br>“/images/db/redis/db-redis-ds-x-4.png” could not be found.<br><br>下面是有关quicklist的更多额外信息:<br>
<br>quicklist.fill的值影响着每个链表结点中, ziplist的长度.

<br>当数值为负数时, 代表以字节数限制单个ziplist的最大长度. 具体为:
<br>-1 不超过4kb
<br>-2 不超过 8kb
<br>-3 不超过 16kb
<br>-4 不超过 32kb
<br>-5 不超过 64kb
<br>当数值为正数时, 代表以entry数目限制单个ziplist的长度. 值即为数目. 由于该字段仅占16位, 所以以entry数目限制ziplist的容量时, 最大值为2^15个


<br>quicklist.compress的值影响着quicklistNode.zl字段指向的是原生的ziplist, 还是经过压缩包装后的quicklistLZF

<br>0 表示不压缩, zl字段直接指向ziplist
<br>1 表示quicklist的链表头尾结点不压缩, 其余结点的zl字段指向的是经过压缩后的quicklistLZF
<br>2 表示quicklist的链表头两个, 与末两个结点不压缩, 其余结点的zl字段指向的是经过压缩后的quicklistLZF
<br>以此类推, 最大值为2^16


<br>quicklistNode.encoding字段, 以指示本链表结点所持有的ziplist是否经过了压缩. 1代表未压缩, 持有的是原生的ziplist, 2代表压缩过
<br>quicklistNode.container字段指示的是每个链表结点所持有的数据类型是什么. 默认的实现是ziplist, 对应的该字段的值是2, 目前Redis没有提供其它实现. 所以实际上, 该字段的值恒为2
<br>quicklistNode.recompress字段指示的是当前结点所持有的ziplist是否经过了解压. 如果该字段为1即代表之前被解压过, 且需要在下一次操作时重新压缩.
<br>quicklist的具体实现代码篇幅很长, 这里就不贴代码片断了, 从内存布局上也能看出来, 由于每个结点持有的ziplist是有上限长度的, 所以在与操作时要考虑的分支情况比较多。<br>quicklist有自己的优点, 也有缺点, 对于使用者来说, 其使用体验类似于线性数据结构, list作为最传统的双链表, 结点通过指针持有数据, 指针字段会耗费大量内存. ziplist解决了耗费内存这个问题. 但引入了新的问题: 每次写操作整个ziplist的内存都需要重分配. quicklist在两者之间做了一个平衡. 并且使用者可以通过自定义quicklist.fill, 根据实际业务情况, 经验主义调参.<br><br>
本质上就是哈希表, 这个在很多语言中都有，对于开发人员人员来说比较熟悉，这里就简单介绍下。
<br><br>哈希表结构定义：<br>typedef struct dictht{
    //哈希表数组
    dictEntry **table;
    //哈希表大小
    unsigned long size;
    //哈希表大小掩码，用于计算索引值
    //总是等于 size-1
    unsigned long sizemask;
    //该哈希表已有节点的数量
    unsigned long used;
 
}dictht
复制<br>哈希表是由数组 table 组成，table 中每个元素都是指向 dict.h/dictEntry 结构，dictEntry 结构定义如下：<br>typedef struct dictEntry{
     //键
     void *key;
     //值
     union{
          void *val;
          uint64_tu64;
          int64_ts64;
     }v;
 
     //指向下一个哈希表节点，形成链表
     struct dictEntry *next;
}dictEntry
复制<br>key 用来保存键，val 属性用来保存值，值可以是一个指针，也可以是uint64_t整数，也可以是int64_t整数。<br>注意这里还有一个指向下一个哈希表节点的指针，我们知道哈希表最大的问题是存在哈希冲突，如何解决哈希冲突，有开放地址法和链地址法。这里采用的便是链地址法，通过next这个指针可以将多个哈希值相同的键值对连接在一起，用来解决哈希冲突。<br>“/images/db/redis/db-redis-ds-x-13.png” could not be found.<br><br>
<br>哈希算法：Redis计算哈希值和索引值方法如下：
<br>#1、使用字典设置的哈希函数，计算键 key 的哈希值
hash = dict-&gt;type-&gt;hashFunction(key);

#2、使用哈希表的sizemask属性和第一步得到的哈希值，计算索引值
index = hash &amp; dict-&gt;ht[x].sizemask;
复制<br>
<br>解决哈希冲突：这个问题上面我们介绍了，方法是链地址法。通过字典里面的 *next 指针指向下一个具有相同索引值的哈希表节点。<br>

<br>扩容和收缩：当哈希表保存的键值对太多或者太少时，就要通过 rerehash(重新散列）来对哈希表进行相应的扩展或者收缩。具体步骤：<br>

<br>1、如果执行扩展操作，会基于原哈希表创建一个大小等于 ht[0].used*2n 的哈希表（也就是每次扩展都是根据原哈希表已使用的空间扩大一倍创建另一个哈希表）。相反如果执行的是收缩操作，每次收缩是根据已使用空间缩小一倍创建一个新的哈希表。<br>2、重新利用上面的哈希算法，计算索引值，然后将键值对放到新的哈希表位置上。<br>3、所有键值对都迁徙完毕后，释放原哈希表的内存空间。<br>
<br>触发扩容的条件：
<br>1、服务器目前没有执行 BGSAVE 命令或者 BGREWRITEAOF 命令，并且负载因子大于等于1。<br>2、服务器目前正在执行 BGSAVE 命令或者 BGREWRITEAOF 命令，并且负载因子大于等于5。<br>ps：负载因子 = 哈希表已保存节点数量 / 哈希表大小。<br>
<br>渐近式 rehash
<br>什么叫渐进式 rehash？也就是说扩容和收缩操作不是一次性、集中式完成的，而是分多次、渐进式完成的。如果保存在Redis中的键值对只有几个几十个，那么 rehash 操作可以瞬间完成，但是如果键值对有几百万，几千万甚至几亿，那么要一次性的进行 rehash，势必会造成Redis一段时间内不能进行别的操作。所以Redis采用渐进式 rehash,这样在进行渐进式rehash期间，字典的删除查找更新等操作可能会在两个哈希表上进行，第一个哈希表没有找到，就会去第二个哈希表上进行查找。但是进行 增加操作，一定是在新的哈希表上进行的。<br><br>
整数集合（intset）是集合类型的底层实现之一，当一个集合只包含整数值元素，并且这个集合的元素数量不多时，Redis 就会使用整数集合作为集合键的底层实现。
<br><br>首先看源码结构<br>typedef struct intset {
    uint32_t encoding;
    uint32_t length;
    int8_t contents[];
} intset;
复制<br>encoding 表示编码方式，的取值有三个：INTSET_ENC_INT16, INTSET_ENC_INT32, INTSET_ENC_INT64<br>length 代表其中存储的整数的个数<br>contents 指向实际存储数值的连续内存区域, 就是一个数组；整数集合的每个元素都是 contents 数组的一个数组项（item），各个项在数组中按值得大小从小到大有序排序，且数组中不包含任何重复项。（虽然 intset 结构将 contents 属性声明为 int8_t 类型的数组，但实际上 contents 数组并不保存任何 int8_t 类型的值，contents 数组的真正类型取决于 encoding 属性的值）<br><br>其内存布局如下图所示<br>“/images/db/redis/db-redis-ds-x-8.png” could not be found.<br>我们可以看到，content数组里面每个元素的数据类型是由encoding来决定的，那么如果原来的数据类型是int16, 当我们再插入一个int32类型的数据时怎么办呢？这就是下面要说的intset的升级。<br><br>当在一个int16类型的整数集合中插入一个int32类型的值，整个集合的所有元素都会转换成32类型。 整个过程有三步：<br>
<br>根据新元素的类型（比如int32），扩展整数集合底层数组的空间大小，并为新元素分配空间。<br>

<br>将底层数组现有的所有元素都转换成与新元素相同的类型， 并将类型转换后的元素放置到正确的位上， 而且在放置元素的过程中， 需要继续维持底层数组的有序性质不变。<br>

<br>最后改变encoding的值，length+1。<br>

<br>那么如果我们删除掉刚加入的int32类型时，会不会做一个降级操作呢？<br>不会。主要还是减少开销的权衡。<br><br>
跳跃表结构在 Redis 中的运用场景只有一个，那就是作为有序列表 (Zset) 的使用。跳跃表的性能可以保证在查找，删除，添加等操作的时候在对数期望时间内完成，这个性能是可以和平衡树来相比较的，而且在实现方面比平衡树要优雅，这就是跳跃表的长处。跳跃表的缺点就是需要的存储空间比较大，属于利用空间来换取时间的数据结构。
<br><br>
跳跃表要解决什么问题呢？如果你一上来就去看它的实现，你很难理解设计的本质，所以先要看它的设计要解决什么问题。
<br>对于于一个单链表来讲，即便链表中存储的数据是有序的，如果我们要想在其中查找某个数据，也只能从头到尾遍历链表。这样查找效率就会很低，时间复杂度会很高，是 O(n)。比如查找12，需要7次查找<br>“/images/db/redis/db-redis-ds-x-9.png” could not be found.<br>如果我们增加如下两级索引，那么它搜索次数就变成了3次<br>“/images/db/redis/db-redis-ds-x-10.png” could not be found.<br><br>redis跳跃表并没有在单独的类（比如skplist.c)中定义，而是其定义在server.h中, 如下:<br>/* ZSETs use a specialized version of Skiplists */
typedef struct zskiplistNode {
    sds ele;
    double score;
    struct zskiplistNode *backward;
    struct zskiplistLevel {
        struct zskiplistNode *forward;
        unsigned int span;
    } level[];
} zskiplistNode;

typedef struct zskiplist {
    struct zskiplistNode *header, *tail;
    unsigned long length;
    int level;
} zskiplist;
复制<br>其内存布局如下图:<br>“/images/db/redis/db-redis-ds-x-11.png” could not be found.<br>zskiplist的核心设计要点<br>
<br>头节点不持有任何数据, 且其level[]的长度为32
<br>每个结点

<br>ele字段，持有数据，是sds类型
<br>score字段, 其标示着结点的得分, 结点之间凭借得分来判断先后顺序, 跳跃表中的结点按结点的得分升序排列.
<br>backward指针, 这是原版跳跃表中所没有的. 该指针指向结点的前一个紧邻结点.
<br>level字段, 用以记录所有结点(除过头节点外)；每个结点中最多持有32个zskiplistLevel结构. 实际数量在结点创建时, 按幂次定律随机生成(不超过32). 每个zskiplistLevel中有两个字段

<br>forward字段指向比自己得分高的某个结点(不一定是紧邻的), 并且, 若当前zskiplistLevel实例在level[]中的索引为X, 则其forward字段指向的结点, 其level[]字段的容量至少是X+1. 这也是上图中, 为什么forward指针总是画的水平的原因.
<br>span字段代表forward字段指向的结点, 距离当前结点的距离. 紧邻的两个结点之间的距离定义为1.




<br><br>
<br>为什么不是平衡树，先看下作者的回答
<br><a rel="noopener" class="external-link" href="https://news.ycombinator.com/item?id=1171423" target="_blank">https://news.ycombinator.com/item?id=1171423</a><br>There are a few reasons:

They are not very memory intensive. It's up to you basically. Changing parameters about the probability of a node to have a given number of levels will make then less memory intensive than btrees.
A sorted set is often target of many ZRANGE or ZREVRANGE operations, that is, traversing the skip list as a linked list. With this operation the cache locality of skip lists is at least as good as with other kind of balanced trees.

They are simpler to implement, debug, and so forth. For instance thanks to the skip list simplicity I received a patch (already in Redis master) with augmented skip lists implementing ZRANK in O(log(N)). It required little changes to the code.

About the Append Only durability &amp; speed, I don't think it is a good idea to optimize Redis at cost of more code and more complexity for a use case that IMHO should be rare for the Redis target (fsync() at every command). Almost no one is using this feature even with ACID SQL databases, as the performance hint is big anyway.
About threads: our experience shows that Redis is mostly I/O bound. I'm using threads to serve things from Virtual Memory. The long term solution to exploit all the cores, assuming your link is so fast that you can saturate a single core, is running multiple instances of Redis (no locks, almost fully scalable linearly with number of cores), and using the "Redis Cluster" solution that I plan to develop in the future.
复制<br>简而言之就是实现简单且达到了类似效果。<br>
<br>skiplist与平衡树、哈希表的比较
<br>来源于：<a rel="noopener" class="external-link" href="https://www.jianshu.com/p/8ac45fd01548" target="_blank">https://www.jianshu.com/p/8ac45fd01548</a><br>skiplist和各种平衡树（如AVL、红黑树等）的元素是有序排列的，而哈希表不是有序的。因此，在哈希表上只能做单个key的查找，不适宜做范围查找。所谓范围查找，指的是查找那些大小在指定的两个值之间的所有节点。<br>在做范围查找的时候，平衡树比skiplist操作要复杂。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在skiplist上进行范围查找就非常简单，只需要在找到小值之后，对第1层链表进行若干步的遍历就可以实现。<br>平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而skiplist的插入和删除只需要修改相邻节点的指针，操作简单又快速。<br>从内存占用上来说，skiplist比平衡树更灵活一些。一般来说，平衡树每个节点包含2个指针（分别指向左右子树），而skiplist每个节点包含的指针数目平均为1/(1-p)，具体取决于参数p的大小。如果像Redis里的实现一样，取p=1/4，那么平均每个节点包含1.33个指针，比平衡树更有优势。<br>查找单个key，skiplist和平衡树的时间复杂度都为O(log n)，大体相当；而哈希表在保持较低的哈希值冲突概率的前提下，查找时间复杂度接近O(1)，性能更高一些。所以我们平常使用的各种Map或dictionary结构，大都是基于哈希表实现的。<br>从算法实现难度上来比较，skiplist比平衡树要简单得多。]]></description><link>04、数据库\02、redis\12、底层原理：数据结构.html</link><guid isPermaLink="false">04、数据库/02、Redis/12、底层原理：数据结构.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Tue, 19 Mar 2024 13:02:10 GMT</pubDate></item><item><title><![CDATA[13、底层原理：网络模型]]></title><description><![CDATA[ 
 <br><br><br><br>Redis 是一个 CS 架构的软件，通信一般分两步（不包括 pipeline 和 PubSub）：<br>客户端（client）向服务端（server）发送一条命令，服务端解析并执行命令，<br>
返回响应结果给客户端，因此客户端发送命令的格式、服务端响应结果的格式必须有一个规范，这个规范就是通信协议。<br>
而在 Redis 中采用的是 RESP（Redis Serialization Protocol）协议：<br>Redis 1.2 版本引入了 RESP 协议<br>
Redis 2.0 版本中成为与 Redis 服务端通信的标准，称为 RESP 2<br>
Redis 6.0 版本中，从 RESP 2 升级到了 RESP 3 协议，增加了更多数据类型并且支持 6.0 的新特性–客户端缓存<br>
但目前，默认使用的依然是 RESP 2 协议。在 RESP 中，通过首字节的字符来区分不同数据类型，常用的数据类型包括 5 种：<br>单行字符串：首字节是‘+’，后面跟上单行字符串，以 CRLF（ “\r\n” ）结尾。例如返回”OK”： “+OK\r\n”<br>错误（Errors）：首字节是‘-’，与单行字符串格式一样，只是字符串是异常信息，例如：”-Error message\r\n”<br>数值：首字节是‘:’，后面跟上数字格式的字符串，以 CRLF 结尾。例如：”: 10\r\n”<br>多行字符串：首字节是‘$’，表示二进制安全的字符串，最大支持 512 MB：<br>如果大小为 0，则代表空字符串：”-1\r\n”<br>
数组：首字节是‘*’，后面跟上数组元素个数，再跟上元素，元素数据类型不限 :<br><img src="\04、数据库\02、redis\assets\13、底层原理：网络模型\img-20240318_215003.png"><br><br>Redis 支持 TCP 通信，因此我们可以使用 Socket 来模拟客户端，与 Redis 服务端建立连接：<br>public class Main {

    static Socket s;
    static PrintWriter writer;
    static BufferedReader reader;

    public static void main(String[] args) {
        try {
            // 1.建立连接
            String host = "192.168.150.101";
            int port = 6379;
            s = new Socket(host, port);
            // 2.获取输出流、输入流
            writer = new PrintWriter(new OutputStreamWriter(s.getOutputStream(), StandardCharsets.UTF_8));
            reader = new BufferedReader(new InputStreamReader(s.getInputStream(), StandardCharsets.UTF_8));

            // 3.发出请求
            // 3.1.获取授权 auth 123321
            sendRequest("auth", "123321");
            Object obj = handleResponse();
            System.out.println("obj = " + obj);

            // 3.2.set name 虎哥
            sendRequest("set", "name", "虎哥");
            // 4.解析响应
            obj = handleResponse();
            System.out.println("obj = " + obj);

            // 3.2.set name 虎哥
            sendRequest("get", "name");
            // 4.解析响应
            obj = handleResponse();
            System.out.println("obj = " + obj);

            // 3.2.set name 虎哥
            sendRequest("mget", "name", "num", "msg");
            // 4.解析响应
            obj = handleResponse();
            System.out.println("obj = " + obj);
        } catch (IOException e) {
            e.printStackTrace();
        } finally {
            // 5.释放连接
            try {
                if (reader != null) reader.close();
                if (writer != null) writer.close();
                if (s != null) s.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
    }

    private static Object handleResponse() throws IOException {
        // 读取首字节
        int prefix = reader.read();
        // 判断数据类型标示
        switch (prefix) {
            case '+': // 单行字符串，直接读一行
                return reader.readLine();
            case '-': // 异常，也读一行
                throw new RuntimeException(reader.readLine());
            case ':': // 数字
                return Long.parseLong(reader.readLine());
            case '$': // 多行字符串
                // 先读长度
                int len = Integer.parseInt(reader.readLine());
                if (len == -1) {
                    return null;
                }
                if (len == 0) {
                    return "";
                }
                // 再读数据,读len个字节。我们假设没有特殊字符，所以读一行（简化）
                return reader.readLine();
            case '*':
                return readBulkString();
            default:
                throw new RuntimeException("错误的数据格式！");
        }
    }

    private static Object readBulkString() throws IOException {
        // 获取数组大小
        int len = Integer.parseInt(reader.readLine());
        if (len &lt;= 0) {
            return null;
        }
        // 定义集合，接收多个元素
        List&lt;Object&gt; list = new ArrayList&lt;&gt;(len);
        // 遍历，依次读取每个元素
        for (int i = 0; i &lt; len; i++) {
            list.add(handleResponse());
        }
        return list;
    }

    // set name 虎哥
    private static void sendRequest(String ... args) {
        writer.println("*" + args.length);
        for (String arg : args) {
            writer.println("$" + arg.getBytes(StandardCharsets.UTF_8).length);
            writer.println(arg);
        }
        writer.flush();
    }
}
复制]]></description><link>04、数据库\02、redis\13、底层原理：网络模型.html</link><guid isPermaLink="false">04、数据库/02、Redis/13、底层原理：网络模型.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Mon, 18 Mar 2024 13:51:51 GMT</pubDate><enclosure url="04、数据库\02、redis\assets\13、底层原理：网络模型\img-20240318_215003.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;04、数据库\02、redis\assets\13、底层原理：网络模型\img-20240318_215003.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[100、 ★ Redis 面试题汇总 ★]]></title><description><![CDATA[ 
 <br><br><br><br><br><br>
<br>redis有哪些数据类型
<br>redis数据类型有哪些命令
<br>谈谈redis的对象机制（redisObject)
<br>redis数据类型有哪些底层数据结构
<br>为什么要设计sds？
<br>一个字符串类型的值能存储最大容量是多少？512M
<br>为什么会设计Stream
<br>Stream用在什么样场景
<br>消息ID的设计是否考虑了时间回拨的问题
<br><br>
<br>Redis 的持久化机制是什么？各自的优缺点？一般怎么用？
<br>Redis 过期键的删除策略有哪些
<br>Redis 内存淘汰算法有哪些
<br>Redis的内存用完了会发生什么？ 如果达到设置的上限，Redis的写命令会返回错误信息（但是读命令还可以正常返回。）或者你可以配置内存淘汰机制，当Redis达到内存上限时会冲刷掉旧的内容。
<br>Redis如何做内存优化？
<br>Redis key 的过期时间和永久有效分别怎么设置？
<br>EXPIRE 和 PERSIST 命令<br>
<br>Redis 中的管道有什么用？
<br>一次请求/响应服务器能实现处理新的请求即使旧的请求还未被响应，这样就可以将多个命令发送到服务器，而不用等待回复，最后在一个步骤中读取该答复。<br>这就是管道（pipelining），是一种几十年来广泛使用的技术。例如许多 POP3 协议已经实现支持这个功能，大大加快了从服务器下载新邮件的过程。<br><br>
<br>什么是redis事务
<br>Redis事务相关命令
<br>Redis事务的三个阶段
<br>watch是如何监视实现的呢
<br>为什么 Redis 不支持回滚
<br>redis 对 ACID的支持性理解
<br>Redis事务其他实现
<br>基于Lua脚本，Redis可以保证脚本内的命令一次性、按顺序地执行，其同时也不提供事务运行错误的回滚，执行过程中如果部分命令运行错误，剩下的命令还是会继续运行完<br>基于中间标记变量，通过另外的标记变量来标识事务是否执行完成，读取数据时先读取该标记变量判断是否事务执行完成。但这样会需要额外写代码实现，比较繁琐<br><br><br>
<br>Redis集群的主从复制模型是怎样的？
<br>全量复制的三个阶段？
<br>为什么会设计增量复制？
<br>增量复制的流程？ 如果在网络断开期间，repl_backlog_size环形缓冲区写满之后，从库是会丢失掉那部分被覆盖掉的数据，还是直接进行全量复制呢？
<br>为什么不持久化的主服务器自动重启非常危险呢?
<br>为什么主从全量复制使用RDB而不使用AOF？
<br>为什么还有无磁盘复制模式？
<br>为什么还会有从库的从库的设计？
<br><br>
<br>Redis哨兵机制？哨兵实现了什么功能呢
<br>哨兵集群是通过什么方式组建的？
<br>哨兵是如何监控Redis集群的？
<br>哨兵如何判断主库已经下线了呢？
<br>哨兵的选举机制是什么样的？
<br>Redis 1主4从，5个哨兵，哨兵配置quorum为2，如果3个哨兵故障，当主库宕机时，哨兵能否判断主库“客观下线”？能否自动切换？
<br>主库判定客观下线了，那么如何从剩余的从库中选择一个新的主库呢？
<br>新的主库选择出来后，如何进行故障的转移？
<br><br>
<br>说说Redis哈希槽的概念？为什么是16384个？<br>

<br>Redis集群会有写操作丢失吗？为什么？<br>

<br>Redis并不能保证数据的强一致性，这意味这在实际中集群在特定的条件下可能会丢失写操作。<br><br>
<br>redis 客户端有哪些
<br>Redisson、Jedis、lettuce等等，官方推荐使用Redisson。<br>Redisson是一个高级的分布式协调Redis客服端，能帮助用户在分布式环境中轻松实现一些Java的对象 (Bloom filter, BitSet, Set, SetMultimap, ScoredSortedSet, SortedSet, Map, ConcurrentMap, List, ListMultimap, Queue, BlockingQueue, Deque, BlockingDeque, Semaphore, Lock, ReadWriteLock, AtomicLong, CountDownLatch, Publish / Subscribe, HyperLogLog)。<br>
<br>Redis如何做大量数据插入？ Redis2.6开始redis-cli支持一种新的被称之为pipe mode的新模式用于执行大量数据插入工作。<br>

<br>redis实现分布式锁实现? 什么是 RedLock?<br>

<br>redis缓存有哪些问题，如何解决<br>

<br>redis和其它数据库一致性问题如何解决<br>

<br>redis性能问题有哪些，如何分析定位解决<br>

<br><br>
<br>Redis单线程模型？ 在6.0之前如何提高多核CPU的利用率？
<br>可以在同一个服务器部署多个Redis的实例，并把他们当作不同的服务器来使用，在某些时候，无论如何一个服务器是不够的， 所以，如果你想使用多个CPU，你可以考虑一下分片（shard）。<br>
<br>6.0版本中多线程
<br>求教学问题：<br>主从哨兵模式：如果主节点 down 机没有被立刻发现，数据丢失问题怎么解决的？<br>主从从模式下，主挂了，会发生什么现象？<br>少数派会拒绝写入吗？<br>如果备份推荐 AOF 还是 RDB]]></description><link>04、数据库\02、redis\100、-★-redis-面试题汇总-★.html</link><guid isPermaLink="false">04、数据库/02、Redis/100、 ★ Redis 面试题汇总 ★.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Sat, 30 Mar 2024 12:21:43 GMT</pubDate></item><item><title><![CDATA[01、Zookeeper 概述]]></title><description><![CDATA[ 
 <br><br>Zookeeper 是 Apache Hadoop 项目下的子项目，开源的、分布式应用程序的协调服务。<br>Zookeeper 特性：文件系统 + 通知机制<br>Zookeeper 翻译过来就是动物园管理员，他是用来管 Hadoop（大象）、Hive (蜜蜂)、Pig (小猪) 的管理员。简称 zk。<br>
<br>Hadoop: 存储海量数据和分析海量数据的工具
<br>Hive: 基于 Hadoop 的一个数据仓库工具，用来进行数据提取、转化、加载
<br>Pig: 基于 Hadoop 的大规模数据分析平台
<br><br>Zookeeper是一个经典的分布式数据一致性解决方案，致力于为分布式应用提供一个高性能、高可用，且具有严格顺序访问控制能力的分布式协调存储服务。<br>
<br>
集群管理 &amp; 注册中心：比如Dubbo的注册中心，或者其他集群协调如 Kafka

<br>
分布式锁：比如卖电影票有好多入口：官网、猫眼、淘票票

<br>
配置管理：比如用来保存的各种配置信息（数据库连接信息）【Apollo（百度开源）、Nacos（阿里开源）】

<br>
分布式ID：实现方式之一。

<br>实际应用中，只有集群管理 &amp; 注册中心比较常用，其他都有更好的实现方案。<br><br><br>Zookeeper 的数据模型类似于文件系统是树状结构，每个树节点（目录）对应一个 Znode 节点。均可以增删改查。<br>Znode，兼具文件和目录两种特点。既像文件一样维护着数据、元信息、ACL、时间戳等数据结构，又像目录一样可以作为路径标识的一部分。每一个 Znode 默认能够存储 1 MB 的数据。<br><img src="\05、中间件\03、zookeeper\assets\01、zookeeper-概述\img-20240320_214959.png"><br><br>我们常用的主要有四种类型的 znode。<br>1、持久化目录节点：PERSISTENT<br>
客户端与 zookeeper 断开连接后，该节点依旧存在，只要不手动删除该节点，他将永远存在。<br>2、持久化顺序编号目录节点：PERSISTENT_SEQUENTIAL<br>
-s客户端与 zookeeper 断开连接后，该节点依旧存在，只是 zookeeper 给该节点名称进行顺序编号。<br>3、临时目录节点：EPHEMERAL :<br>
-e 客户端与 zookeeper 断开连接后，该节点被删除。<br>4、临时顺序编号目录节点： EPHEMERAL_SEQUENTIAL<br>
-es 客户端与 zookeeper 断开连接后，该节点被删除，只是 zookeeper 给该节点名称进行顺序编号。<br><br>Paxos、<br>zab、<br>cap]]></description><link>05、中间件\03、zookeeper\01、zookeeper-概述.html</link><guid isPermaLink="false">05、中间件/03、Zookeeper/01、Zookeeper 概述.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 21 Mar 2024 13:44:47 GMT</pubDate><enclosure url="05、中间件\03、zookeeper\assets\01、zookeeper-概述\img-20240320_214959.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;05、中间件\03、zookeeper\assets\01、zookeeper-概述\img-20240320_214959.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[02、Zookeeper 安装和常见命令]]></title><description><![CDATA[ 
 <br><br><br><br>ZooKeeper服务器是用Java创建的，它运行在JVM之上。需要安装JDK 7或更高版本。<br><br>将下载的ZooKeeper放到/opt/ZooKeeper目录下<br><br>将tar包解压到/opt/zookeeper目录下<br><br><br>进入到 conf 目录拷贝一个 zoo_sample.cfg 并完成 zoo.cfg 配置<br>#进入到conf目录  
cd /opt/zooKeeper/apache-zookeeper-3.5.6-bin/conf/  
#拷贝  
cp  zoo_sample.cfg  zoo.cfg
复制<br>修改：<br>#打开目录  
cd /opt/zooKeeper/  
#创建zooKeeper存储目录  
mkdir  zkdata  
#修改zoo.cfg  
vim /opt/zooKeeper/apache-zookeeper-3.5.6-bin/conf/zoo.cfg
复制<br><br>cd /opt/zooKeeper/apache-zookeeper-3.5.6-bin/bin/  
#启动  
./zkServer.sh  start
复制<br><br>Zookeeper启动成功。standalone 代表zk没有搭建集群，现在是单节点。<br><br>三个虚拟机，搭建 Zookeeper 的伪集群。<br>1、将解压的 Zookeeper 安装包复制三份<br>2、修改 Zookeeper 服务器对应配置文件：<br># 服务器对应端口号
clientPort=2181
# 数据快照文件所在路径
dataDir=/home/service/zookeeper/data
# 集群配置信息
  # 配置格式：server.A=B:C:D
  # server：固定写法
  # A:是一个数字，表示这个服务器的编号
  # B:是这个服务器的ip地址或主机名
  # C:Zookeeper服务器之间的数据同步等通信端口
  # D:Leader选举的端口
server.1=10.211.55.5:2881:3881
server.2=10.211.55.6:2881:3881
server.3=10.211.55.7:2881:3881
复制<br>3、在上一步创建的 dataDir目录中，创建myid文件，然后在该文件中添加上一步 server 配置的对应的A的数字<br># 10.211.55.5上
echo 1 &gt;/home/service/zookeeper/data/myid
# 10.211.55.6上
echo 2 &gt;/home/service/zookeeper/data/myid
# 10.211.55.7上
echo 3 &gt;/home/service/zookeeper/data/myid
复制<br>4、启动三台服务器。<br>/home/service/zookeeper/bin/zkServer.sh start
复制<br>启动之后，客户端登陆检验集群状态，使用 ./zkServer.sh status 查看的状态分别为：leader、follower、follower<br>5、模拟集群异常<br>○　关闭 3 节点<br>/home/service/zookeeper/bin/zkServer.sh stop
复制<br>结果：服务依旧正常。<br>○　再关 1 节点<br>查看2号（主服务器）的状态，发现已经停止运行了。<br>结果：服务不可用，运行的机器需要超过集群总数量的半数。<br>○　重新启动 1 节点<br>结果：服务正常，2 号依然是领导者。<br>○　3 节点启动，2 节点（Leader）关闭<br>结果：发现新的 Leader 产生。<br>○　2 节点启动<br>结果：2 号服务器是 Flower<br>当领导者产生后，再次有新服务器加入集群，不会影响到现任领导者。<br><br><br>启动 ZooKeeper 服务: ./zkServer. Sh start<br>查看 ZooKeeper 服务状态: ./zkServer. Sh status<br>停止 ZooKeeper 服务: ./zkServer. Sh stop<br>重启 ZooKeeper 服务: ./zkServer. Sh restart<br><br>首先连接上zookeeper<br>使用 ./zkCli.sh连接到本机。<br>使用 ./zkCli.sh -server 远程zookeeper服务器ip 连接到远程zookeeper服务器<br><br>命令格式：<br># -s 为有序节点， -e 为临时节点
create [-s] [-e] path data
复制<br>1）创建持久化节点并写入数据：  <br># 创建 hadoop节点，内容为123456
create /hadoop "123456"
# 读取节点内容
get /hadoop
复制<br>2）创建持久化有序节点<br>
此时创建出来的节点名称为：指定的节点名+自增序号：  <br># 此时创建出来的节点名称为/a0000000001
create -s /a "a"

# 再创建/b时，节点名称为/b0000000002
create -s /b "b"
复制<br>3）创建临时节点<br>create -e /tmp "tmp"

# 创建完之后，通过get /tmp可以查到
get /tmp

# 使用quit退出当前会话
quit

# 重新打开zkCli，get /tmp 找不到该节点
get /tmp
复制<br>4）创建临时有序节点<br>
（可用于分布式锁）<br># 创建的临时节点：/t0000000004
create -s -e /t "tt"
复制<br><br>命令格式：<br>get path
stat path
复制<br>1）查看节点的值和属性：  <br>get /hadoop
复制<br>2）只查看节点属性，不查看节点的值：  <br>stat /hadoop
复制<br>节点属性说明：<br>
●cZxid：数据节点创建时的事务ID<br>
●ctime：数据节点创建时的时间<br>
●mZxid：数据节点最后一次更新时的事务ID<br>
●pZxid：数据节点最后一次更新时的时间<br>
●cversion：子节点的更改次数<br>
●dataVersion：节点数据的更改次数<br>
●aclVersion：节点的ACL的更改次数<br>
●ephemeralOwner：如果节点是临时节点，则表示创建该节点的会话sessionID。如果节点是持久节点，则该属性值为0<br>
●dataLength：数据内容的长度<br>
●numChildren：数据节点当前的子节点个数  <br>3）查看子节点列表<br># 命令格式 ls [-s] [-w] [-R] path
# 查看指定节点的子节点列表
ls /hadoop

# 递归查看子节点、子节点的子节点列表
ls -R /hadoop

# 使用 ls -s 或者 ls2 查看节点的子节点、节点的属性
ls -s /hadoop
ls2 /hadoop
复制<br><br>命令格式：<br>set path data [version]
复制<br>使用 set 修改节点的值：  <br>set /hadoop "1234"
复制<br>指定修改的节点的版本号：<br>
节点的 dataVersion 属性从 0 开始，每次修改节点的值之后加 1 。<br># 命令格式set [-v version] path data
# 3.4版本的zookeeper命令格式为：set path data [version]
set -v 1 /hadoop "123"
复制<br>指定修改节点的版本号后，会先校验指定的版本号和节点当前的实际 dataVersion 是否一致。如果指定的修改节点的版本号和节点当前的 dataVersion 不对应，则会修改失败。  <br><br>命令格式：<br># 删除某个节点
delete [-v] path 
# 连带删除下面子节点
deleteall path
复制<br>1）删除指定节点<br>delete /hadoop
复制<br>2）指定版本号删除节点<br>
先校验指定的版本号和节点当前实际的dataVersion是否一致，不一致则不允许删除。  <br>#命令格式 delete [-v version] path
# 3.4版本的zookeeper命令格式为：delete path [version]
delete -v 1 /hadoop
复制<br>3）连带删除<br>create /hadoop "123456"
create /hadoop/node1 "123"
deleteall /hadoop
复制<br><br>可以通过一些命令参数为节点增加不同类型的监听器，当监听的状态发生改变时，向客户端发送通知。<br>
Zookeeper的触发器是一次性的（One-time trigger），即触发一次后就会立即失效。<br>使用 get -w path 注册的监听器，能够在节点内容发生改变的时候，向客户端发出通知。<br># 为/hadoop节点添加触发器
get -w /hadoop
# 修改节点的值
set /hadoop "123"
复制<br>使用 stat -w path 注册的监听器，能够在节点状态发生改变的时候，向客户端发送通知  <br>使用 ls -w path 或者 ls2 path watch 注册的监听器，能够监听该节点下所有子节点的增加和删除操作。<br>WATCHER::
WatchedEvent state:SyncConnected type:NodeChildrenChanged path:/hadoop
复制]]></description><link>05、中间件\03、zookeeper\02、zookeeper-安装和常见命令.html</link><guid isPermaLink="false">05、中间件/03、Zookeeper/02、Zookeeper 安装和常见命令.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 21 Mar 2024 13:00:06 GMT</pubDate></item><item><title><![CDATA[03、ACL 权限控制]]></title><description><![CDATA[ 
 <br><br>Zookeeper 类似 Linux 针对文件权限控制<br>Acl 权限控制，使用 scheme🆔permission 来标识，主要涵盖 3 个方面<br>权限模式 (scheme): 授权的策略<br>
授权对象 (id)：授权的对象<br>
权限 (permission)：授予的权限<br>其特性如下：<br>
<br>Zookeeper 的权限控制是基于每个 znode 节点的，需要对每个节点设置权限
<br>每个 znode 支持设置多种权限控制方案和多个权限
<br>子结点不会继承父节点的权限，客户端无权访问某节点，但可能可以访问它的子结点
<br>例如：<br>SetAcl /test 2 ip: 192.168.60.130: crwda //将节点权限设置为 Ip: 192.168.60.130 的客户端可以对该节点进行增、删、改、查、管理权限<br><br>权限模式 (scheme)<br>
采用何种方式授权<br>World : 只有一个用户：anyone，代表登录 zookeeper 所有人 (默认)<br>
Id：对客户端使用 Ip 地址认证<br>
Auth：使用已添加认证的用户认证<br>
Digest：使用"用户名：密码"方式认证<br>
授权的对象 (id)<br>
给谁授予权限<br>授权对象 ID 是指，权限赋予的实体，例如：IP 地址或用户。<br>授予的权限 (permission)<br>
Create、delete、read、writer、admin 也就是增、删、改、查、管理权限，这 5 种权限简写为 cdrwa, 注意：这 5 种权限中，delete 是指对子结点的删除权限，其它 4 种权限指对自身节点的操作权限。<br>权限	ACL 简写描述<br>
Create	c	可以创建子结点<br>
Delete	d	可以删除子结点 (仅下一级结点)<br>
Read	r	可以读取结点数据以及显示子结点列表<br>
Write	w	可以设置结点数据<br>
Admin	a	可以设置结点访问控制权限列表<br>
授权的相关命令<br>
命令使用方式描述<br>
getAcl	getAcl&lt; path&gt;	读取 ACL 权限<br>
setAcl	setAcl&lt; path&gt;&lt; acl&gt;	设置 ACL 权限<br>
addauth	addauth&lt; scheme&gt;&lt; auth&gt;	添加认证用户<br>
World 授权模式<br>
setAcl <br>例如，取消 d 权限，那么就不能再删除子结点了。<br>IP 授权模式<br>
setAcl <br>远程登录 zookeeper 命令： ./zkCli. Sh server ip 用 129 虚拟机去登录 130 虚拟机的 zookeeper 服务。<br>也可以同时对多个 ip 地址进行限制权限，逗号隔开<br>SetAcl /node 2 ip: 192.168.60.129: cdrwa, ip: 192.168.60.130:cdrwa<br>
1<br>
这里就不演示，主要是限制客户端的访问。<br>Auth 授权模式<br>
adduath digest : 添加认证用户<br>
setAcl <br>另一台客户端如果没有添加该用户就不能读取这个节点。<br>Quit 命令退出后，重新登录 zookeeper 服务，在执行 get /node 3 就不能获取到 node 3 节点的信息了。因为重新登录后，没有添加 shaoyi 这个用户。<br>添加完 shaoyi 这个用户，就能够获取到 node 3 这个节点的信息<br>Digest 授权模式<br>
setAcl <br>echo -n : | openssl dgst -binary -sha 1 | openssl base 64<br>
1<br>注意：要获取加密后的密码，需要退出 zookeeper·服务器，这是 Linux 自带的加密。<br>添加结点/node 4，使用 digest 模式授权<br>多种授权模式<br>
同一个节点可以同时使用多种模式授权，用逗号隔开<br> SetAcl /node 5 ip: 172.16.114.135: cdra, auth:shaoyi: cdrwa, digest:shaoyi: HskhPQW 320+M/KyBVe 9 KP/lKuCk=:cdrwa<br>
1<br>Acl 超级管理员<br>
Zookeeper 的权限管理模式有一种叫做 super, 该模式提供一个超管可以方便的访问任何权限的节点<br>假设这个超管是: super: admin. 需要先为超管生成密码的密文<br>Echo -n super: admin | openssl dgst -binary -sha 1 | openssl base 64<br>
1<br>那么打开 zookeeper 目录下的/bin/zkServer. Sh 服务器脚本文本，找到如下一行:<br>加入这一句<br>"-Dzookeeper. DigestAuthenticationProvider. SuperDigest=super: xQJmxLMiHGwaqBvst 5 y 6 rkB 6 HQs="<br>
1<br>
修改完后，重启 zookeeper<br>./zkServer. Sh stop  关闭 zookeeper<br>
./zkServer. Sh start 开启 zookeeper<br>
1<br>
2<br>登录 zookeeper 服务，创建/node 6，取消创建子结点权限<br>此时，不能创建子结点<br>添加超级管理员用户，可以发现能够成功添加子结点]]></description><link>05、中间件\03、zookeeper\03、acl-权限控制.html</link><guid isPermaLink="false">05、中间件/03、Zookeeper/03、ACL 权限控制.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 21 Mar 2024 14:27:02 GMT</pubDate></item><item><title><![CDATA[04、Zookeeper JavaAPI]]></title><description><![CDATA[ 
 <br><br>常见的 ZooKeeper Java API ：<br>
<br>原生 Java API
<br>ZkClient
<br>Curator
<br><br>Curator 是 Apache ZooKeeper 的 Java 客户端库，目标是简化 ZooKeeper 客户端的使用。<br>
Curator 最初是 Netfix 研发的, 后来捐献了 Apache 基金会, 目前是 Apache 的顶级项目<br>Curator 特点：<br>
<br>解决 session 会话超时重连
<br>Watcher 反复注册
<br>简化开发 API
<br>遵循 Fluent 风格的 API
<br>提供了分布式锁服务、共享计数器、缓存机制等机制
<br><br><br>&lt;!-- zookeeper支持 --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt;
    &lt;artifactId&gt;zookeeper&lt;/artifactId&gt;
    &lt;version&gt;3.6.4&lt;/version&gt;
&lt;/dependency&gt;
&lt;!-- curator-recipes --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.curator&lt;/groupId&gt;
    &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt;
    &lt;version&gt;5.5.0&lt;/version&gt;
&lt;/dependency&gt;
.

&lt;dependency&gt;
    &lt;groupId&gt;org.apache.curator&lt;/groupId&gt;
    &lt;artifactId&gt;curator-framework&lt;/artifactId&gt;
    &lt;version&gt;5.5.0&lt;/version&gt;
&lt;/dependency&gt;
复制<br><br>CuratorFramework client = CuratorFrameworkFactory
    .builder()
    // 服务器地址
    .connectString("192.168.29.137:2181,192.168.29.137:2182,192.168.29.137:2183")
    // 会话超时时间
    .sessionTimeoutMs(5000)
    // 设置重连机制： 会话超时3秒后一次重连
    .retryPolicy(new RetryOneTime(3000))
    // 命名空间（指定父节点）
    .namespace("create")
    .build();

// 打开链接
client.start();
System.out.println(client.getState());
// 关闭连接
client.close();
复制<br>重连策略接口为：RetryPolicy<br>常用的实现类有：<br>
<br>
RetryOneTime(x)<br>
x毫秒后重连一次，只重连一次

<br>
RetryNTimes(x, y)<br>
每y毫秒重连一次，重连x次

<br>
RetryUntilElapsed(x, y)<br>
每y毫秒重连一次，总时间超过x毫秒后停止重连

<br>
ExponenttialBackoffRetry(x, y)<br>
随着重连次数的增加，重建的时间间隔增长。

<br>x为基础等待毫秒baseSleepTime，y为重连次数。<br>重连时间的计算：baseSleepTimesMs * Math.max(1, random.nextInt(1 &lt;&lt; (retryCount + 1)))<br><br><br>public class CuratorCreate {

    String ip = "192.168.29.137:2181,192.168.29.137:2182,192.168.29.137:2183";
    CuratorFramework client;

    @Before
    public void before() {
        client = CuratorFrameworkFactory
                .builder()
                .connectString(ip)
                .sessionTimeoutMs(5000)
                .retryPolicy(new RetryOneTime(3000))
                .namespace("create")
                .build();

        client.start();
    }

    @After
    public void after() {
        client.close();
    }

    @Test
    public void create1() throws Exception {
        client.create()
                // 设置节点类型
                .withMode(CreateMode.PERSISTENT)
                // 配置权限列表
                .withACL(ZooDefs.Ids.OPEN_ACL_UNSAFE)
                // 配置节点路径、节点值。
                // 因为配置了namespace，所以创建的节点会以namespace指定的名称作为父节点
                .forPath("/node1", "test".getBytes());
        System.out.println("创建完成");
    }
}
复制<br>递归创建子节点：<br>@Test
public void create2() throws Exception {
    client.create()
        // 没有/node2节点时自动创建/node2节点
        .creatingParentsIfNeeded()
        .withMode(CreateMode.PERSISTENT)
        .withACL(ZooDefs.Ids.OPEN_ACL_UNSAFE)
        .forPath("/node2/node22", "aaa".getBytes());
    System.out.println("递归创建节点");
}
复制<br>异步创建节点：<br>@Test
public void create3() throws Exception {
    client.create()
        .creatingParentsIfNeeded()
        .withMode(CreateMode.PERSISTENT)
        .withACL(ZooDefs.Ids.OPEN_ACL_UNSAFE)
        .inBackground(new BackgroundCallback() {
            // 异步回调接口
            @Override
            public void processResult(CuratorFramework client, CuratorEvent event) throws Exception {
                System.out.println(event.getPath());
                System.out.println(event.getType());
            }
        })
        .forPath("/node3/node33", "bbb".getBytes());
    System.out.println("异步创建节点");
    Thread.sleep(5000);
    System.out.println("结束");
}
复制<br>]]></description><link>05、中间件\03、zookeeper\04、zookeeper-javaapi.html</link><guid isPermaLink="false">05、中间件/03、Zookeeper/04、Zookeeper JavaAPI.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Sat, 23 Mar 2024 03:02:13 GMT</pubDate></item><item><title><![CDATA[05、Zookeeper 实战应用]]></title><description><![CDATA[ 
 <br><br>场景：数据库用户名和密码信息放在一个配置文件中，应用读取该配置文件，配置信息放入缓存。若数据库的用户名密码改变时候，通过ZooKeeper自动完成缓存同步。  <br>设计思路：<br>
1、连接ZooKeeper服务器<br>
2、读取ZooKeeper中的配置信息，注册Watcher监听器，存入本地变量<br>
3、当ZooKeeper中的配置信息发生变化时，通过Watcher的回调方法捕获数据变化事件<br>
4、重新获取配置信息  <br>在 ZooKeeper 中添加配置信息：<br>create /config "config"
create /config/url "localhost:1521"
create /config/username "mydata"
create /config/password "tiger"
复制<br>编写Watcher作为配置中心：<br>
当监听到节点数据发生变化时，重新获取数据
<br>public class MyConfigCenter implements Watcher {

    // ZK服务器
    static String IP = "192.168.29.137:2181";

    // 计数器对象
    static CountDownLatch countDownLatch = new CountDownLatch(1);

    // 连接对象
    static ZooKeeper zooKeeper;

    // 用于本地化存储配置信息
    private String url;
    private String username;
    private String password;

    public MyConfigCenter() {
		// 创建对象时，先初始化读取一次数据
        initValue(); 
    }

    @Override
    public void process(WatchedEvent event) {
        try {
            // 事件类型
            if (event.getType() == Event.EventType.None) {
                if(event.getState() == Event.KeeperState.SyncConnected) {
                    System.out.println("连接创建成功");
                    countDownLatch.countDown();
                } else if(event.getState() == Event.KeeperState.Disconnected) {
                    System.out.println("断开连接");
                } else if(event.getState() == Event.KeeperState.Expired) {
                    System.out.println("会话超时");
                    zooKeeper = new ZooKeeper(IP, 5000, this);
                } else if(event.getState() == Event.KeeperState.AuthFailed) {
                    System.out.println("认证失败");
                }
            } else if(event.getType() == Event.EventType.NodeDataChanged) {  
                // 监听到当节点数据发生变化时,重新读取数据
                System.out.println("数据发生变化，重新获取数据");
                initValue();
            }
        } catch (Exception e) {
            e.printStackTrace();
        }
    }

    // 连接ZK服务器，读取配置信息
    public void initValue() {
        try {
            // 创建连接
            zooKeeper = new ZooKeeper(IP, 5000, this);
            countDownLatch.await();

            // 读取配置信息
            System.out.println("读取配置信息...");
            this.url = new String(zooKeeper.getData("/config/url", true, null));
            this.username = new String(zooKeeper.getData("/config/username", true, null));
            this.password = new String(zooKeeper.getData("/config/password", true, null));
        } catch (Exception e) {
            e.printStackTrace();
        }
    }

    public static void main(String[] args) throws Exception{
        MyConfigCenter myConfigCenter = new MyConfigCenter();

        // 模拟客户端多次获取的配置信息
        for (int i = 0; i &lt; 20; i++) {
            Thread.sleep(2000);
            System.out.println("url: " + myConfigCenter.getUrl());
            System.out.println("username: " + myConfigCenter.getUsername());
            System.out.println("password: " + myConfigCenter.getPassword());
            System.out.println("=============================");
        }
    }

    public String getUrl() {
        return url;
    }

    public void setUrl(String url) {
        this.url = url;
    }

    public String getUsername() {
        return username;
    }

    public void setUsername(String username) {
        this.username = username;
    }

    public String getPassword() {
        return password;
    }

    public void setPassword(String password) {
        this.password = password;
    }
}
复制<br><br>在单库单表型系统中，通常可以使用数据库字段自带的auto_increment属性来自动为每条记录生成一个唯一ID。但是分库分表后，就无法再依靠数据库的auto_increment属性来唯一标识一条记录了，此时可以使用zookeeper在分布式环境下生成全局唯一ID。<br>设计思路：<br>
1、连接ZooKeeper服务器<br>
2、指定路径生成临时有序节点<br>
3、取序列号为分布式环境下的唯一ID<br>示例程序：<br>public class GloballyUniqueId implements Watcher {
    // ZK服务器
    static String IP = "192.168.29.137:2181";

    // 计数器对象
    static CountDownLatch countDownLatch = new CountDownLatch(1);

    // 连接对象
    static ZooKeeper zooKeeper;

    // 用于生成序列号的节点
    static String defaultPath = "/uniqueId";

    @Override
    public void process(WatchedEvent event) {
        try {
            // 事件类型
            if (event.getType() == Event.EventType.None) {
                if (event.getState() == Event.KeeperState.SyncConnected) {
                    System.out.println("连接创建成功");
                    countDownLatch.countDown();
                } else if (event.getState() == Event.KeeperState.Disconnected) {
                    System.out.println("断开连接");
                } else if (event.getState() == Event.KeeperState.Expired) {
                    System.out.println("会话超时");
                    zooKeeper = new ZooKeeper(IP, 5000, this);
                } else if (event.getState() == Event.KeeperState.AuthFailed) {
                    System.out.println("认证失败");
                }
            }
        } catch (Exception e) {
            e.printStackTrace();
        }
    }

    public GloballyUniqueId() {
        try {
            // 创建连接
            zooKeeper = new ZooKeeper(IP, 5000, this);
            countDownLatch.await();
        } catch (Exception e) {
            e.printStackTrace();
        }
    }

    // 生成id的方法
    public String getUniqueId() {
        String path = "";
        try {
            // 创建临时有序节点
            path = zooKeeper.create(defaultPath, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL);
        } catch (Exception e) {
            e.printStackTrace();
        }

        // 将返回的节点名称截取掉前面的/uniqueId，ZK自动生成的后缀数字即为ID
        return path.substring(9);
    }

    public static void main(String[] args) throws Exception{
        GloballyUniqueId globallyUniqueId = new GloballyUniqueId();
        for (int i = 0; i &lt; 10; i++) {
            Thread.sleep(2000);
            System.out.println(globallyUniqueId.getUniqueId());
        }
    }
}
复制<br><br>分布式锁有多种实现方式，比如通过数据库、redis都可以实现。也可以使用zookeeper进行实现。<br>在ZooKeeper中实现排它锁，设计思路：<br>
<br>
每个客户端往 /Locks 下创建临时有序节点 /Locks/Lock_，创建成功后 /Locks下面会有每个客户端对应的节点，例如 /Locks/Lock_00000001

<br>
客户端取得 /Locks 下子节点，并进行排序，判断排在最前面的是否为自己，如果自己的锁排在第一位，代表获取锁成功。

<br>
如果自己的锁节点不在第一位，则监听自己前一位的锁节点。例如，自己锁节点Lock_00000002，则监听Locks_00000001

<br>
当前一位锁节点（Lock_00000001）对应的客户端执行完成，释放了锁，将会触发监听客户端（Lock_00000002）的逻辑

<br>
监听客户端重新执行第2步逻辑，判断自己是否获得了锁。

<br>示例代码：<br>public class MyLock {
    String ip = "192.168.29.137:2181";

    // 计数器对象
    static CountDownLatch countDownLatch = new CountDownLatch(1);

    ZooKeeper zooKeeper;

    private static final String LOCK_ROOT_PATH = "/Locks";
    private static final String LOCK_NODE_NAME = "Lock_";
    private String lockPath;

    public MyLock() {
        try {
            zooKeeper = new ZooKeeper(ip, 5000, new Watcher() {
                @Override
                public void process(WatchedEvent event) {
                    // 事件类型
                    if (event.getType() == Event.EventType.None) {
                        if (event.getState() == Event.KeeperState.SyncConnected) {
                            System.out.println("连接创建成功");
                            countDownLatch.countDown();
                        } else if (event.getState() == Event.KeeperState.Disconnected) {
                            System.out.println("断开连接");
                        } else if (event.getState() == Event.KeeperState.Expired) {
                            System.out.println("会话超时");
                        } else if (event.getState() == Event.KeeperState.AuthFailed) {
                            System.out.println("认证失败");
                        }
                    }
                }
            });

            countDownLatch.await();

        } catch (Exception e) {
            e.printStackTrace();
        }
    }

    // 获取锁
    public void acquireLock() throws Exception {
        createLock();
        attemptLock();
    }

    // 创建锁
    private void createLock() throws Exception {
        // 判断Locks是否存在
        Stat stat = zooKeeper.exists(LOCK_ROOT_PATH, false);
        if(stat == null) {
            // 不存在该节点则创建一个持久化节点，数据内容不重要可直接为空
            zooKeeper.create(LOCK_ROOT_PATH, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);
        }

        // 创建临时有序节点，并获取节点名称
        lockPath = zooKeeper.create(LOCK_ROOT_PATH + "/" + LOCK_NODE_NAME, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL);
        System.out.println("节点创建完成：" + lockPath);
    }

    // 监视器
    Watcher watcher = new Watcher() {
        @Override
        public void process(WatchedEvent event) {

            // 监听上一个节点什么时候被删除（即释放了锁）
            if(event.getType() == Event.EventType.NodeDeleted) {
                synchronized (this) {
                    notify();
                }
            }
        }
    };

    // 尝试获取锁
    private void attemptLock() throws Exception {
        List&lt;String&gt; children = zooKeeper.getChildren(LOCK_ROOT_PATH, false);
        Collections.sort(children);
        // 获取当前lockPath在所有子节点中的位次
        // lockPath的内容为：/Locks/Lock_00000001，children中的内容只有子节点内容：Lock_00000001，所以需要对lockPath进行截取
        int index = children.indexOf(lockPath.substring(LOCK_ROOT_PATH.length() + 1));

        // 如果当前lockPath在所有子节点中的顺序为第一位，则说明此时应该此节点获得锁
        if(index == 0) {
            System.out.println("获取锁成功");
            return;
        } else {  // 排队中
            // 监视当前节点排队的前一个节点,看上一个节点是否被删除。如果上一个节点删除则意味着上一个节点已经释放锁，自己可以获取锁。
            String path = children.get(index - 1);
            Stat stat = zooKeeper.exists(LOCK_ROOT_PATH + "/" + path, watcher);

            // 接收一下添加监视时返回的节点状态。防止出现添加监视时上一个节点释放锁的情况
            if(stat == null) {
                // 在添加监视时，上一个节点释放了锁
            } else {
                // 上一个节点在此时还在排队中或正在执行中，还没有释放锁
                synchronized (watcher) {
                    watcher.wait(); // 等待上一个节点释放锁
                }
                // 当上一个节点被删除（即释放了锁），当前节点再次尝试获取锁
                attemptLock();
            }
        }
    }

    public void releaseLock() throws Exception {
        zooKeeper.delete(this.lockPath, -1);
        zooKeeper.close();
        System.out.println("锁已经释放：" + this.lockPath);
    }

    public static void main(String[] args) throws Exception{
        MyLock myLock = new MyLock();
        myLock.createLock();
    }

}
复制]]></description><link>05、中间件\03、zookeeper\05、zookeeper-实战应用.html</link><guid isPermaLink="false">05、中间件/03、Zookeeper/05、Zookeeper 实战应用.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 21 Mar 2024 14:24:29 GMT</pubDate></item><item><title><![CDATA[06、监控相关]]></title><description><![CDATA[ 
 <br><br>Zookeeper 支持某些特定的四字命令与其的交互，它们大多是查询命令，用来获取 zookeeper 服务的当前状态及相关信息。<br>用户在客户端可以通过 telnet 或 nc 向 zookeeper 提交相应命令。<br>Zookeeper常用四字命令：<br><br>使用四字命令前，需要先在 zoo.cfg 配置文件中添加配置：<br>4lw.commands.whitelist=*
复制<br>否则会报错：<br>
xx命令 is not executed because it is not in the whitelist.
<br>也可以在 zkServer.sh中指定java参数：<br>else
    echo "JMX disabled by user request" &gt;&amp;2
    ZOOMAIN="org.apache.zookeeper.server.quorum.QuorumPeerMain"
fi
# 在该处下面为ZOOMAIN添加参数
ZOOMAIN="-Dzookeeper.4lw.commands.whitelist=* ${ZOOMAIN}"
复制<br>使用telnet执行四字监控命令：<br>
安装telnet命令：yum install -y telnet<br>telnet 192.168.29.137 2181
# 连接上之后输入要执行的四字命令
mntr
复制<br>使用nc执行四字命令：<br>需要先安装nc：yum install -y nc<br>echo mntr | nc 192.168.29.137 2181
复制<br><br>输出相关服务配置的详细信息：<br>对应zoo.cfg中的配置：<br><br><br>列出所有连接到这台服务器的客户端连接/会话的详细信息。<br>
当有客户端连接到服务器上时，使用cons命令可以看到会话的详细信息：<br>
使用一个客户端连接到服务器上，但是可以看到两个客户端连接：因为使用 nc 命令时，nc 命令也会在服务器上产生一个会话
<br> /192.168.29.137:59072[1](queued=0,recved=1,sent=1,sid=0x1000004eac00000,lop=SESS,est=1616031182009,to=30000,lcxid=0x0,lzxid=0x400000001,lresp=1719290,llat=11,minlat=0,avglat=11,maxlat=11)
 /192.168.29.137:59074[0](queued=0,recved=1,sent=0)
复制<br>输出的内容：<br><br><br>重置当前这台服务器所有连接/会话的统计信息。<br><br>列出未经处理的会话和临时节点。<br>SessionTracker dump:
Global Sessions(2):
0x1000004eac00000	30000ms
0x1000004eac00001	30000ms
ephemeral nodes dump:
Sessions with Ephemerals (2):

# 会话1创建的临时节点：/tmp1、/tmp2
0x1000004eac00000:
	/tmp1
	/tmp2
	
# 会话2创建的临时节点：/tmpA、/tmpB
0x1000004eac00001:
	/tempB
	/tempA
Connections dump:
Connections Sets (3)/(3):
0 expire at Thu Mar 18 09:54:42 CST 2021:
1 expire at Thu Mar 18 09:54:52 CST 2021:
	ip: /192.168.29.137:59104 sessionId: 0x0
2 expire at Thu Mar 18 09:55:02 CST 2021:
	ip: /192.168.29.137:59072 sessionId: 0x1000004eac00000
	ip: /192.168.29.137:59102 sessionId: 0x1000004eac00001
复制<br><br>输出关于服务器的环境配置信息。<br>可以输出系统信息、zookeeper依赖的java信息、zookeeper信息（安装用户、安装路径等）。<br><br>测试服务器是否处于正确运行状态。<br>服务器正会响应：imok。<br><br>输出服务器的详细信息。与srvr相似，但多了每个连接的会话信息。<br>stat命令输出内容：<br>Zookeeper version: 3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 19:49 GMT
Clients:
 /192.168.29.137:59102[1](queued=0,recved=59,sent=59)
 /192.168.29.137:59114[0](queued=0,recved=1,sent=0)

Latency min/avg/max: 0/0/11
Received: 236
Sent: 235
Connections: 2
Outstanding: 0
Zxid: 0x400000007
Mode: follower
Node count: 7
复制<br>srvr命令输出内容：<br>Zookeeper version: 3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 19:49 GMT
Latency min/avg/max: 0/0/11
Received: 291
Sent: 290
Connections: 2
Outstanding: 0
Zxid: 0x400000007
Mode: follower
Node count: 7
复制<br><br><br>重置server状态。<br><br>列出服务器watchers的简洁信息。<br>输出内容：<br>2 connections watching 2 paths
Total watches:2
复制<br><br>通过session分组，列出warcher的所有节点，它的输出时一个与watcher相关的会话节点列表。<br>输出内容：<br>0x1000004eac00001
	/tempA
0x1000004eac00002
	/tmp1
复制<br><br>通过路径分组，列出所有的watcher的sessionId信息。<br>输出内容：<br>/tmp1
	0x1000004eac00002
/tempA
	0x1000004eac00001
复制<br><br>列出服务器的健康状态。<br>输出内容：<br>zk_version	3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 19:49 GMT
zk_avg_latency	0
zk_max_latency	11
zk_min_latency	0
zk_packets_received	409
zk_packets_sent	408
zk_num_alive_connections	3
zk_outstanding_requests	0
zk_server_state	follower
zk_znode_count	8
zk_watch_count	2
zk_ephemerals_count	3
zk_approximate_data_size	211
zk_open_file_descriptor_count	65
zk_max_file_descriptor_count	4096
复制<br><br><br><br>客户端工具<br>下载地址：<a data-tooltip-position="top" aria-label="https://issues.apache.org/jira/secure/attachment/12436620/ZooInspector.zip" rel="noopener" class="external-link" href="https://issues.apache.org/jira/secure/attachment/12436620/ZooInspector.zip" target="_blank">ZooInspector</a><br>解压后，进入目录 ZooInspector\build，运行 zookeeper-dev-ZooInspector.jar<br>java -jar zookeeper-dev-ZooInspector.jar
复制<br>连接上 Zookeeper 服务器之后，就可以图形化的进行节点的添加、数据修改、删除等操作。<br><br>下载地址：<a data-tooltip-position="top" aria-label="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fvran-dev%2FPrettyZoo%2Freleases" rel="noopener" class="external-link" title="下载地址" href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fvran-dev%2FPrettyZoo%2Freleases" target="_blank">下载地址</a>。<br>一个基于Apache Curator和JavaFX实现的Zookeeper图形化管理客户端。<br>使用了 Java 的模块化（Jigsaw）技术，并基于 JPackage 打包了多平台的可运行文件（无需要额外安装 Java 运行时）。<br>目前已提供了 mac（dmg 文件）、Linux（deb 和 rpm 文件）、windows（msi&nbsp;文件） 的安装包。<br><img alt="assets/06、监控相关/img-20240321_212244.png" src="\05、中间件\03、zookeeper\assets\06、监控相关\img-20240321_212244.png" style="width: 625px; max-width: 100%;"><br>
<br>
server info<br>
<img alt="assets/06、监控相关/a59462641505e65092419817276599eb.gif" src="\05、中间件\03、zookeeper\assets\06、监控相关\a59462641505e65092419817276599eb.gif" style="width: 625px; max-width: 100%;">

<br>
node info<br>
<img alt="assets/06、监控相关/857b29bbb196a6f7da96d84f0480af21.gif" src="\05、中间件\03、zookeeper\assets\06、监控相关\857b29bbb196a6f7da96d84f0480af21.gif" style="width: 625px; max-width: 100%;">

<br>
node data highlight

<br><img alt="assets/06、监控相关/f0d9c5c8dc6caffa27b2d5fa7a2505c5.gif" src="\05、中间件\03、zookeeper\assets\06、监控相关\f0d9c5c8dc6caffa27b2d5fa7a2505c5.gif" style="width: 625px; max-width: 100%;"><br>
<br>
node search<br>
<img alt="assets/06、监控相关/f4a1339d666148a85c76844ca733d2d9.gif" src="\05、中间件\03、zookeeper\assets\06、监控相关\f4a1339d666148a85c76844ca733d2d9.gif" style="width: 625px; max-width: 100%;">

<br>
terminal<br>
<img alt="assets/06、监控相关/18bcff5836ee93c18afaa5df20c8f167.gif" src="\05、中间件\03、zookeeper\assets\06、监控相关\18bcff5836ee93c18afaa5df20c8f167.gif" style="width: 625px; max-width: 100%;">

<br>
4-letter

<br><img alt="assets/06、监控相关/ed010fd4336b477ad113715d51463566 1.gif" src="\05、中间件\03、zookeeper\assets\06、监控相关\ed010fd4336b477ad113715d51463566-1.gif" style="width: 625px; max-width: 100%;"><br><br>下载相关文件：<br>
<br>
进入 github，搜索 alibaba/taokeeper

<br>
切换到 release 分支

<br>
进入 release 目录

<br>
下载 taokeeper.sql、taokeeper-monitor.tar.gz、taokeeper-monitor-config.properties 文件

<br>使用 docker 安装 mySQL 数据库：<br> # 拉取mysql镜像
 docker pull hub.c.163.com/library/mysql:latest
 # 配置数据库名、root密码，并运行容器
 docker run -d -p 3306:3306 -e MYSQL_DATABASE=taokeeper -e MYSQL_ROOT_PASSWORD=taokeeper hub.c.163.com/library/mysql
复制<br>使用 dbeaver 连接上 mysql，执行 taokeeper. Sql，创建对应的表：<br>CREATE DATABASE taokeeper;
USE taokeeper;

-- ----------------------------
-- Table: alarm_settings
-- ----------------------------
DROP TABLE IF EXISTS `alarm_settings`;
CREATE TABLE `alarm_settings` (
  `alarm_settings_id` int(11) NOT NULL auto_increment,
  `cluster_id` int(11) NOT NULL,
  `wangwang_list` varchar(255) default NULL,
  `phone_list` varchar(255) default NULL,
  `email_list` varchar(255) default NULL,
  `max_delay_of_check` varchar(255) default NULL,
  `max_cpu_usage` varchar(255) default NULL,
  `max_memory_usage` varchar(255) default NULL,
  `max_load` varchar(255) default NULL,
  `max_connection_per_ip` varchar(255) default NULL,
  `max_watch_per_ip` varchar(255) default NULL,
  `data_dir` varchar(255) default NULL,
  `data_log_dir` varchar(255) default NULL,
  `max_disk_usage` varchar(255) default NULL,
  PRIMARY KEY  (`alarm_settings_id`),
  UNIQUE KEY `uk_alarm_settings_cid` (`cluster_id`)
) ENGINE=InnoDB DEFAULT CHARSET=gbk;

-- ----------------------------
-- Table taokeeper_settings
-- ----------------------------
DROP TABLE IF EXISTS `taokeeper_settings`;
CREATE TABLE `taokeeper_settings` (
  `settings_id` int(11) NOT NULL auto_increment,
  `env_name` varchar(20) default NULL,
  `max_threads_of_zookeeper_check` int(5) default NULL,
  `description` varchar(255) default NULL,
  PRIMARY KEY  (`settings_id`)
) ENGINE=InnoDB DEFAULT CHARSET=gbk;

-- ----------------------------
-- Table: taokeeper_stat
-- ----------------------------
DROP TABLE IF EXISTS `taokeeper_stat`;
CREATE TABLE `taokeeper_stat` (
  `cluster_id` int(11) NOT NULL,
  `server` varchar(30) NOT NULL COMMENT '127.0.0.1:2181',
  `stat_date_time` datetime NOT NULL COMMENT '统计时间 2012-01-05 14:56:20',
  `stat_date` date NOT NULL,
  `connections` int(11) DEFAULT NULL,
  `watches` int(11) DEFAULT NULL COMMENT '订阅者数目',
  `send_times` bigint(20) unsigned DEFAULT 0,
  `receive_times` bigint(20) unsigned DEFAULT 0,
  `node_count` int(11) DEFAULT 0,
  PRIMARY KEY (`cluster_id`,`server`,`stat_date_time`)
) ENGINE=InnoDB DEFAULT CHARSET=gbk;


-- ----------------------------
-- Table: zookeeper_cluster
-- ----------------------------
DROP TABLE IF EXISTS `zookeeper_cluster`;
CREATE TABLE `zookeeper_cluster` (
  `cluster_id` int(11) NOT NULL auto_increment,
  `cluster_name` varchar(255) NOT NULL,
  `server_list` varchar(255) NOT NULL,
  `description` varchar(255) default NULL,
  PRIMARY KEY  (`cluster_id`)
) ENGINE=InnoDB DEFAULT CHARSET=gbk;
复制<br>修改 taokeeper-monitor-config.properties 配置文件中的数据库地址、数据文件路径等配置：<br>创建数据文件夹时，真正的数据存储在 basePath 路径下的 ZooKeeperClientThroughputStat 文件夹中，所以还需在 dataStoreBasePath 指定的文件夹下再创建 ZooKeeperClientThroughputStat 文件夹。<br>即创建文件夹：D:/temp/zookeeper/data/ZooKeeperClientThroughputStat<br>systemInfo.envName=TEST
#DBCP
dbcp.driverClassName=com.mysql.jdbc.Driver
dbcp.dbJDBCUrl=jdbc:mysql://192.168.29.131:3306/taokeeper
dbcp.characterEncoding=GBK
dbcp.username=root
dbcp.password=taokeeper
dbcp.maxActive=30
dbcp.maxIdle=10
dbcp.maxWait=10000
#SystemConstant
# 还需在该文件夹下创建ZooKeeperClientThroughputStat文件夹
SystemConstent.dataStoreBasePath=D:/temp/zookeeper/data
#通过SSH登录Zookeeper，所以需要配置服务器用户名密码。
SystemConstant.userNameOfSSH=zookeeper
SystemConstant.passwordOfSSH=zookeeper
复制<br>解压 taokeeper-monitor.tar.gz ，将 taokeeper-monitor.config.properties 放到 D:/temp/zookeeper 文件夹中。<br>进入 WEB-INF/classes 文件夹，修改 log4j.properties 日志配置，并创建对应的日志文件夹。<br>将程序部署到 tomcat 中，修改 tomcat 的启动文件 catalina.sh，在其中加入 taokeeper-monitor-config.oroperties 配置文件的路径：<br>set "JAVA_OPTS=%JAVA_OPTS% -DconfigFilePath=D:/temp/zookeeper/taokeeper-monitor-config.properties"
复制<br>运行 startup.bat 启动 tomcat。<br>打开浏览器访问：<a rel="noopener" class="external-link" href="http://localhost:8080/taokeeper-monitor" target="_blank">http://localhost:8080/taokeeper-monitor</a> 即可访问。]]></description><link>05、中间件\03、zookeeper\06、监控相关.html</link><guid isPermaLink="false">05、中间件/03、Zookeeper/06、监控相关.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 21 Mar 2024 13:55:26 GMT</pubDate><enclosure url="05、中间件\03、zookeeper\assets\06、监控相关\img-20240321_212244.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;05、中间件\03、zookeeper\assets\06、监控相关\img-20240321_212244.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[★ 常见词汇含义 ★]]></title><description><![CDATA[ 
 <br><br><br>Development和Operations的组合词，是一种 执行规范（思想）<br>主要用于开发、测试、运维之间的沟通协作资源整合。<br>“.pic-0、常见词汇/image-20231019211459600.png” could not be found.<br>软件开发人员（Dev）和  IT运维技术人员（Ops）<br>]]></description><link>06、架构设计\01、架构基础\00、常见词汇.html</link><guid isPermaLink="false">06、架构设计/01、架构基础/00、常见词汇.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:46 GMT</pubDate></item><item><title><![CDATA[01、限流]]></title><description><![CDATA[ 
 <br><br>限流，就是对请求或并发数进行限制；<br>因服务资源有限、处理能力有限，为了保证系统的稳定性、可用性，系统以牺牲部分请求为代价或者延迟处理请求为代价，保证系统整体服务可用。<br>
<br>阈值：在一个单位时间内允许的请求量。如 QPS 限制为10，说明 1 秒内最多接受 10 次请求。
<br>拒绝策略：超过阈值的请求的拒绝策略，常见的拒绝策略有直接拒绝、排队等待等。
<br><br>常见的限流算法有：计数器、令牌桶、漏桶。<br><br>在单位时间内维护一个计数器，能够限制在每个固定的时间段内请求通过的次数，以达到限流的效果。<br><img src="\06、架构设计\01、架构基础\assets\01、限流\img-20240125_201605.png"><br>具体的实现可以是这样的：对于每次服务调用，可以通过&nbsp;AtomicLong#incrementAndGet()方法来给计数器加1并返回最新值，通过这个最新值和阈值进行比较。<br>import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicInteger;

public class FixedWindowCounter {

    private final int limit;  // 限制的请求数
    private final int windowSize;  // 窗口大小，单位秒
    private final AtomicInteger counter;  // 当前窗口内请求数
    private long lastTimestamp;  // 上次重置计数的时间戳

    public FixedWindowCounter(int limit, int windowSize) {
        this.limit = limit;
        this.windowSize = windowSize;
        this.counter = new AtomicInteger(0);
        this.lastTimestamp = System.currentTimeMillis();
    }

    public synchronized boolean allowRequest() {
        long currentTime = System.currentTimeMillis();
        if (currentTime - lastTimestamp &gt;= windowSize * 1000) {
            // 如果当前时间距离上次重置计数的时间超过窗口大小，则重置计数
            counter.set(0);
            lastTimestamp = currentTime;
        }

        int currentCount = counter.incrementAndGet();
        return currentCount &lt;= limit;
    }

    public static void main(String[] args) throws InterruptedException {
        FixedWindowCounter counter = new FixedWindowCounter(5, 1);  // 限制每秒最多5个请求

        for (int i = 0; i &lt; 10; i++) {
            if (counter.allowRequest()) {
                System.out.println("Allow request " + (i + 1));
            } else {
                System.out.println("Reject request " + (i + 1));
            }
            TimeUnit.MILLISECONDS.sleep(200);  // 模拟请求间隔
        }
    }
}
复制<br>优点：&nbsp;实现简单，理解容易。<br>缺点：<br>
<br>“突刺现象”：在单位时间 1 s 内的前 10 ms，已经通过了 100 个请求，那后面的 990 ms，只能眼巴巴的把请求拒绝，我们把这种现象称为。
<br>"边界效应"：无法处理窗口边界问题。因为在某个时间窗口内进行流量控制，就可能会出现窗口边界效应，即在时间窗口的边界处可能会有大量的请求被允许通过，从而导致突发流量。
<br><img src="\06、架构设计\01、架构基础\assets\01、限流\img-20240125_201811.png"><br><br>滑动窗口算法是对固定窗口算法的一种改进。在滑动窗口算法中，窗口的起止时间是动态的，窗口的大小固定。<br>
这种算法能够较好地处理窗口边界问题，但是实现相对复杂，需要记录每个请求的时间戳。<br>实现原理是：&nbsp;每来一个请求，就向后推一个时间窗口，计算这个窗口内的请求数量。如果请求数量超过限制就拒绝请求，否则就处理请求，并记录请求的时间戳。另外还需要一个任务清理过期的时间戳。<br><img src="\06、架构设计\01、架构基础\assets\01、限流\img-20240125_202107.png"><br>优点：&nbsp;解决了固定窗口算法的窗口边界问题，避免突发流量压垮服务器。<br>缺点：&nbsp;“突刺现象”依旧存在。例如：限流是每秒 100个，在第一毫秒发送了 1000个请求，达到限流，剩余窗口时间的请求都将会被拒绝。<br><br>漏桶限流算法是一种常用的流量整形（Traffic Shaping）和流量控制（Traffic Policing）的算法，它可以有效地控制数据的传输速率以及防止网络拥塞。<br>实现原理是：<br>
<br>一个固定容量的漏桶，按照固定速率出水（处理请求）；
<br>当流入水（请求数量）的速度过大会直接溢出（请求数量超过限制则直接拒绝）。
<br>桶里的水（请求）不够则无法出水（桶内没有请求则不处理）。
<br>当请求流量正常或者较小的时候，请求能够得到正常的处理。当请求流量过大时，漏桶限流算法可以通过丢弃部分请求来防止系统过载。<br>这种算法的一个重要特性是，输出数据的速率始终是稳定的，无论输入的数据流量如何变化。这就确保了系统的负载不会超过预设的阈值。但是，由于漏桶的出口速度是固定的，所以无法处理突发流量。此外，如果入口流量过大，漏桶可能会溢出，导致数据丢失。<br><img src="\06、架构设计\01、架构基础\assets\01、限流\img-20240125_203147.png"><br>import java.util.concurrent.Executors;  
import java.util.concurrent.ScheduledExecutorService;  
import java.util.concurrent.ScheduledFuture;  
import java.util.concurrent.TimeUnit;  
  
public class LeakyBucket {  
    private final int capacity;// 漏桶容量，即最大允许的并发请求数  
    private final int rate; // 漏桶的漏水速率，即每秒允许通过的请求数  
    private int water;// 漏桶中当前的水量，表示当前的并发请求数  
    private final ScheduledExecutorService scheduler;// 用于定期执行漏水操作的调度器  
  
    public LeakyBucket(int capacity, int rate) {  
        this.capacity = capacity;  
        this.rate = rate;  
        this.water = 0;  
        this.scheduler = Executors.newScheduledThreadPool(1);  
        scheduleLeak();// 启动定时漏水操作  
    }  
  
    public synchronized boolean submit() {  
        if (water &lt; capacity) {  
            water++;  
            return true; // 请求通过漏桶  
        } else {  
            return false; // 漏桶已满，请求被丢弃  
        }  
    }  
  
    private void scheduleLeak() {  
        ScheduledFuture&lt;?&gt; future = scheduler.scheduleAtFixedRate(() -&gt; {  
            synchronized (LeakyBucket.this) {  
                if (water &gt; 0) {  
                    water--;// 漏水，减少水量  
                }  
            }  
        }, 0, 1000 / rate, TimeUnit.MILLISECONDS);// 以固定速率执行漏水操作  
    }  
  
    public static void main(String[] args) {  
        LeakyBucket leakyBucket = new LeakyBucket(5, 2);  
  
        // 模拟多线程请求  
        for (int i = 1; i &lt;= 10; i++) {  
            int requestId = i;  
            new Thread(() -&gt; {  
                if (leakyBucket.submit()) {  
                    System.out.println("Request " + requestId + " is processed.");  
                } else {  
                    System.out.println("Request " + requestId + " is discarded.");  
                }  
            }).start();  
  
            try {  
                Thread.sleep(500); // 模拟请求间隔  
            } catch (InterruptedException e) {  
                e.printStackTrace();  
            }  
        }  
    }  
}
复制<br>优点：<br>
<br>平滑流量。由于漏桶算法以固定的速率处理请求，可以有效地平滑和整形流量，避免流量的突发和波动（类似于消息队列的削峰填谷的作用）。
<br>防止过载。当流入的请求超过桶的容量时，可以直接丢弃请求，防止系统过载。
<br>缺点：<br>
<br>无法处理突发流量：由于漏桶的出口速度是固定的，无法处理突发流量。例如，即使在流量较小的时候，也无法以更快的速度处理请求。
<br>可能会丢失数据：如果入口流量过大，超过了桶的容量，那么就需要丢弃部分请求。在一些不能接受丢失请求的场景中，这可能是一个问题。
<br>不适合速率变化大的场景：如果速率变化大，或者需要动态调整速率，那么漏桶算法就无法满足需求。
<br><br>通过维护一个令牌桶，该桶以固定的速率生成令牌，而系统中的请求需要获取令牌才能执行。当令牌桶中有足够的令牌时，请求可以被立即执行；否则，需要等待直到有足够的令牌。<br>实现原理：<br>
<br>系统以固定的速率向桶中添加令牌；
<br>当有请求到来时，会尝试从桶中移除一个（或 n 个）令牌，如果桶中有足够的令牌，则请求可以被处理或数据包可以被发送；
<br>如果桶中没有令牌，那么请求将被拒绝；
<br>桶中的令牌数不能超过桶的容量，如果新生成的令牌超过了桶的容量，那么新的令牌会被丢弃。
<br>令牌桶算法的一个重要特性是，它能够应对突发流量。当桶中有足够的令牌时，可以一次性处理多个请求，这对于需要处理突发流量的应用场景非常有用。但是又不会无限制的增加处理速率导致压垮服务器，因为桶内令牌数量是有限制的。<br><img src="\06、架构设计\01、架构基础\assets\01、限流\img-20240125_204209.png"><br>优点：<br>
<br>可以处理突发流量：令牌桶算法可以处理突发流量。当桶满时，能够以最大速度处理请求。这对于需要处理突发流量的应用场景非常有用。
<br>限制平均速率：在长期运行中，数据的传输率会被限制在预定义的平均速率（即生成令牌的速率）。
<br>灵活性：与漏桶算法相比，令牌桶算法提供了更大的灵活性。例如，可以动态地调整生成令牌的速率。
<br>缺点：<br>
<br>可能导致过载：如果令牌产生的速度过快，可能会导致大量的突发流量，这可能会使网络或服务过载。
<br>需要存储空间：令牌桶需要一定的存储空间来保存令牌，可能会导致内存资源的浪费。
<br>实现稍复杂：相比于计数器算法，令牌桶算法的实现稍微复杂一些。
<br><br><br><br>Guava RateLimiter 是由 Google Guava 库提供的一个限流工具。Guava 是 Google 提供的一套 Java 核心库，其中包括了很多对 Java 标准库的扩展和增强。RateLimiter 就是其中之一，它实现了令牌桶算法，用于限制某个操作以固定的频率进行调用。<br>
Guava RateLimiter 提供了令牌桶算法实现：<br>
平滑突发限流 (SmoothBursty)<br>
平滑预热限流(SmoothWarmingUp)
<br><br>RateLimiter 以固定的速率生成令牌，并在请求令牌时按照令牌桶的形式分发，允许一定程度的突发。<br>
适用于允许一定程度的突发请求，但整体速率是固定的，不会发生变化。<br>突发解释：<br>
如果令牌未使用，会生成一定数量的令牌并堆积起来，形成一个令牌桶。<br>
突发量：令牌桶的容量就是堆积的最大令牌数，它决定了允许的一次性突发请求数量。<br>样例代码：<br>import com.google.common.util.concurrent.RateLimiter;

public class SmoothBurstyExample {
    public static void main(String[] args) {
        // 创建一个 SmoothBursty 模式的 RateLimiter，每秒产生 5 个令牌
        RateLimiter rateLimiter = RateLimiter.create(5.0);

        // 模拟请求
        for (int i = 1; i &lt;= 10; i++) {
            double waitTime = rateLimiter.acquire(); // 请求令牌，返回需要等待的时间
            System.out.println("Request " + i + " acquired. Wait time: " + waitTime + "s");
        }
    }
}

复制<br><br>RateLimiter 会在一定的时间内逐渐增加生成令牌的速率，最终达到固定的速率。<br>
适用于系统启动时允许一定程度的预热，即初始时生成的令牌速率较低，随着时间的推移逐渐增加，直至达到设定的固定速率。<br>在预热阶段，RateLimiter 以较低的速率开始生成令牌，即初始速率。<br>创建方式：<br>RateLimiter.create(doublepermitsPerSecond, long warmupPeriod, TimeUnit unit)
//permitsPerSecond表示每秒新增的令牌数，
//warmupPeriod表示在从冷启动速率过渡到平均速率的时间间隔。
//unit时间单位
复制<br>样例代码：<br>import com.google.common.util.concurrent.RateLimiter;

public class SmoothWarmingUpExample {
    public static void main(String[] args) {
        // 创建一个 SmoothWarmingUp 模式的 RateLimiter，每秒产生 5 个令牌，预热时间为 3 秒
        RateLimiter rateLimiter = RateLimiter.create(5.0, 3, TimeUnit.SECONDS);

        // 模拟请求
        for (int i = 1; i &lt;= 10; i++) {
            double waitTime = rateLimiter.acquire(); // 请求令牌，返回需要等待的时间
            System.out.println("Request " + i + " acquired. Wait time: " + waitTime + "s");
        }
    }
}
复制<br><br>Sentinel 是由阿里巴巴开发的一款流量控制和熔断降级的开源框架。它最初由阿里巴巴集团的高德团队开发，用于应对分布式系统中的高并发流量，提供了一系列功能来保护系统的稳定性。<br><br>参考文章：<br><a rel="noopener" class="external-link" href="https://www.jb51.net/article/257674.htm#_label1" target="_blank">https://www.jb51.net/article/257674.htm#_label1</a><br><a rel="noopener" class="external-link" href="https://zhuanlan.zhihu.com/p/629800828" target="_blank">https://zhuanlan.zhihu.com/p/629800828</a>]]></description><link>06、架构设计\01、架构基础\01、限流.html</link><guid isPermaLink="false">06、架构设计/01、架构基础/01、限流.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:46 GMT</pubDate><enclosure url="06、架构设计\01、架构基础\assets\01、限流\img-20240125_201605.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;06、架构设计\01、架构基础\assets\01、限流\img-20240125_201605.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[分布式系统 - 分布式会话及实现方案]]></title><description><![CDATA[ 
 <br><br>
<br>单机 - Session + Cookie
<br>多机器

<br>在负载均衡侧 - Session 粘滞
<br>Session数据同步


<br>多机器，集群 - session集中管理，比如redis；目前方案上用的最多的是SpringSession，早前也有用tomcat集成方式的。
<br>无状态token，比如JWT
<br><br>Http 协议本身是无状态的，客户端只需要向服务器请求下载内容，客户端和服务器都不记录彼此的历史信息，每一次请求都是独立的。<br>因为浏览器与服务器是使用 socke 套接字进行通信，服务器将请求结果返回给浏览器之后，会关闭当前的 socket 链接，而且服务器也会在处理页面完毕之后销毁页面对象。<br>然而在 Web 应用的很多场景下需要维护用户状态才能正常工作 (是否登录等)，或者说提供便捷 (记住密码，浏览历史等)，状态的保持就是一个很重要的功能。因此在 web 应用开发里就出现了保持 http 链接状态的技术：一个是 cookie 技术，另一种是 session 技术。<br><br>Cookie 技术是 http 状态保持在客户端的解决方案，Cookie 就是由服务器发给客户端的特殊信息，而这些信息以文本文件的方式存放在客户端，然后客户端每次向服务器发送请求的时候都会带上这些特殊的信息。<br>当用户首次使用浏览器访问一个支持Cookie的网站的时候，用户会提供包括用户名在内的个人信息并且提交至服务器；接着，服务器在向客户端回传相应的超文本的同时也会发回这些个人信息，当然这些信息并不是存放在HTTP响应体（Response Body）中的，而是存放于HTTP响应头（Response Header）；当客户端浏览器接收到来自服务器的响应之后，浏览器会将这些信息存放在一个统一的位置。<br>存储在硬盘上的cookie 不可以在不同的浏览器间共享，可以在同一浏览器的不同进程间共享，比如两个IE窗口。这是因为每中浏览器存储cookie的位置不一样，比如<br>
<br>Chrome下的cookie放在：C:\Users\sharexie\AppData\Local\Google\Chrome\User Data\Default\Cache <br>

<br>Firefox下的cookie放在：C:\Users\sharexie\AppData\Roaming\Mozilla\Firefox\Profiles\tq2hit6m.default\cookies.sqlite （倒数第二个文件名是随机的文件名字）<br>

<br>Ie下的cookie放在：C:\Users\Administrator\AppData\Roaming\Microsoft\Windows\Cookies
<br><br>cookie的内容主要包括：名字，值，过期时间，路径和域。路径与域合在一起就构成了cookie的作用范围。<br>如果不设置过期时间，则表示这个cookie的生命期为浏览器会话期间，只要关闭浏览器窗口，cookie就消失了，这种生命期为浏览器会话期的 cookie被称为会话cookie。会话cookie一般不存储在硬盘上而是保存在内存里。如果设置了过期时间，浏览器就会把cookie保存到硬盘上，关闭后再次打开浏览器，这些cookie仍然有效直到超过设定的过期时间。<br><br>cookie 的使用是由浏览器按照一定的原则在后台自动发送给服务器的。<br>当客户端二次向服务器发送请求的时候，浏览器检查所有存储的cookie，如果某个cookie所声明的作用范围大于等于将要请求的资源所在的位置，则把该cookie附在请求资源的HTTP请求头上发送给服务器。有了Cookie这样的技术实现，服务器在接收到来自客户端浏览器的请求之后，就能够通过分析存放于请求头的Cookie得到客户端特有的信息，从而动态生成与该客户端相对应的内容。通常，我们可以从很多网站的登录界面中看到“请记住我”这样的选项，如果你勾选了它之后再登录，那么在下一次访问该网站的时候就不需要进行重复而繁琐的登录动作了，而这个功能就是通过Cookie实现的。<br><br>Session一般叫做会话，Session技术是http状态保持在服务端的解决方案，它是通过服务器来保持状态的。我们可以把客户端浏览器与服务器之间一系列交互的动作称为一个 Session。是服务器端为客户端所开辟的存储空间，在其中保存的信息就是用于保持状态。因此，session是解决http协议无状态问题的服务端解决方案，它能让客户端和服务端一系列交互动作变成一个完整的事务。<br><br>那么Session在何时创建呢？当然还是在服务器端程序运行的过程中创建的，不同语言实现的应用程序有不同创建Session的方法。<br>当客户端第一次请求服务端，当server端程序调用 HttpServletRequest.getSession(true)这样的语句时的时候，服务器会为客户端创建一个session，并将通过特殊算法算出一个session的ID，用来标识该session对象。<br>Session存储在服务器的内存中(tomcat服务器通过StandardManager类将session存储在内存中)，也可以持久化到file，数据库，memcache，redis等。客户端只保存sessionid到cookie中，而不会保存session。<br>浏览器的关闭并不会导致Session的删除，只有当超时、程序调用HttpSession.invalidate()以及服务端程序关闭才会删除。<br>
<br>Tomcat中的Session创建
<br>ManagerBase是所有session管理工具类的基类，它是一个抽象类，所有具体实现session管理功能的类都要继承这个类，该类有一个受保护的方法，该方法就是创建sessionId值的方法：<br>(tomcat的session的id值生成的机制是一个随机数加时间加上jvm的id值，jvm的id值会根据服务器的硬件信息计算得来，因此不同jvm的id值都是唯一的)。<br>StandardManager类是tomcat容器里默认的session管理实现类，它会将session的信息存储到web容器所在服务器的内存里。 PersistentManagerBase也是继承ManagerBase类，它是所有持久化存储session信息的基类，PersistentManager继承了PersistentManagerBase，但是这个类只是多了一个静态变量和一个getName方法，目前看来意义不大，对于持久化存储session，tomcat还提供了StoreBase的抽象类，它是所有持久化存储session的基类，另外tomcat还给出了文件存储FileStore和数据存储JDBCStore两个实现。<br><br>cookie和session的方案虽然分别属于客户端和服务端，但是服务端的session的实现对客户端的cookie有依赖关系的，服务端执行session机制时候会生成session的id值，这个id值会发送给客户端，客户端每次请求都会把这个id值放到http请求的头部发送给服务端，而这个id值在客户端会保存下来，保存的容器就是cookie，因此当我们完全禁掉浏览器的cookie的时候，服务端的session也会不能正常使用。<br><br>Session 优点：  <br>
<br>Session 中的信息存储在服务端，相比于 cookie 就在一定程度上加大了数据的安全性。  
<br>Session 数据存储在服务端，相比于 jwt 方便进行管理，也就是说当用户登录和主动注销，只需要添加删除对应的 session 就可以，这样管理起来很方便。<br>
Session 缺点：  
<br>Session 存储在服务端，这就增大了服务器的开销，当用户多的情况下，服务器性能会大大降低。  
<br>因为是基于 cookie 来进行用户识别的, cookie 如果被截获，用户就会很容易受到跨站请求伪造的攻击。  
<br>用户认证之后，服务端做认证记录，如果认证的记录被保存在内存中的话，这意味着用户下次请求还必须要请求在这台服务器上, 这样才能拿到授权的资源，这样在分布式的应用上，相应的限制了负载均衡器的能力。这也意味着限制了应用的扩展能力。
<br>Cookie 优点：  <br>
<br>简单性 Cookie 是一种基于文本的轻量结构，包含简单的键值对。  
<br>数据持久性虽然客户端计算机上 Cookie 的持续时间取决于客户端上的 Cookie 过期处理和用户干预，Cookie 通常是客户端上持续时间最长的数据保留形式。<br>
Cookie 缺点：  
<br>大小受到限制，大多数浏览器对 Cookie 的大小有 4096 字节的限制，尽管在当今新的浏览器和客户端设备版本中，支持 8192 字节的 Cookie 大小已愈发常见。  
<br>非常不安全，cookie 将数据裸露在浏览器中，这样大大增大了数据被盗取的风险，所有我们不应该将中要的数据放在 cookie 中，或者将数据加密处理。  
<br>容易被 csrf 攻击，可以设置 csrf_token 来避免攻击。
<br><br>
无状态的token或者有状态的Session集中管理是目前最为常用的方案。
<br>下面主要讨论的有状态的分布式 Session 会话：<br><br>
为什么这种方案到目前还有很多项目使用呢？因为不需要在项目代码侧改动，而是只需要在负载均衡侧改动。
<br>方案即将客户端的每次请求都转发至同一台服务器，这就需要负载均衡器能够根据每次请求的会话标识（SessionId）来进行请求转发，如下图所示。<br><img src="\06、架构设计\02、分布式系统\assets\分布式系统-分布式会话及实现方案\img-20240318_220818.png"><br>这种方案实现比较简单，对于Web服务器来说和单机的情况一样。但是可能会带来如下问题：<br>
<br>如果有一台服务器宕机或者重启，那么这台机器上的会话数据会全部丢失。
<br>会话标识是应用层信息，那么负载均衡要将同一个会话的请求都保存到同一个Web服务器上的话，就需要进行应用层（第7层）的解析，这个开销比第4层大。
<br>负载均衡器将变成一个有状态的节点，要将会话保存到具体Web服务器的映射。和无状态节点相比，内存消耗更大，容灾方面也会更麻烦。
<br><br>Session Replication 的方案则不对负载均衡器做更改，而是在Web服务器之间增加了会话数据同步的功能，各个服务器之间通过同步保证不同Web服务器之间的Session数据的一致性，如下图所示。<br><img src="\06、架构设计\02、分布式系统\assets\分布式系统-分布式会话及实现方案\img-20240318_220925.png"><br>Session Replication 方案对负载均衡器不再有要求，但是同样会带来以下问题：<br>
<br>同步Session数据会造成额外的网络带宽的开销，只要Session数据有变化，就需要将新产生的Session数据同步到其他服务器上，服务器数量越多，同步带来的网络带宽开销也就越大。
<br>每台Web服务器都需要保存全部的Session数据，如果整个集群的Session数量太多的话，则对于每台机器用于保存Session数据的占用会很严重。
<br><br>Session 数据集中存储方案则是将集群中的所有Session集中存储起来，Web服务器本身则并不存储Session数据，不同的Web服务器从同样的地方来获取Session，如下图所示。<br><img src="\06、架构设计\02、分布式系统\assets\分布式系统-分布式会话及实现方案\img-20240318_220952.png"><br>相对于Session Replication方案，此方案的Session数据将不保存在本机，并且Web服务器之间也没有了Session数据的复制，但是该方案存在的问题在于：<br>
<br>读写Session数据引入了网络操作，这相对于本机的数据读取来说，问题就在于存在时延和不稳定性，但是通信发生在内网，则问题不大。
<br>如果集中存储Session的机器或集群出现问题，则会影响应用。
<br><br>Cookie Based 方案是将Session数据放在Cookie里，访问Web服务器的时候，再由Web服务器生成对应的Session数据，如下图所示。<br><img src="\06、架构设计\02、分布式系统\assets\分布式系统-分布式会话及实现方案\img-20240318_221056.png"><br>但是Cookie Based 方案依然存在不足：<br>
<br>Cookie长度的限制。这会导致Session长度的限制。
<br>安全性。Seesion数据本来是服务端数据，却被保存在了客户端，即使可以加密，但是依然存在不安全性。
<br>带宽消耗。这里不是指内部Web服务器之间的宽带消耗，而是数据中心的整体外部带宽的消耗。
<br>性能影响。每次HTTP请求和响应都带有Seesion数据，对Web服务器来说，在同样的处理情况下，响应的结果输出越少，支持的并发就会越高。
<br><br>JSON Web Token (JWT)，它是目前最流行的跨域身份验证解决方案<br>JWT 的精髓在于：“去中心化”，数据是保存在客户端的。<br>一个 JWT 实际上就是一个字符串，它由三部分组成：头部 (Header)、载荷 (Payload) 与签名 (signature)<br><br>使用基于 Token 的身份验证方法，在服务端不需要存储用户的登录记录。大概的流程是这样的：<br> 1、客户端通过用户名和密码登录服务器；<br>
2、服务端对客户端身份进行验证；<br>
3、服务端对该用户生成 Token，返回给客户端；<br>
4、客户端将 Token 保存到本地浏览器，一般保存到 cookie 中；<br>
5、客户端发起请求，需要携带该 Token；<br>
6、服务端收到请求后，首先验证 Token，之后返回数据。<br>优点：<br>
<br>无状态、可扩展 ：在客户端存储的 Token 是无状态的，并且能够被扩展。基于这种无状态和不存储 Session 信息，负载均衡器能够将用户信息从一个服务传到其他服务器上。
<br>安全：请求中发送 token 而不再是发送 cookie 能够防止 CSRF (跨站请求伪造)。
<br>可提供接口给第三方服务：使用 token 时，可以提供可选的权限给第三方应用程序。
<br>多平台跨域
<br>Jwt 优点：<br>
1、因为 json 的通用性，jwt 可以支持跨语言请求，像 JAVA, JavaScript, NodeJS, PHP 等很多语言都可以使用。<br>
2、因为有了 payload 部分，所以 JWT 可以在自身存储一些其他业务逻辑所必要的非敏感信息。<br>
3、便于传输，jwt 的构成非常简单，字节占用很小，所以它是非常便于传输的。<br>
4、它不需要在服务端保存会话信息, 所以它易于应用的扩展，即信息不保存在服务端，不会存在 session 扩展不方便的情况。<br>Jwt 缺点：<br>
1、登录状态信息续签问题。比如设置 token 的有效期为一个小时，那么一个小时后，如果用户仍然在这个 web 应用上，这个时候当然不能指望用户再登录一次。目前可用的解决办法是在每次用户发出请求都返回一个新的 token，前端再用这个新的 token 来替代旧的，这样每一次请求都会刷新 token 的有效期。但是这样，需要频繁的生成 token。另外一种方案是判断还有多久这个 token 会过期，在 token 快要过期时，返回一个新的 token。  <br>2、用户主动注销。JWT 并不支持用户主动退出登录，当然，可以在客户端删除这个 token，但在别处使用的 token 仍然可以正常访问。为了支持注销，我的解决方案是在注销时将该 token 加入黑名单。  <br>使用 jwt 注意点：<br>
1、在 payload 中不应该存放敏感信息，以为该部分客户端是可以解密的。<br>
2、secret_key 不能泄露。<br><br>存储差异<br>
Cookie 信息和 jwt 存储在客户端，session 信息存储在服务端，但是 cookie 是浏览器客户端独有的。]]></description><link>06、架构设计\02、分布式系统\分布式系统-分布式会话及实现方案.html</link><guid isPermaLink="false">06、架构设计/02、分布式系统/分布式系统 - 分布式会话及实现方案.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Mon, 18 Mar 2024 14:25:38 GMT</pubDate><enclosure url="06、架构设计\02、分布式系统\assets\分布式系统-分布式会话及实现方案\img-20240318_220818.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;06、架构设计\02、分布式系统\assets\分布式系统-分布式会话及实现方案\img-20240318_220818.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[0]]></title><description><![CDATA[ 
 <br><a rel="noopener" class="external-link" href="https://blog.csdn.net/qq_42324086/article/details/121184789" target="_blank">https://blog.csdn.net/qq_42324086/article/details/121184789</a><br><a rel="noopener" class="external-link" href="https://blog.csdn.net/weixin_52880572/article/details/125794836?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-125794836-blog-128910539.235%5Ev43%5Epc_blog_bottom_relevance_base4&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-125794836-blog-128910539.235%5Ev43%5Epc_blog_bottom_relevance_base4&amp;utm_relevant_index=2" target="_blank">https://blog.csdn.net/weixin_52880572/article/details/125794836?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-125794836-blog-128910539.235%5Ev43%5Epc_blog_bottom_relevance_base4&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-125794836-blog-128910539.235%5Ev43%5Epc_blog_bottom_relevance_base4&amp;utm_relevant_index=2</a>]]></description><link>06、架构设计\03、微服务架构\springboot\0.html</link><guid isPermaLink="false">06、架构设计/03、微服务架构/SpringBoot/0.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:45 GMT</pubDate></item><item><title><![CDATA[01、虚拟化Dorcker]]></title><description><![CDATA[ 
 <br><br><br>虚拟化（Virtualization）是一种资源管理技术。将计算机的各种实体资源（服务器、网络、内存及存储等），以抽象、转换后呈现出来，打破实体结构间的不可切割的障碍，使用户可以用更好的方式来利用这些资源。<br><br><br>通过在一台物理计算机上运行多个虚拟机或容器，可以更有效地利用计算资源，降低硬件成本。<br><br>虚拟化使得应用程序和环境可以被打包为独立的虚拟机或容器，可以方便地在不同的计算环境中部署和迁移。<br><br>虚拟化技术提供了隔离的执行环境，使得不同的虚拟机或容器之间相互隔离，提高了安全性和稳定性。<br><br>通过虚拟化，可以更方便地管理和维护计算环境，包括快速部署、备份和恢复等操作。<br><br><br>硬件物理平台本身提供了对特殊指令的截获和重定向的支持。支持虚拟化的硬件，也是一些基于硬件实现软件虚拟化技术的关键。在基于硬件实现软件虚拟化的技术中，在硬件是实现虚拟化的基础，硬件(主要是CPU)会为虚拟化软件提供支持，从而实现硬件资源的虚拟化。<br>支持虚拟化的硬件有：<br>
<br>
Intel-VT-(Intel Virtualization Technology)，Intel公司为解决纯软件虚拟化解决方案在可靠性、安全性和性能上的不足而引进的技术。它可以让一个CPU工作起来像多个CPU在并行运行，从而使得在一部电脑内同时运行多个操作系统成为可能

<br>
AMD-V-(AMD Virtualization)，是AMD公司的虚拟化技术。它是对x86处理器系统架构的一组硬件扩展和硬件辅助虚拟化技术，可以简化纯软件的虚拟化解决方案，改进VMM（虚拟机监视器）的设计，更充分地利用硬件资源，提高服务器和数据中心的虚拟化效率

<br><br>软件虚拟化就是利用软件技术，在现有的物理平台上实现对物理平台访问的截获和模拟。在软件虚拟化技术中，有些技术不需要硬件支持，如：QEMU；而有些软件虚拟化技术，则依赖硬件支持，如：VMware、KVM。<br>对软件虚拟化进行细分，又可以分为以下几类：<br>
<br>完全虚拟化：（Full Virtualization）虚拟机模拟完整的底层硬件环境和特权指令的执行过程，使客户机操作系统可以独立运行。支持完全虚拟化的软件有：Parallels Workstation、VirtualBox、Virtual Iron、Oracle VM、Virtual PC、Virtual Server、Hyper-V、VMware Workstation、QEMU等
<br>硬件辅助虚拟化：（Hardware-assisted Virtualization）是指通过硬件辅助支持模拟运行环境，使客户机操作系统可以独立运行，实现完全虚拟化的功能。支持硬件辅助虚拟化的软件有：Linux KVM、VMware Workstation、VMware Fusion、Virtual PC、Xen、VirtualBox、Parallels Workstation等
<br>部分虚拟化：（Partial Virtualization）只针对部分硬件资源进行虚拟化，虚拟机模拟部分底层硬件环境，特别是地址空间。这样的环境支持资源共享和线程独立，但是不允许建立独立的客户机操作系统。
<br>平行虚拟化：（Para-Virtualization）虚拟机不需要模拟硬件，而是将部分硬件接口以软件的形式提供给客户机操作系统。如：早期的Xen。
<br>操作系统层虚拟化：（OS-level virtualization）这种技术将操作系统内核虚拟化，可以允许使用者空间软件实例被分割成几个独立的单元，在内核中运行，而不是只有一个单一实例运行。这个软件实例，也被称为是一个容器（containers）、虚拟引擎（Virtualization engine）、虚拟专用服务器（virtual private servers）。每个容器的进程是独立的，对于使用者来说，就像是在使用自己的专用服务器。 Docker 容器技术就是属于操作系统层虚拟化的范畴。
<br><br><br>Docker是一个强大的容器化平台，让你能够更轻松地构建、部署和运行应用程序。<br>Docker是一个开源的应用容器引擎，它让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到安装了任何 Linux 发行版本的机器上。Docker基于LXC来实现类似VM的功能，可以在更有限的硬件资源上提供给用户更多的计算资源。与同VM等虚拟化的方式不同，LXC不属于全虚拟化、部分虚拟化或半虚拟化中的任何一个分类，而是一个操作系统级虚拟化。<br>Docker是直接运行在宿主操作系统之上的一个容器，使用沙箱机制完全虚拟出一个完整的操作，容器之间不会有任何接口，从而让容器与宿主机之间、容器与容器之间隔离的更加彻底。每个容器会有自己的权限管理，独立的网络与存储栈，及自己的资源管理能，使同一台宿主机上可以友好的共存多个容器。<br>Docker借助Linux的内核特性，如：控制组（Control Group）、命名空间（Namespace）等，并直接调用操作系统的系统调用接口。从而降低每个容器的系统开销，并实现降低容器复杂度、启动快、资源占用小等特征。<br><br><br>Docker允许将应用程序及其配置打包到一个容器中，使得在不同环境中使用相同的配置变得轻松。这降低了硬件和应用环境之间的依赖关系。<br><br>Docker提供了一致的环境，使得代码从开发到部署的流水线管理变得简单。不同的环境中使用相同的Docker配置，减少了中间环境的差异。<br><br>Docker可以快速搭建开发环境，并使开发环境与生产环境更加贴近。它能够在开发环境中运行多个服务，提高开发者的效率。<br><br>Docker允许在同一台机器上运行不同的应用程序，降低成本和实现松耦合的应用架构。<br><br>Docker的隔离能力使得可以在多个服务器上运行多个应用程序，提高服务器资源利用率。<br><br>Docker提供了丰富的工具，帮助调试应用程序，例如设置检查点、查看容器之间的差异等。<br><br>Docker可用于创建多租户环境，为每个租户提供隔离的应用实例，简化了多租户应用的开发和管理。<br><br>Docker的虚拟化技术使得引入新的硬件资源只需几分钟，加快了部署的速度。<br><br>通过有效的资源分配和灵活的容器创建销毁，Docker可以提高数据中心的资源利用率。<br><br><img src="\07、云原生相关\01、容器化、编排\01、docker\assets\01、虚拟化dorcker\img-20240310_151555.png"><br>
<br>虚拟机

<br>基础设施（Infrastructure）。它可以是你的个人电脑，数据中心的服务器，或者是云主机。
<br>主操作系统（Host Operating System）。你的个人电脑之上，运行的可能是MacOS，Windows或者某个Linux发行版。
<br>虚拟机管理系统（Hypervisor）。利用Hypervisor，可以在主操作系统之上运行多个不同的从操作系统。类型1的Hypervisor有支持MacOS的HyperKit，支持Windows的Hyper-V以及支持Linux的KVM。类型2的Hypervisor有VirtualBox和VMWare。
<br>操作系统（Guest Operating System）。假设你需要运行3个相互隔离的应用，则需要使用Hypervisor启动3个从操作系统，也就是3个虚拟机。这些虚拟机都非常大，也许有700MB，这就意味着它们将占用2.1GB的磁盘空间。更糟糕的是，它们还会消耗很多CPU和内存。
<br>各种依赖。每一个从操作系统都需要安装许多依赖。如果你的的应用需要连接PostgreSQL的话，则需要安装libpq-dev；如果你使用Ruby的话，应该需要安装gems；如果使用其他编程语言，比如Python或者Node.js，都会需要安装对应的依赖库。


<br>Docker容器

<br>主操作系统（Host Operating System）。所有主流的Linux发行版都可以运行Docker。对于MacOS和Windows，也有一些办法"运行"Docker。
<br>Docker守护进程（Docker Daemon）。Docker守护进程取代了Hypervisor，它是运行在操作系统之上的后台进程，负责管理Docker容器。
<br>各种依赖。对于Docker，应用的所有依赖都打包在Docker镜像中，Docker容器是基于Docker镜像创建的。
<br>应用。应用的源代码与它的依赖都打包在Docker镜像中，不同的应用需要不同的Docker镜像。不同的应用运行在不同的Docker容器中，它们是相互隔离的。


<br>虚拟机是在物理资源层面实现的隔离，相对于虚拟机，Docker是你APP层面实现的隔离，并且省去了虚拟机操作系统（Guest OS）），从而节省了一部分的系统资源；Docker守护进程可以直接与主操作系统进行通信，为各个Docker容器分配资源；它还可以将容器与主操作系统隔离，并将各个容器互相隔离。虚拟机启动需要数分钟，而Docker容器可以在数毫秒内启动。由于没有臃肿的从操作系统，Docker可以节省大量的磁盘空间以及其他系统资源。<br>虚拟机与容器docker的区别，在于vm多了一层guest OS，虚拟机的Hypervisor会对硬件资源也进行虚拟化，而容器Docker会直接使用宿主机的硬件资源。<br>下面我们采用形象的比喻区分两者的隔离级别：<br>
<br>服务器：比作一个大型的仓管基地，包含场地与零散的货物——相当于各种服务器资源。<br>

<br>虚拟机技术：比作仓库，拥有独立的空间堆放各种货物或集装箱，仓库之间完全独立——仓库相当于各种系统，独立的应用系统和操作系统。<br>

<br>Docker：比作集装箱，操作各种货物的打包——将各种应用程序和他们所依赖的运行环境打包成标准的容器，容器之间隔离。
<br><br>
<br>隔离性
<br>在于隔离性上面，由于vm对操作系统也进行了虚拟化，隔离的更加彻底。而Docker共享宿主机的操作系统，隔离性较差。<br>
<br>运行效率
<br>由于vm的隔离操作，导致生成虚拟机的速率大大低于容器Docker生成的速度，因为Docker直接利用宿主机的系统内核。比如openstack能够以10台/min的速度创建虚拟机，而docker可以做到在几秒钟之内创建大量容器，它们的启动速度是在数量级上的差距。<br>因为虚拟机增加了一层虚拟硬件层，运行在虚拟机上的应用程序在进行数值计算时是运行在Hypervisor虚拟的CPU上的；另外一方面是由于计算程序本身的特性导致的差异。虚拟机虚拟的cpu架构不同于实际cpu架构，数值计算程序一般针对特定的cpu架构有一定的优化措施，虚拟化使这些措施作废，甚至起到反效果。<br>
<br>资源利用率
<br>在资源利用率上虚拟机由于隔离更彻底，因此利用率也会相对较低。<br>因为虚拟机增加了一层虚拟硬件层，运行在虚拟机上的应用程序在进行数值计算时是运行在Hypervisor虚拟的CPU上的；另外一方面是由于计算程序本身的特性导致的差异。虚拟机虚拟的cpu架构不同于实际cpu架构，数值计算程序一般针对特定的cpu架构有一定的优化措施，虚拟化使这些措施作废，甚至起到反效果。比如对于本次实验的平台，实际的CPU架构是2块物理CPU]]></description><link>07、云原生相关\01、容器化、编排\01、docker\01、虚拟化dorcker.html</link><guid isPermaLink="false">07、云原生相关/01、容器化、编排/01、Docker/01、虚拟化Dorcker.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:43 GMT</pubDate><enclosure url="07、云原生相关\01、容器化、编排\01、docker\assets\01、虚拟化dorcker\img-20240310_151555.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;07、云原生相关\01、容器化、编排\01、docker\assets\01、虚拟化dorcker\img-20240310_151555.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[02、Docker基本概念和安装]]></title><description><![CDATA[ 
 <br><br><br>Docker 使用客户端-服务器 (C/S) 架构模式，使用远程API来管理和创建Docker容器。<br>
<br>Docker 客户端(Client) : Docker 客户端通过命令行或者其他工具使用 Docker SDK (<a rel="noopener" class="external-link" href="https://docs.docker.com/develop/sdk/" target="_blank">https://docs.docker.com/develop/sdk/</a>) 与 Docker 的守护进程通信。
<br>Docker 主机(Host) ：一个物理或者虚拟的机器用于执行 Docker 守护进程和容器。
<br><br>Docker 包括:<br>
<br>镜像（Image）：Docker 镜像（Image），就相当于是一个 root 文件系统。比如官方镜像 ubuntu: 16.04 就包含了完整的一套 Ubuntu 16.04 最小系统的 root 文件系统。
<br>容器（Container）：镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。
<br>仓库（Repository）：仓库可看着一个代码控制中心，用来保存镜像。
<br>从仓库中下载镜像，然后运行镜像成为容器，一个镜像可以运行多次形成多个容器实例。<br><img src="\lib\media\img-20240310_154211.png"><br><br><br>
 从 2017 年 3 月开始 docker 在原来的基础上分为两个分支版本:<br>
Docker CE 和 Docker EE

<br>Docker CE 即社区免费版；
<br>Docker EE 即企业版，强调安全，但需付费使用；

<br>按照官网上 Docker Engine - Community 包现在就是叫做 Docker CE。这里将展示在 CentOS 上安装 Docker。<br><br>官网要求，使用CentOS7的稳定版本，同时：<br>
<br>启用centos-extras
<br>推荐使用overlay2存储驱动
<br><br>
为什么你可能还需要删除较低的Docker安装？因为较旧版本的Docker被称为docker或docker-engine（它是一个简化Docker安装的命令行工具，通过一个简单的命令行即可在相应的平台上安装Docker，比如VirtualBox、 Digital Ocean、Microsoft Azure）
<br>sudo yum remove docker \
                  docker-client \
                  docker-client-latest \
                  docker-common \
                  docker-latest \
                  docker-latest-logrotate \
                  docker-logrotate \
                  docker-engine
复制<br><br>
<br>yum-utils 提供 yum-config-manager 类库
<br>device-mapper-persistent-data 和 lvm2 被devicemapper 存储驱动依赖
<br>sudo yum install -y yum-utils \
  device-mapper-persistent-data \
  lvm2
复制<br>设置稳定版本的库<br>sudo yum-config-manager \
    --add-repo \
    https://download.docker.com/linux/centos/docker-ce.repo
复制<br><br>yum install -y docker-ce
复制<br>安装完之后启动<br>sudo systemctl start docker
复制<br>测试是否安装成功<br>[root@pdai ~]# systemctl status docker
● docker.service - Docker Application Container Engine
   Loaded: loaded (/usr/lib/systemd/system/docker.service; disabled; vendor preset: disabled)
   Active: active (running) since Mon 2020-02-17 13:57:45 CST; 39s ago
     Docs: https://docs.docker.com
 Main PID: 26029 (dockerd)
    Tasks: 8
   Memory: 36.9M
   CGroup: /system.slice/docker.service
           └─26029 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd
复制<br><br>
Docker 安装好以后，我们就要开始为拉取镜像准备了；国内从 DockerHub 拉取镜像有时会特别慢，此时可以配置镜像加速器。
<br>Docker 官方和国内很多云服务商都提供了国内加速器服务，比如：<br>
<br>阿里云的加速器：<a rel="noopener" class="external-link" href="https://help.aliyun.com/document_detail/60750.html" target="_blank">https://help.aliyun.com/document_detail/60750.html</a>
<br>网易加速器：<a rel="noopener" class="external-link" href="http://hub-mirror.c.163.com" target="_blank">http://hub-mirror.c.163.com</a>
<br>Docker官方中国加速器：<a rel="noopener" class="external-link" href="https://registry.docker-cn.com" target="_blank">https://registry.docker-cn.com</a>
<br>ustc 的镜像：<a rel="noopener" class="external-link" href="https://docker.mirrors.ustc.edu.cn" target="_blank">https://docker.mirrors.ustc.edu.cn</a>
<br>daocloud：<a data-tooltip-position="top" aria-label="https://www.daocloud.io/mirror#accelerator-doc%EF%BC%88%E6%B3%A8%E5%86%8C%E5%90%8E%E4%BD%BF%E7%94%A8%EF%BC%89" rel="noopener" class="external-link" href="https://www.daocloud.io/mirror#accelerator-doc%EF%BC%88%E6%B3%A8%E5%86%8C%E5%90%8E%E4%BD%BF%E7%94%A8%EF%BC%89" target="_blank">https://www.daocloud.io/mirror#accelerator-doc（注册后使用）</a>
<br>这里配置 Docker官方中国的加速器：<br>对于使用 systemd 的系统，请在 /etc/docker/daemon.json 中写入如下内容（如果文件不存在请新建该文件）<br>{"registry-mirrors":["https://registry.docker-cn.com"]}
复制<br>之后重新启动服务<br>$ sudo systemctl daemon-reload
$ sudo systemctl restart docker
复制<br><br>
拉一个docker镜像试试吧？
<br>拉取hello world<br>[root@pdai ~]# docker pull hello-world:latest
latest: Pulling from library/hello-world
1b930d010525: Pull complete
Digest: sha256:9572f7cdcee8591948c2963463447a53466950b3fc15a247fcad1917ca215a2f
Status: Downloaded newer image for hello-world:latest
docker.io/library/hello-world:latest
复制<br>看本地仓库是否有这个库<br>[root@pdai ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
hello-world         latest              fce289e99eb9        13 months ago       1.84kB
复制<br>运行这个镜像的实例，即容器<br>[root@pdai ~]# docker run hello-world

Hello from Docker!
This message shows that your installation appears to be working correctly.

To generate this message, Docker took the following steps:
 1. The Docker client contacted the Docker daemon.
 2. The Docker daemon pulled the "hello-world" image from the Docker Hub.
    (amd64)
 3. The Docker daemon created a new container from that image which runs the
    executable that produces the output you are currently reading.
 4. The Docker daemon streamed that output to the Docker client, which sent it
    to your terminal.

To try something more ambitious, you can run an Ubuntu container with:
 $ docker run -it ubuntu bash

Share images, automate workflows, and more with a free Docker ID:
 https://hub.docker.com/

For more examples and ideas, visit:
 https://docs.docker.com/get-started/
复制<br>
注意, 如果你在没有镜像的时候，直接docker run hello-world也是可以的；它会先检查本地是否有这个镜像，没有的话会先从指定仓库中拉取。
<br><br>
上面我们跑了一个官方的Hello-world容器实例, 这里通过介绍运行ubuntu的实例来全面理解如何跑一个Docker实例
<br><br>Docker 允许你在容器内运行应用程序， 使用 docker run 命令来在容器内运行一个应用程序。这里同样是个Hello World，不同在于它是在容器内部运行的。<br>[root@pdai ~]# docker run ubuntu:latest /bin/echo "Hello world"
Unable to find image 'ubuntu:latest' locally
latest: Pulling from library/ubuntu
5c939e3a4d10: Pull complete
c63719cdbe7a: Pull complete
19a861ea6baf: Pull complete
651c9d2d6c4f: Pull complete
Digest: sha256:8d31dad0c58f552e890d68bbfb735588b6b820a46e459672d96e585871acc110
Status: Downloaded newer image for ubuntu:latest
Hello world
复制<br>我们看下各个参数的含义：<br>
<br>docker: Docker 的二进制执行文件。
<br>run: 与前面的 docker 组合来运行一个容器。
<br>ubuntu:latest 指定要运行的镜像，Docker 首先从本地主机上查找镜像是否存在，如果不存在，Docker 就会从镜像仓库 Docker Hub 下载公共镜像。
<br>/bin/echo "Hello world": 在启动的容器里执行的命令
<br>以上命令完整的意思可以解释为：Docker 以 ubuntu 最新的（默认是latest) 镜像创建一个新容器，然后在容器里执行 bin/echo "Hello world"，然后输出结果。<br><br>
以上面例子，容器跑的是Ubuntu是一个系统实例，能否进入系统进行交互呢？
<br>我们通过 docker 的两个参数 -i -t，让 docker 运行的容器实现"对话"的能力：<br>[root@pdai ~]# docker run -i -t ubuntu:latest
root@414bf796cbe4:/# echo 'hello world'
hello world
root@414bf796cbe4:/#
复制<br>各个参数解析：<br>
<br>-t: 在新容器内指定一个伪终端或终端。
<br>-i: 允许你对容器内的标准输入 (STDIN) 进行交互。
<br>我们可以通过运行 exit 命令或者使用 CTRL+D 来退出容器<br>root@414bf796cbe4:/# exit
exit
[root@pdai ~]#
复制<br><br>
我们先来看, 当我们跑完上面例子之后，我们看下后台是否有docker容器实例？
<br>显然没有任何容器实例<br>[root@pdai ~]# docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
复制<br>所以我们需要-d参数，来让容器实例在后台运行，比如：<br>[root@pdai ~]# docker run -d ubuntu:latest /bin/sh -c "while true; do echo hello world; sleep 1; done"
1a51d2f023c947f2be2d9a78eb863e854ca302c89bf354654c409e23e7dd25d7
复制<br>在输出中，我们没有看到期望的 "hello world"，而是一串长字符<br>2b1b7a428627c51ab8810d541d759f072b4fc75487eed05812646b8534a2fe63
复制<br>这个长字符串叫做容器 ID，对每个容器来说都是唯一的，我们可以通过容器 ID 来查看对应的容器发生了什么。<br>首先，我们需要确认容器有在运行，可以通过 docker ps 来查看：<br>[root@pdai ~]# docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED              STATUS              PORTS               NAMES
1a51d2f023c9        ubuntu:latest       "/bin/sh -c 'while t…"   About a minute ago   Up About a minute                       gifted_brown
复制<br>输出详情介绍：<br>
<br>CONTAINER ID: 容器 ID。
<br>IMAGE: 使用的镜像。
<br>COMMAND: 启动容器时运行的命令。
<br>CREATED: 容器的创建时间。
<br>STATUS: 容器状态(状态有7种)。

<br>created（已创建）
<br>restarting（重启中）
<br>running（运行中）
<br>removing（迁移中）
<br>paused（暂停）
<br>exited（停止）
<br>dead（死亡）


<br>PORTS: 容器的端口信息和使用的连接类型（tcp\udp）。
<br>NAMES: 自动分配的容器名称。
<br>我们通过docker logs 命令，查看指定容器内的标准输出:<br>[root@pdai ~]# docker logs 1a51d2f023c9
hello world
hello world
hello world
hello world
hello world
hello world
hello world
hello world
hello world
hello world
hello world
hello world
hello world
hello world
hello world
hello world
hello world
hello world
复制<br>最后我们看下，如何关闭后台实例<br>[root@pdai ~]# docker stop 1a51d2f023c9
1a51d2f023c9
[root@pdai ~]# docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
[root@pdai ~]#
复制]]></description><link>07、云原生相关\01、容器化、编排\01、docker\02、docker基本概念和安装.html</link><guid isPermaLink="false">07、云原生相关/01、容器化、编排/01、Docker/02、Docker基本概念和安装.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:43 GMT</pubDate><enclosure url="lib\media\img-20240310_154211.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\img-20240310_154211.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[03、Docker基本命令]]></title><description><![CDATA[ 
 <br><br><br>当运行容器时，使用的镜像如果在本地中不存在，docker 就会自动从 docker 镜像仓库中下载，默认是从 Docker Hub 公共镜像源下载。<br><br># 搜索镜像
docker search 镜像名称

# 搜索镜像，同时显示显示的结果，只显示10条，不加参数，默认显示25条
docker search --limit 10 镜像名称
复制<br><img src="\07、云原生相关\01、容器化、编排\01、docker\assets\03、docker基本命令\img-20240310_155608.png"><br>搜索会列出很多的镜像，分别是不同的账户、组织提交的，包括名称、描述等信息。<br>NAME：镜像仓库源的名称<br>
DESCRIPTION：镜像的描述<br>
STARTS：是受欢迎程度，用星星数量表示，类似 Github 里面的 star<br>
OFFICIAL ：是否 docker 官方发布<br>
AUTOMATED&nbsp;：表示镜像是否由自动化流程构建。<br><br>每个镜像都有 tag（版本），如果不指定，默认拉取的就是最新版本。<br>
可以登录 dockerhub，查看镜像版本。<br>例如在 dockerhub 上搜索 redis：<br>
<img src="\07、云原生相关\01、容器化、编排\01、docker\assets\03、docker基本命令\img-20240310_160337.png"><br>搜索到镜像以后，可以使用命令拉取镜像到本地：<br># 拉取最新版本的镜像
docker pull 镜像名称

# 拉取指定版本的镜像：
docker pull 镜像名称:版本tag

#列如：
docker pull redis:6.0.20
复制<br><br># 查看本地所有镜像
docker images

# 查看本地所有镜像，包括中间层（intermediate layers）。
docker images -a
复制<br><img src="\07、云原生相关\01、容器化、编排\01、docker\assets\03、docker基本命令\img-20240310_161103.png"><br>显示本地的镜像信息中，包含了镜像的名称、版本标签、镜像 ID，什么时候创建的，镜像的大小。<br>REPOSITORY：表示镜像的仓库源<br>
TAG：镜像的标签, 同一仓库源可以有多个 TAG，代表这个仓库源的不同个版本<br>
IMAGE ID：镜像 ID<br>
CREATED：镜像创建时间<br>
SIZE：镜像大小<br><br>如果存在此镜像的容器/存在镜像依赖，删除会失败。<br>
要删除镜像，需要先删除用这个镜像创建的容器，或使用强制删除。<br># 删除镜像
docker rmi 镜像ID

# 强制删除
docker rmi -f 镜像ID
复制<br>其他指令：<br> # 只会删除最新版本的镜像
docker rmi 镜像名称
# 删除指定版本的镜像
docker rmi 镜像名称:版本tag
 # 删除多个
docker rmi 镜像ID1 镜像ID2
# 删除所有镜像，慎用或不用
# docker -qa是获取到镜像的ID
docker rmi -f $(docker images -qa)	images 
复制<br><br>先跑一个 ubuntu 容器实例，同时在里面进行 apt-get update 更新<br>#进入容器内
docker run -it ubuntu:latest

#执行更新
apt-get update
复制<br>此时 ID 为 0a1556ca3c27 的容器，是按我们的需求更改的容器。我们可以通过命令 docker commit 来提交容器副本：<br>#提交
docker commit -m="update test" -a="pdai" 0a1556ca3c27 
#查看
docker images
复制<br><br>使用命令 docker build ，通过创建一个 Dockerfile 文件，其中包含一组指令来告诉 Docker 如何构建我们的镜像。<br>但是这一过程需要写 Dockerfile<br>docker build -t pdai/ubuntu:v2.0.1 
复制<br><br>docker tag a733d5a264b5 pdai/ubuntu:v3.0.1
复制<br>注意：<br>
<br>Docker tag 镜像 ID，这里是 a 733 d 5 a 264 b 5 ,用户名称、镜像源名 (repository name)和新的标签名 (tag)。
<br>使用 docker images 命令可以看到，ID 为 a 733 d 5 a 264 b 5 的镜像多一个 v 3.0.1标签。
<br><br>镜像导出<br>docker save &gt; pdai-ubuntu-v2.0.2.tar 57544a04cd1a
复制<br>镜像导入<br>docker load &lt; pdai-ubuntu-v2.0.2.tar
复制<br>
<br>若是只想备份images，使用save、load即可
<br>若是在启动容器后，容器内容有变化，需要备份，则使用export、import
<br><br><br># 启动容器，并指定名称
docker run -it --name my-ubuntu ubuntu /bin/bash

# 也可以不起名字，随机名字，新版本也可以不写/bin/bash
docker run -it ubuntu
复制<br>
<br>docker run: Docker命令用于运行一个新容器。
<br>-it&nbsp;可以连写的，表示&nbsp;-i -t
<br>-t: 在新容器内指定一个伪终端或终端。
<br>-i: 允许你对容器内的标准输入 (STDIN) 进行交互
<br>--name my-ubuntu: 这个选项给容器指定一个名称，名字你自己起，这里是my-ubuntu，该参数是可以省略的，省略后系统会随机生成一个名字。
<br>ubuntu: 这是要使用的镜像名称，即Ubuntu操作系统，使用的是最新版本，如果要使用指定的版本需要使用&nbsp;镜像名称:版本tag，例如&nbsp;ubuntu:18.0.2。
<br>/bin/bash: 这是在容器启动后要执行的命令。在这种情况下，它启动了Bash shell，允许你在容器内部进行交互式操作，其实这个是可以省略的，因为不加&nbsp;/bin/bash，会启动一个默认的 shell。对于 Ubuntu 镜像，这个默认 shell 通常是 Bash shell。
<br>docker run -it ubuntu&nbsp;命令是可以运行多次的，那么就会产生多个 Ubuntu 容器实例。<br><br>显示的信息会列出容器的 ID、使用的镜像、创建的时间和状态等信息。<br>#查看正在运行的容器
docker ps

#查看所有容器
docker ps -a

# 查看最近创建的容器
docker ps -l

# 查看容器，只显示容器编号
docker ps -q

# 查看最近n个创建的容器
docker ps -n 5	# 查看最近创建的5个容器
复制<br>查看单个容器具体信息<br>docker inspect 容器ID/名称
复制<br><br>退出容器有两个命令，命令是在容器中执行的：<br># 直接退出容器，容器会停止
exit   	

# 退出容器，容器不会停止
Ctrl + p + q  
复制<br>如果再想进入正在运行的容器，可以使用&nbsp;docker exec&nbsp;或&nbsp;docker attach&nbsp;命令：<br># 进入容器
docker exec -it 容器ID或名称 /bin/bash

# 进入容器
docker attach 容器ID或名称
复制<br>推荐使用&nbsp;docker exec&nbsp;命令。因为&nbsp;docker attach&nbsp;会直接进入容器启动命令的终端，不会启动新的进程，所以用&nbsp;exit&nbsp;退出，会导致容器停止；而&nbsp;docekr exec&nbsp;是现在容器中打开新的终端，是启动了新的进程，时候用&nbsp;exit&nbsp;退出容器，不会导致容器停止。<br><br>#再次启动，同容器
docker start f5332ebce695
#停止
docker stop f5332ebce695
#重启
docker restart f5332ebce695
复制<br>还有一个强制停止容器的命令，用的不多：<br># 强制停止容器
docker kill 容器ID/名称
复制<br>docker stop&nbsp;和&nbsp;docker kill&nbsp;的区别：<br>docker stop比较温柔，它会给容器发送一个TERM信号，给容器充足时间（默认10秒）保存数据，让容器自动安全停止运行，超时后再给系统发送SIGKILL的系统信号强行kill掉进程，最后转变为stop状态。而docker kill则比较生猛，它会直接给系统发送SIGKILL的系统信号强行kill掉进程。<br>设置重启策略：<br>docker run -d -p 6379:6379 --restart=always --name myredis redis
复制<br>其中的&nbsp;--restart&nbsp;参数指定了重启的策略，&nbsp;--restart&nbsp;可以设置为如下值：<br>
<br>no：默认策略，在容器退出时不进行重启。
<br>always：无论容器退出状态如何，都会尝试重启容器。
<br>on-failure：只有在容器以非零状态码退出时才尝试重启容器。
<br>unless-stopped：在容器退出或守护进程重启时，始终重启容器，除非用户明确停止了容器。
<br><br>容器导出：<br>docker export f5332ebce695 &gt; ubuntu-pdai-v2.tar
复制<br>导出容器的时候，容器无需关闭。<br>容器导入：<br>docker import ubuntu-pdai-v2.tar pdai/ubuntu:v2.0.2
复制<br>SIZE可能是不一样的。<br><br># 删除已停止的容器
docker rm 容器ID/名称

# 强制删除容器，运行中的也可以删除
docker rm -f 容器ID/名称
复制<br>删除所有停止的容器:<br>#需要确认
docker container prune
复制<br><br>上面我们已经使用了&nbsp;redis&nbsp;镜像创建了&nbsp;redis&nbsp;容器，但是此时还无法访问这个&nbsp;redis&nbsp;服务，原因是还没有做端口映射。<br>以前我们在&nbsp;Linux&nbsp;系统中部署&nbsp;redis，一般使用的端口是&nbsp;6379，所以访问主机的&nbsp;6379&nbsp;端口就可以访问到这个主机上的&nbsp;redis&nbsp;服务。<br>现在&nbsp;redis&nbsp;服务部署到&nbsp;docker&nbsp;容器中，那么如何通过访问主机访问到&nbsp;docker&nbsp;中的&nbsp;redis&nbsp;服务呢？<br>我们需要在启动容器的时候，将容器的端口映射到主机的端口上，这样就可以通过访问主机端口来访问到容器的端口，进而访问到docker中的服务。<br>举个栗子：<br># 启动 redis 服务
docker run -d -p 6379:6379 --name myredis redis
复制<br>-p&nbsp;表示端口映射，前面的&nbsp;6379&nbsp;表示宿主机的端口号，后面的&nbsp;6379&nbsp;表示容器的端口号。<br>如果使用的命令是：<br># 启动 redis 服务
docker run -d -p 8888:6379 --name myredis redis
复制<br>上面的命令表示通过访问宿主机的&nbsp;8888&nbsp;端口可以访问到&nbsp;myredis&nbsp;容器的&nbsp;6379&nbsp;端口，进而访问到&nbsp;myredis&nbsp;容器中的 redis 服务。<br>通过上面的方式启动，就可以使用 redis 客户端，访问宿主机的&nbsp;8888&nbsp;端口，连接到 redis 服务了。<br>有的容器需要映射多个端口，例如我们给前面的 Ubuntu 容器映射端口：<br>docker run -it --name myUbuntu -p 80:80 -p 8080:8080 Ubuntu /bin/bash
复制<br>在上面的命令中，在启动容器的时候，映射了两个端口，分别是80和8080。<br><br>我们有时候需要在宿主机和容器之间传输文件，使用&nbsp;docker cp&nbsp;命令，在宿主机和容器之间相互拷贝文件：<br>注意：是在宿主机中执行命令，不是容器中。<br># 将宿主机的文件拷贝到容器
docker cp 宿主机路径 容器ID:容器内路径

# 将容器的文件拷贝到宿主机
docker cp 容器ID:容器内路径 宿主机路径
复制<br>举个栗子：<br>
从宿主机复制文件到容器：<br><img src="https://www.doubibiji.com/assets/img/20240130094835.400b96ef.jpg" referrerpolicy="no-referrer"><br>从容器复制文件到宿主机：<br><img src="https://www.doubibiji.com/assets/img/20240130112747.d7418353.jpg" referrerpolicy="no-referrer"><br><br>#创建别名容器
docker run -itd --name pdai-ubuntu-202 pdai/ubuntu:v2.0.2 /bin/bash

#使用别名停止
docker stop pdai-ubuntu-202
复制<br><br>#例：实时查看docker容器名为user-uat的最后10行日志 
docker logs -f -t --tail 10 user-uat

#例：查看指定时间后的日志，只显示最后100行
docker logs -f -t --since="2018-02-08" --tail=100 user-uat 

#例：查看最近30分钟的日志:
docker logs --since 30m user-uat

#例：查看某时间之后的日志： 
docker logs -t --since="2018-02-08T13:23:37" user-uat

#例：查看某时间段日志： 
docker logs -t --since="2018-02-08T13:23:37" --until "2018-02-09T12:23:37" user-uat

#例：将错误日志写入文件： 
docker logs -f -t --since="2018-02-18" user-uat | grep error &gt;&gt; logs_error.txt
复制<br><br><br>
我们以官方的docker hub为例，进行注册和理解。很多人会说官方的速度极慢或者私有仓库上传慢，不试试你怎么知道呢？
<br>1）docker hub（docker cloud）注册用户<br><a rel="noopener" class="external-link" href="https://hub.docker.com/" target="_blank">https://hub.docker.com/</a><br>2）本地登录<br>docker login
#Login with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one.

#输入用户名密码
Username: username
Password: 

#WARNING! Your password will be stored unencrypted in /root/.docker/config.json. Configure a credential helper to remove this warning. See https://docs.docker.com/engine/reference/commandline/login/#credentials-store 
#Login Succeeded
复制<br>3）镜像准备<br>docker tag pdai/ubuntu:v2.0.2 realpdai/ubuntu:v2.0.2
复制<br>4）推送至 Docker Hub 服务器<br>docker push realpdai/ubuntu:v2.0.2 
复制<br>The push refers to repository [docker.io/realpdai/ubuntu] 9a2c43cbe02a: Pushed v2.0.2: digest: sha256:4afd82dd05d0b4a340ae4f4129dcbd63136b5ec7ff92edf313108a41fb0947e0 size: 528
复制<br><br>前面我们使用的是阿里云镜像仓库，个人版只能自己用，企业版本是收费的。<br>可以使用工具搭建我们自己的镜像仓库。类似于使用 GitLab 搭建私有的 Git 仓库，供公司内部使用。<br>Docker 官方提供了&nbsp;Docker Registry&nbsp;私有镜像仓库工具，&nbsp;Docker Registry&nbsp;也是一个 Docker 镜像。<br><br>和前面制作镜像的步骤一样，使用一个 Ubuntu 的镜像创建容器，在容器中安装想要的程序，例如vim，然后使用&nbsp;docker commit&nbsp;命令创建容器。<br>查看一下前面的笔记。<br><br>没什么好说的，执行命令：<br># 下载registry镜像
docker pull registry
复制<br><img src="https://www.doubibiji.com/assets/img/20240205163501.2e9ae209.jpg" referrerpolicy="no-referrer"><br><br>使用 Docker Registry 镜像运行容器：<br>docker run -d --privileged=true -p 5000:5000 \
-v /home/doubi/docker/registry:/tmp/registry registry
复制<br>解释一下：<br>
<br>docker run: Docker 的命令来运行一个容器。
<br>-d: 以后台模式运行容器。
<br>--privileged=true: 以特权模式运行容器，赋予容器几乎所有与宿主机相同的权限。
<br>-p 5000:5000: 端口映射设置，将宿主机的 5000 端口映射到容器的 5000 端口。
<br>-v /home/doubi/docker/registry/:/tmp/registry: 卷映射设置，将宿主机上的&nbsp;/home/doubi/docker/registry/&nbsp;目录映射到容器内的&nbsp;/tmp/registry&nbsp;目录。
<br>registry: 要运行的 Docker 镜像的名称，这里是 Docker 官方的 Registry 镜像。
<br>将宿主机上的&nbsp;/home/doubi/docker/registry/&nbsp;目录映射到容器的&nbsp;/tmp/registry&nbsp;目录。这样配置后，就可以在宿主机的&nbsp;/home/doubi/docker/registry/&nbsp;目录中存储和推送 Docker 镜像，并通过宿主机的 5000 端口访问这些镜像。<br><br>Docker Registry 容器已经运行了，可以查看仓库中有哪些镜像。<br>命令：<br>curl -XGET http://localhost:5000/v2/_catalog
复制<br>因为 Registry 就是在当前机器上，所以使用 localhost。<br>不出意外，镜像仓库是空的，因为我们也没有推送镜像到仓库。<br><img src="https://www.doubibiji.com/assets/img/20240205170829.0f31dc9b.jpg" referrerpolicy="no-referrer"><br><br>下面将安装了我们想要的程序的 Ubuntu 镜像，推送到我们的私有镜像仓库。<br>首先给镜像打上标签<br>命令：<br># 命令
docker tag 本地镜像ID Host:Port/远程仓库名称:[版本tag]

# 例如
docker tag ad0b74b466f7 localhost:5000/myubuntu:1.0
复制<br><img src="https://www.doubibiji.com/assets/img/20240205172131.465a6b3e.jpg" referrerpolicy="no-referrer"><br>这里注意区分，为了突出不同，这里打标签的时候指定的名称和本地镜像的名称是不同的（一个带&nbsp;-&nbsp;一个不带）。<br>当给一个已有的镜像打上新的标签时，Docker 会复制该镜像并创建一个新的镜像，带有新的标签。待会推送到远程仓库的是新生成的镜像。这两个镜像是一样的，ID都一样。<br>修改Docker Registry配置<br>Docker Registry&nbsp;默认是不支持 http 的推送的，所以需要修改一下&nbsp;Docker Registry&nbsp;的配置，取消该限制。<br>修改&nbsp;/etc/docker/daemon.json&nbsp;文件，添加&nbsp;insecure-registries&nbsp;配置：<br>{
  "registry-mirrors": ["https://01e3hiyl.mirror.aliyuncs.com"],
  "insecure-registries":["localhost:5000"]
}
复制<br>上面的&nbsp;insecure-registries&nbsp;配置表示信任这个地址的镜像仓库。<br>注意：上面的格式是 JSON 格式的，别漏掉第一行后面的逗号&nbsp;,&nbsp;。<br>修改完成，如果不生效，重启一下 Docker。<br>sudo systemctl restart docker
复制<br>将镜像推送到私有仓库<br>命令：<br># 命令
docker push 镜像名称:[版本tag]

# 例如
docker push localhost:5000/myubuntu:1.0
复制<br><img src="https://www.doubibiji.com/assets/img/20240205174110.4008bf9e.jpg" referrerpolicy="no-referrer"><br><br>重新查看仓库中有哪些镜像：<br>命令：<br>curl -XGET http://localhost:5000/v2/_catalog
复制<br>1  <br>可以看到上传的镜像：<br><img src="https://www.doubibiji.com/assets/img/20240205174414.9ccbd742.jpg" referrerpolicy="no-referrer"><br><br>镜像已经上传到我们的私有仓库中了，那么如何从私有仓库中拉取镜像呢？<br>首先将本地的仓库删除，因为我们上传的时候在本地已经存在这个镜像了。<br>然后从私有仓库中拉取刚才的镜像。<br># 从私有仓库拉取镜像
docker pull localhost:5000/myubuntu:1.0
复制<br>指定私有仓库的地址、端口、镜像，就可以拉取了：<br><img src="https://www.doubibiji.com/assets/img/20240205175130.4d32f29e.jpg" referrerpolicy="no-referrer"><br>镜像下载完成了，就可以使用这个镜像来运行容器了，上面我们配置的都是 localhost，如果在局域网内共享给大家使用，要配置为自己的 IP 地址，别人拉取的时候，指定 IP 地址即可。<br><br>前面镜像和容器的命令已经介绍的差不多了，还有一些其他的一些命令，简单了解一下。<br><br>下面是控制 Docker 服务的一些命令，这是属于Linux命令。<br># 设置docker开机自启, 正常安装完docker都是开机自启的，所以一般不用执行。
systemctl enable docker

# 查看docker状态
systemctl status docker

# 停止docker
systemctl stop docker

# 启动docker
systemctl start docker

# 重启docker
systemctl restart docker
复制<br><br><br>docker info
复制<br><br>通过这个命令可以看到 docker 有哪些命令和参数。<br>docker --help
复制<br>docker 具体命令 --help
复制<br>具体命令是上面查看帮助文档中列出的命令，通过命令文档可以查看命令需要的参数，这个还是比较实用的。]]></description><link>07、云原生相关\01、容器化、编排\01、docker\03、docker基本命令.html</link><guid isPermaLink="false">07、云原生相关/01、容器化、编排/01、Docker/03、Docker基本命令.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:43 GMT</pubDate><enclosure url="07、云原生相关\01、容器化、编排\01、docker\assets\03、docker基本命令\img-20240310_155608.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;07、云原生相关\01、容器化、编排\01、docker\assets\03、docker基本命令\img-20240310_155608.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[04、Web应用实例]]></title><description><![CDATA[ 
 ]]></description><link>07、云原生相关\01、容器化、编排\01、docker\04、web应用实例.html</link><guid isPermaLink="false">07、云原生相关/01、容器化、编排/01、Docker/04、Web应用实例.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:44 GMT</pubDate></item><item><title><![CDATA[05、Docker网络使用和配置]]></title><description><![CDATA[ 
 ]]></description><link>07、云原生相关\01、容器化、编排\01、docker\05、docker网络使用和配置.html</link><guid isPermaLink="false">07、云原生相关/01、容器化、编排/01、Docker/05、Docker网络使用和配置.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:43 GMT</pubDate></item><item><title><![CDATA[06、Docker数据卷和数据管理]]></title><description><![CDATA[ 
 ]]></description><link>07、云原生相关\01、容器化、编排\01、docker\06、docker数据卷和数据管理.html</link><guid isPermaLink="false">07、云原生相关/01、容器化、编排/01、Docker/06、Docker数据卷和数据管理.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:43 GMT</pubDate></item><item><title><![CDATA[07、Dockerfile详解]]></title><description><![CDATA[ 
 ]]></description><link>07、云原生相关\01、容器化、编排\01、docker\07、dockerfile详解.html</link><guid isPermaLink="false">07、云原生相关/01、容器化、编排/01、Docker/07、Dockerfile详解.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:43 GMT</pubDate></item><item><title><![CDATA[08、DockerCompose详解]]></title><description><![CDATA[ 
 ]]></description><link>07、云原生相关\01、容器化、编排\01、docker\08、dockercompose详解.html</link><guid isPermaLink="false">07、云原生相关/01、容器化、编排/01、Docker/08、DockerCompose详解.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:43 GMT</pubDate></item><item><title><![CDATA[09、Docker底层实现]]></title><description><![CDATA[ 
 ]]></description><link>07、云原生相关\01、容器化、编排\01、docker\09、docker底层实现.html</link><guid isPermaLink="false">07、云原生相关/01、容器化、编排/01、Docker/09、Docker底层实现.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:43 GMT</pubDate></item><item><title><![CDATA[10、Docker安全相关]]></title><description><![CDATA[ 
 ]]></description><link>07、云原生相关\01、容器化、编排\01、docker\10、docker安全相关.html</link><guid isPermaLink="false">07、云原生相关/01、容器化、编排/01、Docker/10、Docker安全相关.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:43 GMT</pubDate></item><item><title><![CDATA[01、个人简历和面试]]></title><description><![CDATA[ 
 <br><br><br>姓名、性别、年龄、联系方式、邮箱、学校学历专业（好的写，不好的放到后面）、籍贯 <br>联系方式、邮箱： 简历再好，联系不到 = 白费！<br>
籍贯：可以碰运气，老乡会有亲切感。<br>
学历：好的放前面<br>
专业：计算机专业可以写。<br>
工作经验：3 年以下不要写。<br>
薪资：不写 / 准确值 / 面议 ，不要写区间范围。<br>以上信息最好列出来，不要堆在一起，并且格式上最好统一。<br><br>求职意向岗位、期望薪水、到岗时间 <br><br><br>不要担心有些内容过于包装，先争取面试机会。<br>我自己可以，是最棒的，不要瞻前顾后。<br><br>不要做的事情：<br>1）不要不敢写技能<br>
哪怕是项目没有使用到，问到不会也没关系，不会有啥损失，也可以<br>2）不要纯粹堆积技术名词<br>
纯堆积毫无意义，面试官会在自己的知识体系中挑选，问几个不会就知道简历上其他的掌握都是假的，哪怕是你后面的东西真的会。<br>3）不要写无关紧要的技术<br>
Html、css 类似于这样的技术点，对于面试和技术体系来说没有任何增值。<br>
甚至有写 Office？毫无意义还减分，认为你是个外行转入。<br>4）不要写了解<br>
了解 = 不会，知道技术名词，对于细节一无所知，是一个减分项目。<br>
最低写熟练应用、熟练掌握、熟悉。<br>需要<br>
1）提前了解企业的招聘需求<br>
不建议海投，针对性的调整和修改。HR 不动技术，会进行筛选，和企业需求相匹配。<br>2）突出技术细节<br>3）带上项目中的应用<br>
可以加上：并在项目中熟练使用。<br>
这样引导面试官去问，给他挖陷阱。<br>
在哪些地方使用，这时候把提前准备好的东西拿出来。<br>
解决过类似问题，技术方案。<br>4）逻辑性和条理性<br>
最好按照先易后难，或者一定技术栈顺序，让别人感觉到你的条理性。<br>5）格式和标点统一<br>精通、熟悉<br>3-5 年，5 年以上要加上精通<br>格式上：写上对一个技术点的掌握程度，对里面的哪些具体内容深入了解，列出来引导面试。<br><br>1、精通、熟悉 java 核心知识，多年一线研发经验，具备良好的编程能力，并熟练使用设计模式熟练掌握 javase 基础知识，对集合、线程、io 等都有深入理解，具备良好的面向对象的编程思想，并熟练使用设计模式<br>
2、精通、熟悉 java 并发编程，对 java 的各种锁机制，线程池机制、AQS 等都有深入理解，并在项目中熟练使用<br>
3、精通、熟悉 JVM，对 GC 算法、垃圾回收器，类加载机制都有深入的理解，并且参与过线上项目的 JVM 调优工作<br>
4、熟悉 spring、springmvc、mybatis、springboot 等核心框架，可以根据需求快速搭建项目，并阅读过核心源码（看过循环依赖的核心代码实现、bean 的生命周期、springboot 自动装配原理、内嵌 tomcat 源码、springboot 启动流程)<br>
（ioc、aop、生命周期、循环依赖、声明式事务、传播特性、项目中 aop 的扩展点、九组件源码、源码的扩展点、自动装配的原理、springboot 启动流程、内嵌 tomcat 原理、代理模式的应用）<br>5、熟悉 springcloud、springcloud alibaba、dubbo 等微服务框架, 对 nacos, sentinel 等组件有深入理解, 对服务划分、服务治理、服务分层等都有深入理解，并具备线上项目经验。<br>6、熟悉常用的分布式解决方案：分布式事务、分布式锁、分布式 ID <br>7、熟悉 mysql，对 mysql 的锁、事务、索引等都有深入研究，并参与过线上项目的调优工作<br>
精通、熟悉 SQL 语言和 mysql 调优，多年实战经验，对索引的优化及存储引擎有深入的研究，对 mysql 的事务、锁有深入理解，对 mysql 集群，主从复制、读写分离，分库分表都有实战经验，对 MHA，MMM 等高可用架构有实际的经验<br>8、熟悉 redis，了解底层磁盘及 IO 模型，数据持久化机制，哨兵机制，对于单机和集群 redis 都有实际经验<br>
了解底层磁盘及网络 IO 模型，数据持久化机制，多数据类型缓存应用，高可用机制以及分布式集群实现，主从复制、哨兵机制，分片集群<br>9、熟悉 kafka，了解核心原理，对于底层刷盘机制、集群分片机制都有深入理解，并对消息丢失和重复消费有对应的线上解决方案<br>了解数据刷盘机制，集群分片化机制，在高吞吐量情况下消息不丢和重复消费以及消息投递一致性问题，<br>
有实际的项目经验 rocketMQ, rabbitMQ, 不建议写 activeMQ<br>10、熟悉 zookeeper 底层原理和实现机制，了解 paxos,zab 算法，对 CAP 有深入理解。<br>了解 paxos, zab 算法，对 CAP 定理有深入理解，选举机制，zookeeper 实现分布式锁<br>熟悉大型网站高并发设计方案，对 nginx, lvs, keepalived, cdn, dns 等都有深入的理解，参与过高并发、高可用，高吞吐，高性能的架构设计方案<br>11、mongodb<br>
12、 es<br>
13、操作系统、机组、网络<br>
14、 netty<br>
15、 docker, k 8 s<br>
16、 nginx, lvs, lua<br>
17、http、 https<br>
18、 xxljob<br><br>避免文字堆积，项目介绍不要太多，非军工企业基本上随便吹。<br>项目名称：XX 系统公司名称 XX 平台项目<br>
描述：三四行文字描述即可，切忌大段落的文字堆积，要凸显出重点，有什么价值（具体的数据量）项目解决了什么问题（提供了什么行业的哪些具体的解决方案，有多少企业和个人在使用），可以添加核心的业务模块，但是不要全部都是核心模块<br>技术架构：项目中用到的所有的技术做罗列（只写技术名词）<br>职责描述：一定要分条展示，同时要虚 (需求分析，数据库建模，项目进度把控，技术选型，架构设计）实（实际的业务开发功能）结合至少要写 5 条以上，凸显出自己的核心价值<br>项目难点：个人不建议添加，一般的项目是没有难点的，可以提前去准备，但是这个是要面试的时候说的，而不是提前写出来的，每个人的技术认知和储备不一样，你写的内容在面试官看来可能不是难点，如果要写，从调优、重构、架构设计方面来考虑<br><br>不建议分条展示，写成一个段落即可展示你的行业背景和技术经验，比如做过什么行业的项目，提出过什么技术解决方案，接触过多大数据量的项目，对那些技术有深入研究，阅读过哪些技术类的书籍，做过哪些博客的积累，热爱工作，沟通能力强，责任心强对于大学生、实习生、经验不多的学生，要展示的是你的学习能力和态度对技术有热情，深入研究过 XXX、XXx 等技术、leetcode 有多少题目的储备、做过哪些教研室的项目，获得了什么成长，自己私下怎么学习技术的，阅读过哪些书籍，看过哪些 github 的项目，做过哪些博客的积累<br><br>公司名称职位时间<br><br> 学校学历专业时间 <br> 1、简历是敲门砖，任何人的简历都是要包装的，所以不要有抵触心理<br>
2、在技术储备有问题的情况下不要想着去碰运气，如果技术不扎实，有面试机会也很难过<br>
3、技术才是王道――<br><br>简历格式，不要左右分屏。<br>
不要带框的，干净简洁。<br>发 PDF 格式<br><br>现在市场卷，并且海投的人较多。<br>
公司层面收到大量简历，觉得自己公司很强。<br><br>对于感兴趣的公司，可以对其加分项观摩写入简历。<br>
同时自己避免乱投海投。<br>原因：对公司有研究，不属于乱投海投的人。<br><br>技术岗、管理岗位、工作年限范围岗。<br>原因：简历后台也可以筛选，扩大被筛选范围。<br><br>最好在工作日的 10-12 点，下午 14-17 点之间投递。<br>原因：人事上班时间，聊天会在上面，容易被观察到。<br><br>在线简历：填写的最基本信息，筛选和查看的主要途径，简历完善度可能也会影响推荐。<br>附件简历：在线简历不能满足个性化需要，或者无法展示你的技能优势。<br>在线简历是投递前能看到的简历，附件简历是投递后才能看到的。<br>
不要关闭在线简历。<br><br>不要"求"，开门见山，简短描述优势。（直接甩价值）<br>不要滋长 HR 嚣张气焰。<br><br>Boss 直聘：类似于求职中的实时通讯，回复率较高，反馈好。<br>
智联招聘：综合性招聘软件，覆盖较广。建议小众、传统、三四线岗位。<br>
拉勾网：互联网基因重，垂直度较高，页面简洁。<br>
58 同城：比较杂，骗子最多。<br>
前程无忧：<br>
猎聘：<br><br>天眼查：查看公司情况<br>
脉脉：入职感受，团队氛围<br>
牛客：笔试面试刷题<br><br>每个公司的技术栈都不一样，选择你去引导面试官，而不是他去结合自己公司来问你。<br><br>1、简历是广告<br>
广告可以虚夸，让别人知道你的价值！<br>2、调整心态<br>
不管你会多少东西，我天下第一，让自己超常发挥。<br>3、不可能完全准备好<br>
可以准备，但不要想着准备充足，先按照当前技术储备取尝试一些公司（我就是来试水的）面试回来之后做总结，不断总结，复盘，才能成长。<br>4、博取概率<br>
不需要百分之百的成功才去做，概率学，50%也要去争取，拼概率就成功，万一 Cover 住在职场再提升。<br>5、不要太谦虚<br>
对自己不要太谦虚，为什么无知的人越自信？有时候技术差自信的人反而吃香。<br>
举例：<br>
100 -&gt; 80  10 成 8   4 W- 3 w<br>
60 -&gt; 80    10 成 2  3 W -2 W<br>6、不患得患失<br>
全中国企业多，好公司也多，没必要在一棵树上吊死。可以有心仪的公司，留到最后，等试完水准备充分再去。<br>7、自尊心不要太强<br>
没有到饥寒交迫的时候，总是有自尊心，害怕结果怕丢人，不敢尝试。年轻人的自尊心不值钱。<br>
面试什么都不损失，不要担心。害怕就永远没有机会。<br><br><br><br>面试录音。<br><br>会发现面试的东西基本一样。哪怕是通过面试来学习，通过概率也是不断增加的。<br><br><br>系统化学习、项目推动学习。<br>细节 - 整体 <br>花费时间长。<br>整体 - 细节<br><br>目的是通过面试。<br>不调试 bug、不纠错、不纠结、先冲刺通过面试。<br>通过面试之后再系统学习。<br><br>1、定位<br>2、目标<br>3、实施<br><br>掌握基本技能<br><br>计算机操作系统<br>
计算机组成原理<br>
计算机网络网络与 I 0 模型<br>
计算机编译原理<br>
算法和数据结构（简易版）<br><br><br><br>深入理解 TCP 原理<br>
JⅣM 调优之底层原理<br>
Java 并发编程原理<br>
深入理解 HTTPS 原理<br><br>LVS 负载均衡<br>
Nginx 调优<br>
JVM 调优性能调优<br>
Mysql 调优<br>
Tomcat 调优<br>
MySQL 性能调优与架构设计<br>
Nginx+lua+OpenResty 高性能实践<br><br>一、线程基础概念<br>
二、并发编程的三大特性<br>
三、锁<br>
四、阻塞队列<br>
五、线程池<br>
六、并发集合<br>
七、JUC 并发工具<br>
八、异步编程<br>
★单机最快 MQ-Disruptor 4<br>
★线程池<br>
★CAS 与原子操作<br>
★ThreadLocal 详解<br>
★JMH<br><br>Spring 底层源码<br>
Spring MVC 源码<br>
Mybatis 源码框架原理源码<br>
Springboot 源码<br>
SpringSecurity 源码<br>
Spring Cloud Alibaba 源码<br>
Spring Webflux 深入实战<br>
Dubbo 源码<br><br><br>Spring Cloud Alibaba 微服务架构实战<br>
apollo 配置中心<br>
领域驱动模型设计与微服务架构<br>
分布式 CAP 理论<br>
分布式微服务架构设计<br>
数据一致性方案<br>
分布式锁<br>
分布式事务<br>
分布式幂等<br>
分布式存储<br>
分布式注册中心架构设计理论（97 h）<br>
分布式配置中心<br>
分布式会话分布式任务<br>
负载均衡<br>
熔断方案<br>
降级方案<br>
限流方案隔离方案服务监控方案响应式 web 响应式数据库响应式编程分布式 ID 生成方案<br><br><br><br><br><br>1、算法<br>2、system design<br>架构设计，春节红包雨活动，30 秒内抢 1 亿元红包，红包数量 1000 万，用户数 3000 万，可以连续抢，只可以抢成功一次；然后再进行资源评估。<br>日志、监控。<br>3、面试八股：JVM 并发，设计模式，源码<br>4、应用项目（2-4 个项目）<br>5、设计相关<br>6、大数据、云原生<br><br>·原单位提升<br>
·跳槽 (频率)·比原来更值钱-&gt;<br>1：阅读工作机会，了解市场<br>
2：定期投一投简历并更新<br><br>IT 薪水高！<br>
各行各业都有中年危机。包括公务员。<br>年轻的时候重视。<br>没有和年龄匹配的技能栈，需要 T 字型技术栈。<br>技术 -  业务  - 管理<br>现在已经大龄，如 38 岁：<br>技术管理 -&gt; 架构师技术管理<br>
快速的补充。]]></description><link>09、职场求职\01、简历面试\01、个人简历和面试.html</link><guid isPermaLink="false">09、职场求职/01、简历面试/01、个人简历和面试.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Fri, 05 Apr 2024 09:35:19 GMT</pubDate></item><item><title><![CDATA[03、面试 HR 通用问题汇总]]></title><description><![CDATA[ 
 ]]></description><link>09、职场求职\01、简历面试\03、面试-hr-通用问题汇总.html</link><guid isPermaLink="false">09、职场求职/01、简历面试/03、面试 HR 通用问题汇总.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Fri, 05 Apr 2024 09:33:55 GMT</pubDate></item><item><title><![CDATA[02、公司企业和员工]]></title><description><![CDATA[ 
 ]]></description><link>09、职场求职\02、企业和员工\02、公司企业和员工.html</link><guid isPermaLink="false">09、职场求职/02、企业和员工/02、公司企业和员工.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:46 GMT</pubDate></item><item><title><![CDATA[04、一些项目术语]]></title><description><![CDATA[ 
 <br>信贷<br>
P2P：P2P借贷平台连接借款人和投资人，通过在线平台提供借贷服务。这种模式通过去除传统金融机构的中介角色，降低了借款成本，并为投资人提供了更高的回报潜力。平台可以通过收取借款人和投资人的费用或利息来盈利。<br>风险：<br>
<br>借款人信用风险：P2P 平台通常吸引了各类借款人，包括信用状况较差的人群。借款人的违约风险可能导致投资人无法获得预期的回报。
<br>投资人信用风险：投资人也面临着借款人违约的风险。如果借款人无法按时还款或违约，投资人可能无法收回本金和利息。
<br>平台风险：P2P平台本身也存在风险。一些平台可能会出现运营不善、违规操作或甚至欺诈行为。这种情况下，投资人可能会面临资金安全和回报损失的风险。
<br>流动性风险：P2P社交借贷通常具有较长的投资期限。投资人在投资资金后，可能需要等待一段时间才能获得回报或提前退出。如果投资人需要在紧急情况下迅速取回资金，可能会面临流动性困难。
<br>法律和监管风险：不同国家和地区对P2P社交借贷平台的监管规定不同。投资人和借款人需要关注相关法律法规，并了解平台是否符合监管要求。监管变化可能会对平台运营和投资人权益产生影响。
<br>信息不对称风险：在P2P平台上，借款人和投资人的信息可能不对称。投资人可能难以准确评估借款人的信用状况和还款能力，从而增加了投资风险。
<br>资金监管模式，来降低风险：<br><img src="\09、职场求职\03、项目和业务\assets\04、一些项目术语\img-20240302_152236.png"><br><img src="\09、职场求职\03、项目和业务\assets\04、一些项目术语\img-20240302_152648.png"><br>标的：借款人在 P 2 P 平台上发布借款的相关信息（金额... 时间.…. 利息….)<br>
发标：借款人在 P 2 P 平台上发布借款的动作<br>
投标：投资人针对某个标的进行出借的动作<br>B2B：企业之间的交易和合作关系。在 B2B 模式中，一个企业提供产品或服务给另一个企业，而不是直接面向个人消费者。这种模式通常涉及大宗交易、供应链合作、跨国企业间的合作等。B2B 模式下的交易可能是定制化的，价格和合同条件通常会根据双方的需求和协商而定。<br>B2C：（企业对个人消费者）是指企业向个人消费者销售产品或提供服务的模式。在B2C模式中，企业直接与个人消费者进行交易，通过零售渠道、电子商务平台或线下商店销售产品和服务。B2C模式通常涉及广告、市场推广、个性化消费体验等方面的活动，以吸引和满足个人消费者的需求。<br>区别：<br>
<br>参与方：B2B 模式中的参与方是企业，而 B2C 模式中的参与方是个人消费者。
<br>交易规模和频率：B2B交易往往涉及大宗交易和长期合作，而B2C交易通常是小额交易，频率较高。
<br>决策过程：在B2B模式中，决策过程可能更为复杂，需要多个层面的决策者参与。而在B2C模式中，决策过程通常由个人消费者自主决定。
<br>销售和营销策略：B2B模式下的销售和营销策略通常更加专业化和面向企业需求，注重建立长期合作关系。B2C模式下的销售和营销策略则更注重个人消费者的情感连接和品牌体验。
<br>C2C（Consumer-to-Consumer）：C2C模式允许个人消费者之间直接进行交易。这种模式通常在在线市场或平台上实现，个人消费者可以在平台上销售自己的产品、提供服务或进行二手交易。平台提供交易撮合、支付处理和信任保障等功能，以促成个人消费者之间的交易。<br>咸鱼是一个典型的C2C（Consumer-to-Consumer）二手交易平台。在咸鱼上，个人消费者可以直接在平台上出售和购买二手物品，实现个人之间的交易。]]></description><link>09、职场求职\03、项目和业务\04、一些项目术语.html</link><guid isPermaLink="false">09、职场求职/03、项目和业务/04、一些项目术语.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 14 Mar 2024 15:07:46 GMT</pubDate><enclosure url="09、职场求职\03、项目和业务\assets\04、一些项目术语\img-20240302_152236.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;09、职场求职\03、项目和业务\assets\04、一些项目术语\img-20240302_152236.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[00、 ★ Git 总览 ★]]></title><description><![CDATA[ 
 ]]></description><link>11、常用工具\git\00、-★-git-总览-★.html</link><guid isPermaLink="false">11、常用工具/git/00、 ★ Git 总览 ★.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Sat, 30 Mar 2024 12:02:55 GMT</pubDate></item><item><title><![CDATA[01、Git 基础]]></title><description><![CDATA[ 
 <br><br><br>Git 是开源的分布式版本控制系统，可以有效、高速地处理从很小到非常大的项目版本管理。<br>
Git 最初是为了帮助管理 Linux 内核开发而开发的一个开放源码的版本控制软件。<br>设计特点：<br>
<br>
速度

<br>
简单的设计

<br>
对非线性开发模式的强力支持（允许成千上万个并行开发的分支）

<br>
完全分布式

<br>
有能力高效管理类似 Linux 内核一样的超大规模项目（速度和数据量）
<img src="\11、常用工具\git\assets\git\image-git.png">

<br>官网： <a rel="noopener" class="external-link" href="https://git-scm.com/" target="_blank">https://git-scm.com/</a><br>
在线学习网站：&nbsp;<a rel="noopener" class="external-link" href="https://learngitbranching.js.org/" target="_blank">https://learngitbranching.js.org/</a><br><br><br>集中式版本控制工具，版本库是集中存放在中央服务器的。<br>
team 里每个人工作时从中央服务器下载代码，是必须联网才能工作，局域网或互联网。个人修改后然后提交到中央版本库。<br>
举例：SVN和CVS<br><img src="\11、常用工具\git\assets\git\image-svn.png"><br><br>分布式版本控制系统没有“中央服务器”，每个人的电脑上都是一个完整的版本库。<br>
工作的时候无需要联网，因为版本库就在你自己的电脑上。多人协作只需要各自的修改推送给对方，就能互相看到对方的修改了。<br><br><img src="\11、常用工具\git\assets\git\image-git流程.png"><br>命令如下：<br>
<br>clone（克隆）: 从远程仓库中克隆代码到本地仓库
<br>checkout （检出）:从本地仓库中检出一个仓库分支然后进行修订
<br>add（添加）: 在提交前先将代码提交到暂存区
<br>commit（提交）: 提交到本地仓库。本地仓库中保存修改的各个历史版本
<br>fetch (抓取) ： 从远程库抓取到本地仓库，不进行任何的合并动作，一般操作比较少。
<br>pull (拉取) ： 从远程库拉到本地库，自动进行合并(merge)，然后放到到工作区，相当于<br>
fetch+merge
<br>push（推送） : 修改完成后，需要和团队成员共享代码时，将代码推送到远程仓库
<br><br>Git命令例子都是在Git Bash中演示的，会用到一些基本的linux命令。<br><br><br>
下载安装
<br>安装完成后，在电脑桌面（也可以是其他目录）点击右键，如果能够看到如下两个菜单则说明Git安装成功。<br><img src="\11、常用工具\git\assets\git\image-安装完成.png"><br>
<br>Git GUI：Git提供的图形界面工具
<br>Git Bash：Git提供的命令行工具
<br>当安装Git后首先要做的事情是设置用户名称和email地址。这是非常重要的，因为每次Git提交都会使用该用户信息。<br>
基本配置
<br>
<br>设置用户信息
<br>git config --global user.name "XXX" # 设置用户名
git config --global user.email "XXXX" # 设置邮箱
复制<br>
<br>查看配置信息
<br>git config --global user.name
git config --global user.email
复制<br><br>有些常用的指令参数非常多，每次都要输入好多参数，我们可以使用别名。<br>
<br>打开用户目录，创建 .bashrc 文件
<br>touch ~/.bashrc
复制<br><img src="\11、常用工具\git\assets\git\image-bashrc.png"><br>
<br>在 .bashrc文件中输入如下内容：
<br># 用于输出git提交日志 
alias git-log='git log --pretty=oneline --all --graph --abbrev-commit' 
#用于输出当前目录所有文件及基本信息 
alias ll='ls -al'
复制<br><img src="\11、常用工具\git\assets\git\image-bashrc-content.png"><br>注：vi退出编辑时，按esc，输入冒号（英文），然后切换到最后一行模式，最后一行模式决定是否保存文件。例如输入wq保存并退出。<br>
<br>打开gitBash，执行：
<br>source ~/.bashrc
复制<br><br>要使用Git对我们的代码进行版本控制，首先需要获得本地仓库<br>
<br>在电脑的任意位置创建一个空目录（例如test）作为我们的本地Git仓库
<br>进入这个目录中，点击右键打开Git bash窗口
<br>执行命令git init
<br>如果创建成功后可在文件夹下看到隐藏的.git目录
<br>git init
复制<br><img src="\11、常用工具\git\assets\git\image-git-init.png"><br><br>Git工作目录下对于文件的修改(增加、删除、更新)会存在几个状态，这些修改的状态会随着我们执行Git的命令而发生变化。<br><img src="\11、常用工具\git\assets\git\image-work.png"><br>本章节主要讲解如何使用命令来控制这些状态之间的转换：<br>
<br>git add (工作区 —&gt; 暂存区)
<br>git commit (暂存区 —&gt; 本地仓库)
<br><br>
<br>作用：查看修改的状态（暂存区、工作区）
<br>命令形式：
<br>git status
复制<br><br>
<br>作用：添加工作区一个或多个文件的修改到暂存区
<br>命令形式：git add 单个文件名|通配符
<br>git add file.txt # 添加单个文件
git add . # 将所有修改加入暂存区
复制<br><br>
<br>作用：提交暂存区内容到本地仓库的当前分支
<br>命令形式：git commit -m ‘注释内容’
<br>git commit -m "XXX update"
复制<br><br>配置的别名git-log就包含了这些参数，所以后续可以直接使用指令 git-log<br>
<br>作用:查看提交记录
<br>命令形式：git log [option] 或者 git-log

<br>—all 显示所有分支
<br>—pretty=oneline 将提交信息显示为一行
<br>—abbrev-commit 使得输出的commitId更简短
<br>—graph 以图的形式显示


<br><br>
<br>作用：版本切换
<br>命令形式：
<br>git reset --hard commitID # commitID 可以使用 git-log 或 git log 指令查看
复制<br><br>一般我们总会有些文件无需纳入Git 的管理，也不希望它们总出现在未跟踪文件列表。 通常都是些自动生成的文件，比如日志文件，或者编译过程中创建的临时文件等。 在这种情况下，我们可以在工作目录中创建一个名为 .gitignore 的文件（文件名称固定），列出要忽略的文件模式。<br><br>1）利用上面初始化好的本地仓库test，新建一个文件 file01.txt，并用status查看状态：<br>touch file01.txt
git status
复制<br><img src="\11、常用工具\git\assets\git\image-git-status.png"><br>2）添加到暂存区<br>git add file01.txt
# 或者
git add .
复制<br><img src="\11、常用工具\git\assets\git\image-git-add.png"><br>3）提交至本地仓库并查看状态<br>git commit -m "commit file01.txt"
git status
复制<br><img src="\11、常用工具\git\assets\git\image-git-commit.png"><br>4）查看日志<br>git log
复制<br><img src="\11、常用工具\git\assets\git\image-git-log.png"><br>5）修改 file01.txt 文件内容并查看状态<br><img src="\11、常用工具\git\assets\git\image-文件修改.png"><br>6）添加至暂存区并查看状态<br><img src="\11、常用工具\git\assets\git\image-git-文件状态.png"><br>7）提交至本地仓库并查看日志<br><img src="\11、常用工具\git\assets\git\image-提交仓库查看日志.png"><br>8）利用git-log查看提交日志，并回退至第一个版本<br>git-log
git reset --hard XXXXX
复制<br><img src="\11、常用工具\git\assets\git\image-回退上一版本.png"><br>点击打开file01.txt，发现其中内容没有了。<br>同样，可以再次回到第二个版本：<br><img src="\11、常用工具\git\assets\git\image-再次回退.png"><br>9）新建文件 file02.txt，加入 .gitignore 中<br>touch file02.txt
touch .gitignore
vi .gitignore # 添加内容： file02.txt
复制<br>.gitignore内容<br>file02.txt
# 也可以使用通配符，例如
*.txt
*.iml
...
复制<br><br>几乎所有的版本控制系统都以某种形式支持分支。 使用分支意味着你可以把你的工作从开发主线上分离开来进行重大的Bug修改、开发新的功能，以免影响开发主线。<br><br>git branch
复制<br><br>git branch 分支名
复制<br><br>git checkout 分支名
复制<br>我们还可以直接切换到一个不存在的分支（创建并切换）：<br>git checkout -b 分支名
复制<br><br>一个分支上的提交可以合并到另一个分支<br>git merge 分支名
复制<br><br>不能删除当前分支，只能删除其他分支<br>git branch -d 分支名 # 删除分支时，需要做各种检查
git branch -D 分支名 # 不做任何检查，强制删除
复制<br><br>当两个分支上对文件的修改可能会存在冲突，例如同时修改了同一个文件的同一行，这时就需要手动解决冲突，解决冲突步骤如下：<br>
<br>处理文件中冲突的地方
<br>将解决完冲突的文件加入暂存区(add)
<br>提交到仓库(commit)
<br><br>几乎所有的版本控制系统都以某种形式支持分支。 使用分支意味着你可以把你的工作从开发主线上分离开来进行重大的Bug修改、开发新的功能，以免影响开发主线。<br>在开发中，一般有如下分支使用原则与流程：<br>
<br>master （生产） 分支：线上分支，主分支，中小规模项目作为线上运行的应用对应的分支；
<br>develop（开发）分支：是从master创建的分支，一般作为开发部门的主要开发分支，如果没有其他并行开发不同期上线要求，都可以在此版本进行开发，阶段开发完成后，需要是合并到master分支，准备上线。
<br>feature/xxxx分支：从develop创建的分支，一般是同期并行开发，但不同期上线时创建的分支，分支上的研发任务完成后合并到develop分支，之后该分支可以删除。
<br>hotfix/xxxx分支：从master派生的分支，一般作为线上bug修复使用，修复完成后需要合并到master、test、develop分支。
<br>还有一些其他分支，在此不再详述，例如test分支（用于代码测试）、pre分支（预上线分支）等<br>
等。<br><img src="\11、常用工具\git\assets\git\image-branch.png"><br>一般来说，团队合作开发的话，每个人都需要在自己的功能分支 feat/XXX 上开发，最后一起合并到总的开发分支 dev 上，然后将开发分支 dev 合并到测试分支上，最后将测试分支合并到正式发布分支上。<br>其中总的开发分支一般叫做 dev 分支，正式发布分支一般是叫 main/master/release 分支。<br><img src="\11、常用工具\git\assets\git\image-分支规范.png"><br>比如说有 A、B、C 三个人协助进行功能开发：<br>
<br>首先 A、B、C 三位小伙伴从总开发分支 Dev 上开辟自己的功能分支，分别是 feat/AXXX、feat/BXXX、feat/CXXX，也就是图中 feat/AXXX、feat/BXXX、feat/CXXX 的三条线；
<br>然后在自己的开发机上进行开发，这里的开发机可以是本地环境也可以是一些云端的开发机。开发完毕后，再分别合到总开发分支 dev 上，也就是图中蓝色的三条线，在这个过程中可能会产生一些代码冲突，挨个 solve 即可；
<br>接着在 dev 分支上确认所有功能开发完毕，进行简单自测，fix 一些 bug 后再向测试分支上进行合并；
<br>这个时候就可以艾特测试组的同学来进行测试，测试通过后再合到 master 分支进行发布。
<br>一般来说，基本的流程就是这样的，不同公司或许其中流程有些出入，不过问题不大，大致方向是如此的。<br><br><br>1、查看分支，并新建分支dev01<br>git branch
git branch dev01
复制<br><img src="\11、常用工具\git\assets\git\image-git-branch.png"><br>其中HEAD指向的是当前工作区所处的分支，例如此时处在master的分支上。<br>2、将上一节中的.gitignore提交，并查看分支：<br><img src="\11、常用工具\git\assets\git\image-git-branch-result.png"><br>2、将当前分支切换到dev01<br>git checkout dev01
复制<br><img src="\11、常用工具\git\assets\git\image-git-checkout.png"><br>同时观察到，test目录下的.gitignore消失了<br>3、重新切换到master分支，.gitignore又出现了。新建分支dev02，并同时切换到上面<br>git checkout -b dev02
复制<br><img src="\11、常用工具\git\assets\git\image-git-checkout-b.png"><br>4、切换到dev01分支，并新建文件file03.txt，并提交<br><img src="\11、常用工具\git\assets\git\image-newfile03.png"><br>5、切换到master分支，并将dev01的提交合并到master上<br>git checkout master
git merge dev01
复制<br><img src="\11、常用工具\git\assets\git\image-merge-dev01.png"><br>此时，可以看到在master分支下的仓库中，有了file03.txt<br>6、删除dev02分支<br>git branch -d dev02
复制<br><img src="\11、常用工具\git\assets\git\image-delete-dev02.png"><br><br>1、删除分支dev01，创建并切换到分支dev上。此时master和dev分支上的file01.txt文件中内容都为update_count = 1<br>git branch -d dev01
git checkout -b dev
复制<br><img src="\11、常用工具\git\assets\git\image-delete-dev01.png"><br>2、在dev分支上修改file01.txt文件内容为update_count = 2，并提交<br><img src="\11、常用工具\git\assets\git\image-update-file01.png"><br>3、在master分支上修改file01.txt文件内容为update_count = 3，并提交<br><img src="\11、常用工具\git\assets\git\image-master-update-file01.png"><br>4、将dev分支合并到master分支上，发现报错。查看file01.txt内容<br>git merge dev
复制<br><a data-tooltip-position="top" aria-label="https://kisugitakumi.oss-cn-chengdu.aliyuncs.com/img7/image-20220119160519282.png" rel="noopener" class="external-link" href="https://kisugitakumi.oss-cn-chengdu.aliyuncs.com/img7/image-20220119160519282.png" target="_blank"></a><br><img src="\11、常用工具\git\assets\git\image-merge-dev2master.png"><br><img src="\11、常用工具\git\assets\git\image-merge-file-content.png"><br>5、解决冲突：将file01.txt提示冲突的地方修改成我们想要的内容，例如再次修改成update_count = 3，并再次提交即可。<br><img src="\11、常用工具\git\assets\git\image-deal-merge.png"><br><br><br>前面我们已经知道了Git中存在两种类型的仓库，即本地仓库和远程仓库。那么我们如何搭建Git远程仓库呢？我们可以借助互联网上提供的一些代码托管服务来实现，其中比较常用的有GitHub、码云、GitLab等。<br>
<br>GitHub（ 地址：<a rel="noopener" class="external-link" href="https://github.com/" target="_blank">https://github.com/</a> ）是一个面向开源及私有软件项目的托管平台，因为只支持Git 作为唯一的版本库格式进行托管，故名GitHub
<br>码云（地址： <a rel="noopener" class="external-link" href="https://gitee.com/" target="_blank">https://gitee.com/</a> ）是国内的一个代码托管平台，由于服务器在国内，所以相比于 GitHub，码云速度会更快
<br>GitLab （地址： <a rel="noopener" class="external-link" href="https://about.gitlab.com/" target="_blank">https://about.gitlab.com/</a> ）是一个用于仓库管理系统的开源项目，使用Git作为代码管理工具，并在此基础上搭建起来的web服务，一般用于在企业、学校等内部网络搭建git私服。
<br><br><br>此操作是先初始化本地库，然后与已创建的远程库进行对接。<br>
<br>命令：

<br>远端名称：默认是origin，取决于远端服务器设置
<br>仓库地址：从远端服务器获取此url


<br>git remote add &lt;远端名称&gt; &lt;仓库地址&gt;
复制<br>例如：<br>git remote add origin git@gitee.com:czbk_zhang_meng/git_test.git
复制<br><img src="\11、常用工具\git\assets\git\image-ssh地址.png"><br><br>
<br>命令：
<br>git remote
复制<br><br>git push [-f] [--set-upstream] [远端名称] [本地分支名][:远端分支名]

复制<br>
<br>-f  表示强制推送，一般在公司内没有这个的使用权限，否则容易冲掉远程仓库的所有代码
<br>--set-upstream 推送到远端的同时，建立起和远端分支的关联关系。用于第一次推送时。
<br>git push 将master分支推送到已关联的远端分支
<br>git push origin master:main
复制<br>如果当前分支已经和远端分支关联，则可以省略分支名和远端名<br>如果远程分支名和本地分支名相同，则可以只写本地分支名<br>git push origin master
复制<br><br>git branch -vv
复制<br><br>如果已经有一个远端仓库，我们可以直接clone到本地。<br>
<br>命令：
<br>git clone &lt;仓库地址&gt; [本地目录]
复制<br>本地目录可以省略，会自动生成一个目录<br><br>远程分支和本地的分支一样，我们可以进行merge操作，只是需要先把远端仓库里的更新都下载到本地，再进行操作。<br>
<br>抓取命令：

<br>抓取指令就是将仓库里的更新都抓取到本地，不会进行合并
<br>如果不指定远端名称和分支名，则抓取所有分支。


<br>git fetch [remote name] [branch name]
复制<br>
<br>拉取命令：

<br>拉取指令就是将远端仓库的修改拉到本地并自动进行合并，等同于fetch+merge
<br>如果不指定远端名称和分支名，则抓取所有并更新当前分支。


<br>git pull [remote name] [branch name]
复制<br><br>在一段时间，A、B用户修改了同一个文件，且修改了同一行位置的代码，此时会发生合并冲突。<br>A用户在本地修改代码后优先推送到远程仓库，此时B用户在本地修订代码，提交到本地仓库后，也需要推送到远程仓库，此时B用户晚于A用户，故需要先拉取远程仓库的提交，经过合并后才能推送到远端分支，如下图所示。<br><img src="\11、常用工具\git\assets\git\image-remote-merge.png"><br>在B用户拉取代码时，因为A、B用户同一段时间修改了同一个文件的相同位置代码，故会发生合并冲突。<br>远程分支也是分支，所以合并时冲突的解决方式也和解决本地分支冲突相同相同，在此不再赘述。<br><br><br>1）初始化本地库（例如使用上一节创建的本地仓库 test），然后与已创建的远程库（例如闯将好一个远程仓库 git_test）进行对接<br>git remote add origin git@gitee.com:zeng-yiming/git_test.git
复制<br><img src="\11、常用工具\git\assets\git\image-git-remote-add-origin.png"><br>2）查看对接好的远程仓库<br>git remote
复制<br><img src="\11、常用工具\git\assets\git\image-git-remote.png"><br>3）推送到远程仓库<br>git push origin master
复制<br>因为本地分支名master和远程分支名master同名，所以省略了远程分支名，完整的指令如下：<br>git push origin master:master
复制<br><img src="\11、常用工具\git\assets\git\image-git-push-origin.png"><br>此时查看远端仓库，已有本地仓库的内容：<br><img src="\11、常用工具\git\assets\git\image-查看push结果.png"><br>提交历史：<br><img src="\11、常用工具\git\assets\git\image-查看提交结果历史.png"><br>4）查看本地分支与远程分支的绑定关系<br>git branch -vv
复制<br><img src="\11、常用工具\git\assets\git\image-git-breach-vv.png"><br>此时尚未有绑定关系<br>5）将本地分支master和远程分支master绑定关系<br>git push --set-upstream origin master:master
复制<br><img src="\11、常用工具\git\assets\git\image-master-to-remote-master.png"><br>发现本地分支master已经和远程分支master绑定成功<br>6）此时本地分支master若要推送到远程分支master上，则可直接使用命令：<br>git push
复制<br><br>1）克隆刚才的远程仓库 git_test，放在目录 git_test 中<br>git clone git@gitee.com:zeng-yiming/git_test.git git_test
复制<br><img src="\11、常用工具\git\assets\git\image-git-clone.png"><br><img src="\11、常用工具\git\assets\git\image-新克隆的结果.png"><br>2）查看克隆仓库的日志<br><img src="\11、常用工具\git\assets\git\image-查看克隆仓库的日志.png"><br>3）在本地仓库test中新建一个文件 file04.txt 并提交和推送<br><img src="\11、常用工具\git\assets\git\image-新建file04提交.png"><br>发现由于快进模式，远端分支master也进入到了和本地仓库test的master分支相同的位置。<br>
<br>本地仓库git_test从远端仓库抓取
<br>git fetch
复制<br><img src="\11、常用工具\git\assets\git\image-test-git-fetch.png"><br>
<br>发现远端分支master比本地分支master的版本更新，因此进行合并
<br>git merge origin/master
复制<br><img src="\11、常用工具\git\assets\git\image-合并或更新远端.png"><br>步骤4和5的指令可用一条指令完成：<br>git pull
复制<br><br>1）在本地仓库 test 和 git_test 中同时修改文件 file01.txt，并提交，但是 test 首先推送至远端<br>
2）在 test 推送后，git_test 首先进行抓取<br><img src="\11、常用工具\git\assets\git\image-进行抓取.png"><br>发现远端分支已经有test的推送结果<br>3） git_test 进行合并，提示冲突<br><img src="\11、常用工具\git\assets\git\image-冲突提示.png"><br><a data-tooltip-position="top" aria-label="https://kisugitakumi.oss-cn-chengdu.aliyuncs.com/img8/image-20220119175617021.png" rel="noopener" class="external-link" href="https://kisugitakumi.oss-cn-chengdu.aliyuncs.com/img8/image-20220119175617021.png" target="_blank"></a><br>4）解决冲突：将 file01.txt 的内容改成我们想要的，例如就改成5，之后提交并推送即可<br><img src="\11、常用工具\git\assets\git\image-处理冲突.png"><br><br><br>场景：本地已经有一个项目，但是并不是git项目，我们需要将这个放到码云的仓库里，和其他开发人员继续一起协作开发。<br><br><img src="\11、常用工具\git\assets\git\image-新建仓库.png"><br><br>
初始化本地仓库
<br><img src="\11、常用工具\git\assets\git\image-初始化本地仓库.png"><br>
选择本项目
<br><img src="\11、常用工具\git\assets\git\image-选择项目.png"><br><br>
查找选项
<br><img src="\11、常用工具\git\assets\git\image-设置远端仓库.png"><br>
输入远程仓库地址
<br><img src="\11、常用工具\git\assets\git\image-输入远端地址.png"><br><br><img src="\11、常用工具\git\assets\git\image-提交本地仓库.png"><br><br><img src="\11、常用工具\git\assets\git\image-推送到远程仓库.png"><br><br>
<br>方法一：最常规的方式
<br><img src="\11、常用工具\git\assets\git\image-创建分支.png"><br>
<br>方法2：最强大的方式
<br><img src="\11、常用工具\git\assets\git\image-方便的创建.png"><br><br>
<br>在IDEA的终端中可使用git命令来完成以上所有功能
<br>切换分支前先提交本地的修改
<br>代码及时提交，提交过了就不会丢
]]></description><link>11、常用工具\git\01、git-基础.html</link><guid isPermaLink="false">11、常用工具/git/01、Git 基础.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Thu, 04 Apr 2024 02:43:38 GMT</pubDate><enclosure url="11、常用工具\git\assets\git\image-git.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;11、常用工具\git\assets\git\image-git.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[100、★ Git 面试题汇总 ★]]></title><description><![CDATA[ 
 ]]></description><link>11、常用工具\git\100、★-git-面试题汇总-★.html</link><guid isPermaLink="false">11、常用工具/git/100、★ Git 面试题汇总 ★.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Fri, 05 Apr 2024 09:32:54 GMT</pubDate></item><item><title><![CDATA[00、 ★ Maven 总览 ★]]></title><description><![CDATA[ 
 ]]></description><link>11、常用工具\maven\00、-★-maven-总览-★.html</link><guid isPermaLink="false">11、常用工具/maven/00、 ★ Maven 总览 ★.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Sat, 30 Mar 2024 12:02:55 GMT</pubDate></item><item><title><![CDATA[01、Maven 基础]]></title><description><![CDATA[ 
 <br><br>Maven 是基于 Java 平台的项目管理和整合工具，将项目的开发和管理过程抽象成项目对象模型&nbsp;(Project Object Model)（POM）。<br>特点：<br>
<br>跨平台：使用 Java 语言编写，标准跨平台（Linux、Windows、MacOS）的自动化项目构建方式
<br>统一结构：提供标准、统一的项目结构
<br>依赖管理：方便快捷的管理项目依赖的资源（jar 包），避免版本冲突问题
<br>相关地址：<br>
Maven 官方网址：<a rel="noopener" class="external-link" href="https://maven.apache.org/" target="_blank">https://maven.apache.org/</a><br>
Maven 依赖搜索：<a rel="noopener" class="external-link" href="https://mvnrepository.com/" target="_blank">https://mvnrepository.com/</a><br>
Maven 下载地址：<a rel="noopener" class="external-link" href="https://maven.apache.org/download.cgi" target="_blank">https://maven.apache.org/download.cgi</a><br><br><br>1、下载<br>打开官网：<a data-tooltip-position="top" aria-label="https://maven.apache.org/" rel="noopener" class="external-link" href="https://maven.apache.org/" target="_blank">Maven官网</a><br>选择合适的版本<br>点击 Download<br><img alt="assets/01、Maven 基础/img-20240330_101404.png" src="\11、常用工具\maven\assets\01、maven-基础\img-20240330_101404.png" style="width: 925px; max-width: 100%;"><br>2、解压安装<br>直接解压到 D 盘根目录下即可<br><img src="\11、常用工具\maven\assets\01、maven-基础\img-20240330_101608.png"><br>
<br>bin：可执行程序目录
<br>boot：maven 自身的启动加载器
<br>conf：maven 配置文件的存放目录
<br>lib：maven 运行所需库的存放目录
<br>3、环境变量<br>右键电脑属性–&gt;点击高级系统设置–&gt;点击环境变量–&gt;新建系统变量%MAVEN_HOME%–&gt;编辑系统变量Path<br>添加变量值：%MAVEN_HOME%\bin<br>4、验证<br>在命令行窗口中输入 mvn -v 查看是否成功<br><br>1、阿里云镜像<br>在 settings. Xml 里面的 mirrors 标签里面导入：<br>&lt;mirror&gt;
  &lt;id&gt;aliyunmaven&lt;/id&gt;
  &lt;mirrorOf&gt;*&lt;/mirrorOf&gt;
  &lt;name&gt;阿里云公共仓库&lt;/name&gt;
  &lt;url&gt;https://maven.aliyun.com/repository/public&lt;/url&gt;
&lt;/mirror&gt;
复制<br>2、配置本地仓库地址<br>在 Maven bin 的同级目录下建立一个文件夹&nbsp;maven-repo<br>在 settings.xml 里面的localRepository下导入：<br>&lt;localRepository&gt;D:\Develop\apache-maven-3.6.1\maven-repo&lt;/localRepository&gt;
复制<br><br><br><img src="\11、常用工具\maven\assets\01、maven-基础\img-20240330_112917.png"><br><br><br>POM 是 Maven 工程的基本工作单元，是一个 XML 文件，包含了项目的基本信息，用于描述项目如何构建，声明项目依赖等等。<br>执行任务或目标时，Maven 会在当前目录中查找 POM，读取 POM，获取所需的配置信息，然后执行目标。<br>POM 中可以指定以下配置等等：<br>
<br>项目配置
<br>项目版本
<br>依赖管理
<br>插件管理
<br>版本管理
<br>构建设置
<br><br><br>用于存储资源，主要是各种jar。<br>
<br>中央仓库：maven 官方的存放仓库，国内用户访问速度慢
<br>镜像仓库：远程仓库，中央仓库的一份实时拷贝，如阿里镜像仓库，访问速度快
<br>私服：各公司/部门等小范围内存储资源的仓库，私服也可以从中央（镜像）仓库获取资源<br>
上面可称为远程仓库
<br>本地仓库：开发者自己电脑上存储资源的仓库，也可从远程仓库获取资源
<br>私服的作用：<br>
（1）保存具有版权的资源，包含购买或自主研发的 jar<br>
（2）一定范围内共享资源，能做到仅对内不对外开放<br><br>坐标的作用<br>
在仓库唯一的标识、定位该资源的位置。它方标我们调用其他包的资源，同时将我们的资源被其他包所调用<br>坐标的组成（GAV）<br>
<br>groupld：定义当前 Maven 项目隶属的实际项目，通常域名反写
<br>artifactld：该元素定义实际项目中的一个 Maven 项目 (模块)
<br>version：定义当前项目版本号
<br>也可能有 packaging、classifier 等但不是必须的<br>打包方式（packaging）<br>
一般有如下三种：<br>
<br>jar：该资源打成jar包，默认是jar java工程打包为jar
<br>war：该资源打成war包 web工程打包为war
<br>pom：该资源是一个父资源（表明使用maven分模块管理），打包时只生成一个pom.xml不生成jar或其他包结构
<br><br><br><br>GVA 搜索网站：<a rel="noopener" class="external-link" href="https://mvnrepository.com/" target="_blank">https://mvnrepository.com/</a><br>Maven 会使用&nbsp;groupId 、artifactId 、version&nbsp;这三个信息拼接字符串，到 maven 的中央仓库去寻找这个依赖，并把它下载到本地仓库，默认 ~/.m2/repository&nbsp;这个目录中。<br>maven 拼接字符串的格式：中央（远程）仓库地址/{groupId}/{artifactId}/{version}/{artifactId}-{version}.jar<br>
注意：groupId 需要把所包含的所有点替换成斜杠
<br>因为 maven 的中央仓库是在外网，在国内访问会很慢，或者打不开，这就是安装完调整为阿里镜像仓库的原因。<br><br>导入的工具包的 GAV 坐标：<br>&lt;project&gt;
    ...
  &lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;com.alibaba&lt;/groupId&gt;
        &lt;artifactId&gt;fastjson&lt;/artifactId&gt;
        &lt;version&gt;1.2.75&lt;/version&gt;
    &lt;/dependency&gt;
      ...
      ...
      	可添加多个依赖
      ...
      ...
  &lt;/dependencies&gt;
    ...
&lt;/project&gt;
复制<br><br>这里的范围主要是指以下三种范围<br>（1）主程序范围有效（src/main 目录范围内）<br>（2）测试程序范围内有效（src/test 目录范围内）<br>（3）是否参与打包（package 指令范围内）<br>此外：scope 标签的取值有四种：compile, test, provided, runtime<br>这四种取值与范围的对应情况如下：<br><img src="\11、常用工具\maven\assets\01、maven-基础\img-20240330_105149.png"><br><br><br>依赖具有传递性，分两种<br>（1）直接依赖：在当前项目中通过依赖配置建立的依赖关系<br>（2）间接依赖：被依赖的资源如果依赖其他资源，则表明当前项目间接依赖其他资源<br><br>在依赖传递过程中产生了冲突，我们有三种优先法则<br>（1）路径优先：当依赖中出现相同资源时，路径最短者优先<br>（2）声明优先：验证路径相同时，先声明者优先<br>（3）特殊优先：当同级配置了相同资源的不同版本时，后配置的覆盖先配置的<br><img src="\11、常用工具\maven\assets\01、maven-基础\img-20240330_104401.png"><br><br>可选依赖指的是对外隐藏当前所依赖的资源➡不透明<br>&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;Junit&lt;/groupId&gt;
        &lt;artifactId&gt;Junit&lt;/artifactId&gt;
        &lt;version&gt;4.12&lt;/version&gt;
        &lt;optional&gt;true&lt;/optional&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;
复制<br><br>排除依赖指主动断开依赖的资源，被排除的资源无需指定版本<br>&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;Junit&lt;/groupId&gt;
        &lt;artifactId&gt;Junit&lt;/artifactId&gt;
        &lt;version&gt;4.12&lt;/version&gt;
        &lt;exclusions&gt;
            &lt;exclusion&gt;
                &lt;groupId&gt;log4j&lt;/groupId&gt;
                &lt;artifactId&gt;log4j&lt;/artifactId&gt;
            &lt;/exclusion&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;
复制<br><br><br>
<br>清理：删除以前的编译结果，为重新编译做好准备。
<br>编译：将 Java 源程序编译为字节码文件。
<br>测试：针对项目中的关键点进行测试，确保项目在迭代开发过程中关键点的正确性，在每次测试后以标准格式记录和展示测试结果。
<br>打包：将一个包含诸多文件的工程封装为一个压缩文件用于安装或部署。Java 工程对应 jar 包，Web 工程对应 war 包。
<br>安装：在 Maven 环境下特指将打包的结果（jar 包或 war 包）安装到本地仓库中。
<br>发布：将打包的结果部署到远程仓库或将 war 包部署到服务器上运行。
<br><br>运行任何一个阶段的时候，它前面的所有阶段都会被运行，例如我们运行 mvn install 的时候，代码会被编译，测试，打包。<br><br>1）IDEA 中跳过测试<br><img alt="assets/01、Maven 基础/img-20240330_144058.png" src="\11、常用工具\maven\assets\01、maven-基础\img-20240330_144058.png" style="width: 425px; max-width: 100%;"><br>2）使用命令跳过测试：<br>mvn install -D skipTest
复制<br>3）POM 文件中设置<br>&lt;plugin&gt;
	&lt;artifactId&gt;maven-surefire-plugn&lt;/artifactId&gt;
	&lt;version&gt;2.22.1&lt;/version&gt;
	&lt;configuration&gt;
		&lt;!--设置跳过测试--&gt;
		&lt;skipTests&gt;true&lt;/skipTests&gt;
	&lt;/configuration&gt;
&lt;/plugin&gt;
复制<br><br>Maven对项目构建的生命周期划分为3套<br>
<br>clear：清理工作
<br>default：核心工作，例如编译、测试、打包、部署等
<br>site：产生报告、发布站点等
<br><br>clean：清理工作<br>
<br>pre-clean：执行一些在clean之前的工作
<br>clean：移除上一次构建产生的所有文件
<br>post-clean：执行一些在clean之后立刻完成的工作
<br><br>default：核心工作，例如编译，测试，打包，部署等<br><img src="\11、常用工具\maven\assets\01、maven-基础\img-20240330_103034.png"><br>其中主要的是：<br>
<br>compile：编译
<br>test：测试
<br>package：打包
<br>install：安装本地仓库
<br>deploy：发布
<br><br>site：产生报告，发布站点等<br>
<br>pre-site：执行一些在生成站点文档之前的工作
<br>site：生成项目的站点文档
<br>post-site：执行一些在生成站点文档之后完成的工作，为部署做准备
<br>site-deploy：将生成的站点文档部署到特定的服务器上
<br><br>Maven 的插件机制是完全依赖 Maven 的生命周期的。<br>
在输入 mvn 命令的时候比如 mvn clean，对应的就是 clean 生命周期中的 clean 阶段。<br>
但是 clean 的具体操作是由 maven-clean-plugin （内置了，不用我们手动添加）来实现的。
<br>
<br>插件与生命周期内的阶段绑定，在执行到对应生命周期时执行对应的插件
<br>maven默认在各个生命周期上都绑定了预先设定的插件来完成相应功能
<br>插件还可以完成一些自定义功能
<br><br>&lt;build&gt;
	&lt;plugins&gt;
		&lt;!-- 编译插件 --&gt;
		&lt;plugin&gt;
			&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
			&lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
			&lt;version&gt;3.2&lt;/version&gt;
			&lt;configuration&gt;
				&lt;source&gt;1.8&lt;/source&gt;
				&lt;target&gt;1.8&lt;/target&gt;
				&lt;encoding&gt;UTF-8&lt;/encoding&gt;
			&lt;/configuration&gt;
		&lt;/plugin&gt;
        ...
        ...
	&lt;/plugins&gt;
&lt;/build&gt; 
复制<br><br><br>插件描述：该插件处理项目的资源文件拷贝到输出目录，可以分别处理 main resources 和 test resources。<br>&lt;build&gt;
	&lt;plugins&gt;
		&lt;!-- 依赖插件 --&gt;
		&lt;plugin&gt;
			&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
			&lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt;
			&lt;version&gt;3.0.1&lt;/version&gt;
			&lt;configuration&gt;
				&lt;encoding&gt;UTF-8&lt;/encoding&gt;
			&lt;/configuration&gt;
		&lt;/plugin&gt;
	&lt;/plugins&gt;
&lt;/build&gt;
复制<br>除了使用&nbsp;maven-resources-plugin&nbsp;也可以使用以下配置来进行资源拷贝：<br>&lt;build&gt;
	&lt;resources&gt;
		&lt;resource&gt;
			&lt;directory&gt;src/main/java&lt;/directory&gt;
			&lt;includes&gt;
				&lt;include&gt;**/*.properties&lt;/include&gt;
				&lt;include&gt;**/*.xml&lt;/include&gt;
				&lt;include&gt;**/*.conf&lt;/include&gt;
			&lt;/includes&gt;
			&lt;filtering&gt;false&lt;/filtering&gt;
		&lt;/resource&gt;
		&lt;resource&gt;
			&lt;directory&gt;src/main/resources&lt;/directory&gt;
			&lt;includes&gt;
				&lt;include&gt;**/*.properties&lt;/include&gt;
				&lt;include&gt;**/*.xml&lt;/include&gt;
				&lt;include&gt;**/*.conf&lt;/include&gt;
			&lt;/includes&gt;
			&lt;filtering&gt;false&lt;/filtering&gt;
		&lt;/resource&gt;
	&lt;/resources&gt;
&lt;/build&gt;
复制<br><br>插件描述：设置 maven 编译的 jdk 版本<br>
<br>Maven 2 默认用 jdk 1.3
<br>Maven 3 默认用 jdk 1.5<br>
除了配置maven安装目录/config/settings.xml文件，也可以使用&nbsp;maven-compiler-plugin&nbsp;进行指定
<br>&lt;build&gt;
	&lt;plugins&gt;
		&lt;!-- 依赖插件 --&gt;
		&lt;plugin&gt;
			&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
			&lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
			&lt;version&gt;3.2&lt;/version&gt;
			&lt;configuration&gt;
				&lt;source&gt;1.8&lt;/source&gt;
				&lt;target&gt;1.8&lt;/target&gt;
				&lt;encoding&gt;UTF-8&lt;/encoding&gt;
			&lt;/configuration&gt;
		&lt;/plugin&gt;
	&lt;/plugins&gt;
&lt;/build&gt;
复制<br><br>插件描述：该插件允许用户整合项目的输出，包括依赖、模块、网站文档和其他文档到一个单独的文件，即可用定制化打包。<br>四种预定义的描述器可用：bin, jar-with-dependencies, src, project。<br>&lt;build&gt;
	&lt;plugins&gt;
        &lt;!-- 依赖插件 --&gt;
		&lt;plugin&gt;
			&lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;
			&lt;configuration&gt;
				&lt;descriptorRefs&gt;
					&lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt;
				&lt;/descriptorRefs&gt;
				&lt;archive&gt;
					&lt;manifest&gt;
						&lt;mainClass&gt;主程序类全路径&lt;/mainClass&gt;
					&lt;/manifest&gt;
				&lt;/archive&gt;
			&lt;/configuration&gt;
			&lt;executions&gt;
				&lt;execution&gt;
					&lt;id&gt;make-assembly&lt;/id&gt;
					&lt;phase&gt;package&lt;/phase&gt;
					&lt;goals&gt;
						&lt;goal&gt;single&lt;/goal&gt;
					&lt;/goals&gt;
				&lt;/execution&gt;
			&lt;/executions&gt;
		&lt;/plugin&gt;
	&lt;/plugins&gt;
&lt;/build&gt;
复制<br><br>插件描述：该插件处理打包项目的源代码。<br>&lt;build&gt;
	&lt;plugins&gt;
		&lt;!-- 依赖插件 --&gt;
		&lt;plugin&gt;
			&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
			&lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt;
			&lt;executions&gt;
				&lt;execution&gt;
					&lt;id&gt;attach-sources&lt;/id&gt;
					&lt;goals&gt;
						&lt;goal&gt;jar&lt;/goal&gt;
					&lt;/goals&gt;
				&lt;/execution&gt;
			&lt;/executions&gt;
		&lt;/plugin&gt;
	&lt;/plugins&gt;
&lt;/build&gt;
复制<br><br>插件描述：自动拷贝 jar 包到 target 目录<br>&lt;build&gt;
	&lt;plugins&gt;
		&lt;!-- 依赖插件 --&gt;
		&lt;plugin&gt;
			&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
			&lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt;
			&lt;version&gt;2.6&lt;/version&gt;
			&lt;executions&gt;
				&lt;execution&gt;
					&lt;id&gt;copy-dependencies&lt;/id&gt;
					&lt;phase&gt;compile&lt;/phase&gt;
					&lt;goals&gt;
						&lt;goal&gt;copy-dependencies&lt;/goal&gt;
					&lt;/goals&gt;
					&lt;configuration&gt;
						&lt;!-- ${project.build.directory}为Maven内置变量，缺省为target --&gt;
						&lt;outputDirectory&gt;${project.build.directory}/lib&lt;/outputDirectory&gt;
						&lt;!-- 表示是否不包含间接依赖的包 --&gt;
						&lt;excludeTransitive&gt;false&lt;/excludeTransitive&gt;
						&lt;!-- 表示复制的jar文件去掉版本信息 --&gt;
						&lt;stripVersion&gt;true&lt;/stripVersion&gt;
					&lt;/configuration&gt;
				&lt;/execution&gt;
			&lt;/executions&gt;
		&lt;/plugin&gt;
	&lt;/plugins&gt;
&lt;/build&gt;
复制<br><br><br>可以让项目直接用 jetty 的服务器运行<br>
命令： mvn jetty:run<br>
默认端口：8080<br>&lt;plugin&gt;
  &lt;groupId&gt;org.mortbay.jetty&lt;/groupId&gt;
  &lt;artifactId&gt;jetty-maven-plugin&lt;/artifactId&gt;
  &lt;version&gt;8.1.16.v20140903&lt;/version&gt;
  &lt;!-- 插件配置选项，可选项 --&gt;
  &lt;configuration&gt;
    &lt;connectors&gt;
      &lt;connector implementation="org.eclipse.jetty.server.nio.SelectChannelConnector"&gt;
        &lt;port&gt;8080&lt;/port&gt;
      &lt;/connector&gt;
    &lt;/connectors&gt;
    &lt;scanIntervalSeconds&gt;10&lt;/scanIntervalSeconds&gt;
  &lt;/configuration&gt;
&lt;/plugin&gt;
复制<br><br>可以让项目直接用 tomcat 的服务器运行<br>
命令： mvn tomcat7:run<br>
默认端口：8080<br>&lt;plugin&gt;
	&lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt;
	&lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt;
	&lt;version&gt;2.2&lt;/version&gt;
  &lt;!-- 插件配置选项，可选项 --&gt;
	&lt;configuration&gt;
	    &lt;path&gt;/&lt;/path&gt;
	    &lt;port&gt;8080&lt;/port&gt;
	    &lt;uriEncoding&gt;UTF-8&lt;/uriEncoding&gt;
	&lt;/configuration&gt;
&lt;/plugin&gt;
复制<br><br>查看版本<br>mvn -v
复制<br>清理项目<br>mvn clean
复制<br>编译主程序<br>mvn compile
复制<br>编译测试程序<br>mvn test-compile
复制<br>执行主程序<br>
首先需要编译 Java 工程：<br>mvn compile
复制<br>不存在参数的情况下运行：<br>mvn exec: java -Dexec. MainClass="主程序入口类，不需要拓展名"
复制<br>在存在参数的情况下运行：<br>mvn exec: java -Dexec. MainClass="主程序入口类，不需要拓展名" -Dexec. Args="arg 0 arg 1 arg 2"
复制<br>执行测试<br>mvn test
复制<br>打包项目<br>
正常打包：<br>mvn package
复制<br>跳过测试：<br>mvn package -Dmaven. Test. Skip=true
复制<br>安装项目<br>
正常安装：<br>mvn install
复制<br>跳过测试：<br>mvn install -Dmaven. Test. Skip=true
复制<br>部署项目<br>
正常部署：<br>mvn deploy
复制<br>跳过测试：<br>mvn deploy -Dmaven. Test. Skip=true
复制<br>依赖管理<br>
打印出已解决依赖的列表：<br>mvn dependency:resolve
复制<br>打印出所有的依赖的列表：<br>mvn dependency:tree
复制<br>创建项目<br>
创建 Maven 版本的 Java 项目：<br>#创建 Maven 版本的 Java 项目
mvn archetype: generate -DgroupId=packageName -DartifactId=appName -Dversion=1.0-SNAPSHOT -DarchetypeArtifactId=maven-archetype-quickstart -DinteractiveMode=false

#编译此项目
mvn compile

#执行此项目
mvn exec: java -Dexec. MainClass="packageName. App"
复制<br>创建 Maven 版本的 JavaWeb 项目：<br>#创建 Maven 版本的 Web 项目
mvn archetype: generate -DgroupId=packageName -DartifactId=webappName -Dversion=1.0-SNAPSHOT -DarchetypeArtifactId=maven-archetype-webapp -DinteractiveMode=false
复制<br>项目转化<br>
将项目转化为 Eclipse 项目 :<br>mvn eclipse:eclipse
复制<br>将项目转化为 Idea 项目 :<br>mvn idea:idea
复制<br>配置清除<br>
清除所有 Eclipse 的工程配置文件：<br>mvn eclipse:clean
复制<br>清除所有 Idea 的工程配置文件：<br>mvn idea:clean
复制<br>其他启动<br>
启动 tomcat 服务<br>mvn tomcat: run  
复制<br><br><br>主要有两个常用内置属性：${basedir}&nbsp;项目的根目录 (包含 pom.xml 文件的目录)，${version}&nbsp;项目版本<br>#用户可以使用该属性引用POM文件中对应元素的值，常用的POM属性包括：
${project.build.sourceDirectory}：项目的主源码目录，默认为 src/main/java
${project.build.testSourceDirectory}：项目的测试源码目录，默认为 src/test/java
${project.build.directory}：项目构件输出目录，默认为 target/
${project.outputDirectory}：项目主代码编译输出目录，默认为 target/classes/
${project.testOutputDirectory}：项目测试代码编译输出目录，默认为 target/test-classes/
${project.groupId}：项目的 groupId
${project.artifactId}：项目的 artifactId
${project.version}：项目的 version，与${version}等价
${project.build.fianlName}：项目打包输出文件的名称。默认为${project.artifactId}-${project.version}

#获取环境变量属性，所有环境变量都可以使用以env.开头的Maven属性引用
${env.xxx}：获取系统环境变量；

#获取Settings属性，用户使用settings.开头的属性引用 settings.xml 文件中XML元素的值
${settings.xxx}：获取settings.xml中对应元素的值；
复制<br><br>使用 &lt;properties&gt; 定义、使用 ${变量名} 引用。<br>样例：<br>&lt;project&gt;
    ...
    &lt;properties&gt;
		&lt;junit.version&gt;3.8.1&lt;/junit.version&gt;
	&lt;/properties&gt;

	&lt;dependencies&gt;
		&lt;dependency&gt;
			&lt;groupId&gt;junit&lt;/groupId&gt;
			&lt;artifactId&gt;junit&lt;/artifactId&gt;
			&lt;version&gt;${junit.version}&lt;/version&gt;
			&lt;scope&gt;test&lt;/scope&gt;
		&lt;/dependency&gt;
	&lt;/dependencies&gt;
    ...
&lt;/project&gt;
复制<br><br>设置<br>&lt;！--创建多环境--&gt;
&lt;profiles&gt;
	&lt;!--定义具体的环境：生产环境--&gt;
	&lt;profile&gt;
		&lt;!--定义环境对应的唯一名称--&gt;
		&lt;id&gt;pro_env&lt;/id&gt;
		&lt;!--定义环境中专用的属性值--&gt;
		&lt;properties&gt;
			&lt;jdbc.url&gt;jdbc:mysql://127.1.1.1:3306/ssm_db&lt;/jdbc.url&gt;
		&lt;/properties&gt;
		&lt;!--设置默认启动--&gt;
		&lt;activation&gt;
			&lt;activeByDefault&gt;true&lt;/activeByDefault&gt;
		&lt;/activation&gt;
	&lt;/profile&gt;
	
	&lt;!--定义具体的环境：开发环境--&gt;
	&lt;profile&gt;
		&lt;id&gt;dev_env&lt;/id&gt;
	&lt;/profile&gt;
&lt;/profiles&gt;
复制<br>执行<br>mvn 指令 -P 环境定义id
#如：
mvn install -P pro_env
复制]]></description><link>11、常用工具\maven\01、maven-基础.html</link><guid isPermaLink="false">11、常用工具/maven/01、Maven 基础.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Sat, 30 Mar 2024 07:40:23 GMT</pubDate><enclosure url="11、常用工具\maven\assets\01、maven-基础\img-20240330_101404.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;11、常用工具\maven\assets\01、maven-基础\img-20240330_101404.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[02、Maven 实战]]></title><description><![CDATA[ 
 <br><br>配置 maven 目录、配置、仓库地址：<br><img src="\11、常用工具\maven\assets\01、maven-基础\img-20240330_104040.png"><br><br><br><br><br><br><br>]]></description><link>11、常用工具\maven\02、maven-实战.html</link><guid isPermaLink="false">11、常用工具/maven/02、Maven 实战.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Sat, 30 Mar 2024 07:41:59 GMT</pubDate><enclosure url="11、常用工具\maven\assets\01、maven-基础\img-20240330_104040.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;11、常用工具\maven\assets\01、maven-基础\img-20240330_104040.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[03、Nexus 私服搭建]]></title><description><![CDATA[ 
 <br><br><br>加速下载速度<br>方便公共使用<br>提高maven稳定性，中央仓库需要连外网才能访问，私服只需要连内网就可以访问。<br><br>Apache 基金会的 archiva：Archiva – The Build Artifact Repository Manager<br>JFrog 的 Artifactory：Artifactory - Universal Artifact Repository Manager - JFrog<br>Sonatype 的 Nexus：My Sonatype | Customer Platform<br>推荐使用 Nexus<br><br>注意：nexus是java开发，所以需要j保证电脑安装了java环境。<br><br>下载地址：<a data-tooltip-position="top" aria-label="https://help.sonatype.com/repomanager3/product-information/download" rel="noopener" class="external-link" title="Download" href="https://help.sonatype.com/repomanager3/product-information/download" target="_blank">Download</a><br>根据环境选择下载：<br><img src="\11、常用工具\maven\assets\03、nexus-私服搭建\img-20240330_110149.png"><br>&nbsp;解压后文件夹后进入bin目录<br>&nbsp;<br>&gt; D:\App\nexus-3.55.0-01-win64\nexus-3.55.0-01\bin&gt;nexus.exe /run
复制<br>右上角登录：<br>用户名：admin（默认）<br>
密码：第一次启动时生成，(在/sonatype-work/nexus3/admin.password&nbsp;文件中)&nbsp;&nbsp;<br>
登录之后可以进行一些修改密码等指引操作。<br>maven仓库既可以从中央仓库拉取依赖，也可以将本地依赖直接发到nexus中，那么就少不了maven中的仓库<br><img src="\11、常用工具\maven\assets\03、nexus-私服搭建\img-20240330_110301.png"><br><br><br>代理仓库主要是让用户通过代理仓库访问外部第三方仓库，如maven中央仓库、阿里的maven仓库。<br>
代理仓库会从被代理的仓库（maven中央仓库、阿里的maven仓库）中下载依赖，缓存在代理仓库中以便让maven用户使用。<br><br>宿主仓库主要是供给自己使用：<br>1、将私有的一些构建通过网页的方式上传到宿主仓库中供大家使用。<br>
2、将自己开发好的一些构建发布到nexus的宿主仓库中供大家使用<br><br>仓库组既然是“组”的概念，说明它里面可以包含多个仓库。<br>因为 maven 用户可以从代理仓库和宿主仓库中下载构建至本地仓库，为了方便从代理仓库和宿主仓库下载构建，maven 提供了仓库组。<br>仓库组可以包含多个宿主仓库和代理仓库，maven 用户访问一个仓库组就可以访问该仓库下的所有仓库。<br>仓库组中的多个仓库是有顺序的，当 maven 用户从仓库组中下载构建时，会按顺序在仓库组中查找组件，查到了就返回给本地仓库，所以一般将速度快的放前面。<br>仓库组内部实际是没有内容的，只是起到一个请求转发的作用，将 maven 用户的下载请求转发给其它仓库处理。<br>Nexus 默认有仓库组 maven-public<br><br>Nexus 预定义了 2 个本地仓库，分别是 maven-releases, maven-snapshots。<br>Maven-releases：这里存放我们自己项目中发布的构建，通常是 Release 版本的，也就是正式版。<br>
Maven-snapshots：这个仓库非常的有用，它的目的是让我们可以发布那些非 release 版本，非稳定版本，也就是快照版。<br><br>一）xml 配置<br>在 setting.xml 文件中配置账号密码：<br>&lt;server&gt;
	&lt;id&gt;maven-nexus&lt;/id&gt;
	&lt;!-- username 和 password 是自己在 nexus 中配置的。--&gt;
	&lt;username&gt;admin&lt;/username&gt;
	&lt;password&gt;1e1e7335-e723-441b-9876-a986b53e4130&lt;/password&gt;
&lt;/server&gt;
复制<br>二）pom 配置<br>  &lt;repositories&gt;
    &lt;repository&gt;
      &lt;id&gt;maven-nexus&lt;/id&gt;
      &lt;url&gt;http://localhost:8081/repository/maven-public/&lt;/url&gt;
      &lt;releases&gt;
        &lt;enabled&gt;true&lt;/enabled&gt;
      &lt;/releases&gt;
      &lt;snapshots&gt;
        &lt;enabled&gt;false&lt;/enabled&gt;
      &lt;/snapshots&gt;
    &lt;/repository&gt;
  &lt;/repositories&gt;
 
  &lt;!--该配置是为了防止pom中的jar包从私服下载之后，但是执行mvn中从插件还是从中央仓库中下载--&gt;
  &lt;pluginRepositories&gt;
    &lt;pluginRepository&gt;
      &lt;id&gt;maven-nexus&lt;/id&gt;
      &lt;url&gt;http://localhost:8081/repository/maven-public/&lt;/url&gt;
    &lt;/pluginRepository&gt;
  &lt;/pluginRepositories&gt;
复制<br>
注意：pom.xml  中的 &lt;id&gt; 需要和 setting.xml 文件中配置的一致。
<br><br><a rel="noopener" class="external-link" href="https://blog.csdn.net/qq_50652600/article/details/131066029" target="_blank">https://blog.csdn.net/qq_50652600/article/details/131066029</a><br><a rel="noopener" class="external-link" href="https://blog.csdn.net/GoodburghCottage/article/details/129132394" target="_blank">https://blog.csdn.net/GoodburghCottage/article/details/129132394</a><br><a rel="noopener" class="external-link" href="https://blog.csdn.net/GoodburghCottage/article/details/129132394" target="_blank">https://blog.csdn.net/GoodburghCottage/article/details/129132394</a>]]></description><link>11、常用工具\maven\03、nexus-私服搭建.html</link><guid isPermaLink="false">11、常用工具/maven/03、Nexus 私服搭建.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Sat, 30 Mar 2024 07:13:15 GMT</pubDate><enclosure url="11、常用工具\maven\assets\03、nexus-私服搭建\img-20240330_110149.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;11、常用工具\maven\assets\03、nexus-私服搭建\img-20240330_110149.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[04、Maven 高频插件使用详解]]></title><description><![CDATA[ 
 ]]></description><link>11、常用工具\maven\04、maven-高频插件使用详解.html</link><guid isPermaLink="false">11、常用工具/maven/04、Maven 高频插件使用详解.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Sat, 30 Mar 2024 07:42:47 GMT</pubDate></item><item><title><![CDATA[100、★ Maven 面试题汇总 ★]]></title><description><![CDATA[ 
 <br><br>1）compile: 编译依赖，默认的依赖方式，在编译（编译项目和编译测试用例），运行测试用例，运行（项目实际运行）三个阶段都有效，典型地有 spring-core 等 jar。<br>
2）test: 测试依赖，只在编译测试用例和运行测试用例有效，典型地有 JUnit。<br>
3）provided: 对于编译和测试有效，不会打包进发布包中，典型的例子为 servlet-api, 一般的 web 工程运行时都使用容器的 servlet-api。<br>
4）runtime: 只在运行测试用例和实际运行时有效，典型地是 jdbc 驱动 jar 包。<br>
5）system: 不从 maven 仓库获取该 jar, 而是通过 systemPath 指定该 jar 的路径。<br>
6）import: 用于一个 dependencyManagement 对另一个 dependencyManagement 的继承。<br><br>仓库分为两类：本地仓库和远程仓库。<br>
远程仓库： <br>
<br>中央
<br>镜像
<br>私有
<br><br>原则：<br>
1、依赖路径最短优先原则<br>
2、声明顺序优先原则<br><br>使用 mvn dependency:tree 查看依赖树，或者安装 IDEA 插件查看，根据依赖原则来调整依赖在 POM 文件的声明顺序。<br>1、execlude 掉<br>
2、如果自己维护公共的项目，可以使用设置 optional 为 true。<br><br>三大生命周期<br>
<br>默认(Default Lifeclyle): 该生命周期表示这项目的构建过程，定义了一个项目的构建要经过的不同的阶段。
<br>清理(Clean Lifecycle): 该生命周期负责清理项目中的多余信息，保持项目资源和代码的整洁性。一般拿来清空directory(即一般的target)目录下的文件。
<br>站点管理(Site Lifecycle) : 不经常使用
<br>默认生命周期<br>
<br>Compile：编译
<br>Test：测试
<br>Package：打包
<br>Install：安装本地仓库
<br>Deploy：发布
<br><br>宿主仓库：hosted repository<br>
代理仓库：proxy repository<br>
仓库组：group repository<br><br>install、clean、compile、deploy]]></description><link>11、常用工具\maven\100、★-maven-面试题汇总-★.html</link><guid isPermaLink="false">11、常用工具/maven/100、★ Maven 面试题汇总 ★.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Sat, 30 Mar 2024 12:39:03 GMT</pubDate></item><item><title><![CDATA[面试题汇总]]></title><description><![CDATA[ 
 <br><br>因是面试题，所以下面将按照简历技能顺序。<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>]]></description><link>index.html</link><guid isPermaLink="false">INDEX.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Sat, 30 Mar 2024 12:35:22 GMT</pubDate></item><item><title><![CDATA[README]]></title><description><![CDATA[<a class="tag" href="?query=tag:Python" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#Python</a> 
 <br><br>记录关于自己的 Java 知识体系。<br><br><br>使用&nbsp;#&nbsp;表示。一级标题是一个&nbsp;#，二级标题是两个&nbsp;#，依此类推，最多到六级标题。<br>Markdown<br>复制<br># 一级标题
## 二级标题
### 三级标题
#### 四级标题
##### 五级标题
###### 六级标题
复制<br><br>
<br>斜体：使用一个星号 *  或下划线 _ 包裹文字，例如：斜体&nbsp;或&nbsp; 斜体 
<br>粗体：使用两个星号 ** 或下划线 __ 包裹文字，例如：粗体&nbsp;或&nbsp; 粗体 
<br>粗斜体：使用三个星号 *** 或下划线  ___ 包裹文字，例如：粗斜体&nbsp;或&nbsp; 粗斜体 
<br>删除线：使用两个波浪线 ~~ 包裹文字，例如：删除线
<br>代码：使用反引号 `` 包裹文字，例如： 代码
<br><br>
<br>
无序列表使用星号 *、加号 + 或减号 - 作为列表标记：  
* 项目1
* 项目2
* 项目3
复制

<br> 有序列表使用数字和一个点 (.)：<br>
    1. 项目1     2. 项目2     3. 项目3    <br>
<br>
列表嵌套：在一个列表项中开始另一个列表来创建嵌套的列表。
1. 项目1
   - 子项目1
   - 子项目2
2. 项目2
   - 子项目1
   - 子项目2
复制

<br><br>
<br>链接：[链接文字](链接地址)
<br>图片：![替代文字](图片地址)
<br>链接：<br>[Google](https://www.google.com)
复制<br>图片：<br>#通用
![image](assets/README/img-20231127_202841.png)
复制<br>调整图片大小：<br>#指定宽高
![image|500x560](assets/README/img-20231127_202841.png)
#指定宽度，图片按照宽度缩放，注意等比缩放
![image|560](assets/README/img-20231127_202841.png)
复制<br><br>引用使用大于符号 (&gt;)：<br>&gt; 这是一个引用。
复制<br>引用可以被嵌套：<br>&gt; 这是第一层引用。
&gt;
&gt;&gt; 这是第二层引用。
复制<br><br>在 Markdown 中，你可以使用反引号 (` ) 来格式化代码。<br>这里反引号 (` )  可以使用 1-3 个，用在不同场景：<br>1、单反引号<br>
对于内联代码，你可以使用单个反引号。例如：<br>这是一个 `内联代码` 示例。
复制<br>这是一个 内联代码 示例。<br>2、双反引号<br>如果你要表示为代码的单词或短语中包含一个或多个反引号，则可以通过将单词或短语包裹在双反引号  (` `  ) 中。例如：<br> ``假如我有 包含`单引号` 的语句需要显示。``
复制<br> 假如我有 包含`单引号` 的语句需要显示。<br>3、三反应号<br>
对于代码块，你可以使用三个反引号。也可以在开头的三个反引号后面添加语言标识符，以启用语法高亮。<br>
例如：<br>```python
def hello_world():
    print("Hello, world!")
```
复制<br><br>| 表头 | 表头 |
| ---- | ---- |
| 内容 | 内容 |
| 内容 | 内容 |
复制<br><br>可以在一行中使用三个或更多的星号 (*)、减号 (-) 或下划线 (_) 来添加分隔线：<br>***
---
___
复制<br><br><br><br><br>使用反斜杠 (\) 转义特殊字符：<br>\*这个星号会被解析成文字，而不是斜体\*
复制<br><br>你可以在 Markdown 文档中直接使用 HTML。<br>&lt;div style="text-align:center"&gt;这是一段居中的文本。&lt;/div&gt;
复制<br><br>可以创建链接到同一文档的其他部分的锚点。<br>[回到顶部](#标题)
复制<br><br>这是一段带有多个脚注的文本[^1][^2]。

[^1]: 这是第一个脚注的内容。

[^2]: 这是第二个脚注的内容。
    它实际上包含了两行。
复制<br>在这个例子中，[^1]&nbsp;是对脚注的引用，[^1]: 这是脚注的内容。&nbsp;<br>
标识符可以是数字或单词，但不能包含空格或制表符。标识符仅将脚注参考与脚注本身相关联-在输出中，脚注按顺序编号。<br>
脚注代号可以随便命名，不过推荐使用数字序号。脚注代号+∶+空格＋脚注内容<br>这是一段带有多个脚注的文本<a href="\#fn-1-33dbe2937a530ff5" class="footnote-link" target="_self" rel="noopener">[1]</a>内容<a href="\#fn-2-33dbe2937a530ff5" class="footnote-link" target="_self" rel="noopener">[2]</a>。<br><br><br><br>可以通过&nbsp;- [ ]&nbsp;来创建一个未完成的任务，通过&nbsp;- [x]&nbsp;来创建一个已完成的任务。例如：<br>- [ ] 这是一个未完成的任务。
- [x] 这是一个已完成的任务。
复制<br>
<br>这是一个未完成的任务。
<br>这是一个已完成的任务。
<br><br><br>和基本语法功能类似，只不过换了标志，对比： <a class="internal-link" data-href="README.md#▶ 链接 &amp; 图片" href="\readme.html#▶_链接_&amp;_图片" target="_self" rel="noopener">▶ 链接 &amp; 图片</a><br>Obsidian 通过使用双方括号&nbsp;[[ ]]&nbsp;实现的。<br>
<br>链接：[[]]
<br>图片：`![[]]
<br>链接：<br>查看我的笔记 [[My Note]]。
复制<br>| 指定显示的文本<br>
#  可以链接到标题输入<br>
^ 链接文本块输入<br>当你点击这个链接时，Obsidian 将会打开 "工具使用" 这个笔记的“主题设置”这一章。<br>
如下： <a data-tooltip-position="top" aria-label="0、提升基础/01、工具使用 > ❈　主题和自定义风格" data-href="0、提升基础/01、工具使用#❈　主题和自定义风格" href="\0、提升基础\01、工具使用#❈　主题和自定义风格" class="internal-link" target="_self" rel="noopener">主题设置</a><br>文本块引用：<br>Obsidian 支持跨文件的块引用。你可以通过对特定文本块的引用，来在另一个文件中引用这个块。 <br>首先，你需要在你想要引用的块后面添加一个&nbsp;^&nbsp;和一个标识符。例如： <br>这是我想引用的文本块。^ab12cd
复制<br>然后，在另一个文件中，你可以通过以下方式引用这个块：<br>这是我对 [[My Note#^ab12cd]] 的引用。
复制<br>这将会创建一个到 "My Note" 笔记中 "block 1" 块的链接。<br>按照 ctrl 鼠标悬浮可以显示内容：<a data-tooltip-position="top" aria-label="README > ^c512d8" data-href="README#^c512d8" href="\readme.html#^c512d8" class="internal-link" target="_self" rel="noopener">测试引用块</a><br>嵌入笔记：<br>你可以在一个笔记中嵌入另一个笔记的内容。这是通过在链接前加上一个感叹号&nbsp;!&nbsp;实现的。例如：<br>这是嵌入的笔记内容：![[My Note]]
复制<br>这将会在当前笔记中显示 "My Note" 这个笔记的所有内容。<br>如果文件不存在会提示：<br>
"MyNote.md" 未创建，点击以创建。<br>图片：<br>#obsidian专有语法
![[assets/README/img-20231127_202841.png]]
复制<br>调整图片大小：<br>#指定宽高
![[assets/README/img-20231127_202841.png | 500x800]]
#指定宽度，图片按照宽度缩放
![[assets/README/img-20231127_202841.png| 500]]        
复制<br><br>你可以使用&nbsp;#&nbsp;符号创建标签，这可以帮助你对你的笔记进行分类和搜索。例如：<br>这是一些关于 #Python 的笔记。
复制<br>这将会给这个笔记添加一个 "Python" 的标签。<br>效果如下：<br>
这是一些关于 <a href=".?query=tag:Python" class="tag" target="_blank" rel="noopener">#Python</a> 的笔记。<br><br>Obaidian 0.14.2 版本后增加了 Callout 功能，这个功能就是之前 Admonition (简称 ad 插件)插件收编的，目前语法跟 MicrosoftDocs 一致。之前用 ad 插件设置的提示框可以一键转换成最新的语法样式。<br>
在笔记中直接书写 (无需代码块)如下内容:<br>&gt;[!规定的标记]
&gt;[!规定的标记] 标题内容
&gt;[!规定的标记] 标题内容
&gt;笔记内容，你会发现和 markdown 中的引用是相同的语法&gt;
&gt;比如分段也是这样空一行

规定的标记类型会根据你输入而提示

复制<br>  测试 note
这是一条 note
<br>Admonition  也可以单独使用，参照：<a class="internal-link" data-href="0、提升基础/01、工具使用.md#○ 警告块" href="\0、提升基础\01、工具使用.md#○ 警告块" target="_self" rel="noopener">○ 警告块</a><br><br>#前面需要加入http

&lt;iframe src="http://player.bilibili.com/player.html?aid=959026749&amp;bvid=BV1wp4y1c7jp&amp;cid=1282492890&amp;p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"&gt; &lt;/iframe&gt;
复制<br><br>%%这是一段注释内容%%
&lt;!--这里也是一行注释--&gt;
复制<br>看不见的注释内容：<br>
<br><br><br>==Text==
复制Dataview (inline field '=Text=='): Error: 
-- PARSING FAILED --------------------------------------------------

&gt; 1 | =Text==
    | ^

Expected one of the following: 

'(', 'null', boolean, date, duration, file link, list ('[1, 2, 3]'), negated field, number, object ('{ a: 1, b: 2 }'), string, variable
<br>Text Highlights<br><br><br>1、数字序号的级别顺序为：<br><br>2、文稿的层次序号：<br>文稿的层次序号分理科与人文两种。在实际应用的过程中，一般都不超过四级。<br>
理科类一律用阿拉伯数字连续编号，人文类一般沿用公文层次序号。<br><br><br><br><br><br>每次在写 md 文档时，总是会花大量时间去考虑笔记的排版问题。<br>
其实更应该将经历注重在学习和记录总结知识方面。因此特定此文档为今后的文档做出规范。加新文档时可直接复制。<br>Markdown 中因为 1. 就是一个序号，所以这边使用 1、来代替。<br>
并且由于笔记原因，层次结构复杂：<br>
以及标题默认为文件名称<br>
所以这里层级可以延伸至<br>即：<br>一级标题：最好和文档名称文字保持一致，如果有多个一级 ★ 一级标题 ★<br>
二级标题：无序的使用符号：▷　，如果需要数字标题使用     一、二、三、四、<br>
三级标题：无序的使用符号：▶　，如果需要数字标题使用     一）二） 三）四）<br>
四级标题：无序的使用符号：❈　，如果需要数字标题使用     1、 2、3、4、<br>
五级标题：无序的使用符号：○　，如果需要数字标题使用     1）2）3）4） 或  ① ② ③ ④ ⑤ ⑥ ⑦ ⑧ ⑨<br>
六级标题：无序的使用符号：●　，如果需要数字标题使用    ❶ ❷ ❸ ❹ ❺ ❻ ❼ ❽ ❾ ❿, 其中需要加空格<br>如果不是大类，三级标题转四，也不算违规，一） 变成 1、，更便于阅读，但目前而言，这种情况是极少数的。<br>
因为 markdown 只支持到 6 级标题。<br>6 级以下：<br>
七级标题：  A.  B. C.    或   (A) (B) (C)<br>
七级标题：  a.  b.  c.    或   (a) (b) (c)<br>如果标题较少，并且无序，不管几级标题也可忽略符号，方便查阅，避免目录全是符号。<br>同时尽量少用标题，虽然可以生成目录头，但是有些没有明显意义的不需要标题，但是加粗加上符号阅读时方便即可。<br>以下是样例代码：<br>#### 1、测试四级标题
####  ❈　测试四级标题

##### ① 测试五级标题

##### ○　测试五级标题

###### ❶ 测试六级标题
###### ●　测试六级标题
复制<br><br>附件统一存放位置：./assets/${filename}<br>
图片命名规范: Img-YYYYMMDD_HHmmss<br>
图片格式最好为：. PNG 这种支持高清方式<br>文章内所有链接统一使用标准 markdown 格式，防止使用 typora 使连接失效。<br>
如果已经有 obisidian 的链接了，单文件可以直接选中已有文件，只要设置对了会自动变成 markdown 的原本格式。<br>
<br>
<br>这是第一个脚注的内容。<a href="\#fnref-1-33dbe2937a530ff5" class="footnote-backref footnote-link" target="_self" rel="noopener">↩︎</a>
<br>这是第二个脚注的内容。<a href="\#fnref-2-33dbe2937a530ff5" class="footnote-backref footnote-link" target="_self" rel="noopener">↩︎</a>
]]></description><link>readme.html</link><guid isPermaLink="false">README.md</guid><dc:creator><![CDATA[kegh]]></dc:creator><pubDate>Sat, 30 Mar 2024 08:45:27 GMT</pubDate></item></channel></rss>